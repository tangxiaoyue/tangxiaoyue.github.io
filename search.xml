<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[Docker高级（1）--架构总览]]></title>
      <url>%2F2017%2F03%2F12%2FDocker%E9%AB%98%E7%BA%A7%EF%BC%881%EF%BC%89--%E6%9E%B6%E6%9E%84%E6%80%BB%E8%A7%88%2F</url>
      <content type="text"><![CDATA[背景Docker简介&#8194;&#8194;&#8194;&#8194;Docker是Docker公司开源的一个基于轻量级虚拟化技术的容器引擎项目,整个项目基于Go语言开发，并遵从Apache 2.0协议。 &#8194;&#8194;&#8194;&#8194;目前，Docker可以在容器内部快速自动化部署应用，并可以通过内核虚拟化技术（namespaces及cgroups等）来提供容器的资源隔离与安全保障等。由于Docker通过操作系统层的虚拟化实现隔离，所以Docker容器在运行时，不需要类似虚拟机（VM）额外的操作系统开销，提高资源利用率，并且提升诸如IO等方面的性能。&#8194;&#8194;&#8194;&#8194;由于众多新颖的特性以及项目本身的开放性，Docker在不到两年的时间里迅速获得诸多厂商的青睐，其中更是包括Google、Microsoft、VMware等业界行业领导者。Google在今年六月份推出了Kubernetes，提供Docker容器的调度服务，而今年8月Microsoft宣布Azure上支持Kubernetes，随后传统虚拟化巨头VMware宣布与Docker强强合作。今年9月中旬，Docker更是获得4000万美元的C轮融资，以推动分布式应用方面的发展。&#8194;&#8194;&#8194;&#8194;从目前的形势来看，Docker的前景一片大好。本系列文章从源码的角度出发，详细介绍Docker的架构、Docker的运行以及Docker的卓越特性。本文是Docker源码分析系列的第一篇­­­——Docker架构篇。 Docker版本信息&#8194;&#8194;&#8194;&#8194;本文关于Docker架构的分析都是基于Docker的源码与Docker相应版本的运行结果，其中Docker为最新的1.2版本。 Docker架构分析内容安排&#8194;&#8194;&#8194;&#8194;本文的目的是：在理解Docker源代码的基础上，分析Docker架构。分析过程中主要按照以下三个步骤进行： ● Docker的总架构图展示 ● Docker架构图内部各模块功能与实现分析 ● 以Docker命令的执行为例，进行Docker运行流程阐述 Docker总架构图&#8194;&#8194;&#8194;&#8194;学习Docker的源码并不是一个枯燥的过程，反而可以从中理解Docker架构的设计原理。Docker对使用者来讲是一个C/S模式的架构，而Docker的后端是一个非常松耦合的架构，模块各司其职，并有机组合，支撑Docker的运行。在此，先附上Docker总架构，如图3.1。&#8194;&#8194;&#8194;&#8194;如图3.1，不难看出，用户是使用Docker Client与Docker Daemon建立通信，并发送请求给后者。&#8194;&#8194;&#8194;&#8194;而Docker Daemon作为Docker架构中的主体部分，首先提供Server的功能使其可以接受Docker Client的请求；而后Engine执行Docker内部的一系列工作，每一项工作都是以一个Job的形式的存在。&#8194;&#8194;&#8194;&#8194;Job的运行过程中，当需要容器镜像时，则从Docker Registry中下载镜像，并通过镜像管理驱动graphdriver将下载镜像以Graph的形式存储；当需要为Docker创建网络环境时，通过网络管理驱动networkdriver创建并配置Docker容器网络环境；当需要限制Docker容器运行资源或执行用户指令等操作时，则通过execdriver来完成。&#8194;&#8194;&#8194;&#8194;而libcontainer是一项独立的容器管理包，networkdriver以及execdriver都是通过libcontainer来实现具体对容器进行的操作。&#8194;&#8194;&#8194;&#8194;当执行完运行容器的命令后，一个实际的Docker容器就处于运行状态，该容器拥有独立的文件系统，独立并且安全的运行环境等。 Docker架构内各模块的功能与实现分析&#8194;&#8194;&#8194;&#8194;接下来，我们将从Docker总架构图入手，抽离出架构内各个模块，并对各个模块进行更为细化的架构分析与功能阐述。主要的模块有：Docker Client、Docker Daemon、Docker Registry、Graph、Driver、libcontainer以及Docker container。 Docker Client&#8194;&#8194;&#8194;&#8194;Docker Client是Docker架构中用户用来和Docker Daemon建立通信的客户端。用户使用的可执行文件为docker，通过docker命令行工具可以发起众多管理container的请求。&#8194;&#8194;&#8194;&#8194;Docker Client可以通过以下三种方式和Docker Daemon建立通信：tcp://host:port，unix://path_to_socket和fd://socketfd。为了简单起见，本文一律使用第一种方式作为讲述两者通信的原型。与此同时，与Docker &#8194;&#8194;&#8194;&#8194;Daemon建立连接并传输请求的时候，Docker Client可以通过设置命令行flag参数的形式设置安全传输层协议(TLS)的有关参数，保证传输的安全性。&#8194;&#8194;&#8194;&#8194;Docker Client发送容器管理请求后，由Docker Daemon接受并处理请求，当Docker Client接收到返回的请求相应并简单处理后，Docker Client一次完整的生命周期就结束了。当需要继续发送容器管理请求时，用户必须再次通过docker可执行文件创建Docker Client。 Docker Daemon&#8194;&#8194;&#8194;&#8194;Docker Daemon是Docker架构中一个常驻在后台的系统进程，功能是：接受并处理Docker Client发送的请求。该守护进程在后台启动了一个Server，Server负责接受Docker &#8194;&#8194;&#8194;&#8194;Client发送的请求；接受请求后，Server通过路由与分发调度，找到相应的Handler来执行请求。&#8194;&#8194;&#8194;&#8194;Docker Daemon启动所使用的可执行文件也为docker，与Docker Client启动所使用的可执行文件docker相同。在docker命令执行时，通过传入的参数来判别Docker Daemon与Docker Client。&#8194;&#8194;&#8194;&#8194;Docker Daemon的架构，大致可以分为以下三部分：Docker Server、Engine和Job。Daemon架构如图4.1。 &#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194; 图4.1 Docker Daemon架构示意图 Docker Server &#8194;&#8194;&#8194;&#8194; Docker Server在Docker架构中是专门服务于Docker Client的server。该server的功能是：接受并调度分发Docker Client发送的请求。Docker Server的架构如图4.2。 &#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194; 图4.2 Docker Server架构示意图 &#8194;&#8194;&#8194;&#8194;在Docker的启动过程中，通过包gorilla/mux，创建了一个mux.Router，提供请求的路由功能。在Golang中，gorilla/mux是一个强大的URL路由器以及调度分发器。该mux.Router中添加了众多的路由项，每一个路由项由HTTP请求方法（PUT、POST、GET或DELETE）、URL、Handler三部分组成。&#8194;&#8194;&#8194;&#8194;若Docker Client通过HTTP的形式访问Docker &#8194;&#8194;&#8194;&#8194;Daemon，创建完mux.Router之后，Docker将Server的监听地址以及mux.Router作为参数，创建一个httpSrv=http.Server{}，最终执行httpSrv.Serve()为请求服务。&#8194;&#8194;&#8194;&#8194;在Server的服务过程中，Server在listener上接受Docker Client的访问请求，并创建一个全新的goroutine来服务该请求。在goroutine中，首先读取请求内容，然后做解析工作，接着找到相应的路由项，随后调用相应的Handler来处理该请求，最后Handler处理完请求之后回复该请求。&#8194;&#8194;&#8194;&#8194;需要注意的是：Docker Server的运行在Docker的启动过程中，是靠一个名为”serveapi”的job的运行来完成的。原则上，Docker Server的运行是众多job中的一个，但是为了强调Docker Server的重要性以及为后续job服务的重要特性，将该”serveapi”的job单独抽离出来分析，理解为Docker Server。 Engine&#8194;&#8194;&#8194;&#8194;Engine是Docker架构中的运行引擎，同时也Docker运行的核心模块。它扮演Docker container存储仓库的角色，并且通过执行job的方式来操纵管理这些容器。&#8194;&#8194;&#8194;&#8194;在Engine数据结构的设计与实现过程中，有一个handler对象。该handler对象存储的都是关于众多特定job的handler处理访问。举例说明，Engine的handler对象中有一项为：{“create”: daemon.ContainerCreate,}，则说明当名为”create”的job在运行时，执行的是daemon.ContainerCreate的handler Job&#8194;&#8194;&#8194;&#8194;一个Job可以认为是Docker架构中Engine内部最基本的工作执行单元。Docker可以做的每一项工作，都可以抽象为一个job。例如：在容器内部运行一个进程，这是一个job；创建一个新的容器，这是一个job，从Internet上下载一个文档，这是一个job；包括之前在Docker Server部分说过的，创建Server服务于HTTP的API，这也是一个job，等等。&#8194;&#8194;&#8194;&#8194;Job的设计者，把Job设计得与Unix进程相仿。比如说：Job有一个名称，有参数，有环境变量，有标准的输入输出，有错误处理，有返回状态等 Docker Registry&#8194;&#8194;&#8194;&#8194;Docker Registry是一个存储容器镜像的仓库。而容器镜像是在容器被创建时，被加载用来初始化容器的文件架构与目录。&#8194;&#8194;&#8194;&#8194;在Docker的运行过程中，Docker Daemon会与Docker Registry通信，并实现搜索镜像、下载镜像、上传镜像三个功能，这三个功能对应的job名称分别为”search”，”pull” 与 “push”。&#8194;&#8194;&#8194;&#8194;其中，在Docker架构中，Docker可以使用公有的Docker Registry，即大家熟知的Docker Hub，如此一来，Docker获取容器镜像文件时，必须通过互联网访问Docker Hub；同时Docker也允许用户构建本地私有的Docker Registry，这样可以保证容器镜像的获取在内网完成 Graph&#8194;&#8194;&#8194;&#8194;Graph在Docker架构中扮演已下载容器镜像的保管者，以及已下载容器镜像之间关系的记录者。一方面，Graph存储着本地具有版本信息的文件系统镜像，另一方面也通过GraphDB记录着所有文件系统镜像彼此之间的关系。Graph的架构如图4.3。&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;图4.3 Graph架构示意图&#8194;&#8194;&#8194;&#8194;其中，GraphDB是一个构建在SQLite之上的小型图数据库，实现了节点的命名以及节点之间关联关系的记录。它仅仅实现了大多数图数据库所拥有的一个小的子集，但是提供了简单的接口表示节点之间的关系。&#8194;&#8194;&#8194;&#8194;同时在Graph的本地目录中，关于每一个的容器镜像，具体存储的信息有：该容器镜像的元数据，容器镜像的大小信息，以及该容器镜像所代表的具体rootfs Driver&#8194;&#8194;&#8194;&#8194;Driver是Docker架构中的驱动模块。通过Driver驱动，Docker可以实现对Docker容器执行环境的定制。由于Docker运行的生命周期中，并非用户所有的操作都是针对Docker容器的管理，另外还有关于Docker运行信息的获取，Graph的存储与记录等。&#8194;&#8194;&#8194;&#8194;因此，为了将Docker容器的管理从Docker Daemon内部业务逻辑中区分开来，设计了Driver层驱动来接管所有这部分请求。&#8194;&#8194;&#8194;&#8194;在Docker Driver的实现中，可以分为以下三类驱动：graphdriver、networkdriver和execdriver。&#8194;&#8194;&#8194;&#8194;graphdriver主要用于完成容器镜像的管理，包括存储与获取。即当用户需要下载指定的容器镜像时，graphdriver将容器镜像存储在本地的指定目录；同时当用户需要使用指定的容器镜像来创建容器的rootfs时，graphdriver从本地镜像存储目录中获取指定的容器镜像。&#8194;&#8194;&#8194;&#8194;在graphdriver的初始化过程之前，有4种文件系统或类文件系统在其内部注册，它们分别是aufs、btrfs、vfs和devmapper。而Docker在初始化之时，通过获取系统环境变量”DOCKER_DRIVER”来提取所使用driver的指定类型。而之后所有的graph操作，都使用该driver来执行。graphdriver的架构如图4.4： &#8194;&#8194;&#8194;&#8194;networkdriver的用途是完成Docker容器网络环境的配置，其中包括Docker启动时为Docker环境创建网桥；Docker容器创建时为其创建专属虚拟网卡设备；以及为Docker容器分配IP、端口并与宿主机做端口映射，设置容器防火墙策略等。networkdriver的架构如图4.5： &#8194;&#8194;&#8194;&#8194;execdriver作为Docker容器的执行驱动，负责创建容器运行命名空间，负责容器资源使用的统计与限制，负责容器内部进程的真正运行等。在execdriver的实现过程中，原先可以使用LXC驱动调用LXC的接口，来操纵容器的配置以及生命周期，而现在execdriver默认使用native驱动，不依赖于LXC。具体体现在Daemon启动过程中加载的ExecDriverflag参数，该参数在配置文件已经被设为”native”。这可以认为是Docker在1.2版本上一个很大的改变，或者说Docker实现跨平台的一个先兆。execdriver架构如图4.6： libcontainer&#8194;&#8194;&#8194;&#8194;libcontainer是Docker架构中一个使用Go语言设计实现的库，设计初衷是希望该库可以不依靠任何依赖，直接访问内核中与容器相关的API。正是由于libcontainer的存在，Docker可以直接调用libcontainer，而最终操纵容器的namespace、cgroups、apparmor、网络设备以及防火墙规则等。这一系列操作的完成都不需要依赖LXC或者其他包。libcontainer架构如图4.7 &#8194;&#8194;&#8194;&#8194;另外，libcontainer提供了一整套标准的接口来满足上层对容器管理的需求。或者说，libcontainer屏蔽了Docker上层对容器的直接管理。又由于libcontainer使用Go这种跨平台的语言开发实现，且本身又可以被上层多种不同的编程语言访问，因此很难说，未来的Docker就一定会紧紧地和Linux捆绑在一起。而于此同时，Microsoft在其著名云计算平台Azure中，也添加了对Docker的支持，可见Docker的开放程度与业界的火热度。&#8194;&#8194;&#8194;&#8194;暂不谈Docker，由于libcontainer的功能以及其本身与系统的松耦合特性，很有可能会在其他以容器为原型的平台出现，同时也很有可能催生出云计算领域全新的项目。 Docker container&#8194;&#8194;&#8194;&#8194;Docker container（Docker容器）是Docker架构中服务交付的最终体现形式。Docker按照用户的需求与指令，订制相应的Docker容器： ● 用户通过指定容器镜像，使得Docker容器可以自定义rootfs等文件系统； ● 用户通过指定计算资源的配额，使得Docker容器使用指定的计算资源； ● 用户通过配置网络及其安全策略，使得Docker容器拥有独立且安全的网络环境； ● 用户通过指定运行的命令，使得Docker容器执行指定的工作。Docker容器示意图如图4.8： Docker运行案例分析上一章节着重于Docker架构中各个部分的介绍。本章的内容，将以串联Docker各模块来简要分析，分析原型为Docker中的docker pull与docker run两个命令。 docker pull&#8194;&#8194;&#8194;&amp;#8194docker pull命令的作用为：从Docker Registry中下载指定的容器镜像，并存储在本地的Graph中，以备后续创建Docker容器时的使用。docker pull命令执行流程如图5.1。 如图，图中标记的红色箭头表示docker pull命令在发起后，Docker所做的一系列运行。以下逐一分析这些步骤。(1) Docker Client接受docker pull命令，解析完请求以及收集完请求参数之后，发送一个HTTP请求给Docker Server，HTTP请求方法为POST，请求URL为”/images/create? “+”xxx”；(2) Docker Server接受以上HTTP请求，并交给mux.Router，mux.Router通过URL以及请求方法来确定执行该请求的具体handler；(3) mux.Router将请求路由分发至相应的handler，具体为PostImagesCreate；(4) 在PostImageCreate这个handler之中，一个名为”pull”的job被创建，并开始执行；(5) 名为”pull”的job在执行过程中，执行pullRepository操作，即从Docker Registry中下载相应的一个或者多个image；(6) 名为”pull”的job将下载的image交给graphdriver；(7) graphdriver负责将image进行存储，一方创建graph对象，另一方面在GraphDB中记录image之间的关系。 docker run&#8194;&#8194;&#8194;docker run命令的作用是在一个全新的Docker容器内部运行一条指令。Docker在执行这条命令的时候，所做工作可以分为两部分：第一，创建Docker容器所需的rootfs；第二，创建容器的网络等运行环境，并真正运行用户指令。因此，在整个执行流程中，Docker Client给Docker Server发送了两次HTTP请求，第二次请求的发起取决于第一次请求的返回状态。Docker run命令执行流程如图5.2。如图，图中标记的红色箭头表示docker run命令在发起后，Docker所做的一系列运行。以下逐一分析这些步骤。(1) Docker Client接受docker run命令，解析完请求以及收集完请求参数之后，发送一个HTTP请求给Docker Server，HTTP请求方法为POST，请求URL为”/containers/create? “+”xxx”；(2) Docker Server接受以上HTTP请求，并交给mux.Router，mux.Router通过URL以及请求方法来确定执行该请求的具体handler；(3) mux.Router将请求路由分发至相应的handler，具体为PostContainersCreate；(4) 在PostImageCreate这个handler之中，一个名为”create”的job被创建，并开始让该job运行；(5) 名为”create”的job在运行过程中，执行Container.Create操作，该操作需要获取容器镜像来为Docker容器创建rootfs，即调用graphdriver；(6) graphdriver从Graph中获取创建Docker容器rootfs所需要的所有的镜像；(7) graphdriver将rootfs所有镜像，加载安装至Docker容器指定的文件目录下；(8) 若以上操作全部正常执行，没有返回错误或异常，则Docker Client收到Docker Server返回状态之后，发起第二次HTTP请求。请求方法为”POST”，请求URL为”/containers/“+container_ID+”/start”；(9) Docker Server接受以上HTTP请求，并交给mux.Router，mux.Router通过URL以及请求方法来确定执行该请求的具体handler；(10)mux.Router将请求路由分发至相应的handler，具体为PostContainersStart；(11)在PostContainersStart这个handler之中，名为”start”的job被创建，并开始执行；(12)名为”start”的job执行完初步的配置工作后，开始配置与创建网络环境，调用networkdriver；(13)networkdriver需要为指定的Docker容器创建网络接口设备，并为其分配IP，port，以及设置防火墙规则，相应的操作转交至libcontainer中的netlink包来完成；(14)netlink完成Docker容器的网络环境配置与创建；(15)返回至名为”start”的job，执行完一些辅助性操作后，job开始执行用户指令，调用execdriver；(16)execdriver被调用，初始化Docker容器内部的运行环境，如命名空间，资源控制与隔离，以及用户命令的执行，相应的操作转交至libcontainer来完成；(17)libcontainer被调用，完成Docker容器内部的运行环境初始化，并最终执行用户要求启动的命令。 总结本文从Docker 1.2的源码入手，分析抽象出Docker的架构图，并对该架构图中的各个模块进行功能与实现的分析，最后通过两个docker命令展示了Docker内部的运行。通过对Docker架构的学习，可以全面深化对Docker设计、功能与价值的理解。同时在借助Docker实现用户定制的分布式系统时，也能更好地找到已有平台与Docker较为理想的契合点。另外，熟悉Docker现有架构以及设计思想，也能对云计算PaaS领域带来更多的启发，催生出更多实践与创新。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker 基础（9）--Dockerfile]]></title>
      <url>%2F2017%2F03%2F11%2FDocker%20%E5%9F%BA%E7%A1%80%EF%BC%889%EF%BC%89--Dockerfile%2F</url>
      <content type="text"><![CDATA[使用Dockerfile构建nginxDockerfile是由一行命令和语句组成的 Dockerfile构建步骤： [root@tang /]# mkdir /dockerfile/nginx -p 我们要在nginx目录上自动化创建一个nginx镜像 注意：D需要大写，当我们构建dockerfile的时候，docker默认会在我们当前目录读取一个名为Dockerfile的文件。这时候的D必须大写 [root@tang nginx]# cat Dockerfile # This Dockerfile # My Name is TangXiaoyue # Base image FROM centos # Maintainer MAINTAINE tang 1060336375@qq.com #Commands RUN rpm -ivh http://mirrors.aliyun.com/epel/epel-release-latest-7.noarch.rpm RUN yum install -y nginx &amp;&amp; yum clean all RUN echo &quot;daemon off;&quot; &gt;&gt;/etc/nginx/nginx.conf ADD index.html /usr/share/nginx/html/index.html EXPOSE 80 CMD [&quot;nginx&quot;] #井号代表注释 #Base image 除了注释的第一行，必须是FROM，意思就是我们需要告诉dockerfile基础镜像是什么 #Maintainer 维护信息 #Commands 命令 #ADD index.html 这个文件需要我们在当前目录下有才可以，我们配置我们可以准备好，然后使用ADD命令进行添加或修改 EXPOSE 对外端口号 CMD [“nginx”] 它要启动的命令是nginx （就算是nginx服务） 我们写好dockerfile还需要一个index.html [root@tang nginx]# echo TangXiaoyue &gt;index.html [root@tang nginx]# ll total 8 -rw-r--r-- 1 root root 364 Apr 2 20:50 Dockerfile -rw-r--r-- 1 root root 12 Apr 2 20:52 index.html 使用docker build进行构建 [root@tang ~]# docker build -t nginx_test:v1 /dockerfile/nginx/ [root@tang ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE nginx_test v1 bc69ee414a0f 17 seconds ago 280.7 MB 启动镜像 [root@tang ~]# docker run --name nginx_test -d -p 82:80 nginx_test:v1 7a02c27a0a04d34eec8f858e35848416b95572dbb1f485310caee5c185d2e426 [root@tang ~]# curl 127.0.0.1:82 TangXiaoyue Dockerfile参数解释FROM格式：FROM&lt;image&gt;或FROM&lt;image&gt;:&lt;tag&gt;。 解释：FROM是Dockerfile里的第一条指令（必须是），后面跟有效的镜像名（如果该镜像你的本地仓库没有则会从远程仓库Pull取）。 然后后面的其它指令FROM的镜像中执行。 MAINTAINER格式：MAINTAINER &lt;name&gt; 解释：指定维护者信息。 RUN格式：RUN &lt;command&gt;或 RUN[&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]。 解释：运行命令，命令较长使可以使用\来换行。推荐使用上面数组的格式 CMD格式： CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] 使用 exec 执行，推荐方式； CMD command param1 param2 在 /bin/sh 中执行，提供给需要交互的应用； CMD [&quot;param1&quot;,&quot;param2&quot;] 提供给ENTRYPOINT的默认参数； 解释： CMD指定容器启动是执行的命令，每个Dockerfile只能有一条CMD命令，如果指定了多条，只有最后一条会被执行。 如果你在启动容器的时候也指定的命令，那么会覆盖Dockerfile构建的镜像里面的CMD命令。 ENTRYPOINT格式： ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;,&quot;param2&quot;] ENTRYPOINT command param1 param2（shell中执行）。 解释：和CMD类似都是配置容器启动后执行的命令，并且不可被 docker run 提供的参数覆盖。 每个 Dockerfile 中只能有一个ENTRYPOINT，当指定多个时，只有最后一个起效。 ENTRYPOINT没有CMD的可替换特性，也就是你启动容器的时候增加运行的命令不会覆盖ENTRYPOINT指定的命令。 所以生产实践中我们可以同时使用ENTRYPOINT和CMD， 例如： ENTRYPOINT [&quot;/usr/bin/rethinkdb&quot;] CMD [&quot;--help&quot;] USER格式：USER daemon 解释：指定运行容器时的用户名和UID，后续的RUN指令也会使用这里指定的用户。 EXPOSE格式：EXPOSE&lt;port&gt; [&lt;port&gt;...] 解释：设置Docker容器内部暴露的端口号，如果需要外部访问，还需要启动容器时增加-p或者-P参数进行分配。 ENV格式：ENV&lt;key&gt; &lt;value&gt; ENV &lt;key&gt;=&lt;value&gt; ... 解释：设置环境变量，可以在RUN之前使用，然后RUN命令时调用，容器启动时这些环境变量都会被指定 ADD格式： ADD &lt;src&gt;... &lt;dest&gt; ADD [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;] 解释： 将指定的&lt;src&gt;复制到容器文件系统中的&lt;dest&gt; 所有拷贝到container中的文件和文件夹权限为0755,uid和gid为0 如果文件是可识别的压缩格式，则docker会帮忙解压缩 VOLUME格式：VOLUME [&quot;/data&quot;] 解释：可以将本地文件夹或者其他container的文件夹挂载到container中。 WORKDIR格式：WORKDIR/path/to/workdir 解释：切换目录，为后续的RUN、CMD、ENTRYPOINT 指令配置工作目录。 可以多次切换(相当于cd命令)， 也可以使用多个WORKDIR 指令，后续命令如果参数是相对路径，则会基于之前命令指定的路径。例如: WORKDIR /a WORKDIR b WORKDIR c RUN pwd 则最终路径为 /a/b/c。 ONBUILDONBUILD 指定的命令在构建镜像时并不执行，而是在它的子镜像中执行 ARG格式：ARG&lt;name&gt;[=&lt;default value&gt;] 解释：ARG指定了一个变量在docker build的时候使用， 可以使用--build-arg &lt;varname&gt;=&lt;value&gt;来指定参数的值，不过如果构建的时候不指定就会报错。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker 基础（7）--数据管理]]></title>
      <url>%2F2017%2F03%2F11%2FDocker%20%E5%9F%BA%E7%A1%80%EF%BC%887%EF%BC%89--%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%2F</url>
      <content type="text"><![CDATA[挂载本地目录到容器里[root@tang /]# mkdir /data/docker -p root@tang docker]# mkdir docker_01 [root@tang docker]# docker run -it -h docker_01 --name docker_01 -v /data/docker/docker_01/:/docker_01 centos bash [root@docker_01 /]# cd /docker_01/ [root@docker_01 docker_01]# touch docker_01.txt [root@docker_01 docker_01]# exit exit [root@tang docker]# cd /data/docker/docker_01/ [root@tang docker_01]# ll total 0 -rw-r--r-- 1 root root 0 Apr 3 08:03 docker_01.txt [root@tang docker_01]# cd .. [root@tang docker]# mkdir docker_02 [root@tang docker]# docker run -it -h docker_02 --name docker_02 -v /data/docker/docker_02/:/docker_02 centos bash [root@docker_02 /]# cd /docker_02/ [root@docker_02 docker_02]# mkdir docker_02.txt [root@docker_02 docker_02]# exit exit [root@tang docker]# cd docker_02/ [root@tang docker_02]# ll total 4 drwxr-xr-x 2 root root 4096 Apr 3 08:05 docker_02.txt 提示： -v: 指定挂载目录 : : 前面的为本地目录 : : 后面到为容器里的目录 即使将删除这个容器,文件也不会丢失. 挂载数据卷(多个容器挂载宿主机的同一个目录)[root@tang data]# docker run -it -h docker_03 --name docker_03 --volumes-from docker_01 centos bash [root@docker_03 /]# cd /docker_01/ [root@docker_03 docker_01]# ll total 0 -rw-r--r-- 1 root root 0 Apr 3 00:03 docker_01.txt [root@docker_03 docker_01]# df -h|grep docker_01 /dev/vda1 99G 5.4G 88G 6% /docker_01 [root@docker_03 docker_01]# echo &quot;This is Doceker_3&quot; &gt; /docker_01/3.txt [root@docker_03 docker_01]# ll total 4 -rw-r--r-- 1 root root 18 Apr 3 00:26 3.txt -rw-r--r-- 1 root root 0 Apr 3 00:03 docker_01.txt [root@tang ~]# docker start docker_01 docker_01 [root@tang ~]# docker-enter docker_01 [root@docker_01 ~]# cd /docker_01/ [root@docker_01 docker_01]# ll total 4 -rw-r--r-- 1 root root 18 Apr 3 00:26 3.txt -rw-r--r-- 1 root root 0 Apr 3 00:03 docker_01.txt 自定义数据卷容器[root@tang ~]# docker run -itd -h node --name node -v /data centos bash 056ac10e28855c3d29a94fe552711e6a712a5670e6e9c43c4b79270cbc6b0a0f #这里的/data是容器node的/data目录,而不是宿主机的/data目录 [root@tang ~]# docker-enter node [root@node ~]# touch /data/1 /data/2 /data/3 [root@node ~]# cd /data/ [root@node data]# ll total 0 -rw-r--r-- 1 root root 0 Apr 3 01:00 1 -rw-r--r-- 1 root root 0 Apr 3 01:00 2 -rw-r--r-- 1 root root 0 Apr 3 01:00 3 [root@node data]# exit logout [root@tang ~]# docker run -itd -h node1 --name node1 --volumes-from node centos bash 2965a8f1184a7a1cbd26ef07e4b3d201fa17e5b68a52c619d6292da75c85d117 [root@tang ~]# docker-enter node1 [root@node1 ~]# cd /data/ [root@node1 data]# ll total 0 -rw-r--r-- 1 root root 0 Apr 3 01:00 1 -rw-r--r-- 1 root root 0 Apr 3 01:00 2 -rw-r--r-- 1 root root 0 Apr 3 01:00 3 [root@node1 data]# touch 4 [root@node data]# ll total 0 -rw-r--r-- 1 root root 0 Apr 3 01:00 1 -rw-r--r-- 1 root root 0 Apr 3 01:00 2 -rw-r--r-- 1 root root 0 Apr 3 01:00 3 -rw-r--r-- 1 root root 0 Apr 3 01:02 4 数据卷的备份[root@docker ~]# mkdir /docker_data_backup [root@docker ~]# docker run -itd -h tang --name tang -v /docker_data_backup/:/backup centos bash 250da7a47222e52c5a5d387ff8ce816a72b221ffb8d481739c4c68073507fe [root@docker ~]# docker-enter tang [root@tang ~]# mkdir /data [root@tang ~]# touch /data/{1,2,3,4} [root@tang ~]# tar cvf /backup/data.tar /data/ [root@tang ~]# cd /backup/ [root@tang backup]# ll total 12 -rw-r--r-- 1 root root 10240 Apr 3 01:30 data.tar [root@tang backup]# exit logout [root@docker ~]# cd /docker_data_backup/ [root@docker docker_data_backup]# ll total 12 -rw-r--r-- 1 root root 10240 Apr 3 09:30 data.tar 数据卷的恢复[root@docker ~]# mkdir /docker_data_backup [root@docker ~]# docker run -itd -h tang --name tang -v /docker_data_backup/:/backup centos bash 3728f6b0a6e5b47f904de0474db7d4479f33e87740906e1539eca385c3fab04d [root@docker ~]# docker-enter tang [root@tang ~]# mkdir /tools/ [root@tang ~]# touch /tools/{1,2,3,4} [root@tang ~]# tar zcvf /backup/tools.tar /tools/ /tools/ /tools/1 /tools/2 /tools/3 /tools/4 [root@tang ~]# ll /backup/ total 4 -rw-r--r-- 1 root root 162 Apr 3 02:08 tools.tar [root@tang ~]# exit logout [root@docker ~]# docker run -itd -h tang1 --name tang1 -v /tang1 centos bash 7ec371bb67f136234878771c227c4245a0ccf6c986e8c94a412d6c4111852a2b [root@docker ~]# docker run -itd -h tang2 --name tang2 --volumes-from tang1 -v /docker_data_backup/:/backup centos bash 53e4cea1c45f3c081a6dd95b935f906aa037e6ed2170b6249a913ccd6fb4c119 [root@docker ~]# docker-enter tang2 [root@tang2 ~]# ll /backup/ total 4 -rw-r--r-- 1 root root 162 Apr 3 02:08 tools.tar [root@tang2 tang1]# tar xvf /backup/tools.tar -C /tang1 [root@tang2 tang1]# exit logout [root@docker ~]# docker-enter tang1 [root@tang1 ~]# cd /tang1/ [root@tang1 tang1]# ll total 4 drwxr-xr-x 2 root root 4096 Apr 3 02:07 tools]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker 基础（5）--容器管理]]></title>
      <url>%2F2017%2F03%2F11%2FDocker%20%E5%9F%BA%E7%A1%80%EF%BC%885%EF%BC%89--%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86%2F</url>
      <content type="text"><![CDATA[查看启动的容器[root@tang ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 2f8c14f16e03 centos &quot;/bin/bash&quot; 5 minutes ago Up 2 minutes tang 查看所有的容器(包括启动、停止)[root@tang ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES e5d7ccb9522c centos &quot;/bin/bash&quot; 15 seconds ago Exited (0) 12 seconds ago tang1 2f8c14f16e03 centos &quot;/bin/bash&quot; 3 minutes ago Up 1 seconds tang Exited:表示该容器已经退出。没有启动 创建容器(create、run)、进入容器[root@tang ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE docker.io/centos latest 98d35105a391 2 weeks ago 192.5 MB docker.io/registry latest 047218491f8c 4 weeks ago 33.17 MB [root@tang ~]# docker create -it --name tang_create centos /bin/bash #使用create创建容器 3b316839ea357a3fe47fcae3488d6f491882ecb8c954412c502cbd6dcf9e2478 [root@tang ~]# docker run -it --name tang_run centos /bin/bash #使用run创建容器 [root@b5dbba42703a /]# exit exit 启动停止容器[root@tang ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES [root@tang ~]# docker start tang_run #start启动容器 tang_run [root@tang ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES b5dbba42703a centos &quot;/bin/bash&quot; 4 minutes ago Up 14 seconds tang_run [root@tang ~]# docker stop tang_run #stop停止容器 tang_run [root@tang ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 创建容器,指定容器名[root@tang ~]# docker run -itd -h tang_run --name tang centos /bin/bash 8afe717f82718214056a61e3881552338d5c911d272a80342edec063b5048 -d: 容器退出后不关闭容器. -h:指定主机名 删除容器/镜像[root@tang ~]# docker rm tang #删除容器 [root@tang ~]# docker rm -f tang #强制删除容器，不管是否在运行 [root@tang ~]# docker rm $(docker ps -a -q) #删除所有容器 导出容器(可迁移到其它机器)/导入容器[root@tang ~]# docker export tang &gt;/opt/tang.tar #导出容器 [root@tang ~]# docker rm tang tang [root@tang ~]# cat /opt/tang.tar |docker import - tang #恢复的只是一个镜像，需要通过镜像创建容器 [root@tang ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE tang latest 393d449b1ed4 44 seconds ago 192.5 MB 提示：如果在之前那个容器内创建的文件，导出，导入之后容器内的文件是不变的]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker 基础（6）--仓库管理]]></title>
      <url>%2F2017%2F03%2F11%2FDocker%20%E5%9F%BA%E7%A1%80%EF%BC%886%EF%BC%89--%E4%BB%93%E5%BA%93%E7%AE%A1%E7%90%86%2F</url>
      <content type="text"><![CDATA[Docker的仓库是DockerHub，类似于github，github有一个开源的软件叫gitlab。Docker也有一个开源软件docker registry [root@tang ~]# docker pull registry [root@tang ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE docker.io/centos latest 98d35105a391 2 weeks ago 192.5 MB docker.io/registry latest 047218491f8c 4 weeks ago 33.17 MB 默认占用5000端口，我们查看是否存在5000端口 [root@tang ~]# netstat -lntup | grep 5000 运行容器 [root@tang ~]# docker run -d -p 5000:5000 registry f002089ab95474290853a2a24b86cb0adbb5848c4a468175304b59b27d6e3b0e 提示：docker比较老的版本运行起来就可以运行，1.7之后都不可以]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker 基础（8）--网络管理]]></title>
      <url>%2F2017%2F03%2F11%2FDocker%20%E5%9F%BA%E7%A1%80%EF%BC%888%EF%BC%89--%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%2F</url>
      <content type="text"><![CDATA[Docker四种网络模式第一种网络模式hosthost模式: 使用--net=host指定docker使用的网络实际上和宿主机一样,在容器内看到的网卡ip是宿主机上的ip. [root@docker ~]# docker run -itd -h node1 --name node1 --net=host centos bash 406cdb306f3c350b6f5344048ae25426f1df3f6863162c0b3a91e3dcd48eba [root@docker ~]# ifconfig |awk -F &apos; &apos; &apos;NR==10{print$2}&apos; 172.17.82.185 [root@docker ~]# docker-enter node1 #进去之后修改主机名，因为主机名个宿主机一样，貌似-h也指定不了主机名 [root@node1 ~]# yum install -y net-tools [root@node1 ~]# ifconfig |awk -F &apos; &apos; &apos;NR==10{print$2}&apos; 172.17.82.185 第二种网络模式containercontainer模式: 使用--net=container:container_id/container_name多个容器使用共同的网络,看到的ip是一样的. [root@docker ~]# docker run -itd -h node2 --name node2 --net=container:node1 centos bash #此处不能指定主机名创建，否则失败 /usr/bin/docker-current: Error response from daemon: Conflicting options: hostname and the network mode. See &apos;/usr/bin/docker-current run --help&apos; [root@docker ~]# docker run -itd --name node2 --net=container:node1 centos bash 0fc16c4a055cf0035c1241ba6cce6c5ad0c711f2ef13e0589c3254f19a96b271 [root@docker ~]# docker-enter node2 [root@node2 ~]# yum install -y net-tools [root@node2 ~]# ifconfig |awk -F &apos; &apos; &apos;NR==10{print$2}&apos; #和node1的ip一样，也和宿主机的ip一样（node1使用的是--net=host模式） 172.17.82.185 第三种网络模式nonenone模式: 使用--net=none, 这种模式下,不会配置任何网络 [root@docker ~]# docker run -itd -h node3 --name node3 --net=none centos c1f4bd859566f11517248718a94456066d16ad66748a2c78743881e450d4ca09 [root@docker ~]# docker-enter node3 [root@node3 ~]# ping www.baidu.com ping: www.baidu.com: Name or service not known 第四种网络模式bridgebridge模式: 使用--net=bridge.创建完容器默认为这种网络模式.类似与vmware的nat网络模式. [root@docker ~]# docker run -itd -h node4 --name node4 --net=bridge centos bash fc4f817e741f22615d0cdbab6608877d268ea15be6ba790cae5706d03871ac41 外部访问容器[root@docker ~]# docker run -itd -h node1 --name node1 centos bash 27df97f0e77e745660ee7b9c8b318c64f63e6aa632db3d3b0c44c4e0f4006124 [root@docker ~]# docker-enter node1 [root@node1 ~]# rpm -ivh http://mirrors.aliyun.com/epel/epel-release-latest-7.noarch.rpm [root@node1 ~]# yum install -y nginx [root@docker ~]# docker commit -m &quot;nginx&quot; -a &quot;tang&quot; 27df97f0e77e nginx:v1 #此处仅容器做为镜像，主要是减少以后重复性的工作，不需要新建一个容器在部署nginx [root@docker ~]# docker run -itd -h nginx --name nginx -p 81:80 nginx:v1 bash #-p 端口映射，射到宿主机81端口上 a5dd375e829d05734a935d5f41723841568b543822a64a4ec277480f5f552e41 [root@docker ~]# docker-enter nginx Last login: Mon Apr 3 07:00:51 UTC 2017 [root@nginx ~]# /usr/sbin/nginx [root@nginx ~]# echo &quot;TangXiaoyue&quot; &gt; /usr/share/nginx/html/1.html [root@nginx ~]# curl 127.0.0.1/1.html TangXiaoyue [root@nginx ~]# exit logout [root@docker ~]# curl 127.0.0.1:81/1.html TangXiaoyue 容器互联1.安装mysql [root@docker ~]# docker run --privileged -itd -h node1 --name node1 centos /sbin/init fd547b535ff3af19bf36b219f542864962d60480a8d56836db30c20f079ec43f [root@docker ~]# docker-enter node1 [root@node1 ~]# yum install -y wget [root@node1 ~]# wget http://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpm [root@node1 ~]# rpm -ivh mysql-community-release-el7-5.noarch.rpm [root@node1 ~]# yum install mysql-community-server [root@node1 ~]# systemctl start mysql.service [root@node1 ~]# mysql -uroot &gt;set password for &apos;root&apos;@&apos;localhost&apos; = password(&apos;123456&apos;); 2.制作mysql镜像 [root@docker ~]# docker commit -m &quot;mysql&quot; -a &quot;tang&quot; fd547b535ff3 mysql:v1 sha256:21af416e70b0302163e4aa279118afdd96a0c8590487268a3d26920caf6c5d1a [root@docker ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE mysql v1 21af416e70b0 4 seconds ago 797.3 MB [root@docker ~]# docker run --privileged -itd -h mysql --name mysql mysql:v1 /sbin/init 8d71a34516a2c05a7ea63fde5773785360d1301509d687797eec5ead62a01d55 3.以mysql、nginx镜像分别创建两个容器并端口映射 [root@docker ~]# docker run -itd -h nginx --name nginx -p 10080:80 --link mysql:db nginx:v1 bash 8aea6116f67c9760b8f4d3de08251b28af839b9e2195860ad4b24d54833c286a [root@docker ~]# docker-enter nginx Last login: Mon Apr 3 07:00:51 UTC 2017 [root@nginx ~]# yum install -y telnet [root@nginx ~]# telnet db 3306 Trying 172.18.0.3... Connected to db. Escape character is &apos;^]&apos;. CHost &apos;172.18.0.4&apos; is not allowed to connect to this MySQL serverConnection closed by foreign host. [root@nginx ~]# cat /etc/hosts 172.18.0.3 db mysql mysql 172.18.0.4 nginx 配置网桥(centos7)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker 基础（2）--命令]]></title>
      <url>%2F2017%2F03%2F11%2FDocker%E5%9F%BA%E7%A1%80%EF%BC%882%EF%BC%89--%E5%91%BD%E4%BB%A4%2F</url>
      <content type="text"><![CDATA[安装下载yum install -y docker #下载 systemctl start docker #启动 systemctl enable docker #自启动 镜像操作docker search images #搜索镜像 docker pull images #下载镜像 docker images #查看镜像 docker tag centos6 centos6_x86 #镜像改名 docker save image&gt;/opt/images.tar.gz #导出镜像 docker load&lt;/opt/images.tar.gz #导入镜像 docker load --input /opt/images.tar.gz #导入镜像 docker rmi images_id #删除镜像 docker rmi $(docker images -q) #删除所有镜像 容器操作docker ps -a #查看容器 docker run centos /bin/echo &quot;hehe&quot; #首次创建一个容器 docekr run -h tang --name tang -t -i centos /bin/bah #创建一个以tang为名的容器； --name：指定容器名 -t：分配一个tty终端 -i：容器的标准输出保持打开状态 -h:指定主机名 docker create -it --name centos1 centos #使用create创建容器 docekr stop ID（name） #停止容器 docker start ID（name） #启动容器 docker attach ID（name） #进入容器 docker exec -it ID(name) /bin/bash docker rm ID（name） #删除容器 -f：强制删除容器，包括在运行的 #exec和attach总结: attach登陆容器后,退出时容器会关闭. 推荐使用exec进入容器 docker rm $(docker ps -a -q) #删除所有容器 映射docker run --name nginx -d -P nginx #随机映射 docker run --name nginx -d -p 81:80 nginx #指定映射 docker run -it --name nginx -p 80:80 nginx /bin/bash #指定映射 日志docker logs ID（name） #查看日志 数据管理docker run -it --name tang -v /data centos #默认挂载目录 docekr inspect ID(name) #查看容器信息 ==查看mounts模块 docekr run -it --name tang -v /data:/data centos #指定挂载目录 docker run -it --name tang -v /data:/data:rw centos #指定权限挂载 ==rw：读写 docker run -it --name tang -v /data:/data:ro centos #指定权限挂载 ==ro：只读 docker run -it --name tang ~/.bash_history:/.bash_history centos #记录历史记录 数据卷容器docker run -d --name nfs -v /data:/data centos #启动nfs容器，挂在一个卷， -d：直接在后台执行 docker run -it --name test1 --volumes-from nfs centos #启动test1容器，挂载到nfs的数据卷容器上 docker run -it --name test2 --volumes-from nfs centos #启动test2容器，挂载到nfs的数据卷容器上 #test1和test2的/data数据可以共享 手动制作镜像docker run -it --name mynginx centos #基础centos进行创建容器mynginx 在mynginx容器内安装nginxrpm -ivh http://mirrors.aliyun.com/epel/epel-release-latest-7.noarch.rpm yum install -y nginx docker commit -m &quot;my nginx&quot; f9c7dfb6f552 tang/mynginx:v1 #提交镜像， ==同时打一个标签叫mynginx:v1 ==tang相当于你向github上提交的用户名 docker run -it --anme nginxv1 tang/mynginx:v1 #基于镜像tang/mynginx:v1创建容器nginxv1 ```]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker 基础（3）--容器登入]]></title>
      <url>%2F2017%2F03%2F11%2FDocker%20%E5%9F%BA%E7%A1%80%EF%BC%883%EF%BC%89--%E5%AE%B9%E5%99%A8%E7%99%BB%E5%85%A5%2F</url>
      <content type="text"><![CDATA[docker-enter登入容器 强烈推荐使用此种方法：简单、方便 下载.bashrc_docker，并将内容放到.bashrc中。 这个文件中定义了很多方便使用Docker的命令，比如docker-pid可以获取某个容器的 PID； 而 docker-enter 可以进入容器或直接在容器内执行命令 [root@tang ~]# wget -P ~ https://github.com/yeasy/docker_practice/raw/master/_local/.bashrc_docker [root@tang ~]# echo &quot;[ -f ~/.bashrc_docker ] &amp;&amp; . ~/.bashrc_docker&quot; &gt;&gt; ~/.bashrc; source ~/.bashrc [root@tang ~]# docker- docker-containerd docker-ctr-current docker-pid docker-containerd-current docker-current docker-storage-setup docker-containerd-shim docker-enter docker-containerd-shim-current docker-ip [root@tang ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES e657e9214a57 centos &quot;/bin/bash&quot; 24 minutes ago Up 23 minutes tang [root@tang ~]# docker-pid tang 19271 [root@tang ~]# nsenter --target 19271 --mount --uts --ipc --net --pid #此种方法进入容器以下会讲到 [root@test /]# exit logout [root@tang ~]# docker-ip tang 172.18.0.2 直接使用docker-enter命令进入容器，非常方便！ [root@tang ~]# docker-enter tang Last login: Sun Apr 2 06:38:47 UTC 2017 [root@test ~]# exit logout [root@tang ~]# docker ps #退出登陆窗口后，容器还在 CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES e657e9214a57 centos &quot;/bin/bash&quot; 26 minutes ago Up 9 seconds tang 注意：以在容器的上下文中运行任意命令！即在宿主机上执行容器里的命令 [root@tang ~]# docker-enter tang uptime 07:06:28 up 1 day, 22:44, 0 users, load average: 0.00, 0.01, 0.05 注意：在宿主机上使用docker-enter命令执行容器中的命令时，最好后面加上--符号，这样容器里的所有存在的命令都可以正常执行。 [root@tang ~]# docker-enter tang -- uptime 07:06:59 up 1 day, 22:45, 0 users, load average: 0.00, 0.01, 0.05 [root@tang ~]# docker-enter tang -- df -h Filesystem Size Used Avail Use% Mounted on /dev/mapper/docker-253:1-2024335-661487685eb1f6a356157463d60db20caa2c1fb3ac273de680c367e3b12dabab 10G 238M 9.8G 3% / tmpfs 920M 0 920M 0% /dev tmpfs 920M 0 920M 0% /sys/fs/cgroup /dev/vda1 99G 4.7G 89G 5% /etc/hosts shm 64M 0 64M 0% /dev/shm [root@tang ~]# cat /etc/redhat-release CentOS Linux release 7.2.1511 (Core) [root@tang ~]# docker-enter tang -- cat /etc/redhat-release CentOS Linux release 7.3.1611 (Core) nsenter登入容器使用外部工具nsenter登陆容器，该工具和docker exec命令的效果差不多。 使用nsenter或dockerexec，都可以在容器的上下文（严格地说，是命名空间）中运行任意命令！ ==nsenter安装： [root@tang ~]# yum install util-linux -y ==nsenter使用： [root@tang ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES e657e9214a57 centos &quot;/bin/bash&quot; 50 minutes ago Up 24 minutes tang [root@tang ~]# docker inspect -f &quot;{{ .State.Pid }}&quot; tang 19271 [root@tang ~]# nsenter -t 19271 -m -u -i -n -p 解释nsenter指令中进程id之后的参数的含义： –mount参数是进去到mount namespace中 –uts参数是进入到uts namespace中 –ipc参数是进入到System V IPC namaspace中 –net参数是进入到network namespace中 –pid参数是进入到pid namespace中 –user参数是进入到user namespace中 [root@tang ~]# nsenter --help Usage: nsenter [options] &lt;program&gt; [&lt;argument&gt;...] Run a program with namespaces of other processes. Options: -t, --target &lt;pid&gt; target process to get namespaces from -m, --mount[=&lt;file&gt;] enter mount namespace -u, --uts[=&lt;file&gt;] enter UTS namespace (hostname etc) -i, --ipc[=&lt;file&gt;] enter System V IPC namespace -n, --net[=&lt;file&gt;] enter network namespace -p, --pid[=&lt;file&gt;] enter pid namespace -U, --user[=&lt;file&gt;] enter user namespace -S, --setuid &lt;uid&gt; set uid in entered namespace -G, --setgid &lt;gid&gt; set gid in entered namespace --preserve-credentials do not touch uids or gids -r, --root[=&lt;dir&gt;] set the root directory -w, --wd[=&lt;dir&gt;] set the working directory -F, --no-fork do not fork before exec ing &lt;program&gt; -Z, --follow-context set SELinux context according to --target PID -h, --help display this help and exit -V, --version output version information and exit 我们进入容器中查看进程 以下是以nsenter启动的进程 [root@test /]# ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.0 11768 1684 ? Ss+ 07:03 0:00 /bin/bash root 77 0.0 0.1 15200 1988 ? S 07:31 0:00 -bash root 90 0.0 0.0 50872 1816 ? R+ 07:31 0:00 ps aux /bin/bash是我们运行容器产生的进程 -bash 是我们使用nsenter产生的，这样如果我们退出容器，容器就不会退出，因为-bash还在运行 [root@test /]# exit logout [root@tang ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES e657e9214a57 centos &quot;/bin/bash&quot; 55 minutes ago Up 29 minutes tang 因为每次进入容器都需要输入那两条命令，所以我们可以写一个脚本来获取。 ==脚本内容如下： [root@tang opt]# cat docker_in.sh #!/bin/bash # Use nsenter to access docker docker_in(){ NAME_ID=$1 PID=$(docker inspect -f &quot;{{ .State.Pid }}&quot; $NAME_ID) nsenter -t $PID -m -u -i -n -p } docker_in $1 [root@tang opt]# chmod +x docker_in.sh [root@tang opt]# ./docker_in.sh tang [root@test /]# ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 07:03 ? 00:00:00 /bin/bash root 91 0 0 07:34 ? 00:00:00 -bash root 104 91 0 07:34 ? 00:00:00 ps -ef [root@test /]# exit logout [root@tang opt]# docker exec tang ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 07:03 ? 00:00:00 /bin/bash root 105 0 0 07:35 ? 00:00:00 ps -ef 我们还可以使用exec进入docker容器中 [root@tang opt]# docker exec -it tang /bin/bash start -ai登入容器对于一个已关闭的容器的登陆，可以使用&quot;docker start -ai container&quot;登陆。这种其实就是先启动容器，然后再进入容器内。 [root@tang ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES e657e9214a57 centos &quot;/bin/bash&quot; About an hour ago Exited (0) 53 seconds ago tang [root@tang ~]# docker start -ai tang #-a -i 都可以 [root@test /]# exit exit [root@tang ~]# docker start -i tang [root@tang ~]# docker start -a tang docker exec登入容器使用自带命令docker exec登陆容器 命令格式：docker exec -ti container_id /bin/bash [root@tang ~]# docker ps #前提是容器已经启动 CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES e657e9214a57 centos &quot;/bin/bash&quot; About an hour ago Up 2 minutes tang [root@tang ~]# docker exec -it tang /bin/bash [root@test /]# exit docker attach登入容器使用自带命令docker attach登陆容器。 命令格式：docker attach container_id [root@tang ~]# docker ps #前提容器已经启动了 CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES e657e9214a57 centos &quot;/bin/bash&quot; About an hour ago Up 5 minutes tang [root@tang ~]# docker attach tang [root@test /]# exit ssh登入容器使用ssh登陆容器。这种方法需要在容器中启动sshd，存在开销和攻击面增大的问题。同时也违反了Docker所倡导的一个容器一个进程的原则 ssh登入会专门写一篇文章介绍。这里就不叙述了]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker问题梳理--持续更新]]></title>
      <url>%2F2017%2F03%2F11%2FDocker%E9%97%AE%E9%A2%98%E6%A2%B3%E7%90%86%2F</url>
      <content type="text"><![CDATA[关于systemctl无法启动服务的问题处理问题： 使用systemctl启动服务的时候出现以下异常： Failed to get D-Bus connection: Operation not permitted 解决： docker run --privileged -itd -h node1 --name node1 centos /sbin/init]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker 基础（4）--镜像管理]]></title>
      <url>%2F2017%2F03%2F11%2FDocker%20%E5%9F%BA%E7%A1%80%EF%BC%884%EF%BC%89--%E9%95%9C%E5%83%8F%E7%AE%A1%E7%90%86%2F</url>
      <content type="text"><![CDATA[使用容器生成镜像[root@tang ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES [root@tang ~]# docker run -it -h nginx --name nginx centos /bin/bash [root@nginx /]# rpm -ivh http://mirrors.aliyun.com/epel/epel-release-latest-7.noarch.rpm [root@nginx /]# yum install -y nginx [root@tang ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES e46c71171306 centos &quot;/bin/bash&quot; 2 minutes ago Exited (0) 40 seconds ago nginx [root@tang ~]# docker commit -m &quot;my nginx&quot; -a &quot;tang&quot; e46c71171306 new_nginx:v1 sha256:c15ceb0a6871e3a56e3b22d67254d09b2e03a8ae909719a6dea0daaf937940ef -m: 改动信息 -a: 作者信息 e46c71171306: 这一串为容器ID new_nginx:01 新镜像的名字 [root@tang ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE new_nginx v1 c15ceb0a6871 About a minute ago 355 MB docker.io/centos latest 98d35105a391 2 weeks ago 192.5 MB docker.io/registry latest 047218491f8c 4 weeks ago 33.17 MB 基于本地模块创建镜像模版获取,直接到openva官网下载(https://openvz.org/Download/template/precreated) [root@tang opt]# wget http://download.openvz.org/template/precreated/centos-6-x86_64-minimal.tar.gz [root@tang opt]# cat centos-6-x86_64-minimal.tar.gz |docker import - centos6 sha256:3d2aed457a111b136bdb9178d6203cb4bb0116501f7a4847088d7593c0930a8c [root@tang opt]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE centos6 镜像导出/导入[root@tang opt]# docker save centos6 &gt;/opt/centos6.tar.gz #导出 [root@tang opt]# ll total 1539880 -rw-r--r-- 1 root root 565194752 Apr 2 16:19 centos6.tar.gz [root@tang opt]# docker rmi centos6 Untagged: centos6:latest Deleted: sha256:3d2aed457a111b136bdb9178d6203cb4bb0116501f7a4847088d7593c0930a8c Deleted: sha256:dbcc6b3893af5f0b45e06f2934f73f5dc34f2e9e54fc4d50a51cc47195f19089 [root@tang opt]# docker load &lt; /opt/centos6.tar.gz #导入 [root@tang opt]# docker load --input /opt/centos6.tar.gz #导入 #以上两种导入方法都可以 [root@tang opt]# docker tag centos6 centos6_x86 #改名 将镜像上传到dockerhub官网需要提前注册dockerhub账号 1. docker hub 帐号在本地验证登陆: [root@tang opt]# docker login Login with your Docker ID to push and pull images from Docker Hub. If you don&apos;t have a Docker ID, head over to https://hub.docker.com to create one. Username: tangxiaoyue Password: Login Succeeded 2. docker push 镜像到docker hub 的仓库 docker push &lt;hub-user&gt;/&lt;repo-name&gt;:&lt;tag&gt; [root@tang ~]# docker tag centos tangxiaoyue/centos_tang:latest [root@tang ~]# docker push tangxiaoyue/centos_tang The push refers to a repository [docker.io/tangxiaoyue/centos_tang] 9b198ff9ff5b: Mounted from library/centos latest: digest: sha256:be5b4a93f116a57ab3fd454ada72421eac892a3a4925627ac9a44f65fcd69cf8 size: 529]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[XtraBackup主从复制及备份]]></title>
      <url>%2F2017%2F03%2F11%2FXtraBackup%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%8F%8A%E5%A4%87%E4%BB%BD%2F</url>
      <content type="text"><![CDATA[XtraBackup备份1、yum安装mysql（以centos7为例） ###主从操作一致 #查看操作系统版本： [root@node2 ~]# cat /etc/redhat-release CentOS Linux release 7.0.1406 (Core) #关闭防火墙和seLinux [root@node2 ~]# systemctl stop firewalld [root@node2 ~]# sed -i &quot;s#SELINUX=enforcing#SELINUX=disabled#g&quot; /etc/selinux/config [root@node2 ~]# setenforce 0 #yum安装mysql wget http://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpm rpm -ivh mysql-community-release-el7-5.noarch.rpm yum install mysql-community-server systemctl start mysql.service mysql -uroot &gt;set password for &apos;root&apos;@&apos;localhost&apos; = password(&apos;123456&apos;); ###配置主从 主： vim /etc/my.cnf [mysqld] log-bin = mysql-bin server-id=1 从： vim /etc/my.cnf [mysqld] log-bin = mysql-bin server-id=2 2、安装xtrabackup备份软件（主从进行安装） wget https://www.percona.com/downloads/XtraBackup/Percona-XtraBackup-2.3.4/binary/redhat/6/x86_64/percona-xtrabackup-2.3.4-1.el6.x86_64.rpm yum install -y epel-release yum localinstall percona-xtrabackup-2.3.4-1.el6.x86_64.rpm yum install -y perl-Time-HiRes #查看版本 &gt;select version(); #查看前默认的存储引擎 &gt;show variables like &apos;%storage_engine%&apos;; 3、导入数据（为了模拟比较真实可以往主库导入数据）（主库操作） #导入bubi_api数据库 [root@node2 opt]# mysql -uroot -ppassword &lt; bubi_api.sql # 查看数据大小 &gt; use information_schema; Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed &gt; select concat(round(sum(data_length/1024/1024),2),&apos;MB&apos;) as data from tables; +----------+ | data | +----------+ | 194.94MB | +----------+ 1 row in set (0.04 sec) 4、数据库备份（主操作） ###备份 [root@node2 opt]# mkdir /extrabackup [root@node2 opt]# innobackupex --defaults-file=/etc/my.cnf --socket=/var/lib/mysql/mysql.sock --user=root --password=bubi --parallel=4 /mnt/resource/extrabackup ###出现completed OK! 表示备份成功 语法解释：–user=数据库用户 –password=数据库密码 –socket=指定socket –default-file=指定配置文件 - 最后面是存放位 ###保持事务一致（主操作） [root@node2 2017-02-17_14-45-11]# innobackupex --defaults-file=/etc/my.cnf --socket=/var/lib/mysql/mysql.sock --user=root --password=123456 --parallel=4 --apply-log /extrabackup/2017-02-17_14-45-11/ ###出现completed OK!表示事务保持了一致，可以用于恢复 二、mysql主从同步操作 1、传输数据、将/extrabackup/2017-02-17_14-45-11/拷贝到从库 [root@node2 extrabackup]# scp -r 2017-02-17_14-45-11 root@192.168.1.13:/extrabackup/ 2、从库恢复数据 [root@node3 extrabackup]# ll 总用量 0 drwx------. 4 root root 47 2月 17 14:47 2017-02-17_14-45-11 #停止mysql [root@node3 extrabackup]# systemctl stop mysql #清空mysql data目录 [root@node3 extrabackup]# cd /var/lib/mysql [root@node3 mysql]# mv * /opt/mysqlbak/ #数据恢复 innobackupex --defaults-file=/etc/my.cnf --socket=/var/lib/mysql/mysql.sock --user=root --password=123456 --copy-back /extrabackup/2017-02-17_11-49-35/ ###出现completed OK! 表示恢复成功 #还原权限 [root@node3 mysql]# cd .. [root@node3 lib]# chown mysql:mysql mysql -R #重启mysql并查看数据的大小 [root@node3 lib]# systemctl start mysql [root@node3 lib]# ps -ef | grep mysql mysql 8173 1 0 14:59 ? 00:00:00 /bin/sh /usr/bin/mysqld_safe --basedir=/usr mysql 8338 8173 3 14:59 ? 00:00:00 /usr/sbin/mysqld --basedir=/usr --datadir=/var/lib/mysql --plugin-dir=/usr/lib64/mysql/plugin --log-error=/var/log/mysqld.log --pid-file=/var/run/mysqld/mysqld.pid --socket=/var/lib/mysql/mysql.sock root 8364 5840 0 15:00 pts/0 00:00:00 grep --color=auto mysql &gt; use information_schema; Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed mysql&gt; +----------+ | data | +----------+ | 194.94MB | +----------+ 1 row in set (0.26 sec) ###数据主从大小都一样 3、mysql主从同步操作 ###主库授权 &gt; GRANT REPLICATION SLAVE ON *.* TO &apos;rep&apos;@&apos;192.168.1.13&apos; IDENTIFIED BY &apos;123456&apos;; &gt;FLUSH PRIVILEGES; ###从库开启同步 [root@node3 mysql]# cat /extrabackup/2017-02-17_14-45-11/xtrabackup_binlog_info mysql-bin.000001 171510867 CHANGE MASTER TO MASTER_HOST=&apos;10.25.159.23&apos;, MASTER_USER=&apos;rep&apos;, MASTER_PASSWORD=&apos;db0226&apos;, MASTER_PORT=3306, MASTER_LOG_FILE=&apos;mysql-bin.000003&apos;, MASTER_LOG_POS=982559769; ####在还没同步之前我们可以在主库继续增加入一个库，验证不锁表是否可以同步 mysql&gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | bubi_api | | mysql | | performance_schema | | tang | +--------------------+ 5 rows in set (0.00 sec) #####开启主从同步 &gt;flush logs; &gt; start slave; ###从库操作 &gt; show slave status\G Slave_IO_Running: Yes Slave_SQL_Running: Yes ##查看从库数据 mysql&gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | bubi_api | | mysql | | performance_schema | | tang | +--------------------+ 5 rows in set (0.00 sec) 注意： 1、当从库停掉了（宕机还没测试）。主库继续写入数据，从库开启时，会自动同步 ##########mysql命令 #查看binlog是否开启 &gt;show binary logs; #查看serverid &gt;show variables like &apos;server_id&apos;; #查看binlog模式 &gt;show variables like &apos;%log%&apos;; &gt;/dev/null 2&gt;&amp;1]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Markdown语法大全]]></title>
      <url>%2F2017%2F03%2F11%2FMarkdown%E8%AF%AD%E6%B3%95%E5%A4%A7%E5%85%A8%2F</url>
      <content type="text"><![CDATA[题记：随着Markdown语言的热度不断提升，越来越多的人喜欢使用Markdown这种简洁、便宜的语言来编辑自己的blog、文章。下面笔者就一些简单常用的Markdown语句进行介绍，希望对大家在进行Markdown语言编辑自己的文章时有所帮助。 1.斜体和粗体 代码： 1. *斜体*或_斜体_ 2. **粗体** 3. ***加粗斜体*** 显示效果： 这是一段斜体 这是一段粗体 这是一段加粗斜体 2.分级标题 第一种写法： 1.这是一个一级标题 2.================ 3. 4. 这是一个一级标题 5. -------------------------- 第二种写法： # 一级标题 ## 二级标题 ### 三级标题 #### 四级标题 ##### 五级标题 ###### 六级标题 3.超链接行内式 代码： 1.欢迎来到[梵居闹市](http:// blog.leanote.com/freewalk) 2. 3.欢迎来到[梵居闹市](http:// blog.leanote.com/freewalk &quot;梵居闹市&quot;) 显示效果： 欢迎来到梵居闹市欢迎来到梵居闹市 参考式 代码： 我经常去的几个网站[Google][1]、[Leanote][2]以及[自己的博客][3] [Leanote 笔记][2]是一个不错的[网站][]。 [1]: http://www. google.com &quot;Google&quot; [2]:http://www. leanote.com &quot;Leanote&quot; [3]:http://http:/ /blog.leanote.com/freewalk &quot;梵居闹市&quot; [网站]:http: //http://blog.leanote.com/freewalk 显示效果： 我经常去的几个网站Google、Leanote以及自己的博客Leanote 笔记是一个不错的网站。 自动链接 代码： &lt;http://example.com/&gt; &lt;address@example.com&gt; 显示效果： http://example.com/&#97;&#x64;&#100;&#114;&#101;&#115;&#x73;&#x40;&#x65;&#x78;&#97;&#109;&#x70;&#x6c;&#101;&#46;&#x63;&#111;&#x6d; 4.锚点 代码： 跳转到[目录](#index) 显示效果： 跳转到目录 5.列表无序列表 使用 *，+，- 表示无序列表。 代码： 无序列表项 一 无序列表项 二 无序列表项 三 显示效果： 无序列表项 一 无序列表项 二 无序列表项 三 有序列表 代码： 1. 有序列表项 一 2. 有序列表项 二 3. 有序列表项 三 显示效果： 有序列表项 一 有序列表项 二 有序列表项 三 列表缩进 代码： * 轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。 那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。 软泥上的青荇， 油油的在水底招摇； 在康河的柔波里， 我甘心做一条水草！ * 那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。 寻梦？撑一支长篙， 向青草更青处漫溯； 满载一船星辉， 在星辉斑斓里放歌。 但我不能放歌， 悄悄是别离的笙箫； 夏虫也为我沉默， 沉默是今晚的康桥！ 悄悄的我走了， 正如我悄悄的来； 我挥一挥衣袖， 不带走一片云彩 显示效果： 轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。软泥上的青荇， 油油的在水底招摇； 在康河的柔波里， 我甘心做一条水草！ 那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。寻梦？撑一支长篙， 向青草更青处漫溯； 满载一船星辉， 在星辉斑斓里放歌。但我不能放歌， 悄悄是别离的笙箫； 夏虫也为我沉默， 沉默是今晚的康桥！悄悄的我走了， 正如我悄悄的来； 我挥一挥衣袖， 不带走一片云彩 包含段落的列表 代码： * 轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。 那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。 软泥上的青荇， 油油的在水底招摇； 在康河的柔波里， 我甘心做一条水草！ 那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。 寻梦？撑一支长篙， 向青草更青处漫溯； 满载一船星辉， 在星辉斑斓里放歌。 但我不能放歌， 悄悄是别离的笙箫； 夏虫也为我沉默， 沉默是今晚的康桥！ * 悄悄的我走了， 正如我悄悄的来； 我挥一挥衣袖， 不带走一片云彩。 显示效果： 轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。软泥上的青荇， 油油的在水底招摇； 在康河的柔波里， 我甘心做一条水草！ 那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。寻梦？撑一支长篙， 向青草更青处漫溯； 满载一船星辉， 在星辉斑斓里放歌。但我不能放歌， 悄悄是别离的笙箫； 夏虫也为我沉默， 沉默是今晚的康桥！ 悄悄的我走了， 正如我悄悄的来； 我挥一挥衣袖， 不带走一片云彩。 包含引用的列表 代码： * 阅读的方法:（一个空格） &gt; 打开书本。 &gt; 打开电灯。 显示效果： 阅读的方法: 打开书本。打开电灯。 包含代码区块的引用语法说明：如果要放代码区块的话，该区块就需要缩进两次，也就是 8 个空格或是 2 个制表符： 一列表项包含一个列表区块： &lt;代码写在这&gt; 一个特殊情况在特殊情况下，项目列表很可能会不小心产生，像是下面这样的写法： 1986. What a great season. 会显示成： What a great season. 换句话说，也就是在行首出现数字-句点-空白，要避免这样的状况，你可以在句点前面加上反斜杠： 1986\. What a great season. 会显示成：1986. What a great season. 6. 引用 代码： &gt; 这是一个有两段文字的引用, &gt; 无意义的占行文字1. &gt; 无意义的占行文字2. &gt; &gt; 无意义的占行文字3. &gt; 无意义的占行文字4 显示效果： 这是一个有两段文字的引用,无意义的占行文字1.无意义的占行文字2. 无意义的占行文字3.无意义的占行文字4. 引用的多层嵌套 代码： &gt;&gt;&gt; 请问 Markdwon 怎么用？ - 小白 &gt;&gt; 自己看教程！ - 愤青 &gt; 教程在哪？ - 小白 显示效果： 请问 Markdwon 怎么用？ - 小白 自己看教程！ - 愤青 教程在哪？ - 小白 引用其它要素 代码： &gt; 1. 这是第一行列表项。 &gt; 2. 这是第二行列表项。 &gt; &gt; 给出一些例子代码： &gt; &gt; return shell_exec(&quot;echo $input | $markdown_script&quot;); 显示效果： 这是第一行列表项。 这是第二行列表项。 给出一些例子代码： return shell_exec(&quot;echo $input | $markdown_script&quot;); 7. 插入图像行内式 代码： 高圆圆： ![高圆圆](ht tp://pic2016.5442.com:82/2015/1117/16/7.jpg%21960.jpg &quot;高圆圆&quot;) 显示效果 高圆圆： 8. 内容目录 markdownpad居然不支持该语法，我就呵呵了. 代码： [TOC]0.目录 [TOC]1. 斜体和粗体 [TOC]2. 分级标题 [TOC]3. 超链接 [TOC] 行内式 [TOC] 参考式 [TOC] 自动链接 [TOC]4. 锚点 9. 注脚 代码： 使用 Markdown[1]可以效率的书写文档,你可以使用 Leanote[Le] 编辑器进行书写。 [1]:Markdown是一种纯文本标记语言 [Le]:开源笔记平台，支持Markdown和笔记直接发为博文 显示效果： 使用 Markdown1可以效率的书写文档,你可以使用 LeanoteLe 编辑器进行书写。 原文链接：http://blog.leanote.com/post/freewalk/Markdown-语法手册]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hexo常用命令]]></title>
      <url>%2F2017%2F03%2F11%2FHexo%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
      <content type="text"><![CDATA[Hexo部署步骤 npm install npm install hexo-deployer-git --save hexo new &quot;新页面&quot; hexo clean hexo generate hexo deploy Hexo常用命令 hexo new &quot;postName&quot; #新建文章 hexo new page &quot;pageName&quot; #新建页面 hexo generate #生成静态页面至public目录 hexo server #开启预览访问端口（默认端口4000，&apos;ctrl + c&apos;关闭server） hexo deploy #将.deploy目录部署到GitHub hexo help #查看帮助 hexo version #查看Hexo的版本 复合命令 hexo deploy -g #生成加部署 hexo server -g #生成加预览 命令的简写为： hexo n == hexo new hexo g == hexo generate hexo s == hexo server hexo d == hexo deploy]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[运维与自动化发展(1)]]></title>
      <url>%2F2017%2F01%2F01%2F%E8%BF%90%E7%BB%B4%E4%B8%8E%E8%87%AA%E5%8A%A8%E5%8C%96%E5%8F%91%E5%B1%95(1)%2F</url>
      <content type="text"><![CDATA[一、运维学习和发展的一个线路1.搭建服务（部署并运行起来） 2.用好服务（监控、管理、优化） 3.自动化（服务直接的关联和协同工作） 4.产品设计（如何设计一个监控系统） 云计算的核心竞争力是运维！ 系统架构师（还有偏管理系统架构师）：网络 系统 数据库 开发 云计算 自动化 运维管理 服务管理 项目管理 测试 业务 ==比较难学的开发和业务（相对于运维来说） 专注于某一领域：资深、科学家 二、运维知识体系赵班长运维知识体系：https://www.unixhot.com/page/ops 运维工作内容分类： 监控运维（7X24运维值班、故障处理） 应用运维（业务熟悉、服务部署、项目上线、业务部署、版本管理、灰度发布、日志收集、应用监控） 安全运维（整体的安全方案、规范、漏洞检测、安全防护等） 系统运维（架构层面的分布式缓存、分布式文件系统、环境规划（测试、开发、生产）、架构设计、性能优化） 基础服务运维（包含运维开发）（内部DNS、负载均衡、系统监控、资产管理、运维平台） 基础设施运维（系统初始化、网络维护） 机房运维（负责设备上下架、巡检、保修、硬件监控） 三、运维自动化发展发展层级： 智能化 服务化、api化 Web化、平台化 标准化、工具化 1.标准化物理设备层面： 1.服务器标签化、设备负责人、设备采购详情、设备摆放标准（例如：负载均衡两台机器不能放同一机柜）。 2.网络划分、远程控制卡、网卡端口 3.服务器机型、硬盘、内存统一。根据业务分类 4.资产命名规范、编号规范、类型规范 5.监控标准 操作系统层面： 1.操作系统版本 2.系统初始化（DNS、NTP、内存参数调优、rsyslog、主机名规范） 3.基础Agent配备（zabbix Agent、logstach Agent、saltstack monitor） 4.系统监控标准（cpu、内存、硬盘、网络、进程） 应用服务层面： 1.Web服务器选型（apache、nginx） 2.进程启动用户、端口监听规范、日志收集规范（访问日志、错误日志、运行日志） 3.配置管理（配置文件规范、脚本规范） 4.架构规范（nginx+keepalived、lvs+keepalived等等） 5.部署规范（位置、包命名等） 运维操作层面： 1.机房巡检流程（周期、内容、报修流程） 2.业务部署流程（先测试、后生成。回滚） 3.故障处理流程（紧急处理、故障升级） 4.工作日志标准（如何编写工作日志） 5.业务上线流程（1.项目发起人 2.系统安装 3.部署nginx 4.解析域名 5.测试 6.加监控 7.备份） 6.业务下线流程（1.谁发起 2.数据如何处理 3.服务器回收 4.系统是否重装） 7.运维安全规范（密码复杂度、更改周期、vpn使用规范、服务器登入规范） 标准化（规范化、流程化、文档化） 目标：文档化 2.工具化1.shell脚本（功能性（流程）、坚持性、报表性） 2.开源工具：Zabbix ELKstack SaltStack cobbler 目标： 1.促进标准化的实施 2.将重复的操作，简单化 3.将多次操作，流程化 4.减少人为操作的低效和降低故障率 工具化和标准化是好基友！！！ 痛点： 1.你至少要ssh到服务器执行，可能犯错 2.多个脚本有执行顺序的时候，可能犯错 3.权限不好管理，日志没法统计。 4.无法避免手工操作 例子：比如某天我们要对一台数据库从库进行版本升级。那么要求进行评估： 停机的影响：3:00晚上有定时任务链接该数据库，做数据报表统计。 1.凌晨3:00我们所有系统的定时任务有哪些 crontab 2.这些croneab哪些连接我们要停止的从库 3.哪些可以停，哪些不能停（修改到主库），哪些可以后补 4.这些需要后补的脚本哪个业务，谁加的，什么时候加的 3.Web化（运维操作平台）1.做成Web界面 2.权限控制 3.日志记录 4.弱化流程 5.不用ssh到服务器，减少人为操作造成的故障 4.服务化（API化）DNS Web管理 bind-DLZ dns-api 负载均衡Web管理 slb-api Job管理平台 job-api 监控Web管理 zabbix zabbix-api 操作系统安装平台 cobbler-api 部署平台 deploy-api 配置管理平台 saltstack-api 自动化测试平台 test-api 1.调用cobbler-api安装操作系统 2.调用saltstack-api进行系统初始化 3.调用dns-api解析主机名 4.调用zabbix-api将新上线机器加上监控 5.再次调用saltstack-api部署软件（安装Nginx+php） 6.调用deploy-api 将当前版本的代码部署到服务器上 7.调用test-api 测试当前服务器运行十分正常 8.调用slb-api 将该节点加入集群 5.智能化 智能化的自动化扩容、缩容、服务降级、故障自愈 触发机制--&gt;决策系统（决策树） 一、自动化扩容 1.zabbix触发Action 触发： 1.当某个集群的访问量超过最大的支撑量，比如10000 1.1.cpu使用率达到多少 2.并持续5分钟 3.不是攻击 4.资源池有可用资源 4.1.当前网络带宽使用率 4.2.如果公有云-钱够不够 5.当前后端服务支撑量是否超过阈值，如果超过应该后端先扩容 6.数据库是否可以支撑当前并发 7.当前自动化扩展队列，是否有正在扩容的节点 8.其它业务相关的 决策之前：先判断buffer是否有最近X小时，已经移除的之前创建的虚拟机。并查询软件版本是否和当前一致，如果一致，跳过2 3 4步骤。如果不一致，跳过2 3步骤 2.Openstack 创建虚拟机 3.Saltstack配置环境---监控 4.部署系统当前代码 5.测试服务是否可用（注意间隔和次数） 6.加入集群 7.通知（短信、邮件、花费时间） 二、自动化缩容 1.触发条件和决策 2.从集群中移除节点---先关闭监控--移除 3.通知 4.移除的节点存放在buffer里面 5.buffer里面超过一天的虚拟机，自动关闭，存放于某去 6.某区的虚拟机，每7天清理删除 1.部署openstack 2.在openstack上创建虚拟机 3.在虚拟机上部署Mesos+docker+Marathon 4.自动化创建Docker容器进行自动化扩容 四. 基于ITIL的运维管理体系1. ITIL 简介什么是服务： 服务是向客户提供的一种手段，使客户不用承担特定的成本和风险就可以获得所期望的结果。 什么是服务管理： 服务管理是一套特定的组织能力，以服务的形式为客户提供价值 ITSM 和ITIL 的关系： 1.现有ITSM，后有ITIL。 2.因为ITIL，ITSM得到关注和发扬 3.ITIL是ITIM的最佳时间.ITIL为ITSM创建了一组核心流程和专有名词 4.ITIL并不是ITSM的全部，ITIL只是告诉我们，什么该做，但没有说具体该怎么做。而对ITSM而言，这些都是ITSM的范围。 ITIL是： ITIL即IT基础架构库（Information Technology Infrastructure Library）。 英国商务办公司从20世纪80年代开始开发的一套IT管理方法。 已成为事实上的行业标准，并以其为中心在全球形成了完整的产业。 任何单位和个人都可以免费试用的“公共框架”。 实际上是一系由所谓“最佳实践”形成图书。 一个可以直接使用的标准。 ITIL的目的： 1.将IT管理工作标准化，模式化，减少人为误操作带来的隐患 2.通过服务目录，服务报告，告诉业务部门，我们可以做什么，做了什么 3.通过系列流程，只是库减轻对英雄式工程师的以来，把经验积累下来。 4.通过对流程的管控，减少成本，降低风险，提供客户满意度 ITIL和ISO 20000 ITIL自发布以来，一直被业界认为是IT服务管理领域事实上的管理标准，直到2000年11月，英国标准协会（BSI）正式发布了以ITIL为核心的国家标准BS15000； 随后，2005年5月，国际标准化组织（ISO）快速通道的方式批准通过了ISO2000的标准协议，并于12月15日正式发布了ISO20000标准。 ITIL和ISO20000区别 ITIL ISO2000 提供最佳实践指导 提供衡量ITSM的指标 没有固定的能力衡量指标 全球统一 对人员进行认证 对机构进行认证 咨询机构提供他们眼中的ITSM成熟度结果 关注于服务提供的独立认证，从IT服务管理体系的角度出发 ITSM内容 管什么（管理对象） 怎么管（管理方法） 管得咋样（成熟度） IT service CMM 初始级： 被动相应，没有文档记录，几乎没有过程，是经过定义的 ； 各项目经验无法重用，以来与个人的努力和永雄主义 可重复级： 建立了基本的服务管理过程； 所有项目有默认的规则，但未文档化，系统化； 产品或服务化无清晰的目标和策略； 定义级： 已将IT服务过程文档化，标准化，并综合成标准服务过程； 根据客户需求调整服务产品和服务战略； 适当的工具和信息报告； 管理级： 受监督、测量的IT服务体系； 根据业务战略调整服务体系； 优化级（PDCA）： 持续改进的IT服务体系； IT与业务指标建立关系； IT与业务协作改进流程； 成为运维经理： 1.技术，运维只是体系 2.服务管理ITIL 项目管理PMP 3.做人 五. ITIL 服务运营ITIL v3 将ITIL理论分成五部分： 1.服务战略 2.服务设计 3.服务转换 4.服务运营 5.持续服务改进 ITIL v3 核心模块 服务运营： SLA：服务级别协议 OLA：运营水平协议 CSF：关键成功因素 KPI：关键绩效指标 客户要求——SLA——OLA——CSF——KPI——月报 服务台： 作为IT服务支持团队的一线支持，其首要目标是为用户和IT组织之间建立沟通的纽带； 确保用户的故障请求和服务请求能够以最快的速度得到满足，并确保用户满意。 服务台作用： 1.路由器 2.监视器 3.单一联系点 4.客服窗口 5.广播台 6.过滤器 六. 服务运营-故障管理1.故障管理的目标： 故障管理的目标是尽可能快的恢复正常的服务运营，将故障对业务运营的负面影响减少到最低。 并确保到达最好的服务质量和可用性水平。 2.故障优先级： --紧急度 --影响度 3.故障输入输出： 故障管理流程输入 故障请求提交 故障单记录模板 故障单填写模板 故障分类规则 故障优先级确定规则 故障升级规则 故障处理时间规则 故障关闭规则 故障管理流程输出： 故障历史记录 故障分类汇总统计表 故障处理用户满意度 4.故障管理的绩效指标（KPI） 一线支持解决的事故百分比 无升级的平均呼叫时长 分配错误的事故百分比 在目标时间之内，按照优先级解决的事故百分比 二线支持平均响应时间 事故平均解决时间 重新分配的事故百分比 归类错误的事故百分比 绕过一线支持的呼叫百分比 客户满意度 服务请求呼叫百分比 一次解决正确的事故百分比 主动解决的事故百分比 5.服务运营-问题管理 问题管理的目标： 问题管理的主要目标是预防问题产生及由此引发的故障，消除重复的出现故障，并对不能预防的故障尽量减低其对业务的影响 问题管理对业务的价值： 提供IT服务的可用性 提高业务和IT人员的生成效率 减少无效的规避措施或修补措施的开支 减少在救火或解决重复故障方面的成本 有助于知识库的积累]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[五分钟商学院--大纲]]></title>
      <url>%2F2016%2F09%2F25%2F%E4%BA%94%E5%88%86%E9%92%9F%E5%95%86%E5%AD%A6%E9%99%A2--%E5%A4%A7%E7%BA%B2%2F</url>
      <content type="text"><![CDATA[商业四大体系合体。 1）商业，你与企业外部的关系；2）管理，你与企业内部的关系；3）个人，你与自己的关系；4）以及提升前三者的：工具。 商业篇消费心理学1.心理账户2.沉没成本3.比例偏见4.损失规避5.价格锚点 商业世界五大基础逻辑6.流量之河7.倍率之刀8.价量之秤9.风险之眼10.规则之缝 互联网世界五大基本定律11.信息对称12.平台经济13.边际成本14.长尾理论15.免费理论 行为经济学16.结果偏见17.适应性偏见18.鸡蛋理论19.概率偏见20.凡勃伦效应 微观经济学21.供需理论22.边际效用23.机会成本24.代理两难25.科斯定理 宏观经济学26.节约悖论27.张维迎林毅夫之争28.人口抚养比29.经济泡沫30.福利经济 金融法律31.风险投资32.公司的形态：有限责任，合伙企业，个人独资33.期权（员工激励方案）34.庞氏骗局35.互联网金融 市场营销 Product36.产品定位37.自我认知38.极致单品39.三驾马车40.最小可用品 市场营销 Price41.渗透定价法42.组合定价法43.撇脂定价法44.价格歧视45.客户自定价 市场营销 Promotion46.定位营销47.饥饿营销48.死亡之井49.危机公关50.独特的销售主张-USP 市场营销 Place51.深度分销52.直接销售53.虚实结合54.社区商务55.反向定制 市场营销 互联网营销56.社群经济57.口碑经济（POE理论）58.粉丝经济59.引爆点60.红利理论 所有现象背后都有商业逻辑61.运动对赌62.雇佣客户63.服务行业美女越多，经济越不景气64.狩猎式 vs 农耕式65.稳定平衡态 vs 不稳定平衡态 管理篇管理选人66.上下车法则67.奥格尔维定律68.首因效应/光环效应69.特雷默定律70.重视面试被拒的人 管理育人71.蘑菇定律72.师傅制73.情境领导II74.鲶鱼效应75.贝尼斯定理 管理用人76.不值得定律77.懒蚂蚁效应78.热炉法则79.拜伦法则80.波特定律 管理留人81.酒与污水定律82.格雷欣法则（劣币驱逐良币）83.雷尼尔效应84.南风法则85.离职面试 管理就是激励需求理论86.马斯洛人类需求五层次理论-生理87.马斯洛人类需求五层次理论-安全88.马斯洛人类需求五层次理论-归属89.马斯洛人类需求五层次理论-尊重90.马斯洛人类需求五层次理论-实现 管理就是激励其他理论91.卡诺满意度模型92.赫兹伯格的双因素激励理论93.亚佛斯德原则（期望理论）94.马蝇效应95.波什定律 从员工到经理96.古狄逊定理97.吉格勒定理98.刺猬法则99.目标置换效应100.篮球架子原理 管理1101.崔西定律102.蓝柏格定理103.阿什定律104.彼得斯定律105.超限效应 管理2106.奥卡姆剃刀定律107.法约尔原则（责权利心法）108.例外原则109.洛克忠告110.海恩法则 管理3111.波特法则112.卡贝定律113.飞轮效应114.墨菲定律115.克里夫兰法则 团队合作116.球队，交响乐队，军队117.木桶定律118.多样性（异性效应）119.苛希纳定律120.蚁群效应 项目管理121.作战指挥室122.关键路径123.范围、时间、资源的金三角124.风险管理（已知的未知风险）125.权利来源：专业 管理常见病126.破窗效应127.旁观者效应128.帕金森定律129.彼得原理130.手表定律 个人篇高效能人士的七种习惯131.范式转变132.情感账户133.积极主动134.以终为始135.要事第一 高效能人士的七种习惯136.双赢思维137.知彼解己138.统合综效139.不断更新140.找到心声 时间管理141.时间成本142.GTD143.猴子理论144.三八理论145.番茄钟 职业素养146.如何打招呼147.如何吃西餐148.如何和老板一起坐车149.如何搭配衣服150.邮件礼仪 学习能力151.幸存者偏见152.库博经验学习圈153.知识、技能、态度154.学习小组（私人董事会）155.如何最快速的学习 思考能力156.六顶思考帽157.批判性思维/辩证思维158.系统思维-关联的、整体的、动态的159.正向思维160.逆向思维 逻辑思维161.偷换概念-同一律162.自相矛盾-矛盾律163.模棱两可-排中律164.三段论165.归纳法与黑天鹅事件 谈判能力166.吉普赛陷阱167.定位调整偏见168.有限的权利 &amp; 不露面的人169.战略延迟 &amp; 最终期限170.吃惊 &amp; 撤退 情感能力171.元能力：同理心172.元能力：自我认知（卢维斯定理）173.元能力：自我控制174.元能力：自我激励175.元能力：人际关系处理 演讲能力176.导游心法177.注意力法则178.空中加油179.案例和幽默感180.打透 沟通能力181.快乐痛苦四原则182.亨利法则183.踢猫效应184.电梯测验185.如何问出好问题 创新能力186.创新者的窘境187.人无我有，人有我优，人优我廉……188.达维多定律189.路径依赖190.比伦定律 领导能力191.远（后喻文明）192.小（科斯定理）193.变（企业生命周期）194.快（快鱼吃慢鱼）195.专（网状激活系统） 战略篇战略工具196.麦肯锡·MECE法197.波特·五力模型198.波士顿矩阵199.金字塔原理200.通用电器矩阵 战略工具201.正态分布理论202.逻辑树/决策树203.平衡计分表204.SWOT模型205.麦肯锡·七步成诗法 博弈工具206.纳什均衡207.囚徒困境208.贝叶斯均衡209.智猪博弈210.公地悲剧 博弈工具211.你分我拿212.拍卖逻辑213.零和游戏原理214.拍卖美元215.用餐者困境 决策工具216.儒佛尔定律217.吉德林法则218.布利丹效应219.羊群效应220.麦穗哲理 创新工具221.减法创新222.除法创新223.乘法创新224.任务统筹策略225.属性依存策略 管理工具226.OKR227.MBTI人格理论（自我管理）228.SMART原则（目标管理）229.PDCA循环规则（项目管理）230.5W2H法（目标管理） 思考工具231.头脑风暴法232.思考工具：白板233.思维导图234.5WHY分析法235.复盘 沟通工具236.有效的1：1237.罗伯特议事规则238.白板墙、低隔板、下午茶和即时贴239.拉波波特评论规则240.结构沟通法 财务工具241.财务分析中的五力分析法242.零基预算？243.本福特定律244.独立P&amp;L245.计算企业价值 营销工具246.直播营销247.Focus Group248.STP249.4C250.4P 未来已来256.零边际成本社会257.奇点临近258.比特币259.基因科技260.人工智能]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySQ binlog三种模式及设置方法]]></title>
      <url>%2F2016%2F03%2F12%2FMySQ%20binlog%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F%E5%8F%8A%E8%AE%BE%E7%BD%AE%E6%96%B9%E6%B3%95%2F</url>
      <content type="text"><![CDATA[MySQ binlog三种模式及设置方法Row Level 行模式日志中会记录每一行数 据被修改的形式，然后在slave端再对相同的数据进行修改 优点：在row level模式下，bin-log中可以不记录执行的sql语句的上下文相关的信息，仅仅只需要记录那一条被修改。所以rowlevel的日志内容会非常清楚的记录下每一行数据修改的细节。 不会出现某些特定的情况下的存储过程或function，以及trigger的调用和触发无法被正确复制的问题 缺点：row level，所有的执行的语句当记录到日志中的时候，都将以每行记录的修改来记录，会产生大量的日志内容。 Statement Level（默认每一条会修改数据的sql都会记录到master的bin-log中。slave在复制的时候sql进程会解析成和原来master端执行过的相同的sql来再次执行 优点：statement level下的优点首先就是解决了row level下的缺点，不需要记录每一行数据的变化，减少bin-log日志量，节约IO，提高性能，因为它只需要在Master上锁执行的语句的细节，以及执行语句的上下文的信息。 缺点：由于只记录语句，所以，在statement level下 已经发现了有不少情况会造成MySQL的复制出现问题，主要是修改数据的时候使用了某些定的函数或者功能的时候会出现。 Mixed 自动模式在Mixed模式下，MySQL会根据执行的每一条具体的sql语句来区分对待记录的日志格式，也就是在Statement和Row之间选择一种。 如果sql语句确实就是update或者delete等修改数据的语句，那么还是会记录所有行的变更。 企业场景如何选择binlog模式1、互联网公司，使用MySQL的功能相对少（存储过程、触发器、函数） 选择默认的语句模式，Statement Level（默认） 2、公司如果用到使用MySQL的特殊功能（存储过程、触发器、函数） 则选择Mixed模式 3、公司如果用到使用MySQL的特殊功能（存储过程、触发器、函数）又希望数据最大化一直，此时最好选择Row level模式 行模式和语句模式的区别1.语句模式： 100万条记录 只需1条delete * from test；就可以删除100万条记录 2.row模式 100万条记录 记录100万条删除命令]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Mysql优化系列--总结梳理]]></title>
      <url>%2F2016%2F03%2F12%2FMysql%E4%BC%98%E5%8C%96%E7%B3%BB%E5%88%97--%E6%80%BB%E7%BB%93%E6%A2%B3%E7%90%86%2F</url>
      <content type="text"><![CDATA[对于一个网站来说，在运行很长一段时间后，数据库瓶颈问题会越来越暴露出来。作为运维人员，对数据库做必要的优化十分重要！ 下面总结以往查阅到的以及自己工作中的一些优化操作经验，并根据OSI七层模型从下往上进行优化mysql数据库记录。 物理层面1、cpu:2-16个 2*4双四核，L1L2越大越好 2、内存:越大越好 3、磁盘:SAS或者固态 300G*12磁盘越多IO越高 raid 0&gt;10&gt;5&gt;1 4、网卡:千兆 5、slave的配置最好大于等于master 系统配置如下，配置系统内核参数/etc/sysctl.conf（配置后，使用sysctl -p使之生效） net.ipv4.tcp_fin_timeout = 2 net.ipv4.tcp_tw_reuse = 1 net.ipv4.tcp_tw_recycle = 1 net.ipv4.tcp_syncookies = 1 net.ipv4.tcp_keepalive_time =600 net.ipv4.ip_local_port_range = 4000 65000 net.ipv4.tcp_max_syn_backlog = 16384 net.ipv4.tcp_max_tw_buckets = 36000 net.ipv4.route.gc_timeout = 100 net.ipv4.tcp_syn_retries = 1 net.ipv4.tcp_synack_retries = 1 net.core.somaxconn = 16384 net.core.netdev_max_backlog = 16384 net.ipv4.tcp_max_orphans = 16384 vm.swappiness=0 //尽量不使用swap vm.dirty_backgroud_ratio 5-10 vm.dirty_ratio //上面的值的两倍 将操作系统的脏数据刷到磁 mysql的安装MySQL数据库的线上环境安装，建议采取编译安装的方式，这样性能会有较大的提升。服务器系统则建议CentOS6.7 X86_64，源码包的编译参数会默认以Debug模式生成二进制代码，而Debug模式给MySQL带来的性能损失是比较大的，所以当我们编译准备安装的产品代码时，一定不要忘记使用–without-debug参数禁止Debug模式。如果把–with-mysqld-ldflags和–with-client-ld-flags两个编译参数设置为–all-static的话，可以告诉编译器以静态的方式编译，编译结果将得到最高的性能。使用静态编译和使用动态编译的代码相比，性能差距可能会达到5%至10%之多。在后面我会跟大家分享我们线上MySQL数据库的编译参数，大家可以参考下，然后根据自己的线上环境自行修改内容。 下面是对mysql服务配置文件my.cnf的详解： [client] port = 3306 # 客户端端口号为3306 socket = /data/3306/mysql.sock default-character-set = utf8 # 客户端字符集,(控制character_set_client、character_set_connection、character_set_results) [mysql] no-auto-rehash # 仅仅允许使用键值的updates和deletes [mysqld] # 组包括了mysqld服务启动的参数，它涉及的方面很多，其中有MySQL的目录和文件，通信、网络、信息安全，内存管理、优化、查询缓存区，还有MySQL日志设置等。 user = mysql # mysql_safe脚本使用MySQL运行用户(编译时--user=mysql指定),推荐使用mysql用户。 port = 3306 # MySQL服务运行时的端口号。建议更改默认端口,默认容易遭受攻击。 socket = /data/3306/mysql.sock # socket文件是在Linux/Unix环境下特有的，用户在Linux/Unix环境下客户端连接可以不通过TCP/IP网络而直接使用unix socket连接MySQL。 basedir = /application/mysql # mysql程序所存放路径,常用于存放mysql启动、配置文件、日志等 datadir = /data/3306/data # MySQL数据存放文件(极其重要) character-set-server = utf8 # 数据库和数据库表的默认字符集。(推荐utf8,以免导致乱码) log-error=/data/3306/mysql.err # mysql错误日志存放路径及名称(启动出现错误一定要看错误日志,百分之百都能通过错误日志排插解决。) pid-file=/data/3306/mysql.pid # MySQL_pid文件记录的是当前mysqld进程的pid，pid亦即ProcessID。 skip-locking # 避免MySQL的外部锁定，减少出错几率，增强稳定性。 skip-name-resolv # 禁止MySQL对外部连接进行DNS解析，使用这一选项可以消除MySQL进行DNS解析的时候。但是需要注意的是，如果开启该选项，则所有远程主机连接授权都要使用IP地址方式了，否则MySQL将无法正常处理连接请求！ skip-networking # 开启该选项可以彻底关闭MySQL的TCP/IP连接方式，如果Web服务器是以远程连接的方式访问MySQL数据库服务器的，则不要开启该选项，否则无法正常连接！ open_files_limit = 1024 # MySQLd能打开文件的最大个数,如果出现too mant open files之类的就需要调整该值了。 back_log = 384 # back_log参数是值指出在MySQL暂时停止响应新请求之前，短时间内的多少个请求可以被存在堆栈中。如果系统在短时间内有很多连接，则需要增加该参数的值，该参数值指定到来的TCP/IP连接的监听队列的大小。不同的操作系统在这个队列的大小上有自己的限制。如果试图将back_log设置得高于操作系统的限制将是无效的，其默认值为50.对于Linux系统而言，推荐设置为小于512的整数。 max_connections = 800 # 指定MySQL允许的最大连接进程数。如果在访问博客时经常出现 Too Many Connections的错误提示，则需要增大该参数值。 max_connect_errors = 6000 # 设置每个主机的连接请求异常中断的最大次数，当超过该次数，MySQL服务器将禁止host的连接请求，直到MySQL服务器重启或通过flush hosts命令清空此host的相关信息。 wait_timeout = 120 # 指定一个请求的最大连接时间，对于4GB左右内存的服务器来说，可以将其设置为5~10。 table_cache = 614K # table_cache指示表高速缓冲区的大小。当MySQL访问一个表时，如果在MySQL缓冲区还有空间，那么这个表就被打开并放入表缓冲区，这样做的好处是可以更快速地访问表中的内容。一般来说，可以查看数据库运行峰值时间的状态值Open_tables和Open_tables，用以判断是否需要增加table_cache的值，即如果Open_tables接近table_cache的时候，并且Opened_tables这个值在逐步增加，那就要考虑增加这个值的大小了。 external-locking = FALSE # MySQL选项可以避免外部锁定。True为开启。 max_allowed_packet =16M # 服务器一次能处理最大的查询包的值，也是服务器程序能够处理的最大查询 sort_buffer_size = 1M # 设置查询排序时所能使用的缓冲区大小，系统默认大小为2MB。 # 注意：该参数对应的分配内存是每个连接独占的，如果有100个连接，那么实际分配的总排序缓冲区大小为100 x6=600MB。所以，对于内存在4GB左右的服务器来说，推荐将其设置为6MB~8MB join_buffer_size = 8M # 联合查询操作所能使用的缓冲区大小，和sort_buffer_size一样，该参数对应的分配内存也是每个连接独享。 thread_cache_size = 64 # 设置Thread Cache池中可以缓存的连接线程最大数量，可设置为0~16384，默认为0.这个值表示可以重新利用保存在缓存中线程的数量，当断开连接时如果缓存中还有空间，那么客户端的线程将被放到缓存中;如果线程重新被请求，那么请求将从缓存中读取,如果缓存中是空的或者是新的请求，那么这个线程将被重新创建，如果有很多线程，增加这个值可以改善系统性能。通过比较Connections和Threads_created状态的变量，可以看到这个变量的作用。我们可以根据物理内存设置规则如下:1GB内存我们配置为8,2GB内存我们配置为16,3GB我们配置为32,4GB或4GB以上我们给此值为64或更大的值。 thread_concurrency = 8 # 该参数取值为服务器逻辑CPU数量x 2，在本例中，服务器有两个物理CPU，而每个物理CPU又支持H.T超线程，所以实际取值为4 x 2 = 8。这也是双四核主流服务器的配置。 query_cache_size = 64M # 指定MySQL查询缓冲区的大小。可以通过在MySQL控制台观察，如果Qcache_lowmem_prunes的值非常大，则表明经常出现缓冲不够的情况;如果Qcache_hits的值非常大，则表明查询缓冲使用得非常频繁。另外如果改值较小反而会影响效率，那么可以考虑不用查询缓冲。对于Qcache_free_blocks，如果该值非常大，则表明缓冲区中碎片很多。 query_cache_limit = 2M # 只有小于此设置值的结果才会被缓存 query_cache_min_res_unit = 2k # 设置查询缓存分配内存的最小单位，要适当第设置此参数，可以做到为减少内存快的申请和分配次数，但是设置过大可能导致内存碎片数值上升。默认值为4K，建议设置为1K~16K。 default_table_type = InnoDB # 默认表的类型为InnoDB thread_stack = 256K # 设置MySQL每个线程的堆栈大小，默认值足够大，可满足普通操作。可设置范围为128KB至4GB，默认为192KB #transaction_isolation = Level # 数据库隔离级别 (READ UNCOMMITTED(读取未提交内容) READ COMMITTED(读取提交内容) REPEATABLE READ(可重读) SERIALIZABLE(可串行化)) tmp_table_size = 64M # 设置内存临时表最大值。如果超过该值，则会将临时表写入磁盘，其范围1KB到4GB。 max_heap_table_size = 64M # 独立的内存表所允许的最大容量。 table_cache = 614 # 给经常访问的表分配的内存，物理内存越大，设置就越大。调大这个值，一般情况下可以降低磁盘IO，但相应的会占用更多的内存,这里设置为614。 table_open_cache = 512 # 设置表高速缓存的数目。每个连接进来，都会至少打开一个表缓存。因此， table_cache 的大小应与 max_connections 的设置有关。例如，对于 200 个并行运行的连接，应该让表的缓存至少有 200 × N ，这里 N 是应用可以执行的查询的一个联接中表的最大数量。此外，还需要为临时表和文件保留一些额外的文件描述符。 long_query_time = 1 # 慢查询的执行用时上限,默认设置是10s,推荐(1s~2s) log_long_format # 没有使用索引的查询也会被记录。(推荐,根据业务来调整) log-slow-queries = /data/3306/slow.log # 慢查询日志文件路径(如果开启慢查询,建议打开此日志) log-bin = /data/3306/mysql-bin # logbin数据库的操作日志,例如update、delete、create等都会存储到binlog日志,通过logbin可以实现增量恢复 relay-log = /data/3306/relay-bin # relay-log日志记录的是从服务器I/O线程将主服务器的二进制日志读取过来记录到从服务器本地文件,然后SQL线程会读取relay-log日志的内容并应用到从服务器 relay-log-info-file = /data/3306/relay-log.info # 从服务器用于记录中继日志相关信息的文件,默认名为数据目录中的relay-log.info。 binlog_cache_size = 4M # 在一个事务中binlog为了记录sql状态所持有的cache大小，如果你经常使用大的，多声明的事务，可以增加此值来获取更大的性能，所有从事务来的状态都被缓冲在binlog缓冲中，然后再提交后一次性写入到binlog中，如果事务比此值大，会使用磁盘上的临时文件来替代，此缓冲在每个链接的事务第一次更新状态时被创建。 max_binlog_cache_size = 8M # 最大的二进制Cache日志缓冲尺寸。 max_binlog_size = 1G # 二进制日志文件的最大长度(默认设置1GB)一个二进制文件信息超过了这个最大长度之前,MySQL服务器会自动提供一个新的二进制日志文件接续上。 expire_logs_days = 7 # 超过7天的binlog,mysql程序自动删除(如果数据重要,建议不要开启该选项) key_buffer_size = 256M # 指定用于索引的缓冲区大小，增加它可得到更好的索引处理性能。对于内存在4GB左右的服务器来说，该参数可设置为256MB或384MB。 # 注意：如果该参数值设置得过大反而会使服务器的整体效率降低！ read_buffer_size = 4M # 读查询操作所能使用的缓冲区大小。和sort_buffer_size一样，该参数对应的分配内存也是每个连接独享。 read_rnd_buffer_size = 16M # 设置进行随机读的时候所使用的缓冲区。此参数和read_buffer_size所设置的Buffer相反，一个是顺序读的时候使用，一个是随机读的时候使用。但是两者都是针对与线程的设置，每个线程都可以产生两种Buffer中的任何一个。默认值256KB，最大值4GB。 bulk_insert_buffer_size = 8M # 如果经常性的需要使用批量插入的特殊语句来插入数据,可以适当调整参数至16MB~32MB,建议8MB。 myisam_sort_buffer_size = 8M # 设置在REPAIR Table或用Create index创建索引或 Alter table的过程中排序索引所分配的缓冲区大小，可设置范围4Bytes至4GB，默认为8MB lower_case_table_names = 1 # 实现MySQL不区分大小。(发开需求-建议开启) slave-skip-errors = 1032,1062 # 从库可以跳过的错误数字值(mysql错误以数字代码反馈,全的mysql错误代码大全,以后会发布至博客)。 replicate-ignore-db=mysql # 在做主从的情况下,设置不需要同步的库。 server-id = 1 # 表示本机的序列号为1,如果做主从，或者多实例,serverid一定不能相同。 myisam_sort_buffer_size = 128M # 当需要对于执行REPAIR, OPTIMIZE, ALTER 语句重建索引时，MySQL会分配这个缓存，以及LOAD DATA INFILE会加载到一个新表，它会根据最大的配置认真的分配的每个线程。 myisam_max_sort_file_size = 10G # 当重新建索引（REPAIR，ALTER，TABLE，或者LOAD，DATA，TNFILE）时，MySQL被允许使用临时文件的最大值。 myisam_repair_threads = 1 # 如果一个表拥有超过一个索引, MyISAM 可以通过并行排序使用超过一个线程去修复他们. myisam_recover # 自动检查和修复没有适当关闭的 MyISAM 表. innodb_additional_mem_pool_size = 4M # 用来设置InnoDB存储的数据目录信息和其他内部数据结构的内存池大小。应用程序里的表越多，你需要在这里面分配越多的内存。对于一个相对稳定的应用，这个参数的大小也是相对稳定的，也没有必要预留非常大的值。如果InnoDB用广了这个池内的内存，InnoDB开始从操作系统分配内存，并且往MySQL错误日志写警告信息。默认为1MB，当发现错误日志中已经有相关的警告信息时，就应该适当的增加该参数的大小。 innodb_buffer_pool_size = 64M # InnoDB使用一个缓冲池来保存索引和原始数据，设置越大，在存取表里面数据时所需要的磁盘I/O越少。强烈建议不要武断地将InnoDB的Buffer Pool值配置为物理内存的50%~80%，应根据具体环境而定。 innodb_data_file_path = ibdata1:128M:autoextend # 设置配置一个可扩展大小的尺寸为128MB的单独文件，名为ibdata1.没有给出文件的位置，所以默认的是在MySQL的数据目录内。 innodb_file_io_threads = 4 # InnoDB中的文件I/O线程。通常设置为4，如果是windows可以设置更大的值以提高磁盘I/O innodb_thread_concurrency = 8 # 你的服务器有几个CPU就设置为几，建议用默认设置，一般设为8。 innodb_flush_log_at_trx_commit = 1 # 设置为0就等于innodb_log_buffer_size队列满后在统一存储，默认为1，也是最安全的设置。 innodb_log_buffer_size = 2M # 默认为1MB，通常设置为8~16MB就足够了。 innodb_log_file_size = 32M # 确定日志文件的大小，更大的设置可以提高性能，但也会增加恢复数据库的时间。 innodb_log_files_in_group = 3 # 为提高性能,MySQL可以以循环方式将日志文件写到多个文件。推荐设置为3。 innodb_max_dirty_pages_pct = 90 # InnoDB主线程刷新缓存池中的数据。 innodb_lock_wait_timeout = 120 # InnoDB事务被回滚之前可以等待一个锁定的超时秒数。InnoDB在它自己的锁定表中自动检测事务死锁并且回滚事务。InnoDB用locak tables 语句注意到锁定设置。默认值是50秒。 innodb_file_per_table = 0 # InnoDB为独立表空间模式，每个数据库的每个表都会生成一个数据空间。0关闭，1开启。 # 独立表空间优点： # 1、每个表都有自己独立的表空间。 # 2 、每个表的数据和索引都会存在自己的表空间中。 # 3、可以实现单表在不同的数据库中移动。 # 4、空间可以回收（除drop table操作处，表空不能自己回收。） [mysqldump] quick max_allowed_packet = 2M # 设定在网络传输中一次消息传输量的最大值。系统默认值为1MB，最大值是1GB，必须设置为1024的倍数。单位为字节。 一些建议： 强烈建议不要武断地将InnoDB的Buffer Pool值配置为物理内存的50%~80%，应根据具体环境而定。 如果key_reads太大，则应该把my.cnf中的key_buffer_size变大，保持key_reads/key_read_re-quests至少在1/100以上，越小越好。 如果qcache_lowmem_prunes很大，就要增加query_cache_size的值。 不过很多时候需要具体情况具体分析，其他参数的变更我们可以等MySQL上线稳定一段时间后在根据status值进行调整。 配置范例: 一份电子商务网站MySQL数据库调整后所运行的配置文件/etc/my.cnf(服务器为DELL R710、16GB内存、RAID10)，大家可以根据实际的MySQL数据库硬件情况进行调整配置文件如下： [client] port = 3306 socket = /data/3306/mysql.sock default-character-set = utf8 [mysqld] user = mysql port = 3306 character-set-server = utf8 socket = /data/3306/mysql.sock basedir = /application/mysql datadir = /data/3306/data log-error=/data/3306/mysql_err.log pid-file=/data/3306/mysql.pid log_slave_updates = 1 log-bin = /data/3306/mysql-bin binlog_format = mixed binlog_cache_size = 4M max_binlog_cache_size = 8M max_binlog_size = 1G expire_logs_days = 90 binlog-ignore - db = mysql binlog-ignore - db = information_schema key_buffer_size = 384M sort_buffer_size = 2M read_buffer_size = 2M read_rnd_buffer_size = 16M join_buffer_size = 2M thread_cache_size = 8 query_cache_size = 32M query_cache_limit = 2M query_cache_min_res_unit = 2k thread_concurrency = 32 table_cache = 614 table_open_cache = 512 open_files_limit = 10240 back_log = 600 max_connections = 5000 max_connect_errors = 6000 external-locking = FALSE max_allowed_packet =16M thread_stack = 192K transaction_isolation = READ-COMMITTED tmp_table_size = 256M max_heap_table_size = 512M bulk_insert_buffer_size = 64M myisam_sort_buffer_size = 64M myisam_max_sort_file_size = 10G myisam_repair_threads = 1 myisam_recover long_query_time = 2 slow_query_log slow_query_log_file = /data/3306/slow.log skip-name-resolv skip-locking skip-networking server-id = 1 innodb_additional_mem_pool_size = 16M innodb_buffer_pool_size = 512M innodb_data_file_path = ibdata1:256M:autoextend innodb_file_io_threads = 4 innodb_thread_concurrency = 8 innodb_flush_log_at_trx_commit = 2 innodb_log_buffer_size = 16M innodb_log_file_size = 128M innodb_log_files_in_group = 3 innodb_max_dirty_pages_pct = 90 innodb_lock_wait_timeout = 120 innodb_file_per_table = 0 [mysqldump] quick max_allowed_packet = 64M [mysql] no – auto - rehash 存储引擎的选择关于存储引擎的选择请看博客：MySQL存储引擎之Myisam和Innodb总结性梳理 线上优化调整 MySQL数据库上线后，可以等其稳定运行一段时间后再根据服务器的status状态进行适当优化，我们可以用如下命令列出MySQL服务器运行的各种状态值。通过命令：show global status; 也可以通过 show status like ‘查询%’; 慢查询有时我们为了定位系统中效率比较低下的Query语法，需要打开慢查询日志，也就是Slow Query log。打开慢查询日志的相关命令如下： mysql&gt;show variables like &apos;%slow%&apos;; +---------------------+-----------------------------------------+ | Variable_name | Value | +---------------------+-----------------------------------------+ | log_slow_queries | ON | | slow_launch_time | 2 | +---------------------+-----------------------------------------+ mysql&gt;show global status like &apos;%slow%&apos;; +---------------------+-------+ | Variable_name | Value | +---------------------+-------+ | Slow_launch_threads | 0 | | Slow_queries | 2128 | +---------------------+-------+ 打开慢查询日志可能会对系统性能有一点点影响，如果你的MySQL是主从结构，可以考虑打开其中一台从服务器的慢查询日志，这样既可以监控慢查询，对系统性能影响也会很小。另外，可以用MySQL自带的命令mysqldumpslow进行查询。比如：下面的命令可以查出访问次数最多的20个SQL语句：mysqldumpslow -s c -t 20 host-slow.log 连接数我们如果经常遇见MySQL：ERROR1040：Too many connections的情况，一种情况是访问量确实很高，MySQL服务器扛不住了，这个时候就要考虑增加从服务器分散读压力，从架构层面。另外一种情况是MySQL配置文件中max_connections的值过小。来看一个例子。 mysql&gt; show variables like &apos;max_connections&apos;; +-----------------+-------+ | Variable_name | Value | +-----------------+-------+ | max_connections | 800 | +-----------------+-------+ 这台服务器最大连接数是256，然后查询一下该服务器响应的最大连接数； mysql&gt; show global status like &apos;Max_used_connections&apos;; +----------------------+-------+ | Variable_name | Value | +----------------------+-------+ | Max_used_connections | 245 | +----------------------+-------+ MySQL服务器过去的最大连接数是245，没有达到服务器连接数的上线800，不会出现1040错误。 Max_used_connections /max_connections * 100% = 85%最大连接数占上限连接数的85%左右,如果发现比例在10%以下，则说明MySQL服务器连接数的上限设置得过高了。 key_buffer_sizekey_buffer_size是设置MyISAM表索引缓存空间的大小，此参数对MyISAM表性能影响最大。下面是一台MyISAM为主要存储引擎服务器的配置： mysql&gt; show variables like &apos;key_buffer_size&apos;; +-----------------+-----------+ | Variable_name | Value | +-----------------+-----------+ | key_buffer_size | 536870912 | +-----------------+-----------+ 从上面可以看出，分配了512MB内存给key_buffer_size。再来看key_buffer_size的使用情况： mysql&gt; show global status like &apos;key_read%&apos;; +-------------------+--------------+ | Variable_name | Value | +-------------------+-------+ | Key_read_requests | 27813678766 | | Key_reads | 6798830| +-------------------+--------------+ 一共有27813678766个索引读取请求，有6798830个请求在内存中没有找到，直接从硬盘读取索引。 key_cache_miss_rate = key_reads / key_read_requests * 100% 比如上面的数据，key_cache_miss_rate为0.0244%，4000%个索引读取请求才有一个直接读硬盘，效果已经很好了，key_cache_miss_rate在0.1%以下都很好，如果key_cache_miss_rate在0.01%以下的话，则说明key_buffer_size分配得过多，可以适当减少。 临时表当执行语句时，关于已经被创建了隐含临时表的数量，我们可以用如下命令查询其具体情况： mysql&gt; show global status like &apos;created_tmp%&apos;; +-------------------------+----------+ | Variable_name | Value | +-------------------------+----------+ | Created_tmp_disk_tables | 21119 | | Created_tmp_files | 6 | | Created_tmp_tables | 17715532 | +-------------------------+----------+ MySQL服务器对临时表的配置： mysql&gt; show variables where Variable_name in (&apos;tmp_table_size&apos;,&apos;max_heap_table_size&apos;); +---------------------+---------+ | Variable_name | Value | +---------------------+---------+ | max_heap_table_size | 2097152 | | tmp_table_size | 2097152 | +---------------------+---------+ 每次创建临时表时，Created_tmp_table都会增加，如果磁盘上创建临时表，Created_tmp_disk_tables也会增加。Created_tmp_files表示MySQL服务创建的临时文件数，比较理想的配置是： Created_tmp_disk_tables / Created_tmp_files *100% &lt;= 25% 比如上面的服务器： Created_tmp_disk_tables / Created_tmp_files *100% =1.20%，这个值就很棒了。 打开表的情况Open_tables表示打开表的数量，Opened_tables表示打开过的表数量，我们可以用如下命令查看其具体情况： mysql&gt; show global status like &apos;open%tables%&apos;; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | Open_tables | 351 | | Opened_tables | 1455 | 查询下服务器table_open_cache; mysql&gt; show variables like &apos;table_open_cache&apos;; +------------------+-------+ | Variable_name | Value | +------------------+-------+ | table_open_cache | 2048 | +------------------+-------+ 如果Opened_tables数量过大，说明配置中table_open_cache的值可能太小。 比较合适的值为： open_tables / opened_tables* 100% &gt; = 85% open_tables / table_open_cache* 100% &lt; = 95% 进程使用情况如果我们在MySQL服务器的配置文件中设置了thread_cache_size，当客户端断开时，服务器处理此客户请求的线程将会缓存起来以响应一下客户而不是销毁(前提是缓存数未达上线)Thread_created表示创建过的线程数，我们可以用如下命令查看： mysql&gt; show global status like &apos;thread%&apos;; +-------------------+-------+ | Variable_name | Value | +-------------------+-------+ | Threads_cached | 40| | Threads_connected | 1 | | Threads_created | 330 | | Threads_running | 1 | +-------------------+-------+ 查询服务器thread_cache_size配置如下： mysql&gt; show variables like &apos;thread_cache_size&apos;; +-------------------+-------+ | Variable_name | Value | +-------------------+-------+ | thread_cache_size | 100 | +-------------------+-------+ 如果发现Threads_created的值过大的话，表明MySQL服务器一直在创建线程，这也是比较耗费资源的，可以适当增大配置文件中thread_cache_size的值。 查询缓存(query cache) 它主要涉及两个参数，query_cache_size是设置MySQL的Query Cache大小，query_cache_type是设置使用查询缓存的类型，我们可以用如下命令查看其具体情况： mysql&gt; show global status like &apos;qcache%&apos;; +-------------------------+-----------+ | Variable_name | Value | +-------------------------+-----------+ | Qcache_free_blocks | 22756 | | Qcache_free_memory | 76764704 | | Qcache_hits | 213028692 | | Qcache_inserts | 208894227 | | Qcache_lowmem_prunes | 4010916 | | Qcache_not_cached | 13385031 | | Qcache_queries_in_cache | 43560 | | Qcache_total_blocks | 111212 | +-------------------------+-----------+ MySQL查询缓存变量的相关解释如下： Qcache_free_blocks： 缓存中相领内存快的个数。数目大说明可能有碎片。flush query cache会对缓存中的碎片进行整理，从而得到一个空间块。Qcache_free_memory：缓存中的空闲空间。Qcache_hits：多少次命中。通过这个参数可以查看到Query Cache的基本效果。Qcache_inserts：插入次数，没插入一次查询时就增加1。命中次数除以插入次数就是命中比率。Qcache_lowmem_prunes：多少条Query因为内存不足而被清楚出Query Cache。通过Qcache_lowmem_prunes和Query_free_memory相互结合，能 够更清楚地了解到系统中Query Cache的内存大小是否真的足够，是否非常频繁地出现因为内存不足而有Query被换出的情况。Qcache_not_cached：不适合进行缓存的查询数量，通常是由于这些查询不是select语句或用了now()之类的函数。Qcache_queries_in_cach：当前缓存的查询和响应数量。Qcache_total_blocks：缓存中块的数量。 query_cache的配置命令： mysql&gt; show variables like &apos;query_cache%&apos;; +------------------------------+---------+ | Variable_name | Value | +------------------------------+---------+ | query_cache_limit | 1048576 | | query_cache_min_res_unit | 2048 | | query_cache_size | 2097152 | | query_cache_type | ON | | query_cache_wlock_invalidate | OFF | +------------------------------+---------+ 字段解释如下： query_cache_limit：超过此大小的查询将不缓存。query_cache_min_res_unit：缓存块的最小值。query_cache_size：查询缓存大小。query_cache_type：缓存类型，决定缓存什么样的查询，示例中表示不缓存select sql_no_cache查询。query_cache_wlock_invalidat：表示当有其他客户端正在对MyISAM表进行写操作，读请求是要等WRITE LOCK释放资源后再查询还是允许直接从Query Cache中读取结果，默认为OFF（可以直接从Query Cache中取得结果。）query_cache_min_res_unit的配置是一柄双刃剑，默认是4KB，设置值大对大数据查询有好处，但如果你的查询都是小数据查询，就容易造成内存碎片和浪费。 查询缓存碎片率 = Qcache_free_blocks /Qcache_total_blocks * 100%如果查询碎片率超过20%，可以用 flush query cache 整理缓存碎片，或者试试减少query_cache_min_res_unit，如果你查询都是小数据库的话。查询缓存利用率 = (Qcache_free_size – Qcache_free_memory)/query_cache_size * 100%查询缓存利用率在25%一下的话说明query_cache_size设置得过大，可适当减少;查询缓存利用率在80%以上而且Qcache_lowmem_prunes &gt; 50的话则说明query_cache_size可能有点小，不然就是碎片太多。 查询命中率 = (Qcache_hits - Qcache_insert)/Qcache)hits * 100%示例服务器中的查询缓存碎片率等于20%左右，查询缓存利用率在50%，查询命中率在2%，说明命中率很差，可能写操作比较频繁，而且可能有些碎片。 排序使用情况它表示系统中对数据进行排序时所用的Buffer，我们可以用如下命令查看： mysql&gt; show global status like &apos;sort%&apos;; +-------------------+----------+ | Variable_name | Value | +-------------------+----------+ | Sort_merge_passes | 10 | | Sort_range | 37431240 | | Sort_rows | 6738691532 | | Sort_scan | 1823485 | +-------------------+----------+ Sort_merge_passes包括如下步骤：MySQL首先会尝试在内存中做排序，使用的内存大小由系统变量sort_buffer_size来决定，如果它不够大则把所有的记录都读在内存中，而MySQL则会把每次在内存中排序的结果存到临时文件中，等MySQL找到所有记录之后，再把临时文件中的记录做一次排序。这次再排序就会增加sort_merge_passes。实际上，MySQL会用另外一个临时文件来存储再次排序的结果，所以我们通常会看sort_merge_passes增加的数值是建临时文件数的两倍。因为用到了临时文件，所以速度可能会比较慢，增大sort_buffer_size会减少sort_merge_passes和创建临时文件的次数，但盲目地增大sort_buffer_size并不一定能提高速度。 文件打开数(open_files)我们现在处理MySQL故障时，发现当Open_files大于open_files_limit值时，MySQL数据库就会发生卡住的现象，导致Nginx服务器打不开相应页面。这个问题大家在工作中应注意，我们可以用如下命令查看其具体情况： show global status like ‘open_files’; +—————+——-+ | Variable_name | Value | +—————+——-+ | Open_files | 1481 | +—————+——-+ mysql&gt; show global status like ‘open_files_limit’; +——————+——-+ | Variable_name | Value | +——————+——–+ | Open_files_limit | 4509 | +——————+——–+ 比较合适的设置是：Open_files / Open_files_limit * 100% &lt; = 75% InnoDB_buffer_pool_cache合理设置InnoDB存储引擎的缓存机制和MyISAM的最大区别就在于，InnoDB不仅仅缓存索引，同时还会缓存实际的数据。此参数用来设置InnoDB最主要的Buffer的大小，也就是缓存用户表及索引数据的最主要缓存空间，对InnoDB整体性能影响也最大。无论是MySQL官方手册还是网络上许多人分享的InnoDB优化建议，都是简单地建议将此值设置为整个系统物理内存的50%~80%。这种做法其实不妥，我们应根据实际的运行场景来正确设置此项参数。 很多时候我们会发现，通过参数设置进行性能优化所带来的性能提升，并不如许多人想象的那样会产生质的飞跃，除非是之前的设置存在严重不合理的情况。我们不能将性能调优完全依托与通过DBA在数据库上线后进行参数调整，而应该在系统设计和开发阶段就尽可能减少性能问题。(重点在于前期架构合理的设计及开发的程序合理) MySQL数据库的可扩展架构方案（即高可用方案） 可参考：mysql高可用方案总结性说明如果凭借MySQL的优化任无法顶住压力，这个时候我们就必须考虑MySQL的可扩展性架构了(有人称为MySQL集群)它有以下明显的优势： 1）成本低，很容易通过价格低廉Pc server搭建出一个处理能力非常强大的计算机集群。2）不太容易遇到瓶颈，因为很容易通过添加主机来增加处理能力。3）单节点故障对系统的整体影响较小。 主从复制解决方案这是MySQL自身提供的一种高可用解决方案，数据同步方法采用的是MySQL replication技术。MySQL replication就是从服务器到主服务器拉取二进制日志文件，然后再将日志文件解析成相应的SQL在从服务器上重新执行一遍主服务器的操作，通过这种方式保证数据的一致性。为了达到更高的可用性，在实际的应用环境中，一般都是采用MySQL replication技术配合高可用集群软件keepalived来实现自动failover，这种方式可以实现95.000%的SLA。 在实际应用场景中，MySQL Replication是使用最为广泛的一种提高系统扩展性的设计手段。众多的MySQL使用者通过Replication功能提升系统的扩展性后，通过 简单的增加价格低廉的硬件设备成倍 甚至成数量级地提高了原有系统的性能，是广大MySQL中低端使用者非常喜欢的功能之一，也是许多MySQL使用者选择MySQL最为重要的原因。比较常规的MySQL Replication架构也有好几种，这里分别简单说明下： MySQL Replication架构一：常规复制架构–Master-slaves是由一个Master复制到一个或多个Salve的架构模式，主要用于读压力大的应用数据库端廉价扩展解决方案，读写分离，Master主要负责写方面的压力。MySQL Replication架构二：级联复制架构即Master-Slaves-Slaves,这个也是为了防止Slaves的读压力过大，而配置一层二级 Slaves，很容易解决Master端因为附属slave太多而成为瓶劲的风险。MySQL Replication架构三：Dual Master与级联复制结合架构即Master-Master-Slaves，最大的好处是既可以避免主Master的写操作受到Slave集群的复制带来的影响，而且保证了主Master的单点故障。MySQL Replication的不足：如果Master主机硬件故障无法恢复，则可能造成部分未传送到slave端的数据丢失。所以大家应该根据自己目前的网络 规划，选择自己合理的Mysql架构方案，跟自己的MySQL DBA和程序员多沟涌，多备份(备份我至少会做到本地和异地双备份)，多测试，数据的事是最大的事，出不得半点差错，切记切记 MMM/MHA高可用解决方案MMM提供了MySQL主主复制配置的监控、故障转移和管理的一套可伸缩的脚本套件。在MMM高可用方案中，典型的应用是双主多从架构，通过MySQL replication技术可以实现两个服务器互为主从，且在任何时候只有一个节点可以被写入，避免了多点写入的数据冲突。同时，当可写的主节点故障时，MMM套件可以立刻监控到，然后将服务自动切换到另一个主节点，继续提供服务，从而实现MySQL的高可用。 Heartbeat/SAN高可用解决方案在这个方案中，处理failover的方式是高可用集群软件Heartbeat，它监控和管理各个节点间连接的网络，并监控集群服务，当节点出现故障或者服务不可用时，自动在其他节点启动集群服务。在数据共享方面，通过SAN（Storage Area Network）存储来共享数据，这种方案可以实现99.990%的SLA。 Heartbeat/DRBD高可用解决方案此方案处理failover的方式上依旧采用Heartbeat，不同的是，在数据共享方面，采用了基于块级别的数据同步软件DRBD来实现。DRBD是一个用软件实现的、无共享的、服务器之间镜像块设备内容的存储复制解决方案。和SAN网络不同，它并不共享存储，而是通过服务器之间的网络复制数据。 percona xtradb clusterPercona XtraDB Cluster（简称PXC集群）提供了MySQL高可用的一种实现方法。1）集群是有节点组成的，推荐配置至少3个节点，但是也可以运行在2个节点上。2）每个节点都是普通的mysql/percona服务器，可以将现有的数据库服务器组成集群，反之，也可以将集群拆分成单独的服务器。3）每个节点都包含完整的数据副本。PXC集群主要由两部分组成：Percona Server with XtraDB和Write Set Replication patches（使用了Galera library，一个通用的用于事务型应用的同步、多主复制插件）。 MYSQL经典应用架构 其中：Dbm157是mysql主，dbm158是mysql主的备机，dbs159/160/161是mysql从。MySQL写操作一般采用基于heartbeat+DRBD+MySQL搭建高可用集群的方案。通过heartbeat实现对mysql主进行状态监测，而DRBD实现dbm157数据同步到dbm158。读操作普遍采用基于LVS+Keepalived搭建高可用高扩展集群的方案。前端AS应用通过提高的读VIP连接LVS，LVS有keepliaved做成高可用模式，实现互备。最后，mysql主的从节点dbs159/160/161通过mysql主从复制功能同步mysql主的数据，通过lvs功能提供给前端AS应用进行读操作，并实现负载均衡。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Mysqladmin命令总结]]></title>
      <url>%2F2016%2F03%2F11%2FMysqladmin%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93%2F</url>
      <content type="text"><![CDATA[mysqladmin 工具的使用格式： mysqladmin [option] command [command option] command ...... 参数选项： -c number 自动运行次数统计，必须和 -i 一起使用 -i number 间隔多长时间重复执行 0）每个两秒查看一次服务器的状态，总共重复5次。 [root@test-huanqiu ~]# mysqladmin -uroot -p -i 2 -c 5 status 1）查看服务器的状况：status [root@test-huanqiu ~]# mysqladmin -uroot -p status 2）修改root 密码： [root@test-huanqiu ~]# mysqladmin -u root -p原密码 password &apos;newpassword&apos; 3）检查mysqlserver是否可用： [root@test-huanqiu ~]# mysqladmin -uroot -p ping 4）查询服务器的版本 [root@test-huanqiu ~]# mysqladmin -uroot -p version 5）查看服务器状态的当前值： [root@test-huanqiu ~]# mysqladmin -uroot -p extended-status 6）查询服务器系统变量值： [root@test-huanqiu ~]# mysqladmin -uroot -p variables 7）显示服务器所有运行的进程： [root@test-huanqiu ~]# mysqladmin -uroot -p processlist [root@test-huanqiu ~]# mysqladmin -uroot -p-i 1 processlist 8）创建数据库 [root@test-huanqiu ~]# mysqladmin -uroot -p create daba-test//每秒刷新一次 9）显示服务器上的所有数据库 [root@test-huanqiu ~]# mysqlshow -uroot -p 10）显示数据库daba-test下有些什么表： [root@test-huanqiu ~]# mysqlshow -uroot -p daba-test 11）统计daba-test 下数据库表列的汇总 [root@test-huanqiu ~]# mysqlshow -uroot -p daba-test -v 12）统计daba-test 下数据库表的列数和行数 [root@test-huanqiu ~]# mysqlshow -uroot -p daba-test -v -v 13）删除数据库 daba-test [root@test-huanqiu ~]# mysqladmin -uroot -p drop daba-test 14）重载权限信息 [root@test-huanqiu ~]# mysqladmin -uroot -p reload 15）刷新所有表缓存，并关闭和打开log [root@test-huanqiu ~]# mysqladmin -uroot -p refresh 16）使用安全模式关闭数据库 [root@test-huanqiu ~]# mysqladmin -uroot -p shutdown 17）刷新命令mysqladmin flush commands [root@test-huanqiu ~]# mysqladmin -u root -ptmppassword flush-hosts [root@test-huanqiu ~]# mysqladmin -u root -ptmppassword flush-logs [root@test-huanqiu ~]# mysqladmin -u root -ptmppassword flush-privileges [root@test-huanqiu ~]# mysqladmin -u root -ptmppassword flush-status [root@test-huanqiu ~]# mysqladmin -u root -ptmppassword flush-tables [root@test-huanqiu ~]# mysqladmin -u root -ptmppassword flush-threads 18）mysqladmin 执行kill 进程： [root@test-huanqiu ~]# mysqladmin -uroot -p processlist [root@test-huanqiu ~]# mysqladmin -uroot -p kill idnum 19）停止和启动MySQL replication on a slave server [root@test-huanqiu ~]# mysqladmin -u root -p stop-slave [root@test-huanqiu ~]# mysqladmin -u root -p start-slave 20）同时执行多个命令 [root@test-huanqiu ~]# mysqladmin -u root -p process status version]]></content>
    </entry>

    
  
  
</search>
