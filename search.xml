<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
    
    <entry>
      <title><![CDATA[Nginx配置文件nginx.conf中文详解]]></title>
      <url>http://yoursite.com/2017/04/30/Nginx%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6nginx.conf%E4%B8%AD%E6%96%87%E8%AF%A6%E8%A7%A3/</url>
      <content type="html"><![CDATA[<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div></pre></td><td class="code"><pre><div class="line">#定义Nginx运行的用户和用户组</div><div class="line">user www www;</div><div class="line"></div><div class="line">#nginx进程数，建议设置为等于CPU总核心数。</div><div class="line">worker_processes 8;</div><div class="line"></div><div class="line">#全局错误日志定义类型，[ debug | info | notice | warn | error | crit ]</div><div class="line">error_log /var/log/nginx/error.log info;</div><div class="line"></div><div class="line">&lt;!-- more --&gt;</div><div class="line"></div><div class="line">#进程文件</div><div class="line">pid /var/run/nginx.pid;</div><div class="line"></div><div class="line">#一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（系统的值ulimit -n）与nginx进程数相除，但是nginx分配请求并不均匀，所以建议与ulimit -n的值保持一致。</div><div class="line">worker_rlimit_nofile 65535;</div><div class="line"></div><div class="line">#工作模式与连接数上限</div><div class="line">events</div><div class="line">&#123;</div><div class="line">#参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型是Linux 2.6以上版本内核中的高性能网络I/O模型，如果跑在FreeBSD上面，就用kqueue模型。</div><div class="line">use epoll;</div><div class="line">#单个进程最大连接数（最大连接数=连接数*进程数）</div><div class="line">worker_connections 65535;</div><div class="line">&#125;</div><div class="line"></div><div class="line">#设定http服务器</div><div class="line">http</div><div class="line">&#123;</div><div class="line">include mime.types; #文件扩展名与文件类型映射表</div><div class="line">default_type application/octet-stream; #默认文件类型</div><div class="line">#charset utf-8; #默认编码</div><div class="line">server_names_hash_bucket_size 128; #服务器名字的hash表大小</div><div class="line">client_header_buffer_size 32k; #上传文件大小限制</div><div class="line">large_client_header_buffers 4 64k; #设定请求缓</div><div class="line">client_max_body_size 8m; #设定请求缓</div><div class="line">sendfile on; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。</div><div class="line">autoindex on; #开启目录列表访问，合适下载服务器，默认关闭。</div><div class="line">tcp_nopush on; #防止网络阻塞</div><div class="line">tcp_nodelay on; #防止网络阻塞</div><div class="line">keepalive_timeout 120; #长连接超时时间，单位是秒</div><div class="line"></div><div class="line">#FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。</div><div class="line">fastcgi_connect_timeout 300;</div><div class="line">fastcgi_send_timeout 300;</div><div class="line">fastcgi_read_timeout 300;</div><div class="line">fastcgi_buffer_size 64k;</div><div class="line">fastcgi_buffers 4 64k;</div><div class="line">fastcgi_busy_buffers_size 128k;</div><div class="line">fastcgi_temp_file_write_size 128k;</div><div class="line"></div><div class="line">#gzip模块设置</div><div class="line">gzip on; #开启gzip压缩输出</div><div class="line">gzip_min_length 1k; #最小压缩文件大小</div><div class="line">gzip_buffers 4 16k; #压缩缓冲区</div><div class="line">gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0）</div><div class="line">gzip_comp_level 2; #压缩等级</div><div class="line">gzip_types text/plain application/x-javascript text/css application/xml;</div><div class="line">#压缩类型，默认就已经包含text/html，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。</div><div class="line">gzip_vary on;</div><div class="line">#limit_zone crawler $binary_remote_addr 10m; #开启限制IP连接数的时候需要使用</div><div class="line"></div><div class="line">upstream blog.ha97.com &#123;</div><div class="line">#upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。</div><div class="line">server 192.168.80.121:80 weight=3;</div><div class="line">server 192.168.80.122:80 weight=2;</div><div class="line">server 192.168.80.123:80 weight=3;</div><div class="line">&#125;</div><div class="line"></div><div class="line">#虚拟主机的配置</div><div class="line">server</div><div class="line">&#123;</div><div class="line">#监听端口</div><div class="line">listen 80;</div><div class="line">#域名可以有多个，用空格隔开</div><div class="line">server_name www.ha97.com ha97.com;</div><div class="line">index index.html index.htm index.php;</div><div class="line">root /data/www/ha97;</div><div class="line">location ~ .*\.(php|php5)?$</div><div class="line">&#123;</div><div class="line">fastcgi_pass 127.0.0.1:9000;</div><div class="line">fastcgi_index index.php;</div><div class="line">include fastcgi.conf;</div><div class="line">&#125;</div><div class="line">#图片缓存时间设置</div><div class="line">location ~ .*\.(gif|jpg|jpeg|png|bmp|swf)$</div><div class="line">&#123;</div><div class="line">expires 10d;</div><div class="line">&#125;</div><div class="line">#JS和CSS缓存时间设置</div><div class="line">location ~ .*\.(js|css)?$</div><div class="line">&#123;</div><div class="line">expires 1h;</div><div class="line">&#125;</div><div class="line">#日志格式设定</div><div class="line">log_format access &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos;</div><div class="line">&apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos;</div><div class="line">&apos;&quot;$http_user_agent&quot; $http_x_forwarded_for&apos;;</div><div class="line">#定义本虚拟主机的访问日志</div><div class="line">access_log /var/log/nginx/ha97access.log access;</div><div class="line"></div><div class="line">#对 &quot;/&quot; 启用反向代理</div><div class="line">location / &#123;</div><div class="line">proxy_pass http://127.0.0.1:88;</div><div class="line">proxy_redirect off;</div><div class="line">proxy_set_header X-Real-IP $remote_addr;</div><div class="line">#后端的Web服务器可以通过X-Forwarded-For获取用户真实IP</div><div class="line">proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</div><div class="line">#以下是一些反向代理的配置，可选。</div><div class="line">proxy_set_header Host $host;</div><div class="line">client_max_body_size 10m; #允许客户端请求的最大单文件字节数</div><div class="line">client_body_buffer_size 128k; #缓冲区代理缓冲用户端请求的最大字节数，</div><div class="line">proxy_connect_timeout 90; #nginx跟后端服务器连接超时时间(代理连接超时)</div><div class="line">proxy_send_timeout 90; #后端服务器数据回传时间(代理发送超时)</div><div class="line">proxy_read_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时)</div><div class="line">proxy_buffer_size 4k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小</div><div class="line">proxy_buffers 4 32k; #proxy_buffers缓冲区，网页平均在32k以下的设置</div><div class="line">proxy_busy_buffers_size 64k; #高负荷下缓冲大小（proxy_buffers*2）</div><div class="line">proxy_temp_file_write_size 64k;</div><div class="line">#设定缓存文件夹大小，大于这个值，将从upstream服务器传</div><div class="line">&#125;</div><div class="line"></div><div class="line">#设定查看Nginx状态的地址</div><div class="line">location /NginxStatus &#123;</div><div class="line">stub_status on;</div><div class="line">access_log on;</div><div class="line">auth_basic &quot;NginxStatus&quot;;</div><div class="line">auth_basic_user_file conf/htpasswd;</div><div class="line">#htpasswd文件的内容可以用apache提供的htpasswd工具来产生。</div><div class="line">&#125;</div><div class="line"></div><div class="line">#本地动静分离反向代理配置</div><div class="line">#所有jsp的页面均交由tomcat或resin处理</div><div class="line">location ~ .(jsp|jspx|do)?$ &#123;</div><div class="line">proxy_set_header Host $host;</div><div class="line">proxy_set_header X-Real-IP $remote_addr;</div><div class="line">proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</div><div class="line">proxy_pass http://127.0.0.1:8080;</div><div class="line">&#125;</div><div class="line">#所有静态文件由nginx直接读取不经过tomcat或resin</div><div class="line">location ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt|pdf|xls|mp3|wma)$</div><div class="line">&#123; expires 15d; &#125;</div><div class="line">location ~ .*.(js|css)?$</div><div class="line">&#123; expires 1h; &#125;</div><div class="line">&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>]]></content>
      
        <categories>
            
            <category> nginx </category>
            
        </categories>
        
        
        <tags>
            
            <tag> nginx </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Docker高级（1）--架构总览]]></title>
      <url>http://yoursite.com/2017/03/12/Docker%E9%AB%98%E7%BA%A7%EF%BC%881%EF%BC%89--%E6%9E%B6%E6%9E%84%E6%80%BB%E8%A7%88/</url>
      <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><h3 id="Docker简介"><a href="#Docker简介" class="headerlink" title="Docker简介"></a>Docker简介</h3><p>&#8194;&#8194;&#8194;&#8194;Docker是Docker公司开源的一个基于轻量级虚拟化技术的容器引擎项目,整个项目基于Go语言开发，并遵从Apache 2.0协议。<br><a id="more"></a></p>
<p>&#8194;&#8194;&#8194;&#8194;目前，Docker可以在容器内部快速自动化部署应用，并可以通过内核虚拟化技术（namespaces及cgroups等）来提供容器的资源隔离与安全保障等。由于Docker通过操作系统层的虚拟化实现隔离，所以Docker容器在运行时，不需要类似虚拟机（VM）额外的操作系统开销，提高资源利用率，并且提升诸如IO等方面的性能。<br>&#8194;&#8194;&#8194;&#8194;由于众多新颖的特性以及项目本身的开放性，Docker在不到两年的时间里迅速获得诸多厂商的青睐，其中更是包括Google、Microsoft、VMware等业界行业领导者。Google在今年六月份推出了Kubernetes，提供Docker容器的调度服务，而今年8月Microsoft宣布Azure上支持Kubernetes，随后传统虚拟化巨头VMware宣布与Docker强强合作。今年9月中旬，Docker更是获得4000万美元的C轮融资，以推动分布式应用方面的发展。<br>&#8194;&#8194;&#8194;&#8194;从目前的形势来看，Docker的前景一片大好。本系列文章从源码的角度出发，详细介绍Docker的架构、Docker的运行以及Docker的卓越特性。本文是Docker源码分析系列的第一篇­­­——Docker架构篇。</p>
<h3 id="Docker版本信息"><a href="#Docker版本信息" class="headerlink" title="Docker版本信息"></a>Docker版本信息</h3><p>&#8194;&#8194;&#8194;&#8194;本文关于Docker架构的分析都是基于Docker的源码与Docker相应版本的运行结果，其中Docker为最新的1.2版本。</p>
<h2 id="Docker架构分析内容安排"><a href="#Docker架构分析内容安排" class="headerlink" title="Docker架构分析内容安排"></a>Docker架构分析内容安排</h2><p>&#8194;&#8194;&#8194;&#8194;本文的目的是：在理解Docker源代码的基础上，分析Docker架构。分析过程中主要按照以下三个步骤进行：<br>  ● Docker的总架构图展示<br>  ● Docker架构图内部各模块功能与实现分析<br>  ● 以Docker命令的执行为例，进行Docker运行流程阐述</p>
<h2 id="Docker总架构图"><a href="#Docker总架构图" class="headerlink" title="Docker总架构图"></a>Docker总架构图</h2><p>&#8194;&#8194;&#8194;&#8194;学习Docker的源码并不是一个枯燥的过程，反而可以从中理解Docker架构的设计原理。Docker对使用者来讲是一个C/S模式的架构，而Docker的后端是一个非常松耦合的架构，模块各司其职，并有机组合，支撑Docker的运行。<br>在此，先附上Docker总架构，如图3.1。<br><img src="http://static.zybuluo.com/BruceTang/fwvm0m4xch6xlf4zxi0u1eht/3.1.jpeg" alt="3.1.jpeg-238.3kB"><br>&#8194;&#8194;&#8194;&#8194;如图3.1，不难看出，用户是使用Docker Client与Docker Daemon建立通信，并发送请求给后者。<br>&#8194;&#8194;&#8194;&#8194;而Docker Daemon作为Docker架构中的主体部分，首先提供Server的功能使其可以接受Docker Client的请求；而后Engine执行Docker内部的一系列工作，每一项工作都是以一个Job的形式的存在。<br>&#8194;&#8194;&#8194;&#8194;Job的运行过程中，当需要容器镜像时，则从Docker Registry中下载镜像，并通过镜像管理驱动graphdriver将下载镜像以Graph的形式存储；当需要为Docker创建网络环境时，通过网络管理驱动networkdriver创建并配置Docker容器网络环境；当需要限制Docker容器运行资源或执行用户指令等操作时，则通过execdriver来完成。<br>&#8194;&#8194;&#8194;&#8194;而libcontainer是一项独立的容器管理包，networkdriver以及execdriver都是通过libcontainer来实现具体对容器进行的操作。<br>&#8194;&#8194;&#8194;&#8194;当执行完运行容器的命令后，一个实际的Docker容器就处于运行状态，该容器拥有独立的文件系统，独立并且安全的运行环境等。</p>
<h2 id="Docker架构内各模块的功能与实现分析"><a href="#Docker架构内各模块的功能与实现分析" class="headerlink" title="Docker架构内各模块的功能与实现分析"></a>Docker架构内各模块的功能与实现分析</h2><p>&#8194;&#8194;&#8194;&#8194;接下来，我们将从Docker总架构图入手，抽离出架构内各个模块，并对各个模块进行更为细化的架构分析与功能阐述。主要的模块有：Docker Client、Docker Daemon、Docker Registry、Graph、Driver、libcontainer以及Docker container。</p>
<h3 id="Docker-Client"><a href="#Docker-Client" class="headerlink" title="Docker Client"></a>Docker Client</h3><p>&#8194;&#8194;&#8194;&#8194;Docker Client是Docker架构中用户用来和Docker Daemon建立通信的客户端。用户使用的可执行文件为docker，通过docker命令行工具可以发起众多管理container的请求。<br>&#8194;&#8194;&#8194;&#8194;Docker Client可以通过以下三种方式和Docker Daemon建立通信：tcp://host:port，unix://path_to_socket和fd://socketfd。为了简单起见，本文一律使用第一种方式作为讲述两者通信的原型。与此同时，与Docker &#8194;&#8194;&#8194;&#8194;Daemon建立连接并传输请求的时候，Docker Client可以通过设置命令行flag参数的形式设置安全传输层协议(TLS)的有关参数，保证传输的安全性。<br>&#8194;&#8194;&#8194;&#8194;Docker Client发送容器管理请求后，由Docker Daemon接受并处理请求，当Docker Client接收到返回的请求相应并简单处理后，Docker Client一次完整的生命周期就结束了。当需要继续发送容器管理请求时，用户必须再次通过docker可执行文件创建Docker Client。</p>
<h3 id="Docker-Daemon"><a href="#Docker-Daemon" class="headerlink" title="Docker Daemon"></a>Docker Daemon</h3><p>&#8194;&#8194;&#8194;&#8194;Docker Daemon是Docker架构中一个常驻在后台的系统进程，功能是：接受并处理Docker Client发送的请求。该守护进程在后台启动了一个Server，Server负责接受Docker &#8194;&#8194;&#8194;&#8194;Client发送的请求；接受请求后，Server通过路由与分发调度，找到相应的Handler来执行请求。<br>&#8194;&#8194;&#8194;&#8194;Docker Daemon启动所使用的可执行文件也为docker，与Docker Client启动所使用的可执行文件docker相同。在docker命令执行时，通过传入的参数来判别Docker Daemon与Docker Client。<br>&#8194;&#8194;&#8194;&#8194;Docker Daemon的架构，大致可以分为以下三部分：Docker Server、Engine和Job。Daemon架构如图4.1。<br>  &#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194; 图4.1 Docker Daemon架构示意图<br>  <img src="http://static.zybuluo.com/BruceTang/jzln1v9ufcecae7y9giqqvbj/4.1.jpeg" alt="4.1.jpeg-173.9kB"></p>
<h3 id="Docker-Server"><a href="#Docker-Server" class="headerlink" title="Docker Server"></a>Docker Server</h3><p> &#8194;&#8194;&#8194;&#8194; Docker Server在Docker架构中是专门服务于Docker Client的server。该server的功能是：接受并调度分发Docker Client发送的请求。Docker Server的架构如图4.2。<br> &#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194; 图4.2 Docker Server架构示意图<br> <img src="http://static.zybuluo.com/BruceTang/epr8qkhqg5gwn6ctk70lur7d/4.2.jpeg" alt="4.2.jpeg-157.5kB"></p>
<p> &#8194;&#8194;&#8194;&#8194;在Docker的启动过程中，通过包gorilla/mux，创建了一个mux.Router，提供请求的路由功能。在Golang中，gorilla/mux是一个强大的URL路由器以及调度分发器。该mux.Router中添加了众多的路由项，每一个路由项由HTTP请求方法（PUT、POST、GET或DELETE）、URL、Handler三部分组成。<br>&#8194;&#8194;&#8194;&#8194;若Docker Client通过HTTP的形式访问Docker &#8194;&#8194;&#8194;&#8194;Daemon，创建完mux.Router之后，Docker将Server的监听地址以及mux.Router作为参数，创建一个httpSrv=http.Server{}，最终执行httpSrv.Serve()为请求服务。<br>&#8194;&#8194;&#8194;&#8194;在Server的服务过程中，Server在listener上接受Docker Client的访问请求，并创建一个全新的goroutine来服务该请求。在goroutine中，首先读取请求内容，然后做解析工作，接着找到相应的路由项，随后调用相应的Handler来处理该请求，最后Handler处理完请求之后回复该请求。<br>&#8194;&#8194;&#8194;&#8194;需要注意的是：Docker Server的运行在Docker的启动过程中，是靠一个名为”serveapi”的job的运行来完成的。原则上，Docker Server的运行是众多job中的一个，但是为了强调Docker Server的重要性以及为后续job服务的重要特性，将该”serveapi”的job单独抽离出来分析，理解为Docker Server。</p>
<h3 id="Engine"><a href="#Engine" class="headerlink" title="Engine"></a>Engine</h3><p>&#8194;&#8194;&#8194;&#8194;Engine是Docker架构中的运行引擎，同时也Docker运行的核心模块。它扮演Docker container存储仓库的角色，并且通过执行job的方式来操纵管理这些容器。<br>&#8194;&#8194;&#8194;&#8194;在Engine数据结构的设计与实现过程中，有一个handler对象。该handler对象存储的都是关于众多特定job的handler处理访问。举例说明，Engine的handler对象中有一项为：{“create”: daemon.ContainerCreate,}，则说明当名为”create”的job在运行时，执行的是daemon.ContainerCreate的handler</p>
<h3 id="Job"><a href="#Job" class="headerlink" title="Job"></a>Job</h3><p>&#8194;&#8194;&#8194;&#8194;一个Job可以认为是Docker架构中Engine内部最基本的工作执行单元。Docker可以做的每一项工作，都可以抽象为一个job。例如：在容器内部运行一个进程，这是一个job；创建一个新的容器，这是一个job，从Internet上下载一个文档，这是一个job；包括之前在Docker Server部分说过的，创建Server服务于HTTP的API，这也是一个job，等等。<br>&#8194;&#8194;&#8194;&#8194;Job的设计者，把Job设计得与Unix进程相仿。比如说：Job有一个名称，有参数，有环境变量，有标准的输入输出，有错误处理，有返回状态等</p>
<h3 id="Docker-Registry"><a href="#Docker-Registry" class="headerlink" title="Docker Registry"></a>Docker Registry</h3><p>&#8194;&#8194;&#8194;&#8194;Docker Registry是一个存储容器镜像的仓库。而容器镜像是在容器被创建时，被加载用来初始化容器的文件架构与目录。<br>&#8194;&#8194;&#8194;&#8194;在Docker的运行过程中，Docker Daemon会与Docker Registry通信，并实现搜索镜像、下载镜像、上传镜像三个功能，这三个功能对应的job名称分别为”search”，”pull” 与 “push”。<br>&#8194;&#8194;&#8194;&#8194;其中，在Docker架构中，Docker可以使用公有的Docker Registry，即大家熟知的Docker Hub，如此一来，Docker获取容器镜像文件时，必须通过互联网访问Docker Hub；同时Docker也允许用户构建本地私有的Docker Registry，这样可以保证容器镜像的获取在内网完成</p>
<h3 id="Graph"><a href="#Graph" class="headerlink" title="Graph"></a>Graph</h3><p>&#8194;&#8194;&#8194;&#8194;Graph在Docker架构中扮演已下载容器镜像的保管者，以及已下载容器镜像之间关系的记录者。一方面，Graph存储着本地具有版本信息的文件系统镜像，另一方面也通过GraphDB记录着所有文件系统镜像彼此之间的关系。Graph的架构如图4.3。<br>&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;图4.3 Graph架构示意图<br><img src="http://static.zybuluo.com/BruceTang/f2c2esg9j8i2y21kdth25zmm/4.3.jpeg" alt="4.3.jpeg-217.7kB"><br>&#8194;&#8194;&#8194;&#8194;其中，GraphDB是一个构建在SQLite之上的小型图数据库，实现了节点的命名以及节点之间关联关系的记录。它仅仅实现了大多数图数据库所拥有的一个小的子集，但是提供了简单的接口表示节点之间的关系。<br>&#8194;&#8194;&#8194;&#8194;同时在Graph的本地目录中，关于每一个的容器镜像，具体存储的信息有：该容器镜像的元数据，容器镜像的大小信息，以及该容器镜像所代表的具体rootfs</p>
<h3 id="Driver"><a href="#Driver" class="headerlink" title="Driver"></a>Driver</h3><p>&#8194;&#8194;&#8194;&#8194;Driver是Docker架构中的驱动模块。通过Driver驱动，Docker可以实现对Docker容器执行环境的定制。由于Docker运行的生命周期中，并非用户所有的操作都是针对Docker容器的管理，另外还有关于Docker运行信息的获取，Graph的存储与记录等。<br>&#8194;&#8194;&#8194;&#8194;因此，为了将Docker容器的管理从Docker Daemon内部业务逻辑中区分开来，设计了Driver层驱动来接管所有这部分请求。<br>&#8194;&#8194;&#8194;&#8194;在Docker Driver的实现中，可以分为以下三类驱动：graphdriver、networkdriver和execdriver。<br>&#8194;&#8194;&#8194;&#8194;graphdriver主要用于完成容器镜像的管理，包括存储与获取。即当用户需要下载指定的容器镜像时，graphdriver将容器镜像存储在本地的指定目录；同时当用户需要使用指定的容器镜像来创建容器的rootfs时，graphdriver从本地镜像存储目录中获取指定的容器镜像。<br>&#8194;&#8194;&#8194;&#8194;在graphdriver的初始化过程之前，有4种文件系统或类文件系统在其内部注册，它们分别是aufs、btrfs、vfs和devmapper。而Docker在初始化之时，通过获取系统环境变量”DOCKER_DRIVER”来提取所使用driver的指定类型。而之后所有的graph操作，都使用该driver来执行。<br>graphdriver的架构如图4.4：<br><img src="http://static.zybuluo.com/BruceTang/u6ldju10lxgsc2ieh08wjuj7/4.4.jpeg" alt="4.4.jpeg-144kB"></p>
<p>&#8194;&#8194;&#8194;&#8194;networkdriver的用途是完成Docker容器网络环境的配置，其中包括Docker启动时为Docker环境创建网桥；Docker容器创建时为其创建专属虚拟网卡设备；以及为Docker容器分配IP、端口并与宿主机做端口映射，设置容器防火墙策略等。networkdriver的架构如图4.5：</p>
<p>&#8194;&#8194;&#8194;&#8194;execdriver作为Docker容器的执行驱动，负责创建容器运行命名空间，负责容器资源使用的统计与限制，负责容器内部进程的真正运行等。在execdriver的实现过程中，原先可以使用LXC驱动调用LXC的接口，来操纵容器的配置以及生命周期，而现在execdriver默认使用native驱动，不依赖于LXC。具体体现在Daemon启动过程中加载的ExecDriverflag参数，该参数在配置文件已经被设为”native”。这可以认为是Docker在1.2版本上一个很大的改变，或者说Docker实现跨平台的一个先兆。execdriver架构如图4.6：<br><img src="http://static.zybuluo.com/BruceTang/x701lqh7cz8idszumchpftk7/4.6.jpeg" alt="4.6.jpeg-95.8kB"></p>
<h3 id="libcontainer"><a href="#libcontainer" class="headerlink" title="libcontainer"></a>libcontainer</h3><p>&#8194;&#8194;&#8194;&#8194;libcontainer是Docker架构中一个使用Go语言设计实现的库，设计初衷是希望该库可以不依靠任何依赖，直接访问内核中与容器相关的API。<br>正是由于libcontainer的存在，Docker可以直接调用libcontainer，而最终操纵容器的namespace、cgroups、apparmor、网络设备以及防火墙规则等。这一系列操作的完成都不需要依赖LXC或者其他包。libcontainer架构如图4.7<br><img src="http://static.zybuluo.com/BruceTang/yewf5xufgahy74p9gkiot5bu/4.7.jpeg" alt="4.7.jpeg-128.9kB"></p>
<p>&#8194;&#8194;&#8194;&#8194;另外，libcontainer提供了一整套标准的接口来满足上层对容器管理的需求。或者说，libcontainer屏蔽了Docker上层对容器的直接管理。又由于libcontainer使用Go这种跨平台的语言开发实现，且本身又可以被上层多种不同的编程语言访问，因此很难说，未来的Docker就一定会紧紧地和Linux捆绑在一起。而于此同时，Microsoft在其著名云计算平台Azure中，也添加了对Docker的支持，可见Docker的开放程度与业界的火热度。<br>&#8194;&#8194;&#8194;&#8194;暂不谈Docker，由于libcontainer的功能以及其本身与系统的松耦合特性，很有可能会在其他以容器为原型的平台出现，同时也很有可能催生出云计算领域全新的项目。</p>
<h3 id="Docker-container"><a href="#Docker-container" class="headerlink" title="Docker container"></a>Docker container</h3><p>&#8194;&#8194;&#8194;&#8194;Docker container（Docker容器）是Docker架构中服务交付的最终体现形式。<br>Docker按照用户的需求与指令，订制相应的Docker容器：<br>  ● 用户通过指定容器镜像，使得Docker容器可以自定义rootfs等文件系统；<br>  ● 用户通过指定计算资源的配额，使得Docker容器使用指定的计算资源；<br>  ● 用户通过配置网络及其安全策略，使得Docker容器拥有独立且安全的网络环境；<br>  ● 用户通过指定运行的命令，使得Docker容器执行指定的工作。<br>Docker容器示意图如图4.8：</p>
<p><img src="http://static.zybuluo.com/BruceTang/l0st9jymm96ifjkilt2xvk3c/4.8.jpeg" alt="4.8.jpeg-172.2kB"></p>
<h2 id="Docker运行案例分析"><a href="#Docker运行案例分析" class="headerlink" title="Docker运行案例分析"></a>Docker运行案例分析</h2><p>上一章节着重于Docker架构中各个部分的介绍。本章的内容，将以串联Docker各模块来简要分析，分析原型为Docker中的docker pull与docker run两个命令。</p>
<h3 id="docker-pull"><a href="#docker-pull" class="headerlink" title="docker pull"></a>docker pull</h3><p>&#8194;&#8194;&#8194;&amp;#8194docker pull命令的作用为：从Docker Registry中下载指定的容器镜像，并存储在本地的Graph中，以备后续创建Docker容器时的使用。docker pull命令执行流程如图5.1。<br><img src="http://static.zybuluo.com/BruceTang/je37t67jpqe4d8wi7e0quo86/5.1.jpeg" alt="5.1.jpeg-453.6kB"></p>
<p>如图，图中标记的红色箭头表示docker pull命令在发起后，Docker所做的一系列运行。以下逐一分析这些步骤。<br>(1) Docker Client接受docker pull命令，解析完请求以及收集完请求参数之后，发送一个HTTP请求给Docker Server，HTTP请求方法为POST，请求URL为”/images/create? “+”xxx”；<br>(2) Docker Server接受以上HTTP请求，并交给mux.Router，mux.Router通过URL以及请求方法来确定执行该请求的具体handler；<br>(3) mux.Router将请求路由分发至相应的handler，具体为PostImagesCreate；<br>(4) 在PostImageCreate这个handler之中，一个名为”pull”的job被创建，并开始执行；<br>(5) 名为”pull”的job在执行过程中，执行pullRepository操作，即从Docker Registry中下载相应的一个或者多个image；<br>(6) 名为”pull”的job将下载的image交给graphdriver；<br>(7) graphdriver负责将image进行存储，一方创建graph对象，另一方面在GraphDB中记录image之间的关系。</p>
<h3 id="docker-run"><a href="#docker-run" class="headerlink" title="docker run"></a>docker run</h3><p>&#8194;&#8194;&#8194;docker run命令的作用是在一个全新的Docker容器内部运行一条指令。Docker在执行这条命令的时候，所做工作可以分为两部分：第一，创建Docker容器所需的rootfs；第二，创建容器的网络等运行环境，并真正运行用户指令。因此，在整个执行流程中，Docker Client给Docker Server发送了两次HTTP请求，第二次请求的发起取决于第一次请求的返回状态。Docker run命令执行流程如图5.2。<br><img src="http://static.zybuluo.com/BruceTang/81m0w55hy9f79tmo0d2f6fyb/5.2.jpeg" alt="5.2.jpeg-670.6kB"><br>如图，图中标记的红色箭头表示docker run命令在发起后，Docker所做的一系列运行。以下逐一分析这些步骤。<br>(1) Docker Client接受docker run命令，解析完请求以及收集完请求参数之后，发送一个HTTP请求给Docker Server，HTTP请求方法为POST，请求URL为”/containers/create? “+”xxx”；<br>(2) Docker Server接受以上HTTP请求，并交给mux.Router，mux.Router通过URL以及请求方法来确定执行该请求的具体handler；<br>(3) mux.Router将请求路由分发至相应的handler，具体为PostContainersCreate；<br>(4) 在PostImageCreate这个handler之中，一个名为”create”的job被创建，并开始让该job运行；<br>(5) 名为”create”的job在运行过程中，执行Container.Create操作，该操作需要获取容器镜像来为Docker容器创建rootfs，即调用graphdriver；<br>(6) graphdriver从Graph中获取创建Docker容器rootfs所需要的所有的镜像；<br>(7) graphdriver将rootfs所有镜像，加载安装至Docker容器指定的文件目录下；<br>(8) 若以上操作全部正常执行，没有返回错误或异常，则Docker Client收到Docker Server返回状态之后，发起第二次HTTP请求。请求方法为”POST”，请求URL为”/containers/“+container_ID+”/start”；<br>(9) Docker Server接受以上HTTP请求，并交给mux.Router，mux.Router通过URL以及请求方法来确定执行该请求的具体handler；<br>(10)mux.Router将请求路由分发至相应的handler，具体为PostContainersStart；<br>(11)在PostContainersStart这个handler之中，名为”start”的job被创建，并开始执行；<br>(12)名为”start”的job执行完初步的配置工作后，开始配置与创建网络环境，调用networkdriver；<br>(13)networkdriver需要为指定的Docker容器创建网络接口设备，并为其分配IP，port，以及设置防火墙规则，相应的操作转交至libcontainer中的netlink包来完成；<br>(14)netlink完成Docker容器的网络环境配置与创建；<br>(15)返回至名为”start”的job，执行完一些辅助性操作后，job开始执行用户指令，调用execdriver；<br>(16)execdriver被调用，初始化Docker容器内部的运行环境，如命名空间，资源控制与隔离，以及用户命令的执行，相应的操作转交至libcontainer来完成；<br>(17)libcontainer被调用，完成Docker容器内部的运行环境初始化，并最终执行用户要求启动的命令。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文从Docker 1.2的源码入手，分析抽象出Docker的架构图，并对该架构图中的各个模块进行功能与实现的分析，最后通过两个docker命令展示了Docker内部的运行。<br>通过对Docker架构的学习，可以全面深化对Docker设计、功能与价值的理解。同时在借助Docker实现用户定制的分布式系统时，也能更好地找到已有平台与Docker较为理想的契合点。另外，熟悉Docker现有架构以及设计思想，也能对云计算PaaS领域带来更多的启发，催生出更多实践与创新。</p>
]]></content>
      
        <categories>
            
            <category> Docker </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Markdown语法大全]]></title>
      <url>http://yoursite.com/2017/03/11/Markdown%E8%AF%AD%E6%B3%95%E5%A4%A7%E5%85%A8/</url>
      <content type="html"><![CDATA[<p><strong>题记：随着Markdown语言的热度不断提升，越来越多的人喜欢使用Markdown这种简洁、便宜的语言来编辑自己的blog、文章。下面笔者就一些简单常用的Markdown语句进行介绍，希望对大家在进行Markdown语言编辑自己的文章时有所帮助。</strong></p>
<a id="more"></a>
<h2 id="1-斜体和粗体"><a href="#1-斜体和粗体" class="headerlink" title="1.斜体和粗体"></a>1.斜体和粗体</h2><blockquote>
<p>代码：</p>
</blockquote>
<pre><code>1. *斜体*或_斜体_
2. **粗体**
3. ***加粗斜体***
</code></pre><blockquote>
<p>显示效果：</p>
</blockquote>
<ul>
<li><em>这是一段斜体</em>   </li>
<li><strong>这是一段粗体</strong>   </li>
<li><strong><em>这是一段加粗斜体</em></strong>   </li>
</ul>
<h2 id="2-分级标题"><a href="#2-分级标题" class="headerlink" title="2.分级标题"></a>2.分级标题</h2><blockquote>
<p>第一种写法： </p>
</blockquote>
<pre><code>1.这是一个一级标题   
2.================
3.   
4. 这是一个一级标题   
5. --------------------------
</code></pre><blockquote>
<p>第二种写法：</p>
</blockquote>
<pre><code># 一级标题
## 二级标题
### 三级标题
#### 四级标题
##### 五级标题
###### 六级标题
</code></pre><h2 id="3-超链接"><a href="#3-超链接" class="headerlink" title="3.超链接"></a>3.超链接</h2><h3 id="行内式"><a href="#行内式" class="headerlink" title="行内式"></a>行内式</h3><blockquote>
<p>代码：</p>
</blockquote>
<pre><code>1.欢迎来到[梵居闹市](http:// blog.leanote.com/freewalk)     
2.  
3.欢迎来到[梵居闹市](http:// blog.leanote.com/freewalk &quot;梵居闹市&quot;)   
</code></pre><blockquote>
<p>显示效果：</p>
</blockquote>
<p>欢迎来到<a href="http://blog.leanote.com/freewalk" target="_blank" rel="external">梵居闹市</a><br>欢迎来到<a href="http://blog.leanote.com/freewalk" title="梵居闹市" target="_blank" rel="external">梵居闹市</a></p>
<h3 id="参考式"><a href="#参考式" class="headerlink" title="参考式"></a>参考式</h3><blockquote>
<p>代码：   </p>
</blockquote>
<pre><code>我经常去的几个网站[Google][1]、[Leanote][2]以及[自己的博客][3]    
[Leanote 笔记][2]是一个不错的[网站][]。     
[1]: http://www. google.com &quot;Google&quot;  
[2]:http://www. leanote.com &quot;Leanote&quot;
[3]:http://http:/ /blog.leanote.com/freewalk &quot;梵居闹市&quot;       
[网站]:http: //http://blog.leanote.com/freewalk
</code></pre><blockquote>
<p>显示效果：    </p>
</blockquote>
<p>我经常去的几个网站<a href="Markdown是一种纯文本标记语言">Google</a>、<a href="http://www.leanote.com" title="Leanote" target="_blank" rel="external">Leanote</a>以及<a href="http://http://blog.leanote.com/freewalk" title="梵居闹市" target="_blank" rel="external">自己的博客</a><br><a href="http://www.leanote.com" title="Leanote" target="_blank" rel="external">Leanote 笔记</a>是一个不错的<a href="http://http://blog.leanote.com/freewalk" target="_blank" rel="external">网站</a>。</p>
<h3 id="自动链接"><a href="#自动链接" class="headerlink" title="自动链接"></a>自动链接</h3><blockquote>
<p>代码： </p>
</blockquote>
<pre><code>&lt;http://example.com/&gt;   
&lt;address@example.com&gt;
</code></pre><blockquote>
<p>显示效果：</p>
</blockquote>
<p><a href="http://example.com/" target="_blank" rel="external">http://example.com/</a><br><a href="&#109;&#x61;&#105;&#108;&#116;&#111;&#58;&#97;&#x64;&#x64;&#x72;&#x65;&#x73;&#115;&#64;&#101;&#x78;&#x61;&#109;&#112;&#x6c;&#x65;&#x2e;&#x63;&#x6f;&#109;">&#97;&#x64;&#x64;&#x72;&#x65;&#x73;&#115;&#64;&#101;&#x78;&#x61;&#109;&#112;&#x6c;&#x65;&#x2e;&#x63;&#x6f;&#109;</a></p>
<h2 id="4-锚点"><a href="#4-锚点" class="headerlink" title="4.锚点"></a>4.锚点</h2><blockquote>
<p>代码：  </p>
</blockquote>
<pre><code>跳转到[目录](#index)
</code></pre><blockquote>
<p>显示效果：</p>
</blockquote>
<p>跳转到<a href="#index">目录</a></p>
<h2 id="5-列表"><a href="#5-列表" class="headerlink" title="5.列表"></a>5.列表</h2><h3 id="无序列表"><a href="#无序列表" class="headerlink" title="无序列表"></a>无序列表</h3><ul>
<li><p>使用 *，+，- 表示无序列表。</p>
<blockquote>
<p>代码：  </p>
</blockquote>
<ul>
<li>无序列表项 一</li>
<li>无序列表项 二</li>
<li>无序列表项 三<blockquote>
<p>显示效果：</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<ul>
<li>无序列表项 一</li>
<li>无序列表项 二</li>
<li>无序列表项 三</li>
</ul>
<h3 id="有序列表"><a href="#有序列表" class="headerlink" title="有序列表"></a>有序列表</h3><blockquote>
<p>代码：</p>
</blockquote>
<pre><code>1. 有序列表项 一
2. 有序列表项 二
3. 有序列表项 三
</code></pre><blockquote>
<p>显示效果：</p>
</blockquote>
<ol>
<li>有序列表项 一</li>
<li>有序列表项 二</li>
<li>有序列表项 三</li>
</ol>
<h3 id="列表缩进"><a href="#列表缩进" class="headerlink" title="列表缩进"></a>列表缩进</h3><blockquote>
<p>代码：</p>
</blockquote>
<pre><code>*   轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。
那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。 
软泥上的青荇， 油油的在水底招摇； 在康河的柔波里， 我甘心做一条水草！ 
*   那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。 
寻梦？撑一支长篙， 向青草更青处漫溯； 满载一船星辉， 在星辉斑斓里放歌。 
但我不能放歌， 悄悄是别离的笙箫； 夏虫也为我沉默， 沉默是今晚的康桥！ 
悄悄的我走了， 正如我悄悄的来； 我挥一挥衣袖， 不带走一片云彩
</code></pre><blockquote>
<p>显示效果：</p>
</blockquote>
<ul>
<li>轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。<br>那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。<br>软泥上的青荇， 油油的在水底招摇； 在康河的柔波里， 我甘心做一条水草！ </li>
<li>那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。<br>寻梦？撑一支长篙， 向青草更青处漫溯； 满载一船星辉， 在星辉斑斓里放歌。<br>但我不能放歌， 悄悄是别离的笙箫； 夏虫也为我沉默， 沉默是今晚的康桥！<br>悄悄的我走了， 正如我悄悄的来； 我挥一挥衣袖， 不带走一片云彩</li>
</ul>
<h3 id="包含段落的列表"><a href="#包含段落的列表" class="headerlink" title="包含段落的列表"></a>包含段落的列表</h3><blockquote>
<p>代码：</p>
</blockquote>
<pre><code>*   轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。
那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。 
软泥上的青荇， 油油的在水底招摇； 在康河的柔波里， 我甘心做一条水草！

     那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。 
寻梦？撑一支长篙， 向青草更青处漫溯； 满载一船星辉， 在星辉斑斓里放歌。 
但我不能放歌， 悄悄是别离的笙箫； 夏虫也为我沉默， 沉默是今晚的康桥！


*    悄悄的我走了， 正如我悄悄的来； 我挥一挥衣袖， 不带走一片云彩。
</code></pre><blockquote>
<p>显示效果：</p>
</blockquote>
<ul>
<li><p>轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。<br>那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。<br>软泥上的青荇， 油油的在水底招摇； 在康河的柔波里， 我甘心做一条水草！</p>
<p> 那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。<br>寻梦？撑一支长篙， 向青草更青处漫溯； 满载一船星辉， 在星辉斑斓里放歌。<br>但我不能放歌， 悄悄是别离的笙箫； 夏虫也为我沉默， 沉默是今晚的康桥！ </p>
</li>
<li>悄悄的我走了， 正如我悄悄的来； 我挥一挥衣袖， 不带走一片云彩。</li>
</ul>
<h3 id="包含引用的列表"><a href="#包含引用的列表" class="headerlink" title="包含引用的列表"></a>包含引用的列表</h3><blockquote>
<p>代码：</p>
</blockquote>
<pre><code>*  阅读的方法:（一个空格）
    &gt; 打开书本。
    &gt; 打开电灯。
</code></pre><blockquote>
<p>显示效果：</p>
</blockquote>
<ul>
<li>阅读的方法:<blockquote>
<p>打开书本。<br>打开电灯。</p>
</blockquote>
</li>
</ul>
<h3 id="包含代码区块的引用"><a href="#包含代码区块的引用" class="headerlink" title="包含代码区块的引用"></a>包含代码区块的引用</h3><p><strong>语法说明：</strong><br>如果要放代码区块的话，该区块就需要缩进两次，也就是 8 个空格或是 2 个制表符：   </p>
<ul>
<li><p>一列表项包含一个列表区块： </p>
<pre><code>&lt;代码写在这&gt;
</code></pre></li>
</ul>
<h3 id="一个特殊情况"><a href="#一个特殊情况" class="headerlink" title="一个特殊情况"></a>一个特殊情况</h3><p>在特殊情况下，项目列表很可能会不小心产生，像是下面这样的写法：     </p>
<pre><code>1986. What a great season.
</code></pre><p>会显示成：     </p>
<ol>
<li>What a great season.</li>
</ol>
<p>换句话说，也就是在行首出现数字-句点-空白，要避免这样的状况，你可以在句点前面加上反斜杠：      </p>
<pre><code>1986\. What a great season.
</code></pre><p>会显示成：<br>1986. What a great season.</p>
<h2 id="6-引用"><a href="#6-引用" class="headerlink" title="6. 引用"></a>6. 引用</h2><ul>
<li><p>代码：</p>
<pre><code>&gt; 这是一个有两段文字的引用,
&gt; 无意义的占行文字1.
&gt; 无意义的占行文字2.
&gt; 
&gt; 无意义的占行文字3.
&gt; 无意义的占行文字4
</code></pre></li>
<li>显示效果：  </li>
</ul>
<blockquote>
<p>这是一个有两段文字的引用,<br>无意义的占行文字1.<br>无意义的占行文字2.     </p>
<p>无意义的占行文字3.<br>无意义的占行文字4.     </p>
</blockquote>
<h3 id="引用的多层嵌套"><a href="#引用的多层嵌套" class="headerlink" title="引用的多层嵌套"></a>引用的多层嵌套</h3><ul>
<li><p>代码：</p>
<pre><code>&gt;&gt;&gt; 请问 Markdwon 怎么用？ - 小白

&gt;&gt; 自己看教程！ - 愤青

&gt; 教程在哪？ - 小白
</code></pre></li>
<li>显示效果：</li>
</ul>
<blockquote>
<blockquote>
<blockquote>
<p>请问 Markdwon 怎么用？ - 小白</p>
</blockquote>
<p>自己看教程！ - 愤青</p>
</blockquote>
<p>教程在哪？ - 小白</p>
</blockquote>
<h3 id="引用其它要素"><a href="#引用其它要素" class="headerlink" title="引用其它要素"></a>引用其它要素</h3><ul>
<li><p>代码：</p>
<pre><code>&gt; 1.   这是第一行列表项。
&gt; 2.   这是第二行列表项。
&gt; 
&gt; 给出一些例子代码：
&gt; 
&gt;     return shell_exec(&quot;echo $input | $markdown_script&quot;);
</code></pre></li>
<li>显示效果：</li>
</ul>
<blockquote>
<ol>
<li>这是第一行列表项。</li>
<li>这是第二行列表项。</li>
</ol>
<p>给出一些例子代码：</p>
<pre><code>return shell_exec(&quot;echo $input | $markdown_script&quot;);
</code></pre></blockquote>
<h2 id="7-插入图像"><a href="#7-插入图像" class="headerlink" title="7. 插入图像"></a>7. 插入图像</h2><h3 id="行内式-1"><a href="#行内式-1" class="headerlink" title="行内式"></a>行内式</h3><ul>
<li><p>代码： </p>
<pre><code>高圆圆： 
![高圆圆](ht tp://pic2016.5442.com:82/2015/1117/16/7.jpg%21960.jpg &quot;高圆圆&quot;)
</code></pre></li>
</ul>
<ul>
<li>显示效果</li>
</ul>
<p>高圆圆：<br><img src="http://pic2016.5442.com:82/2015/1117/16/7.jpg%21960.jpg" alt="高圆圆" title="高圆圆"></p>
<h2 id="8-内容目录"><a href="#8-内容目录" class="headerlink" title="8. 内容目录"></a>8. 内容目录</h2><ul>
<li>markdownpad居然不支持该语法，我就呵呵了.<blockquote>
<p>代码：</p>
</blockquote>
</li>
</ul>
<pre><code>[TOC]0.目录   
[TOC]1. 斜体和粗体          
[TOC]2. 分级标题
[TOC]3. 超链接
[TOC]     行内式
[TOC]     参考式
[TOC]    自动链接
[TOC]4. 锚点
</code></pre><h2 id="9-注脚"><a href="#9-注脚" class="headerlink" title="9. 注脚"></a>9. 注脚</h2><blockquote>
<p>代码：</p>
</blockquote>
<pre><code>使用 Markdown[1]可以效率的书写文档,你可以使用 Leanote[Le] 编辑器进行书写。

[1]:Markdown是一种纯文本标记语言

[Le]:开源笔记平台，支持Markdown和笔记直接发为博文
</code></pre><blockquote>
<p>显示效果：</p>
</blockquote>
<p>使用 Markdown<a href="Markdown是一种纯文本标记语言">1</a>可以效率的书写文档,你可以使用 Leanote<a href="开源笔记平台，支持Markdown和笔记直接发为博文">Le</a> 编辑器进行书写。       </p>
<p><br></p>
<p><br></p>
<p>   <strong>原文链接：<a href="http://blog.leanote.com/post/freewalk/Markdown-语法手册" target="_blank" rel="external">http://blog.leanote.com/post/freewalk/Markdown-语法手册</a></strong></p>
]]></content>
      
        <categories>
            
            <category> 博客搭建 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 博客搭建 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Docker 基础（9）--Dockerfile]]></title>
      <url>http://yoursite.com/2017/03/11/Docker%20%E5%9F%BA%E7%A1%80%EF%BC%889%EF%BC%89--Dockerfile/</url>
      <content type="html"><![CDATA[<h2 id="使用Dockerfile构建nginx"><a href="#使用Dockerfile构建nginx" class="headerlink" title="使用Dockerfile构建nginx"></a>使用Dockerfile构建nginx</h2><pre><code>Dockerfile是由一行命令和语句组成的



Dockerfile构建步骤：

[root@tang /]# mkdir /dockerfile/nginx -p
我们要在nginx目录上自动化创建一个nginx镜像
</code></pre><a id="more"></a>
<pre><code>注意：D需要大写，当我们构建dockerfile的时候，docker默认会在我们当前目录读取一个名为Dockerfile的文件。这时候的D必须大写

[root@tang nginx]# cat Dockerfile 
# This Dockerfile
# My Name is TangXiaoyue
# Base image
FROM centos

# Maintainer
MAINTAINE tang 1060336375@qq.com

#Commands
RUN rpm -ivh http://mirrors.aliyun.com/epel/epel-release-latest-7.noarch.rpm
RUN yum install -y nginx &amp;&amp; yum clean all
RUN echo &quot;daemon off;&quot; &gt;&gt;/etc/nginx/nginx.conf
ADD index.html /usr/share/nginx/html/index.html
EXPOSE 80
CMD [&quot;nginx&quot;]


#井号代表注释
#Base image  除了注释的第一行，必须是FROM，意思就是我们需要告诉dockerfile基础镜像是什么
#Maintainer 维护信息

#Commands 命令

#ADD index.html 这个文件需要我们在当前目录下有才可以，我们配置我们可以准备好，然后使用ADD命令进行添加或修改
EXPOSE 对外端口号
CMD [“nginx”] 它要启动的命令是nginx （就算是nginx服务）




我们写好dockerfile还需要一个index.html
[root@tang nginx]#  echo TangXiaoyue &gt;index.html
[root@tang nginx]# ll
total 8
-rw-r--r-- 1 root root 364 Apr  2 20:50 Dockerfile
-rw-r--r-- 1 root root  12 Apr  2 20:52 index.html

使用docker build进行构建
[root@tang ~]# docker build -t nginx_test:v1 /dockerfile/nginx/
[root@tang ~]# docker images
REPOSITORY           TAG                 IMAGE ID            CREATED             SIZE
nginx_test           v1                  bc69ee414a0f        17 seconds ago      280.7 MB


启动镜像
[root@tang ~]# docker run --name nginx_test -d -p 82:80 nginx_test:v1
7a02c27a0a04d34eec8f858e35848416b95572dbb1f485310caee5c185d2e426

[root@tang ~]# curl 127.0.0.1:82
TangXiaoyue
</code></pre><h2 id="Dockerfile参数解释"><a href="#Dockerfile参数解释" class="headerlink" title="Dockerfile参数解释"></a>Dockerfile参数解释</h2><h3 id="FROM"><a href="#FROM" class="headerlink" title="FROM"></a>FROM</h3><pre><code>格式：FROM&lt;image&gt;或FROM&lt;image&gt;:&lt;tag&gt;。

解释：FROM是Dockerfile里的第一条指令（必须是），后面跟有效的镜像名（如果该镜像你的本地仓库没有则会从远程仓库Pull取）。
然后后面的其它指令FROM的镜像中执行。
</code></pre><h3 id="MAINTAINER"><a href="#MAINTAINER" class="headerlink" title="MAINTAINER"></a>MAINTAINER</h3><pre><code>格式：MAINTAINER &lt;name&gt;

    解释：指定维护者信息。
</code></pre><h3 id="RUN"><a href="#RUN" class="headerlink" title="RUN"></a>RUN</h3><pre><code>格式：RUN &lt;command&gt;或 RUN[&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]。

    解释：运行命令，命令较长使可以使用\来换行。推荐使用上面数组的格式
</code></pre><h3 id="CMD"><a href="#CMD" class="headerlink" title="CMD"></a>CMD</h3><pre><code>格式：
CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] 使用 exec 执行，推荐方式；
CMD command param1 param2 在 /bin/sh 中执行，提供给需要交互的应用；
CMD [&quot;param1&quot;,&quot;param2&quot;] 提供给ENTRYPOINT的默认参数；

解释： 
CMD指定容器启动是执行的命令，每个Dockerfile只能有一条CMD命令，如果指定了多条，只有最后一条会被执行。
如果你在启动容器的时候也指定的命令，那么会覆盖Dockerfile构建的镜像里面的CMD命令。
</code></pre><h3 id="ENTRYPOINT"><a href="#ENTRYPOINT" class="headerlink" title="ENTRYPOINT"></a>ENTRYPOINT</h3><pre><code>格式：
   ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;,&quot;param2&quot;]
   ENTRYPOINT command param1 param2（shell中执行）。

解释：和CMD类似都是配置容器启动后执行的命令，并且不可被 docker run 提供的参数覆盖。 

每个 Dockerfile 中只能有一个ENTRYPOINT，当指定多个时，只有最后一个起效。
ENTRYPOINT没有CMD的可替换特性，也就是你启动容器的时候增加运行的命令不会覆盖ENTRYPOINT指定的命令。 
　
所以生产实践中我们可以同时使用ENTRYPOINT和CMD， 

例如：
    ENTRYPOINT [&quot;/usr/bin/rethinkdb&quot;]
    CMD [&quot;--help&quot;]
</code></pre><h3 id="USER"><a href="#USER" class="headerlink" title="USER"></a>USER</h3><pre><code>格式：USER daemon

    解释：指定运行容器时的用户名和UID，后续的RUN指令也会使用这里指定的用户。
</code></pre><h3 id="EXPOSE"><a href="#EXPOSE" class="headerlink" title="EXPOSE"></a>EXPOSE</h3><pre><code>格式：EXPOSE&lt;port&gt; [&lt;port&gt;...]

解释：设置Docker容器内部暴露的端口号，如果需要外部访问，还需要启动容器时增加-p或者-P参数进行分配。
</code></pre><h3 id="ENV"><a href="#ENV" class="headerlink" title="ENV"></a>ENV</h3><pre><code>格式：ENV&lt;key&gt; &lt;value&gt;
ENV &lt;key&gt;=&lt;value&gt; ...

    解释：设置环境变量，可以在RUN之前使用，然后RUN命令时调用，容器启动时这些环境变量都会被指定
</code></pre><h3 id="ADD"><a href="#ADD" class="headerlink" title="ADD"></a>ADD</h3><pre><code>格式：
   ADD &lt;src&gt;... &lt;dest&gt;
   ADD [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;]

    解释：
        将指定的&lt;src&gt;复制到容器文件系统中的&lt;dest&gt; 
           所有拷贝到container中的文件和文件夹权限为0755,uid和gid为0 
        如果文件是可识别的压缩格式，则docker会帮忙解压缩
</code></pre><h3 id="VOLUME"><a href="#VOLUME" class="headerlink" title="VOLUME"></a>VOLUME</h3><pre><code>格式：VOLUME [&quot;/data&quot;]

    解释：可以将本地文件夹或者其他container的文件夹挂载到container中。
</code></pre><h3 id="WORKDIR"><a href="#WORKDIR" class="headerlink" title="WORKDIR"></a>WORKDIR</h3><pre><code>格式：WORKDIR/path/to/workdir

    解释：切换目录，为后续的RUN、CMD、ENTRYPOINT 指令配置工作目录。 
    可以多次切换(相当于cd命令)， 
    也可以使用多个WORKDIR 指令，后续命令如果参数是相对路径，则会基于之前命令指定的路径。例如:

    WORKDIR /a
    WORKDIR b
    WORKDIR c
    RUN pwd
    则最终路径为 /a/b/c。
</code></pre><h3 id="ONBUILD"><a href="#ONBUILD" class="headerlink" title="ONBUILD"></a>ONBUILD</h3><pre><code>ONBUILD 指定的命令在构建镜像时并不执行，而是在它的子镜像中执行
</code></pre><h3 id="ARG"><a href="#ARG" class="headerlink" title="ARG"></a>ARG</h3><pre><code>格式：ARG&lt;name&gt;[=&lt;default value&gt;]

    解释：ARG指定了一个变量在docker build的时候使用，
         可以使用--build-arg &lt;varname&gt;=&lt;value&gt;来指定参数的值，不过如果构建的时候不指定就会报错。
</code></pre>]]></content>
      
        <categories>
            
            <category> Docker </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Docker 基础（7）--数据管理]]></title>
      <url>http://yoursite.com/2017/03/11/Docker%20%E5%9F%BA%E7%A1%80%EF%BC%887%EF%BC%89--%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86/</url>
      <content type="html"><![CDATA[<h4 id="挂载本地目录到容器里"><a href="#挂载本地目录到容器里" class="headerlink" title="挂载本地目录到容器里"></a>挂载本地目录到容器里</h4><pre><code>[root@tang /]# mkdir /data/docker -p
root@tang docker]# mkdir docker_01
[root@tang docker]# docker run -it -h docker_01 --name docker_01 -v /data/docker/docker_01/:/docker_01 centos bash
[root@docker_01 /]# cd /docker_01/        
[root@docker_01 docker_01]# touch docker_01.txt
</code></pre><a id="more"></a>
<pre><code>[root@docker_01 docker_01]# exit
exit
[root@tang docker]# cd /data/docker/docker_01/
[root@tang docker_01]# ll
total 0
-rw-r--r-- 1 root root 0 Apr  3 08:03 docker_01.txt

[root@tang docker_01]# cd ..
[root@tang docker]# mkdir docker_02
[root@tang docker]# docker run -it -h docker_02 --name docker_02 -v /data/docker/docker_02/:/docker_02 centos bash
[root@docker_02 /]# cd /docker_02/
[root@docker_02 docker_02]# mkdir docker_02.txt
[root@docker_02 docker_02]# exit
exit
[root@tang docker]# cd docker_02/
[root@tang docker_02]# ll
total 4
drwxr-xr-x 2 root root 4096 Apr  3 08:05 docker_02.txt

提示：    
      -v: 指定挂载目录
      : : 前面的为本地目录
      : : 后面到为容器里的目录
      即使将删除这个容器,文件也不会丢失.
</code></pre><h4 id="挂载数据卷-多个容器挂载宿主机的同一个目录"><a href="#挂载数据卷-多个容器挂载宿主机的同一个目录" class="headerlink" title="挂载数据卷(多个容器挂载宿主机的同一个目录)"></a>挂载数据卷(多个容器挂载宿主机的同一个目录)</h4><pre><code>[root@tang data]# docker run -it -h docker_03 --name docker_03
--volumes-from docker_01 centos bash
[root@docker_03 /]# cd /docker_01/
[root@docker_03 docker_01]# ll
total 0
-rw-r--r-- 1 root root 0 Apr  3 00:03 docker_01.txt
[root@docker_03 docker_01]# df -h|grep docker_01
/dev/vda1                           99G  5.4G   88G   6% /docker_01
[root@docker_03 docker_01]# echo &quot;This is Doceker_3&quot; &gt; /docker_01/3.txt
[root@docker_03 docker_01]# ll
total 4
-rw-r--r-- 1 root root 18 Apr  3 00:26 3.txt
-rw-r--r-- 1 root root  0 Apr  3 00:03 docker_01.txt
[root@tang ~]# docker start docker_01
docker_01
[root@tang ~]# docker-enter docker_01
[root@docker_01 ~]# cd /docker_01/
[root@docker_01 docker_01]# ll
total 4
-rw-r--r-- 1 root root 18 Apr  3 00:26 3.txt
-rw-r--r-- 1 root root  0 Apr  3 00:03 docker_01.txt
</code></pre><h4 id="自定义数据卷容器"><a href="#自定义数据卷容器" class="headerlink" title="自定义数据卷容器"></a>自定义数据卷容器</h4><pre><code>[root@tang ~]# docker run -itd -h node --name node -v /data centos bash
056ac10e28855c3d29a94fe552711e6a712a5670e6e9c43c4b79270cbc6b0a0f
                #这里的/data是容器node的/data目录,而不是宿主机的/data目录

[root@tang ~]# docker-enter node
[root@node ~]#  touch /data/1 /data/2 /data/3
[root@node ~]# cd /data/
[root@node data]# ll
total 0
-rw-r--r-- 1 root root 0 Apr  3 01:00 1
-rw-r--r-- 1 root root 0 Apr  3 01:00 2
-rw-r--r-- 1 root root 0 Apr  3 01:00 3
[root@node data]# exit
logout
[root@tang ~]# docker run -itd -h node1 --name node1 --volumes-from node centos bash
2965a8f1184a7a1cbd26ef07e4b3d201fa17e5b68a52c619d6292da75c85d117
[root@tang ~]# docker-enter node1
[root@node1 ~]# cd /data/
[root@node1 data]# ll
total 0
-rw-r--r-- 1 root root 0 Apr  3 01:00 1
-rw-r--r-- 1 root root 0 Apr  3 01:00 2
-rw-r--r-- 1 root root 0 Apr  3 01:00 3
[root@node1 data]# touch 4
[root@node data]# ll
total 0
-rw-r--r-- 1 root root 0 Apr  3 01:00 1
-rw-r--r-- 1 root root 0 Apr  3 01:00 2
-rw-r--r-- 1 root root 0 Apr  3 01:00 3
-rw-r--r-- 1 root root 0 Apr  3 01:02 4
</code></pre><h4 id="数据卷的备份"><a href="#数据卷的备份" class="headerlink" title="数据卷的备份"></a>数据卷的备份</h4><pre><code>[root@docker ~]# mkdir /docker_data_backup
[root@docker ~]# docker run -itd -h tang --name tang -v /docker_data_backup/:/backup centos bash
250da7a47222e52c5a5d387ff8ce816a72b221ffb8d481739c4c68073507fe
[root@docker ~]# docker-enter tang
[root@tang ~]# mkdir /data
[root@tang ~]# touch /data/{1,2,3,4}
[root@tang ~]# tar cvf /backup/data.tar /data/
[root@tang ~]# cd /backup/
[root@tang backup]# ll
total 12
-rw-r--r-- 1 root root 10240 Apr  3 01:30 data.tar
[root@tang backup]# exit
logout
[root@docker ~]# cd /docker_data_backup/
[root@docker docker_data_backup]# ll
total 12
-rw-r--r-- 1 root root 10240 Apr  3 09:30 data.tar
</code></pre><h4 id="数据卷的恢复"><a href="#数据卷的恢复" class="headerlink" title="数据卷的恢复"></a>数据卷的恢复</h4><pre><code>[root@docker ~]# mkdir /docker_data_backup
[root@docker ~]# docker run -itd -h tang --name tang -v /docker_data_backup/:/backup centos bash
3728f6b0a6e5b47f904de0474db7d4479f33e87740906e1539eca385c3fab04d
[root@docker ~]# docker-enter tang
[root@tang ~]# mkdir /tools/
[root@tang ~]# touch /tools/{1,2,3,4}
[root@tang ~]# tar zcvf /backup/tools.tar /tools/
/tools/
/tools/1
/tools/2
/tools/3
/tools/4
[root@tang ~]# ll /backup/
total 4
-rw-r--r-- 1 root root 162 Apr  3 02:08 tools.tar
[root@tang ~]# exit
logout

[root@docker ~]# docker run -itd -h tang1 --name tang1 -v /tang1 centos bash
7ec371bb67f136234878771c227c4245a0ccf6c986e8c94a412d6c4111852a2b
[root@docker ~]# docker run -itd -h tang2 --name tang2 --volumes-from tang1 -v /docker_data_backup/:/backup centos bash
53e4cea1c45f3c081a6dd95b935f906aa037e6ed2170b6249a913ccd6fb4c119
[root@docker ~]# docker-enter tang2
[root@tang2 ~]# ll /backup/
total 4
-rw-r--r-- 1 root root 162 Apr  3 02:08 tools.tar
[root@tang2 tang1]# tar xvf /backup/tools.tar -C /tang1
[root@tang2 tang1]# exit
logout
[root@docker ~]# docker-enter tang1
[root@tang1 ~]# cd /tang1/
[root@tang1 tang1]# ll
total 4
drwxr-xr-x 2 root root 4096 Apr  3 02:07 tools
</code></pre>]]></content>
      
        <categories>
            
            <category> Docker </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Docker问题梳理--持续更新]]></title>
      <url>http://yoursite.com/2017/03/11/Docker%E9%97%AE%E9%A2%98%E6%A2%B3%E7%90%86/</url>
      <content type="html"><![CDATA[<h3 id="关于systemctl无法启动服务的问题处理"><a href="#关于systemctl无法启动服务的问题处理" class="headerlink" title="关于systemctl无法启动服务的问题处理"></a>关于systemctl无法启动服务的问题处理</h3><pre><code>问题：

使用systemctl启动服务的时候出现以下异常：

Failed to get D-Bus connection: Operation not permitted 


解决：

docker run --privileged -itd -h node1 --name node1 centos /sbin/init
</code></pre>]]></content>
      
        <categories>
            
            <category> Docker </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Docker 基础（2）--命令]]></title>
      <url>http://yoursite.com/2017/03/11/Docker%E5%9F%BA%E7%A1%80%EF%BC%882%EF%BC%89--%E5%91%BD%E4%BB%A4/</url>
      <content type="html"><![CDATA[<h3 id="安装下载"><a href="#安装下载" class="headerlink" title="安装下载"></a>安装下载</h3><pre><code>yum install -y docker                                    #下载
systemctl start docker                                    #启动
systemctl enable docker                                    #自启动
</code></pre><a id="more"></a>
<h3 id="镜像操作"><a href="#镜像操作" class="headerlink" title="镜像操作"></a>镜像操作</h3><pre><code>docker search  images                                    #搜索镜像
docker pull images                                    #下载镜像
docker    images                                    #查看镜像
docker tag centos6  centos6_x86                                    #镜像改名
docker save image&gt;/opt/images.tar.gz                                    #导出镜像
docker load&lt;/opt/images.tar.gz                                    #导入镜像
docker load --input /opt/images.tar.gz                                            #导入镜像
docker rmi images_id                                                            #删除镜像
docker rmi $(docker images -q)                                                    #删除所有镜像
</code></pre><h3 id="容器操作"><a href="#容器操作" class="headerlink" title="容器操作"></a>容器操作</h3><pre><code>docker ps -a                                                                    #查看容器
docker run centos /bin/echo &quot;hehe&quot;                                                #首次创建一个容器
docekr run -h tang --name tang -t -i centos /bin/bah                            #创建一个以tang为名的容器；
                                                                                    --name：指定容器名    
                                                                                    -t：分配一个tty终端    
                                                                                    -i：容器的标准输出保持打开状态 
                                                                                    -h:指定主机名
docker create -it --name centos1 centos                                            #使用create创建容器
docekr stop ID（name）                                                            #停止容器
docker start ID（name）                                                            #启动容器
docker attach ID（name）                                                            #进入容器
docker exec -it ID(name)  /bin/bash
docker rm  ID（name）                                                            #删除容器    
                                                                                    -f：强制删除容器，包括在运行的
                                                                                #exec和attach总结: 
                                                                                    attach登陆容器后,退出时容器会关闭. 
                                                                                    推荐使用exec进入容器
docker rm $(docker ps -a -q)                                                    #删除所有容器
</code></pre><h3 id="映射"><a href="#映射" class="headerlink" title="映射"></a>映射</h3><pre><code>docker run --name nginx -d -P nginx                                                #随机映射 
docker run --name nginx -d -p 81:80 nginx                                         #指定映射
docker run -it --name nginx -p 80:80 nginx /bin/bash                            #指定映射
</code></pre><h3 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h3><pre><code>docker logs ID（name）                                                            #查看日志
</code></pre><h3 id="数据管理"><a href="#数据管理" class="headerlink" title="数据管理"></a>数据管理</h3><pre><code>docker run -it --name tang -v /data centos                                         #默认挂载目录
docekr inspect ID(name)                                                            #查看容器信息
                                                                                    ==查看mounts模块
docekr run -it --name tang -v /data:/data centos                                   #指定挂载目录
docker run -it --name tang -v /data:/data:rw centos                                 #指定权限挂载
                                                                                    ==rw：读写
docker run -it --name tang -v /data:/data:ro centos                             #指定权限挂载
                                                                                ==ro：只读
docker run -it --name tang  ~/.bash_history:/.bash_history centos                #记录历史记录
</code></pre><h3 id="数据卷容器"><a href="#数据卷容器" class="headerlink" title="数据卷容器"></a>数据卷容器</h3><pre><code>docker run -d --name nfs -v /data:/data centos                                     #启动nfs容器，挂在一个卷，
                                            -d：直接在后台执行
docker run -it --name test1 --volumes-from nfs centos                            #启动test1容器，挂载到nfs的数据卷容器上
docker run -it --name test2 --volumes-from nfs centos                             #启动test2容器，挂载到nfs的数据卷容器上
                                        #test1和test2的/data数据可以共享
</code></pre><h3 id="手动制作镜像"><a href="#手动制作镜像" class="headerlink" title="手动制作镜像"></a>手动制作镜像</h3><pre><code>docker run -it --name mynginx centos                                            #基础centos进行创建容器mynginx
</code></pre><h2 id="在mynginx容器内安装nginx"><a href="#在mynginx容器内安装nginx" class="headerlink" title="在mynginx容器内安装nginx"></a>在mynginx容器内安装nginx</h2><pre><code>rpm -ivh http://mirrors.aliyun.com/epel/epel-release-latest-7.noarch.rpm
yum install -y nginx
docker commit -m &quot;my nginx&quot; f9c7dfb6f552 tang/mynginx:v1                        #提交镜像，
                                            ==同时打一个标签叫mynginx:v1
                                            ==tang相当于你向github上提交的用户名
docker run -it --anme nginxv1 tang/mynginx:v1                                    #基于镜像tang/mynginx:v1创建容器nginxv1
```
</code></pre>]]></content>
      
        <categories>
            
            <category> Docker </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Docker 基础（3）--容器登入]]></title>
      <url>http://yoursite.com/2017/03/11/Docker%20%E5%9F%BA%E7%A1%80%EF%BC%883%EF%BC%89--%E5%AE%B9%E5%99%A8%E7%99%BB%E5%85%A5/</url>
      <content type="html"><![CDATA[<h3 id="docker-enter登入容器"><a href="#docker-enter登入容器" class="headerlink" title="docker-enter登入容器"></a>docker-enter登入容器</h3><blockquote>
<p>强烈推荐使用此种方法：简单、方便</p>
</blockquote>
<pre><code>下载.bashrc_docker，并将内容放到.bashrc中。

这个文件中定义了很多方便使用Docker的命令，比如docker-pid可以获取某个容器的 PID；
而 docker-enter 可以进入容器或直接在容器内执行命令
</code></pre><a id="more"></a>
<pre><code>[root@tang ~]# wget -P ~ https://github.com/yeasy/docker_practice/raw/master/_local/.bashrc_docker

[root@tang ~]# echo &quot;[ -f ~/.bashrc_docker ] &amp;&amp; . ~/.bashrc_docker&quot; &gt;&gt; ~/.bashrc; source ~/.bashrc


[root@tang ~]# docker-
docker-containerd               docker-ctr-current              docker-pid
docker-containerd-current       docker-current                  docker-storage-setup
docker-containerd-shim          docker-enter                    
docker-containerd-shim-current  docker-ip 

[root@tang ~]# docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
e657e9214a57        centos              &quot;/bin/bash&quot;         24 minutes ago      Up 23 minutes                           tang

[root@tang ~]# docker-pid tang
19271

[root@tang ~]# nsenter --target 19271  --mount --uts --ipc --net --pid  #此种方法进入容器以下会讲到
[root@test /]# exit
logout

[root@tang ~]# docker-ip tang
172.18.0.2

直接使用docker-enter命令进入容器，非常方便！
[root@tang ~]# docker-enter tang
Last login: Sun Apr  2 06:38:47 UTC 2017

[root@test ~]# exit
logout

[root@tang ~]# docker ps   #退出登陆窗口后，容器还在
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
e657e9214a57        centos              &quot;/bin/bash&quot;         26 minutes ago      Up 9 seconds                            tang

注意：以在容器的上下文中运行任意命令！即在宿主机上执行容器里的命令

[root@tang ~]# docker-enter tang uptime
 07:06:28 up 1 day, 22:44,  0 users,  load average: 0.00, 0.01, 0.05

注意：在宿主机上使用docker-enter命令执行容器中的命令时，最好后面加上--符号，这样容器里的所有存在的命令都可以正常执行。
[root@tang ~]# docker-enter tang -- uptime

 07:06:59 up 1 day, 22:45,  0 users,  load average: 0.00, 0.01, 0.05

[root@tang ~]# docker-enter tang -- df -h
Filesystem                                                                                         Size  Used Avail Use% Mounted on
/dev/mapper/docker-253:1-2024335-661487685eb1f6a356157463d60db20caa2c1fb3ac273de680c367e3b12dabab   10G  238M  9.8G   3% /
tmpfs                                                                                              920M     0  920M   0% /dev
tmpfs                                                                                              920M     0  920M   0% /sys/fs/cgroup
/dev/vda1                                                                                           99G  4.7G   89G   5% /etc/hosts
shm                                                                                                 64M     0   64M   0% /dev/shm

[root@tang ~]# cat /etc/redhat-release 
CentOS Linux release 7.2.1511 (Core) 

[root@tang ~]# docker-enter tang -- cat /etc/redhat-release 
CentOS Linux release 7.3.1611 (Core)
</code></pre><h3 id="nsenter登入容器"><a href="#nsenter登入容器" class="headerlink" title="nsenter登入容器"></a>nsenter登入容器</h3><pre><code>使用外部工具nsenter登陆容器，该工具和docker exec命令的效果差不多。

使用nsenter或dockerexec，都可以在容器的上下文（严格地说，是命名空间）中运行任意命令！


==nsenter安装：
[root@tang ~]#  yum install util-linux -y 


==nsenter使用：
[root@tang ~]# docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
e657e9214a57        centos              &quot;/bin/bash&quot;         50 minutes ago      Up 24 minutes                           tang

[root@tang ~]# docker inspect -f &quot;{{ .State.Pid }}&quot; tang
19271

[root@tang ~]# nsenter -t 19271  -m -u -i -n -p

解释nsenter指令中进程id之后的参数的含义：

–mount参数是进去到mount namespace中 
–uts参数是进入到uts namespace中 
–ipc参数是进入到System V IPC namaspace中 
–net参数是进入到network namespace中 
–pid参数是进入到pid namespace中 
–user参数是进入到user namespace中

[root@tang ~]#  nsenter --help

Usage:
 nsenter [options] &lt;program&gt; [&lt;argument&gt;...]

Run a program with namespaces of other processes.

Options:
 -t, --target &lt;pid&gt;     target process to get namespaces from
 -m, --mount[=&lt;file&gt;]   enter mount namespace
 -u, --uts[=&lt;file&gt;]     enter UTS namespace (hostname etc)
 -i, --ipc[=&lt;file&gt;]     enter System V IPC namespace
 -n, --net[=&lt;file&gt;]     enter network namespace
 -p, --pid[=&lt;file&gt;]     enter pid namespace
 -U, --user[=&lt;file&gt;]    enter user namespace
 -S, --setuid &lt;uid&gt;     set uid in entered namespace
 -G, --setgid &lt;gid&gt;     set gid in entered namespace
     --preserve-credentials do not touch uids or gids
 -r, --root[=&lt;dir&gt;]     set the root directory
 -w, --wd[=&lt;dir&gt;]       set the working directory
 -F, --no-fork          do not fork before exec ing &lt;program&gt;
 -Z, --follow-context   set SELinux context according to --target PID
 -h, --help     display this help and exit
 -V, --version  output version information and exit

我们进入容器中查看进程 
以下是以nsenter启动的进程
[root@test /]# ps aux
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root         1  0.0  0.0  11768  1684 ?        Ss+  07:03   0:00 /bin/bash
root        77  0.0  0.1  15200  1988 ?        S    07:31   0:00 -bash
root        90  0.0  0.0  50872  1816 ?        R+   07:31   0:00 ps aux

/bin/bash是我们运行容器产生的进程
-bash 是我们使用nsenter产生的，这样如果我们退出容器，容器就不会退出，因为-bash还在运行

[root@test /]# exit
logout

[root@tang ~]# docker ps 
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
e657e9214a57        centos              &quot;/bin/bash&quot;         55 minutes ago      Up 29 minutes                           tang

因为每次进入容器都需要输入那两条命令，所以我们可以写一个脚本来获取。 

==脚本内容如下：
[root@tang opt]# cat docker_in.sh 
#!/bin/bash
# Use nsenter to access docker
docker_in(){
  NAME_ID=$1
  PID=$(docker inspect -f &quot;{{ .State.Pid }}&quot; $NAME_ID)
  nsenter -t $PID -m -u -i -n -p
}
docker_in $1

[root@tang opt]# chmod +x docker_in.sh 
[root@tang opt]# ./docker_in.sh tang
[root@test /]# ps -ef
UID        PID  PPID  C STIME TTY          TIME CMD
root         1     0  0 07:03 ?        00:00:00 /bin/bash
root        91     0  0 07:34 ?        00:00:00 -bash
root       104    91  0 07:34 ?        00:00:00 ps -ef
[root@test /]# exit
logout
[root@tang opt]# docker exec tang ps -ef
UID        PID  PPID  C STIME TTY          TIME CMD
root         1     0  0 07:03 ?        00:00:00 /bin/bash
root       105     0  0 07:35 ?        00:00:00 ps -ef


我们还可以使用exec进入docker容器中

[root@tang opt]# docker exec -it tang /bin/bash
</code></pre><h3 id="start-ai登入容器"><a href="#start-ai登入容器" class="headerlink" title="start -ai登入容器"></a>start -ai登入容器</h3><pre><code>对于一个已关闭的容器的登陆，可以使用&quot;docker start -ai container&quot;登陆。这种其实就是先启动容器，然后再进入容器内。

[root@tang ~]# docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                      PORTS               NAMES
e657e9214a57        centos              &quot;/bin/bash&quot;         About an hour ago   Exited (0) 53 seconds ago                       tang

[root@tang ~]# docker start -ai tang   #-a -i 都可以
[root@test /]# exit
exit
[root@tang ~]# docker start -i tang
[root@tang ~]# docker start -a tang
</code></pre><h3 id="docker-exec登入容器"><a href="#docker-exec登入容器" class="headerlink" title="docker exec登入容器"></a>docker exec登入容器</h3><pre><code>使用自带命令docker exec登陆容器

命令格式：docker exec -ti container_id /bin/bash

[root@tang ~]# docker ps    #前提是容器已经启动
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
e657e9214a57        centos              &quot;/bin/bash&quot;         About an hour ago   Up 2 minutes                            tang
[root@tang ~]# docker exec -it tang /bin/bash
[root@test /]# exit
</code></pre><h3 id="docker-attach登入容器"><a href="#docker-attach登入容器" class="headerlink" title="docker attach登入容器"></a>docker attach登入容器</h3><pre><code>使用自带命令docker attach登陆容器。

命令格式：docker attach container_id

[root@tang ~]# docker ps   #前提容器已经启动了
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
e657e9214a57        centos              &quot;/bin/bash&quot;         About an hour ago   Up 5 minutes                            tang
[root@tang ~]# docker attach tang
[root@test /]# exit
</code></pre><h3 id="ssh登入容器"><a href="#ssh登入容器" class="headerlink" title="ssh登入容器"></a>ssh登入容器</h3><pre><code>使用ssh登陆容器。这种方法需要在容器中启动sshd，存在开销和攻击面增大的问题。同时也违反了Docker所倡导的一个容器一个进程的原则

ssh登入会专门写一篇文章介绍。这里就不叙述了
</code></pre>]]></content>
      
        <categories>
            
            <category> Docker </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Docker 基础（4）--镜像管理]]></title>
      <url>http://yoursite.com/2017/03/11/Docker%20%E5%9F%BA%E7%A1%80%EF%BC%884%EF%BC%89--%E9%95%9C%E5%83%8F%E7%AE%A1%E7%90%86/</url>
      <content type="html"><![CDATA[<h3 id="使用容器生成镜像"><a href="#使用容器生成镜像" class="headerlink" title="使用容器生成镜像"></a>使用容器生成镜像</h3><pre><code>[root@tang ~]# docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
</code></pre>  <a id="more"></a>
<pre><code>[root@tang ~]# docker run -it -h nginx --name nginx  centos  /bin/bash

[root@nginx /]# rpm -ivh
http://mirrors.aliyun.com/epel/epel-release-latest-7.noarch.rpm

[root@nginx /]# yum install -y nginx

[root@tang ~]# docker ps -a 
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                      PORTS               NAMES
e46c71171306        centos              &quot;/bin/bash&quot;         2 minutes ago       Exited (0) 40 seconds ago                       nginx

[root@tang ~]# docker commit -m &quot;my nginx&quot; -a &quot;tang&quot; e46c71171306 new_nginx:v1
sha256:c15ceb0a6871e3a56e3b22d67254d09b2e03a8ae909719a6dea0daaf937940ef

    -m: 改动信息
    -a: 作者信息
    e46c71171306: 这一串为容器ID
    new_nginx:01 新镜像的名字

[root@tang ~]# docker images
REPOSITORY           TAG                 IMAGE ID            CREATED              SIZE
new_nginx            v1                  c15ceb0a6871        About a minute ago   355 MB
docker.io/centos     latest              98d35105a391        2 weeks ago          192.5 MB
docker.io/registry   latest              047218491f8c        4 weeks ago          33.17 MB
</code></pre><h3 id="基于本地模块创建镜像"><a href="#基于本地模块创建镜像" class="headerlink" title="基于本地模块创建镜像"></a>基于本地模块创建镜像</h3><pre><code>模版获取,直接到openva官网下载(https://openvz.org/Download/template/precreated)

[root@tang opt]# wget http://download.openvz.org/template/precreated/centos-6-x86_64-minimal.tar.gz

[root@tang opt]# cat centos-6-x86_64-minimal.tar.gz |docker import - centos6
sha256:3d2aed457a111b136bdb9178d6203cb4bb0116501f7a4847088d7593c0930a8c

[root@tang opt]# docker images
REPOSITORY           TAG                 IMAGE ID            CREATED             SIZE
centos6      
</code></pre><h3 id="镜像导出-导入"><a href="#镜像导出-导入" class="headerlink" title="镜像导出/导入"></a>镜像导出/导入</h3><pre><code>[root@tang opt]# docker save centos6 &gt;/opt/centos6.tar.gz   #导出

[root@tang opt]# ll
total 1539880
-rw-r--r-- 1 root root 565194752 Apr  2 16:19 centos6.tar.gz

[root@tang opt]# docker rmi centos6
Untagged: centos6:latest
Deleted: sha256:3d2aed457a111b136bdb9178d6203cb4bb0116501f7a4847088d7593c0930a8c
Deleted: sha256:dbcc6b3893af5f0b45e06f2934f73f5dc34f2e9e54fc4d50a51cc47195f19089

[root@tang opt]# docker load &lt; /opt/centos6.tar.gz              #导入
[root@tang opt]# docker load --input /opt/centos6.tar.gz        #导入

#以上两种导入方法都可以

[root@tang opt]# docker tag centos6  centos6_x86                #改名
</code></pre><h3 id="将镜像上传到dockerhub官网"><a href="#将镜像上传到dockerhub官网" class="headerlink" title="将镜像上传到dockerhub官网"></a>将镜像上传到dockerhub官网</h3><pre><code>需要提前注册dockerhub账号

1. docker hub 帐号在本地验证登陆:

[root@tang opt]# docker login
Login with your Docker ID to push and pull images from Docker Hub. If you don&apos;t have a Docker ID, head over to https://hub.docker.com to create one.
Username: tangxiaoyue
Password: 
Login Succeeded

2. docker push 镜像到docker hub 的仓库
docker push
&lt;hub-user&gt;/&lt;repo-name&gt;:&lt;tag&gt;

[root@tang ~]# docker tag centos tangxiaoyue/centos_tang:latest

[root@tang ~]# docker push tangxiaoyue/centos_tang
The push refers to a repository [docker.io/tangxiaoyue/centos_tang]
9b198ff9ff5b: Mounted from library/centos 
latest: digest: sha256:be5b4a93f116a57ab3fd454ada72421eac892a3a4925627ac9a44f65fcd69cf8 size: 529
</code></pre>]]></content>
      
        <categories>
            
            <category> Docker </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Docker 基础（8）--网络管理]]></title>
      <url>http://yoursite.com/2017/03/11/Docker%20%E5%9F%BA%E7%A1%80%EF%BC%888%EF%BC%89--%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86/</url>
      <content type="html"><![CDATA[<h3 id="Docker四种网络模式"><a href="#Docker四种网络模式" class="headerlink" title="Docker四种网络模式"></a>Docker四种网络模式</h3><h4 id="第一种网络模式host"><a href="#第一种网络模式host" class="headerlink" title="第一种网络模式host"></a>第一种网络模式host</h4><pre><code>host模式: 使用--net=host指定docker使用的网络实际上和宿主机一样,在容器内看到的网卡ip是宿主机上的ip.
</code></pre><a id="more"></a>
<pre><code>[root@docker ~]# docker run -itd -h node1 --name node1 --net=host centos bash
406cdb306f3c350b6f5344048ae25426f1df3f6863162c0b3a91e3dcd48eba
[root@docker ~]# ifconfig |awk -F &apos; &apos;  &apos;NR==10{print$2}&apos;
172.17.82.185
[root@docker ~]# docker-enter node1    #进去之后修改主机名，因为主机名个宿主机一样，貌似-h也指定不了主机名
[root@node1 ~]# yum install -y net-tools
[root@node1 ~]# ifconfig |awk -F &apos; &apos;  &apos;NR==10{print$2}&apos;
172.17.82.185
</code></pre><h4 id="第二种网络模式container"><a href="#第二种网络模式container" class="headerlink" title="第二种网络模式container"></a>第二种网络模式container</h4><pre><code>container模式: 使用--net=container:container_id/container_name多个容器使用共同的网络,看到的ip是一样的.


[root@docker ~]# docker run -itd -h node2 --name node2  --net=container:node1 centos bash     #此处不能指定主机名创建，否则失败
/usr/bin/docker-current: Error response from daemon: Conflicting options: hostname and the network mode.
See &apos;/usr/bin/docker-current run --help&apos;
[root@docker ~]# docker run -itd  --name node2 --net=container:node1 centos bash
0fc16c4a055cf0035c1241ba6cce6c5ad0c711f2ef13e0589c3254f19a96b271
[root@docker ~]# docker-enter node2
[root@node2 ~]# yum install -y net-tools
[root@node2 ~]# ifconfig |awk -F &apos; &apos;  &apos;NR==10{print$2}&apos;    #和node1的ip一样，也和宿主机的ip一样（node1使用的是--net=host模式）
172.17.82.185
</code></pre><h4 id="第三种网络模式none"><a href="#第三种网络模式none" class="headerlink" title="第三种网络模式none"></a>第三种网络模式none</h4><pre><code>none模式: 使用--net=none, 这种模式下,不会配置任何网络

[root@docker ~]# docker run -itd -h node3 --name node3 --net=none centos
c1f4bd859566f11517248718a94456066d16ad66748a2c78743881e450d4ca09
[root@docker ~]# docker-enter node3
[root@node3 ~]# ping www.baidu.com
ping: www.baidu.com: Name or service not known
</code></pre><h4 id="第四种网络模式bridge"><a href="#第四种网络模式bridge" class="headerlink" title="第四种网络模式bridge"></a>第四种网络模式bridge</h4><pre><code>bridge模式: 使用--net=bridge.创建完容器默认为这种网络模式.类似与vmware的nat网络模式.

[root@docker ~]# docker run -itd -h node4 --name node4 --net=bridge centos bash
fc4f817e741f22615d0cdbab6608877d268ea15be6ba790cae5706d03871ac41
</code></pre><h3 id="外部访问容器"><a href="#外部访问容器" class="headerlink" title="外部访问容器"></a>外部访问容器</h3><pre><code>[root@docker ~]# docker run -itd -h node1 --name node1 centos bash
27df97f0e77e745660ee7b9c8b318c64f63e6aa632db3d3b0c44c4e0f4006124
[root@docker ~]# docker-enter node1
[root@node1 ~]# rpm -ivh http://mirrors.aliyun.com/epel/epel-release-latest-7.noarch.rpm
[root@node1 ~]# yum install -y nginx
[root@docker ~]# docker commit -m &quot;nginx&quot; -a &quot;tang&quot; 27df97f0e77e nginx:v1
    #此处仅容器做为镜像，主要是减少以后重复性的工作，不需要新建一个容器在部署nginx

[root@docker ~]# docker run -itd -h nginx --name nginx -p 81:80 nginx:v1 bash      #-p 端口映射，射到宿主机81端口上
a5dd375e829d05734a935d5f41723841568b543822a64a4ec277480f5f552e41
[root@docker ~]# docker-enter nginx
Last login: Mon Apr  3 07:00:51 UTC 2017
[root@nginx ~]# /usr/sbin/nginx 
[root@nginx ~]# echo &quot;TangXiaoyue&quot; &gt; /usr/share/nginx/html/1.html
[root@nginx ~]# curl 127.0.0.1/1.html
TangXiaoyue
[root@nginx ~]# exit
logout
[root@docker ~]#  curl 127.0.0.1:81/1.html
TangXiaoyue
</code></pre><h3 id="容器互联"><a href="#容器互联" class="headerlink" title="容器互联"></a>容器互联</h3><pre><code>1.安装mysql
[root@docker ~]# docker run --privileged -itd -h node1 --name node1 centos /sbin/init
fd547b535ff3af19bf36b219f542864962d60480a8d56836db30c20f079ec43f
[root@docker ~]# docker-enter node1
[root@node1 ~]# yum install -y wget
[root@node1 ~]# wget http://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpm
[root@node1 ~]# rpm -ivh mysql-community-release-el7-5.noarch.rpm
[root@node1 ~]# yum install mysql-community-server
[root@node1 ~]# systemctl start mysql.service
[root@node1 ~]# mysql -uroot
&gt;set password for &apos;root&apos;@&apos;localhost&apos; = password(&apos;123456&apos;);

2.制作mysql镜像
[root@docker ~]# docker commit -m &quot;mysql&quot; -a &quot;tang&quot; fd547b535ff3 mysql:v1
sha256:21af416e70b0302163e4aa279118afdd96a0c8590487268a3d26920caf6c5d1a
[root@docker ~]# docker images
REPOSITORY           TAG                 IMAGE ID            CREATED             SIZE
mysql                v1                  21af416e70b0        4 seconds ago       797.3 MB


[root@docker ~]# docker run --privileged -itd -h mysql --name mysql mysql:v1 /sbin/init
8d71a34516a2c05a7ea63fde5773785360d1301509d687797eec5ead62a01d55


3.以mysql、nginx镜像分别创建两个容器并端口映射
[root@docker ~]# docker run -itd -h nginx --name nginx -p 10080:80 --link mysql:db nginx:v1 bash
8aea6116f67c9760b8f4d3de08251b28af839b9e2195860ad4b24d54833c286a
[root@docker ~]# docker-enter nginx
Last login: Mon Apr  3 07:00:51 UTC 2017
[root@nginx ~]# yum install -y telnet
[root@nginx ~]# telnet db 3306
Trying 172.18.0.3...
Connected to db.
Escape character is &apos;^]&apos;.
CHost &apos;172.18.0.4&apos; is not allowed to connect to this MySQL serverConnection closed by foreign host.
[root@nginx ~]# cat /etc/hosts
172.18.0.3    db mysql mysql
172.18.0.4    nginx
</code></pre><h3 id="配置网桥-centos7"><a href="#配置网桥-centos7" class="headerlink" title="配置网桥(centos7)"></a>配置网桥(centos7)</h3>]]></content>
      
        <categories>
            
            <category> Docker </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Docker 基础（5）--容器管理]]></title>
      <url>http://yoursite.com/2017/03/11/Docker%20%E5%9F%BA%E7%A1%80%EF%BC%885%EF%BC%89--%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/</url>
      <content type="html"><![CDATA[<h4 id="查看启动的容器"><a href="#查看启动的容器" class="headerlink" title="查看启动的容器"></a>查看启动的容器</h4><pre><code>[root@tang ~]# docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
2f8c14f16e03        centos              &quot;/bin/bash&quot;         5 minutes ago       Up 2 minutes                            tang
</code></pre>  <a id="more"></a>
<h4 id="查看所有的容器-包括启动、停止"><a href="#查看所有的容器-包括启动、停止" class="headerlink" title="查看所有的容器(包括启动、停止)"></a>查看所有的容器(包括启动、停止)</h4><pre><code>[root@tang ~]# docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                      PORTS               NAMES
e5d7ccb9522c        centos              &quot;/bin/bash&quot;         15 seconds ago      Exited (0) 12 seconds ago                       tang1
2f8c14f16e03        centos              &quot;/bin/bash&quot;         3 minutes ago       Up 1 seconds                                    tang

Exited:表示该容器已经退出。没有启动
</code></pre><h4 id="创建容器-create、run-、进入容器"><a href="#创建容器-create、run-、进入容器" class="headerlink" title="创建容器(create、run)、进入容器"></a>创建容器(create、run)、进入容器</h4><pre><code>[root@tang ~]# docker images
REPOSITORY           TAG                 IMAGE ID            CREATED             SIZE
docker.io/centos     latest              98d35105a391        2 weeks ago         192.5 MB
docker.io/registry   latest              047218491f8c        4 weeks ago         33.17 MB

[root@tang ~]# docker create -it --name tang_create centos /bin/bash                     #使用create创建容器
3b316839ea357a3fe47fcae3488d6f491882ecb8c954412c502cbd6dcf9e2478

[root@tang ~]# docker run -it --name tang_run centos /bin/bash                          #使用run创建容器
[root@b5dbba42703a /]# exit
exit
</code></pre><h4 id="启动停止容器"><a href="#启动停止容器" class="headerlink" title="启动停止容器"></a>启动停止容器</h4><pre><code>[root@tang ~]# docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES

[root@tang ~]# docker start tang_run                #start启动容器
tang_run

[root@tang ~]# docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
b5dbba42703a        centos              &quot;/bin/bash&quot;         4 minutes ago       Up 14 seconds                           tang_run

[root@tang ~]# docker stop tang_run                 #stop停止容器
tang_run
[root@tang ~]# docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
</code></pre><h4 id="创建容器-指定容器名"><a href="#创建容器-指定容器名" class="headerlink" title="创建容器,指定容器名"></a>创建容器,指定容器名</h4><pre><code>[root@tang ~]# docker run -itd -h tang_run --name tang centos /bin/bash
8afe717f82718214056a61e3881552338d5c911d272a80342edec063b5048
        -d: 容器退出后不关闭容器.
        -h:指定主机名
</code></pre><h4 id="删除容器-镜像"><a href="#删除容器-镜像" class="headerlink" title="删除容器/镜像"></a>删除容器/镜像</h4><pre><code>[root@tang ~]# docker rm tang                               #删除容器
[root@tang ~]# docker rm -f tang                            #强制删除容器，不管是否在运行
[root@tang ~]# docker rm $(docker ps -a -q)                 #删除所有容器
</code></pre><h4 id="导出容器-可迁移到其它机器-导入容器"><a href="#导出容器-可迁移到其它机器-导入容器" class="headerlink" title="导出容器(可迁移到其它机器)/导入容器"></a>导出容器(可迁移到其它机器)/导入容器</h4><pre><code>[root@tang ~]# docker export tang &gt;/opt/tang.tar            #导出容器
[root@tang ~]# docker rm tang
tang
[root@tang ~]# cat /opt/tang.tar |docker import - tang      #恢复的只是一个镜像，需要通过镜像创建容器
[root@tang ~]# docker images
REPOSITORY           TAG                 IMAGE ID            CREATED             SIZE
tang                 latest              393d449b1ed4        44 seconds ago      192.5 MB


提示：如果在之前那个容器内创建的文件，导出，导入之后容器内的文件是不变的
</code></pre>]]></content>
      
        <categories>
            
            <category> Docker </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Docker 基础（6）--仓库管理]]></title>
      <url>http://yoursite.com/2017/03/11/Docker%20%E5%9F%BA%E7%A1%80%EF%BC%886%EF%BC%89--%E4%BB%93%E5%BA%93%E7%AE%A1%E7%90%86/</url>
      <content type="html"><![CDATA[<blockquote>
<p>Docker的仓库是DockerHub，类似于github，github有一个开源的软件叫gitlab。Docker也有一个开源软件docker registry</p>
</blockquote>
<a id="more"></a>
<pre><code>[root@tang ~]# docker pull registry

[root@tang ~]# docker images
REPOSITORY           TAG                 IMAGE ID            CREATED             SIZE
docker.io/centos     latest              98d35105a391        2 weeks ago         192.5 MB
docker.io/registry   latest              047218491f8c        4 weeks ago         33.17 MB

默认占用5000端口，我们查看是否存在5000端口
[root@tang ~]# netstat -lntup | grep 5000

运行容器
[root@tang ~]# docker run -d -p 5000:5000 registry
f002089ab95474290853a2a24b86cb0adbb5848c4a468175304b59b27d6e3b0e

提示：docker比较老的版本运行起来就可以运行，1.7之后都不可以
</code></pre>]]></content>
      
        <categories>
            
            <category> Docker </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[XtraBackup主从复制及备份]]></title>
      <url>http://yoursite.com/2017/03/11/XtraBackup%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%8F%8A%E5%A4%87%E4%BB%BD/</url>
      <content type="html"><![CDATA[<h4 id="XtraBackup备份"><a href="#XtraBackup备份" class="headerlink" title="XtraBackup备份"></a>XtraBackup备份</h4><pre><code>1、yum安装mysql（以centos7为例）
</code></pre><a id="more"></a>
<pre><code>###主从操作一致

#查看操作系统版本：
[root@node2 ~]# cat /etc/redhat-release
CentOS Linux release 7.0.1406 (Core)

#关闭防火墙和seLinux
[root@node2 ~]# systemctl stop firewalld
[root@node2 ~]# sed -i &quot;s#SELINUX=enforcing#SELINUX=disabled#g&quot; /etc/selinux/config
[root@node2 ~]# setenforce 0

#yum安装mysql
wget http://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpm
rpm -ivh mysql-community-release-el7-5.noarch.rpm
yum install mysql-community-server
systemctl start mysql.service
mysql -uroot
&gt;set password for &apos;root&apos;@&apos;localhost&apos; = password(&apos;123456&apos;);

###配置主从
主：
vim /etc/my.cnf
[mysqld]
log-bin = mysql-bin
server-id=1

从：
vim /etc/my.cnf
[mysqld]
log-bin = mysql-bin
server-id=2

2、安装xtrabackup备份软件（主从进行安装）
wget https://www.percona.com/downloads/XtraBackup/Percona-XtraBackup-2.3.4/binary/redhat/6/x86_64/percona-xtrabackup-2.3.4-1.el6.x86_64.rpm
yum install -y epel-release
yum localinstall percona-xtrabackup-2.3.4-1.el6.x86_64.rpm
yum install -y perl-Time-HiRes

#查看版本
&gt;select version();

#查看前默认的存储引擎
&gt;show variables like &apos;%storage_engine%&apos;;


3、导入数据（为了模拟比较真实可以往主库导入数据）（主库操作）
#导入bubi_api数据库
[root@node2 opt]# mysql -uroot -ppassword &lt; bubi_api.sql #
查看数据大小 
&gt; use information_schema;
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A

Database changed
&gt; select concat(round(sum(data_length/1024/1024),2),&apos;MB&apos;) as data from tables;
+----------+
| data |
+----------+
| 194.94MB |
+----------+
1 row in set (0.04 sec)

4、数据库备份（主操作）
###备份
[root@node2 opt]# mkdir /extrabackup
[root@node2 opt]# innobackupex --defaults-file=/etc/my.cnf --socket=/var/lib/mysql/mysql.sock --user=root --password=bubi --parallel=4 /mnt/resource/extrabackup
###出现completed OK! 表示备份成功

语法解释：–user=数据库用户
–password=数据库密码
–socket=指定socket
–default-file=指定配置文件
- 最后面是存放位

###保持事务一致（主操作）
[root@node2 2017-02-17_14-45-11]# innobackupex --defaults-file=/etc/my.cnf --socket=/var/lib/mysql/mysql.sock --user=root --password=123456 --parallel=4 --apply-log /extrabackup/2017-02-17_14-45-11/
###出现completed OK!表示事务保持了一致，可以用于恢复




二、mysql主从同步操作
1、传输数据、将/extrabackup/2017-02-17_14-45-11/拷贝到从库
[root@node2 extrabackup]# scp -r 2017-02-17_14-45-11 root@192.168.1.13:/extrabackup/

2、从库恢复数据
[root@node3 extrabackup]# ll
总用量 0
drwx------. 4 root root 47 2月 17 14:47 2017-02-17_14-45-11

#停止mysql
[root@node3 extrabackup]# systemctl stop mysql

#清空mysql data目录
[root@node3 extrabackup]# cd /var/lib/mysql
[root@node3 mysql]# mv * /opt/mysqlbak/

#数据恢复
innobackupex --defaults-file=/etc/my.cnf --socket=/var/lib/mysql/mysql.sock --user=root --password=123456 --copy-back /extrabackup/2017-02-17_11-49-35/
###出现completed OK! 表示恢复成功

#还原权限
[root@node3 mysql]# cd ..
[root@node3 lib]# chown mysql:mysql mysql -R

#重启mysql并查看数据的大小
[root@node3 lib]# systemctl start mysql
[root@node3 lib]# ps -ef | grep mysql
mysql 8173 1 0 14:59 ? 00:00:00 /bin/sh /usr/bin/mysqld_safe --basedir=/usr
mysql 8338 8173 3 14:59 ? 00:00:00 /usr/sbin/mysqld --basedir=/usr --datadir=/var/lib/mysql --plugin-dir=/usr/lib64/mysql/plugin --log-error=/var/log/mysqld.log --pid-file=/var/run/mysqld/mysqld.pid --socket=/var/lib/mysql/mysql.sock
root 8364 5840 0 15:00 pts/0 00:00:00 grep --color=auto mysql

&gt; use information_schema;
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A

Database changed
mysql&gt;    
+----------+
| data |
+----------+
| 194.94MB |
+----------+
1 row in set (0.26 sec)

###数据主从大小都一样

3、mysql主从同步操作
###主库授权
&gt; GRANT REPLICATION SLAVE ON *.* TO &apos;rep&apos;@&apos;192.168.1.13&apos; IDENTIFIED BY &apos;123456&apos;;
&gt;FLUSH PRIVILEGES;

###从库开启同步
[root@node3 mysql]# cat /extrabackup/2017-02-17_14-45-11/xtrabackup_binlog_info
mysql-bin.000001 171510867

CHANGE MASTER TO
MASTER_HOST=&apos;10.25.159.23&apos;,
MASTER_USER=&apos;rep&apos;,
MASTER_PASSWORD=&apos;db0226&apos;,
MASTER_PORT=3306,
MASTER_LOG_FILE=&apos;mysql-bin.000003&apos;,
MASTER_LOG_POS=982559769;

####在还没同步之前我们可以在主库继续增加入一个库，验证不锁表是否可以同步
mysql&gt; show databases;
+--------------------+
| Database |
+--------------------+
| information_schema |
| bubi_api |
| mysql |
| performance_schema |
| tang |
+--------------------+
5 rows in set (0.00 sec)

#####开启主从同步
&gt;flush logs;
&gt; start slave; ###从库操作
&gt; show slave status\G
Slave_IO_Running: Yes
Slave_SQL_Running: Yes

##查看从库数据
mysql&gt; show databases;
+--------------------+
| Database |
+--------------------+
| information_schema |
| bubi_api |
| mysql |
| performance_schema |
| tang |
+--------------------+
5 rows in set (0.00 sec)

注意：
1、当从库停掉了（宕机还没测试）。主库继续写入数据，从库开启时，会自动同步




##########mysql命令
#查看binlog是否开启
&gt;show binary logs;

#查看serverid
&gt;show variables like &apos;server_id&apos;;

#查看binlog模式
&gt;show variables like &apos;%log%&apos;;


&gt;/dev/null 2&gt;&amp;1
</code></pre>]]></content>
      
        <categories>
            
            <category> Mysql </category>
            
        </categories>
        
        
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hexo常用命令]]></title>
      <url>http://yoursite.com/2017/03/11/Hexo%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
      <content type="html"><![CDATA[<p><strong><em>Hexo部署步骤</em></strong></p>
<pre><code>npm install    
npm install hexo-deployer-git --save   
hexo new &quot;新页面&quot;    
hexo clean   
hexo generate
hexo deploy    
</code></pre><a id="more"></a>
<p> <br></p>
<p><strong><em>Hexo常用命令</em></strong></p>
<pre><code>hexo new &quot;postName&quot;                 #新建文章     
hexo new page &quot;pageName&quot;             #新建页面   
hexo generate                         #生成静态页面至public目录    
hexo server                            #开启预览访问端口（默认端口4000，&apos;ctrl + c&apos;关闭server）    
hexo deploy                         #将.deploy目录部署到GitHub       
hexo help                             #查看帮助
hexo version                        #查看Hexo的版本
</code></pre><p><br></p>
<p><strong><em>复合命令</em></strong></p>
<pre><code>hexo deploy -g #生成加部署   
hexo server -g #生成加预览    
</code></pre><p>命令的简写为：</p>
<pre><code>hexo n == hexo new    
hexo g == hexo generate   
hexo s == hexo server   
hexo d == hexo deploy   
</code></pre>]]></content>
      
        <categories>
            
            <category> 博客搭建 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 博客搭建 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[运维与自动化发展(1)]]></title>
      <url>http://yoursite.com/2017/01/01/%E8%BF%90%E7%BB%B4%E4%B8%8E%E8%87%AA%E5%8A%A8%E5%8C%96%E5%8F%91%E5%B1%95/</url>
      <content type="html"><![CDATA[<h3 id="一、运维学习和发展的一个线路"><a href="#一、运维学习和发展的一个线路" class="headerlink" title="一、运维学习和发展的一个线路"></a>一、运维学习和发展的一个线路</h3><pre><code>1.搭建服务（部署并运行起来）

2.用好服务（监控、管理、优化）
</code></pre><a id="more"></a>
<pre><code>3.自动化（服务直接的关联和协同工作）

4.产品设计（如何设计一个监控系统）

云计算的核心竞争力是运维！

系统架构师（还有偏管理系统架构师）：网络 系统 数据库 开发 云计算 自动化 运维管理 服务管理 项目管理 测试 业务
==比较难学的开发和业务（相对于运维来说）


专注于某一领域：资深、科学家
</code></pre><h3 id="二、运维知识体系"><a href="#二、运维知识体系" class="headerlink" title="二、运维知识体系"></a>二、运维知识体系</h3><pre><code>赵班长运维知识体系：https://www.unixhot.com/page/ops


运维工作内容分类：

监控运维（7X24运维值班、故障处理）
应用运维（业务熟悉、服务部署、项目上线、业务部署、版本管理、灰度发布、日志收集、应用监控）



安全运维（整体的安全方案、规范、漏洞检测、安全防护等）


系统运维（架构层面的分布式缓存、分布式文件系统、环境规划（测试、开发、生产）、架构设计、性能优化）
基础服务运维（包含运维开发）（内部DNS、负载均衡、系统监控、资产管理、运维平台）


基础设施运维（系统初始化、网络维护）
机房运维（负责设备上下架、巡检、保修、硬件监控）
</code></pre><h3 id="三、运维自动化发展"><a href="#三、运维自动化发展" class="headerlink" title="三、运维自动化发展"></a>三、运维自动化发展</h3><pre><code>发展层级：
    智能化
    服务化、api化
    Web化、平台化
    标准化、工具化
</code></pre><h4 id="1-标准化"><a href="#1-标准化" class="headerlink" title="1.标准化"></a>1.标准化</h4><pre><code>物理设备层面：
    1.服务器标签化、设备负责人、设备采购详情、设备摆放标准（例如：负载均衡两台机器不能放同一机柜）。
    2.网络划分、远程控制卡、网卡端口
    3.服务器机型、硬盘、内存统一。根据业务分类
    4.资产命名规范、编号规范、类型规范
    5.监控标准

操作系统层面：
    1.操作系统版本
    2.系统初始化（DNS、NTP、内存参数调优、rsyslog、主机名规范）
    3.基础Agent配备（zabbix Agent、logstach Agent、saltstack monitor）
    4.系统监控标准（cpu、内存、硬盘、网络、进程）

应用服务层面：
    1.Web服务器选型（apache、nginx）
    2.进程启动用户、端口监听规范、日志收集规范（访问日志、错误日志、运行日志）
    3.配置管理（配置文件规范、脚本规范）
    4.架构规范（nginx+keepalived、lvs+keepalived等等）
    5.部署规范（位置、包命名等）

运维操作层面：
    1.机房巡检流程（周期、内容、报修流程）
    2.业务部署流程（先测试、后生成。回滚）
    3.故障处理流程（紧急处理、故障升级）
    4.工作日志标准（如何编写工作日志）
    5.业务上线流程（1.项目发起人 2.系统安装 3.部署nginx 4.解析域名 5.测试 6.加监控 7.备份）
    6.业务下线流程（1.谁发起 2.数据如何处理 3.服务器回收 4.系统是否重装）
    7.运维安全规范（密码复杂度、更改周期、vpn使用规范、服务器登入规范）



    标准化（规范化、流程化、文档化） 目标：文档化
</code></pre><h4 id="2-工具化"><a href="#2-工具化" class="headerlink" title="2.工具化"></a>2.工具化</h4><pre><code>1.shell脚本（功能性（流程）、坚持性、报表性）
2.开源工具：Zabbix ELKstack SaltStack  cobbler

目标：
    1.促进标准化的实施
    2.将重复的操作，简单化
    3.将多次操作，流程化
    4.减少人为操作的低效和降低故障率

工具化和标准化是好基友！！！

痛点：
    1.你至少要ssh到服务器执行，可能犯错
    2.多个脚本有执行顺序的时候，可能犯错
    3.权限不好管理，日志没法统计。
    4.无法避免手工操作

    例子：比如某天我们要对一台数据库从库进行版本升级。那么要求进行评估：

        停机的影响：3:00晚上有定时任务链接该数据库，做数据报表统计。

        1.凌晨3:00我们所有系统的定时任务有哪些 crontab
        2.这些croneab哪些连接我们要停止的从库
        3.哪些可以停，哪些不能停（修改到主库），哪些可以后补
        4.这些需要后补的脚本哪个业务，谁加的，什么时候加的
</code></pre><h4 id="3-Web化（运维操作平台）"><a href="#3-Web化（运维操作平台）" class="headerlink" title="3.Web化（运维操作平台）"></a>3.Web化（运维操作平台）</h4><pre><code>1.做成Web界面
2.权限控制
3.日志记录
4.弱化流程
5.不用ssh到服务器，减少人为操作造成的故障
</code></pre><h4 id="4-服务化（API化）"><a href="#4-服务化（API化）" class="headerlink" title="4.服务化（API化）"></a>4.服务化（API化）</h4><pre><code>DNS Web管理             bind-DLZ   dns-api
负载均衡Web管理         slb-api
Job管理平台             job-api
监控Web管理  zabbix     zabbix-api
操作系统安装平台        cobbler-api
部署平台                deploy-api
配置管理平台            saltstack-api
自动化测试平台          test-api


1.调用cobbler-api安装操作系统
2.调用saltstack-api进行系统初始化
3.调用dns-api解析主机名
4.调用zabbix-api将新上线机器加上监控
5.再次调用saltstack-api部署软件（安装Nginx+php）
6.调用deploy-api     将当前版本的代码部署到服务器上
7.调用test-api 测试当前服务器运行十分正常
8.调用slb-api 将该节点加入集群
</code></pre><h4 id="5-智能化"><a href="#5-智能化" class="headerlink" title="5.智能化"></a>5.智能化</h4><blockquote>
<p>智能化的自动化扩容、缩容、服务降级、故障自愈</p>
</blockquote>
<pre><code>触发机制--&gt;决策系统（决策树）


一、自动化扩容

1.zabbix触发Action
触发：
    1.当某个集群的访问量超过最大的支撑量，比如10000
        1.1.cpu使用率达到多少
    2.并持续5分钟
    3.不是攻击
    4.资源池有可用资源
        4.1.当前网络带宽使用率
        4.2.如果公有云-钱够不够
    5.当前后端服务支撑量是否超过阈值，如果超过应该后端先扩容
    6.数据库是否可以支撑当前并发
    7.当前自动化扩展队列，是否有正在扩容的节点
    8.其它业务相关的

决策之前：先判断buffer是否有最近X小时，已经移除的之前创建的虚拟机。并查询软件版本是否和当前一致，如果一致，跳过2 3 4步骤。如果不一致，跳过2 3步骤


2.Openstack 创建虚拟机

3.Saltstack配置环境---监控

4.部署系统当前代码

5.测试服务是否可用（注意间隔和次数）

6.加入集群

7.通知（短信、邮件、花费时间）


二、自动化缩容

1.触发条件和决策
2.从集群中移除节点---先关闭监控--移除
3.通知
4.移除的节点存放在buffer里面
5.buffer里面超过一天的虚拟机，自动关闭，存放于某去
6.某区的虚拟机，每7天清理删除


1.部署openstack
2.在openstack上创建虚拟机
3.在虚拟机上部署Mesos+docker+Marathon
4.自动化创建Docker容器进行自动化扩容
</code></pre><h3 id="四-基于ITIL的运维管理体系"><a href="#四-基于ITIL的运维管理体系" class="headerlink" title="四. 基于ITIL的运维管理体系"></a>四. 基于ITIL的运维管理体系</h3><h4 id="1-ITIL-简介"><a href="#1-ITIL-简介" class="headerlink" title="1. ITIL 简介"></a>1. ITIL 简介</h4><pre><code>什么是服务：
    服务是向客户提供的一种手段，使客户不用承担特定的成本和风险就可以获得所期望的结果。

什么是服务管理：
    服务管理是一套特定的组织能力，以服务的形式为客户提供价值

ITSM 和ITIL 的关系：
    1.现有ITSM，后有ITIL。
    2.因为ITIL，ITSM得到关注和发扬
    3.ITIL是ITIM的最佳时间.ITIL为ITSM创建了一组核心流程和专有名词
    4.ITIL并不是ITSM的全部，ITIL只是告诉我们，什么该做，但没有说具体该怎么做。而对ITSM而言，这些都是ITSM的范围。

ITIL是：
    ITIL即IT基础架构库（Information Technology Infrastructure Library）。

    英国商务办公司从20世纪80年代开始开发的一套IT管理方法。

    已成为事实上的行业标准，并以其为中心在全球形成了完整的产业。

    任何单位和个人都可以免费试用的“公共框架”。

    实际上是一系由所谓“最佳实践”形成图书。

    一个可以直接使用的标准。

ITIL的目的：
    1.将IT管理工作标准化，模式化，减少人为误操作带来的隐患
    2.通过服务目录，服务报告，告诉业务部门，我们可以做什么，做了什么
    3.通过系列流程，只是库减轻对英雄式工程师的以来，把经验积累下来。
    4.通过对流程的管控，减少成本，降低风险，提供客户满意度

ITIL和ISO 20000
    ITIL自发布以来，一直被业界认为是IT服务管理领域事实上的管理标准，直到2000年11月，英国标准协会（BSI）正式发布了以ITIL为核心的国家标准BS15000；
    随后，2005年5月，国际标准化组织（ISO）快速通道的方式批准通过了ISO2000的标准协议，并于12月15日正式发布了ISO20000标准。

ITIL和ISO20000区别

ITIL                                                ISO2000
提供最佳实践指导                                提供衡量ITSM的指标
没有固定的能力衡量指标                          全球统一
对人员进行认证                                  对机构进行认证
咨询机构提供他们眼中的ITSM成熟度结果              关注于服务提供的独立认证，从IT服务管理体系的角度出发

ITSM内容
    管什么（管理对象）
    怎么管（管理方法）
    管得咋样（成熟度）

IT service CMM

初始级：
    被动相应，没有文档记录，几乎没有过程，是经过定义的 ；
    各项目经验无法重用，以来与个人的努力和永雄主义

可重复级：
    建立了基本的服务管理过程；
    所有项目有默认的规则，但未文档化，系统化；
    产品或服务化无清晰的目标和策略；

定义级：
    已将IT服务过程文档化，标准化，并综合成标准服务过程；
    根据客户需求调整服务产品和服务战略；
    适当的工具和信息报告；

管理级：
    受监督、测量的IT服务体系；
    根据业务战略调整服务体系；

优化级（PDCA）：
    持续改进的IT服务体系；
    IT与业务指标建立关系；
    IT与业务协作改进流程；


成为运维经理：
    1.技术，运维只是体系
    2.服务管理ITIL
      项目管理PMP
    3.做人
</code></pre><h3 id="五-ITIL-服务运营"><a href="#五-ITIL-服务运营" class="headerlink" title="五. ITIL 服务运营"></a>五. ITIL 服务运营</h3><pre><code>ITIL v3 将ITIL理论分成五部分：
    1.服务战略
    2.服务设计
    3.服务转换
    4.服务运营
    5.持续服务改进
</code></pre><p>ITIL v3 核心模块<br><img src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1492912887&amp;di=7a98f884c0ce6d774f12c86b44c38cd2&amp;imgtype=jpg&amp;er=1&amp;src=http%3A%2F%2Fgroup.vsharing.com%2FUploads%2FUserDirs%2F3%2F1000%2F399697%2FITIL%2520V3%25E4%25B8%258EITIL%2520V2%25E7%259A%2584%25E4%25BB%25B7%25E5%2580%25BC%25E5%25B7%25AE%25E5%25BC%2582%25EF%25BC%2588%25E5%259B%25BE%25E4%25B8%2580%25EF%25BC%2589.jpg" alt="image"></p>
<pre><code>服务运营：
SLA：服务级别协议
OLA：运营水平协议
CSF：关键成功因素
KPI：关键绩效指标

客户要求——SLA——OLA——CSF——KPI——月报

服务台：

    作为IT服务支持团队的一线支持，其首要目标是为用户和IT组织之间建立沟通的纽带；
    确保用户的故障请求和服务请求能够以最快的速度得到满足，并确保用户满意。

服务台作用：
    1.路由器
    2.监视器
    3.单一联系点
    4.客服窗口
    5.广播台
    6.过滤器
</code></pre><h3 id="六-服务运营-故障管理"><a href="#六-服务运营-故障管理" class="headerlink" title="六. 服务运营-故障管理"></a>六. 服务运营-故障管理</h3><pre><code>1.故障管理的目标：

    故障管理的目标是尽可能快的恢复正常的服务运营，将故障对业务运营的负面影响减少到最低。
    并确保到达最好的服务质量和可用性水平。

2.故障优先级：
--紧急度
--影响度



3.故障输入输出：

    故障管理流程输入
        故障请求提交
        故障单记录模板
        故障单填写模板
        故障分类规则
        故障优先级确定规则
        故障升级规则
        故障处理时间规则
        故障关闭规则

    故障管理流程输出：
        故障历史记录
        故障分类汇总统计表
        故障处理用户满意度

4.故障管理的绩效指标（KPI）

    一线支持解决的事故百分比
    无升级的平均呼叫时长
    分配错误的事故百分比
    在目标时间之内，按照优先级解决的事故百分比
    二线支持平均响应时间
    事故平均解决时间
    重新分配的事故百分比
    归类错误的事故百分比
    绕过一线支持的呼叫百分比
    客户满意度
    服务请求呼叫百分比
    一次解决正确的事故百分比
    主动解决的事故百分比

5.服务运营-问题管理

问题管理的目标：
    问题管理的主要目标是预防问题产生及由此引发的故障，消除重复的出现故障，并对不能预防的故障尽量减低其对业务的影响

问题管理对业务的价值：

    提供IT服务的可用性
    提高业务和IT人员的生成效率
    减少无效的规避措施或修补措施的开支
    减少在救火或解决重复故障方面的成本
    有助于知识库的积累
</code></pre>]]></content>
      
        <categories>
            
            <category> 运维自动化 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 运维自动化 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[zabbix 3.0 自定义监控]]></title>
      <url>http://yoursite.com/2016/10/03/zabbix%203.0%20%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9B%91%E6%8E%A7/</url>
      <content type="html"><![CDATA[<h2 id="为什么要自定义KEY"><a href="#为什么要自定义KEY" class="headerlink" title="为什么要自定义KEY"></a>为什么要自定义KEY</h2><p>有时候我们想让被监控端执行一个zabbix没有预定义的检测，zabbix的用户自定义参数功能提供了这个方法。我们可以在客户端配置文件zabbix_angentd.conf里面配置UserParameter.<br><a id="more"></a><br>语法如下:</p>
<blockquote>
<p>UserParameter=key,command</p>
</blockquote>
<p>用户自定义参数包含一个key和一个命令，key必须整个系统唯一，配置好之后，重启客户端。</p>
<p>然后配置item,在key的位置填上我们自定义的key即可。</p>
<p>用户自定义参数里指定的脚本由zabbix agent来执行，最大可以返回512KB的数据.</p>
<p>实例（以监控memory free为例）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[root@node-11 ~]# vim /etc/zabbix/zabbix_agentd.conf</div><div class="line">UserParameter=memory.free,/usr/bin/free | awk &apos;/^Mem:/&#123;print $4&#125;&apos;</div></pre></td></tr></table></figure></p>
<p><code>说明</code>：UserParameter为语法，memory.free为key值， /usr/bin/free为free的全路径，awk ‘/^Men:/{print $4}’为用awk所执行的命令，同时这里也可以把脚本路径填写到这里。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@node-11 ~]# systemctl restart  zabbix-agent</div></pre></td></tr></table></figure></p>
<p>在服务器端模拟获取数据（如获取不到数据，仔细查看你的key或Ip是否对，等等）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">[root@node-11 ~]# /usr/bin/free </div><div class="line">             total       used       free     shared    buffers     cached</div><div class="line">Mem:       1878212    1779704      98508       8908         64    1205268</div><div class="line">-/+ buffers/cache:     574372    1303840</div><div class="line">Swap:      8273916          0    8273916</div><div class="line">[root@node-10 ~]#  zabbix_get -s 192.168.1.11  -k &quot;memory.free&quot;</div><div class="line">98360</div><div class="line"></div><div class="line">提示：因为内存正在使用，所以获取的值有一点相差，不影响</div></pre></td></tr></table></figure></p>
<h2 id="在服务端添加到监控项"><a href="#在服务端添加到监控项" class="headerlink" title="在服务端添加到监控项"></a>在服务端添加到监控项</h2><p>配置—–主机—–你的主机—–监控项<br><img src="http://static.zybuluo.com/BruceTang/xxdnr0n7ked9ttoyvp6rcled/image_1bf11tv32rcf1338aa21r7s3gf34.png" alt="image_1bf11tv32rcf1338aa21r7s3gf34.png-159.5kB"><br>监控项—-创建监控项—–添加<br><img src="http://static.zybuluo.com/BruceTang/20idxm2qwyz78nsh7cpqn639/image_1bf1378rr1k7s9konmfocfpfk5v.png" alt="image_1bf122m8j1jvnj93dlfrja1go43h.png-182.6kB"><br>配置–主机–图形–创建图形<br><img src="http://static.zybuluo.com/BruceTang/y4phc4t4211tfwy5s8i02rqe/image_1bf126nn6grtm59o9e1d4l1dpf3u.png" alt="image_1bf126nn6grtm59o9e1d4l1dpf3u.png-174.5kB"><br><img src="http://static.zybuluo.com/BruceTang/ptbgpu9iqzq2ncn6ceocy9mz/image_1bf127c7p1m8q1grs8o21j541k0p4b.png" alt="image_1bf127c7p1m8q1grs8o21j541k0p4b.png-192.5kB"><br><img src="http://static.zybuluo.com/BruceTang/pzqmhcv7nirpdgnfpa8md61k/image_1bf129hon18sq1r571j9h64n4qm4o.png" alt="image_1bf129hon18sq1r571j9h64n4qm4o.png-346.9kB"><br>查看图形结果<br><img src="http://static.zybuluo.com/BruceTang/91gedw8aeav65kg20t70hxrr/image_1bf1386ai1odb7801d0mrbeimf6c.png" alt="image_1bf1386ai1odb7801d0mrbeimf6c.png-322.6kB"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[root@node-11 ~]# free -m</div><div class="line">             total       used       free     shared    buffers     cached</div><div class="line">Mem:          1834       1735         98          8          0       1177</div><div class="line">-/+ buffers/cache:        558       1275</div><div class="line">Swap:         8079          0       8079</div></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> 运维监控 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> zabbix3.0 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[zabbix 3.0 服务监控--Web监控]]></title>
      <url>http://yoursite.com/2016/10/03/zabbix%203.0%20%E6%9C%8D%E5%8A%A1%E7%9B%91%E6%8E%A7--Web%E7%9B%91%E6%8E%A7/</url>
      <content type="html"><![CDATA[<h2 id="检查"><a href="#检查" class="headerlink" title="检查"></a>检查</h2><p>1.查看进程<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[root@node-11 ~]# ps -ef | grep java</div><div class="line">root     27297     1  3 18:43 pts/1    00:00:04 /usr/local/java/bin/java -Djava.util.logging.config.file=/usr/local/apache-tomcat-8.0.9/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Djava.endorsed.dirs=/usr/local/apache-tomcat-8.0.9/endorsed -classpath /usr/local/apache-tomcat-8.0.9/bin/bootstrap.jar:/usr/local/apache-tomcat-8.0.9/bin/tomcat-juli.jar -Dcatalina.base=/usr/local/apache-tomcat-8.0.9 -Dcatalina.home=/usr/local/apache-tomcat-8.0.9 -Djava.io.tmpdir=/usr/local/apache-tomcat-8.0.9/temp org.apache.catalina.startup.Bootstrap start</div><div class="line">root     27993  2730  0 18:45 pts/1    00:00:00 grep --color=auto java</div></pre></td></tr></table></figure></p>
<a id="more"></a>
<p>2.查看端口<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[root@node-11 ~]# lsof -i:8080</div><div class="line">COMMAND   PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME</div><div class="line">java    27297 root   49u  IPv6 148863      0t0  TCP *:webcache (LISTEN)</div></pre></td></tr></table></figure></p>
<p>3.测试是否可以访问8080端口<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[root@node-11 ~]#  curl  -I 192.168.1.11:8080</div><div class="line">HTTP/1.1 200 OK</div><div class="line">Server: Apache-Coyote/1.1</div><div class="line">Content-Type: text/html;charset=UTF-8</div><div class="line">Transfer-Encoding: chunked</div><div class="line">Date: Sat, 29 Apr 2017 10:46:51 GMT</div></pre></td></tr></table></figure></p>
<h2 id="Zabbix-Web界面配置"><a href="#Zabbix-Web界面配置" class="headerlink" title="Zabbix Web界面配置"></a>Zabbix Web界面配置</h2><p><img src="http://static.zybuluo.com/BruceTang/kz17dvimywbelx57br72cps5/image_1bev6qnjf1lb91rb81suj1vj7u42a.png" alt="image_1bev6qnjf1lb91rb81suj1vj7u42a.png-188.4kB"><br><strong>提示： 监控Web 不依赖于agent，是server直接发送请求的</strong><br><img src="http://static.zybuluo.com/BruceTang/lptove1xf8s4v27ybf5p5fbt/image_1bev6s8p7p2lui8lka37ghnf2n.png" alt="image_1bev6s8p7p2lui8lka37ghnf2n.png-153kB"><br>提示： 这里名字叫做Web场景，因为我们可以设置触发上面3个选项后，才进行报警<br><img src="http://static.zybuluo.com/BruceTang/5x8mg0w8a6ynealfn3504dgh/image_1bev73jns1doj9kf1nefefr1i6v34.png" alt="image_1bev73jns1doj9kf1nefefr1i6v34.png-162.2kB"><br>提示： 字符串里面可以添加一些字符串，当请求下来有这个字符串就是正常，没有就是不正常。但是最常用的还是状态<br><img src="http://static.zybuluo.com/BruceTang/g3ikswqp3ldtrs2xw4qwt0en/image_1bev75c4cito938ac4fp91arn3h.png" alt="image_1bev75c4cito938ac4fp91arn3h.png-166.1kB"></p>
<p><strong>新添加web监控，zabbix默认是没有给我们设置触发器的，需要我们自己设置</strong><br><img src="http://static.zybuluo.com/BruceTang/vimeqk9yl563j3kwzd4u4hbw/image_1bf0r8ctjsrs1c4s1amd18lb7759.png" alt="image_1bf0r8ctjsrs1c4s1amd18lb7759.png-378.3kB"></p>
<h2 id="触发器添加"><a href="#触发器添加" class="headerlink" title="触发器添加"></a>触发器添加</h2><p><img src="http://static.zybuluo.com/BruceTang/oae0fg901d0s0xx45j6ef1vn/image_1bf0ran3pa4u1o14u8ibr6op2m.png" alt="image_1bf0ran3pa4u1o14u8ibr6op2m.png-175.7kB"></p>
<p>Web监控中默认不含有触发器，所以需要手动添加<br><img src="http://static.zybuluo.com/BruceTang/des9cftvyz2o8ugoblormytq/image_1bf0rcmro1a9f1osa1ti41rhu1n6h13.png" alt="image_1bf0rcmro1a9f1osa1ti41rhu1n6h13.png-291.9kB"><br><img src="http://static.zybuluo.com/BruceTang/ny633o9e2c7wp5ucqeap5y8i/image_1bf0rf8sgo96a0s1vm113j31j8e1g.png" alt="image_1bf0rf8sgo96a0s1vm113j31j8e1g.png-183.1kB"><br><img src="http://static.zybuluo.com/BruceTang/2rn27e3311bvjxdinfyb22ds/image_1bf0rgn8u1pf6c6u1sl39v97mv1t.png" alt="image_1bf0rgn8u1pf6c6u1sl39v97mv1t.png-351.9kB"><br>最终结果：<br><img src="http://static.zybuluo.com/BruceTang/tsmijy5us0zkrstlg12b03lh/image_1bf0rjbr1rt1misgnbfod1dvu2a.png" alt="image_1bf0rjbr1rt1misgnbfod1dvu2a.png-159.6kB"></p>
]]></content>
      
        <categories>
            
            <category> 运维监控 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> zabbix3.0 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[zabbix 3.0 服务监控--MySQL]]></title>
      <url>http://yoursite.com/2016/10/02/zabbix%203.0%20%E6%9C%8D%E5%8A%A1%E7%9B%91%E6%8E%A7--MySQL/</url>
      <content type="html"><![CDATA[<p>Mysql监控<br>zabbix自带了一个监控mysql的模板，但是真正监控mysql的并不是zabbix自带的模板。而是percona公司的一个监控mysql模板<br>　<em> percona官网： www.percona.com<br><a id="more"></a><br><em>*Percona组成介绍</em></em></p>
<pre><code>1、php脚本    用来数据采集
2、shell脚本  用来调用采集信息
3、zabbix配置文件
4、zabbix模板文件
</code></pre><p>安装文档：<a href="https://www.percona.com/doc/percona-monitoring-plugins/LATEST/zabbix/index.html" target="_blank" rel="external">https://www.percona.com/doc/percona-monitoring-plugins/LATEST/zabbix/index.html</a><br>　　percona 利用的是php来获取mysql的相关信息，所以如果我们想使用percona插件监控mysql就需要在agent端安装php。在安装文档上有写哦~<br><img src="http://static.zybuluo.com/BruceTang/dy8905qhs5ziio5o3ul25au8/image_1beu2alu21fr713i5d2e1t577kj9.png" alt="image_1beu2alu21fr713i5d2e1t577kj9.png-171.9kB"><br>安装步骤： 查看上面的链接也可以进行安装<br>我们安装在zabbix-agent上，因为上面有一个MySQL<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">[root@node-11 web]# yum install http://www.percona.com/downloads/percona-release/redhat/0.1-3/percona-release-0.1-3.noarch.rpm</div><div class="line">[root@node-11 web]# yum install percona-zabbix-templates php php-mysql -y</div><div class="line">#percona插件是通过php去获取mysql的参数，所以我们要安装php和php-mysql</div><div class="line"></div><div class="line">我们可以查看它都安装了那些软件</div><div class="line">[root@node-11 web]# rpm -ql percona-zabbix-templates</div><div class="line">/var/lib/zabbix/percona</div><div class="line">/var/lib/zabbix/percona/scripts</div><div class="line">/var/lib/zabbix/percona/scripts/get_mysql_stats_wrapper.sh  #shell脚本</div><div class="line">/var/lib/zabbix/percona/scripts/ss_get_mysql_stats.php      #php获取mysql信息</div><div class="line">/var/lib/zabbix/percona/templates</div><div class="line">/var/lib/zabbix/percona/templates/userparameter_percona_mysql.conf #zabbix配置文件</div><div class="line">/var/lib/zabbix/percona/templates/zabbix_agent_template_percona_mysql_server_ht_2.0.9-sver1.1.6.xml  </div><div class="line">#zabbix模板文件在percona组成我们已经说过了，此处只是略微介绍</div></pre></td></tr></table></figure></p>
<p>我们将zabbix模板下载下来<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@node-11 web]# sz /var/lib/zabbix/percona/templates/zabbix_agent_template_percona_mysql_server_ht_2.0.9-sver1.1.6.xml</div></pre></td></tr></table></figure></p>
<p>然后我们需要将模板通过web界面导入到zabbix中<br><img src="http://static.zybuluo.com/BruceTang/u8mn9wzijy535kmttzlpnlrc/image_1beu2f5lrcf2lvqdp51q0p1pimm.png" alt="image_1beu2f5lrcf2lvqdp51q0p1pimm.png-349.1kB"><br><img src="http://static.zybuluo.com/BruceTang/h8tfadwpsgo4m806yy9ywhcu/image_1beu2fgf51av097h1t6n24a1s8l13.png" alt="image_1beu2fgf51av097h1t6n24a1s8l13.png-101.8kB"></p>
<p><strong>提示</strong>：如果出现错误，可能是zabbix 3.0版本的问题。我们这里提供了一个生产的模板<br>下载链接：<a href="http://pan.baidu.com/s/1pLjKvxh" target="_blank" rel="external">http://pan.baidu.com/s/1pLjKvxh</a> 密码：75g0<br>然后从新上传之后导入即可</p>
<p>复制配置文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[root@node-11 web]# cp /var/lib/zabbix/percona/templates/userparameter_percona_mysql.conf /etc/zabbix/zabbix_agentd.d/</div><div class="line">[root@node-11 web]# ls /etc/zabbix/zabbix_agentd.d/</div><div class="line">#安装完软件包后会在/var/lib/zabbix/percona/templates/目录下产生一个配置文件，我们将它拷贝，因为在前面的博文中，我们已经修改过zabbix的配置文件[Include=/etc/abbix/zabbix_agentd.d/</div><div class="line">] 所以将配置文件放在这个目录下，zabbix就会自己在这个目录下查找相关信息</div><div class="line">[root@node-11 web]# systemctl restart zabbix-agent.service </div><div class="line">重启一下！</div></pre></td></tr></table></figure></p>
<p>下面就应该配置与MySQL的连接<br>在<code>/var/lib/zabbix/percona/scripts/ss_get_mysql_stats.php.cnf</code>创建一个文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[root@linux-node1 ~]# cat /var/lib/zabbix/percona/scripts/ss_get_mysql_stats.php.cnf</div><div class="line">&lt;?php</div><div class="line">$mysql_user = &apos;root&apos;;</div><div class="line">$mysql_pass = &apos;&apos;;</div><div class="line">#用户名密码可以自己创建，有密码写密码，没密码为空就好了</div></pre></td></tr></table></figure></p>
<p>提示： 正常这里的用户我们应该创建一个专门用来监控的，由于我这里是测试环境。就不浪费时间了</p>
<p><strong>测试</strong><br>查看是否可以获取到值，随便找一个测试<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">[root@node-11 ~]# cat /var/lib/zabbix/percona/templates/userparameter_percona_mysql.conf</div><div class="line">选择一个肯定有值的key</div><div class="line">[root@node-11 ~]# cat /var/lib/zabbix/percona/templates/userparameter_percona_mysql.conf|grep gm</div><div class="line">UserParameter=MySQL.read-views,/var/lib/zabbix/percona/scripts/get_mysql_stats_wrapper.sh gm</div><div class="line">测试结果如下：</div><div class="line">[root@node-11 ~]# cd /var/lib/zabbix/percona/scripts/</div><div class="line">[root@node-11 scripts]# ./get_mysql_stats_wrapper.sh gm</div><div class="line">1</div><div class="line">[root@node-11 scripts]# ./get_mysql_stats_wrapper.sh gw</div><div class="line">468</div><div class="line">可以获取到值，说明没有问题</div></pre></td></tr></table></figure></p>
<p>温馨提示： shell脚本中数据库的路径是localhost，如果我们没有授权localhost会获取不到值<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@node-11 scripts]# cat get_mysql_stats_wrapper.sh </div><div class="line">HOST=localhost</div><div class="line">    RES=`HOME=~zabbix mysql -e &apos;SHOW SLAVE STATUS\G&apos; | egrep &apos;(Slave_IO_Running|Slave_SQL_Running):&apos; | awk -F: &apos;&#123;print $2&#125;&apos; | tr &apos;\n&apos; &apos;,&apos;`</div><div class="line">#mysql是通过命令来获取的，如果环境变量不一样 也可能造成影响</div></pre></td></tr></table></figure></p>
<p><strong>Zabbix_Web界面配置</strong><br>添加mysql监控模板（之前上传的模板）<br><img src="http://static.zybuluo.com/BruceTang/w1ab39zccz0tljsfzvs4i1na/image_1bev53r7edua1em5bfv1c7j1jbu9.png" alt="image_1bev53r7edua1em5bfv1c7j1jbu9.png-177.8kB"><br><img src="http://static.zybuluo.com/BruceTang/myvivvv31aix0kpu5pdnu8w0/image_1bev55cfl1a4g1o699b102i13sdm.png" alt="image_1bev55cfl1a4g1o699b102i13sdm.png-143.5kB"><br><img src="http://static.zybuluo.com/BruceTang/duenq36yvf99cpe6y6lwnmj9/image_1bev56ate29m1kcm57s9fheak13.png" alt="image_1bev56ate29m1kcm57s9fheak13.png-180.5kB"></p>
<p>结果如下图<br><img src="http://static.zybuluo.com/BruceTang/plbsp2l5642bwycd9luig2t6/image_1bev585u0i29hev4tl27v177t1g.png" alt="image_1bev585u0i29hev4tl27v177t1g.png-401.9kB"><br><img src="http://static.zybuluo.com/BruceTang/huc2e0r9zzuw7kvhcuywibgz/image_1bev59nho1k071dvrbs3rn89621t.png" alt="image_1bev59nho1k071dvrbs3rn89621t.png-335.5kB"></p>
<p><strong>思想：</strong><br>　　如果出现错误我们需要先查看shell的脚本，因为shell是去调用php。 错误的因素有很多，最简单的方法就是用shell 后面加上key 看看是否可以有值。<br>　　其中报错最多的地方就是php和mysql连接的问题，还有我们mysql授权的一些问题。</p>
]]></content>
      
        <categories>
            
            <category> 运维监控 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> zabbix3.0 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[zabbix 3.0 服务监控--nginx]]></title>
      <url>http://yoursite.com/2016/10/02/zabbix%203.0%20%E6%9C%8D%E5%8A%A1%E7%9B%91%E6%8E%A7--nginx/</url>
      <content type="html"><![CDATA[<p>在zabbix agentd客户端上，查看nginx是否加载了–with-http_stub_status_module。因为zabbix监控nginx是根据nginx的Stub Status模块，抓取Status模块所提供的数据。假如以前没开启，现在想启用StubStatus 模块，在编译nginx 的时候要加上参数 –with-http_stub_status_module，执行./configure &amp;&amp; make就可以了，不用make install。不过，一般情况下都是安装了的。<br><a id="more"></a></p>
<h2 id="nginx安装"><a href="#nginx安装" class="headerlink" title="nginx安装"></a>nginx安装</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@node-11 ~]# yum install -y nginx</div></pre></td></tr></table></figure>
<h2 id="添加nginx-status模块"><a href="#添加nginx-status模块" class="headerlink" title="添加nginx_status模块"></a>添加nginx_status模块</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">[root@node-11 ~]# cd /etc/nginx/conf.d/</div><div class="line">[root@node-11 conf.d]# vim nginx_status.conf </div><div class="line">server &#123;</div><div class="line">    listen    80;</div><div class="line">    location /nginx_status &#123;</div><div class="line">    stub_status on;</div><div class="line">        allow 127.0.0.1;   </div><div class="line">        allow 192.168.1.10;  </div><div class="line">    access_log off;</div><div class="line">&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">提示：nginx必须要有--with-http_stub_status_module模块</div></pre></td></tr></table></figure>
<h2 id="nginx状态测试"><a href="#nginx状态测试" class="headerlink" title="nginx状态测试"></a>nginx状态测试</h2><p>测试：<a href="http://192.168.1.11/nginx_status" target="_blank" rel="external">http://192.168.1.11/nginx_status</a><br><img src="http://static.zybuluo.com/BruceTang/22kbpb7sl7qtsvzwjm9surq7/image_1besj334d1sod120dhjk8q5nrm52.png" alt="image_1besj334d1sod120dhjk8q5nrm52.png-97.9kB"></p>
<p>解释说明：使用zabbix来监控nginx状态，通过status状态模块为前提<br>我们现在命令取出我们想要的值，例如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[root@node-11 conf.d]# curl -s http://192.168.1.11/nginx_status|grep Active|awk -F &quot;[ ]&quot; &apos;&#123;print $3&#125;&apos;</div><div class="line">1</div><div class="line">这里我们现在只是监控了nginx的一种最大连接数的状态，其实我们可以监控其他的状态</div></pre></td></tr></table></figure></p>
<h2 id="nginx自定义文件"><a href="#nginx自定义文件" class="headerlink" title="nginx自定义文件"></a>nginx自定义文件</h2><blockquote>
<p>自己编写一个nginx文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">[root@node-11 ~]# cd /etc/zabbix/zabbix_agentd.d/</div><div class="line">[root@node-11 zabbix_agentd.d]# ll</div><div class="line">总用量 12</div><div class="line">-rw-r--r--. 1 root root  469 4月  29 17:04 nginx_status.conf</div><div class="line">[root@node-11 zabbix_agentd.d]# cat nginx_status.conf </div><div class="line">UserParameter=nginx.active,/usr/local/src/nginx_status.sh active</div><div class="line">UserParameter=nginx.accepts,/usr/local/src/nginx_status.sh accepts</div><div class="line">UserParameter=nginx.handled,/usr/local/src/nginx_status.sh handled</div><div class="line">UserParameter=nginx.requests,/usr/local/src/nginx_status.sh requests</div><div class="line">UserParameter=nginx.reading,/usr/local/src/nginx_status.sh reading</div><div class="line">UserParameter=nginx.writing,/usr/local/src/nginx_status.sh writing</div><div class="line">UserParameter=nginx.waiting,/usr/local/src/nginx_status.sh waiting</div></pre></td></tr></table></figure></p>
<p>添加nginx监控脚本<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">[root@node-11 zabbix_agentd.d]# cd /usr/local/src/</div><div class="line">[root@node-11 src]# ll</div><div class="line">总用量 8</div><div class="line">-rwxr-xr-x. 1 root root  759 4月  29 17:05 nginx_status.sh</div><div class="line">[root@node-11 src]# cat nginx_status.sh</div><div class="line">#!/bin/bash</div><div class="line">case $1 in</div><div class="line">    active)</div><div class="line">        curl -s http://127.0.0.1/nginx_status | awk &apos;/Active/ &#123;print $3&#125;&apos; ;;</div><div class="line">    accepts)</div><div class="line">        curl -s http://127.0.0.1/nginx_status | awk &apos;NR==3 &#123;print $1&#125;&apos; ;;</div><div class="line">    handled)</div><div class="line">        curl -s http://127.0.0.1/nginx_status | awk &apos;NR==3 &#123;print $2&#125;&apos; ;;</div><div class="line">    requests)</div><div class="line">        curl -s http://127.0.0.1/nginx_status | awk &apos;NR==3 &#123;print $3&#125;&apos; ;;</div><div class="line">    reading)</div><div class="line">        curl -s http://127.0.0.1/nginx_status | awk &apos;/Reading/ &#123;print $2&#125;&apos; ;;</div><div class="line">    writing)</div><div class="line">        curl -s http://127.0.0.1/nginx_status | awk &apos;/Writing/ &#123;print $4&#125;&apos; ;;</div><div class="line">    waiting)</div><div class="line">        curl -s http://127.0.0.1/nginx_status | awk &apos;/Waiting/ &#123;print $6&#125;&apos; ;;</div><div class="line">    *)</div><div class="line">        echo &quot;Usage: $0 &#123; active | accepts | handled | requests | reading | writing | waiting &#125;&quot; ;;</div><div class="line">esa</div></pre></td></tr></table></figure></p>
</blockquote>
<p><strong>修改完配置文件都要重启zabbix-agent</strong></p>
<h2 id="在server端对nginx进行测试"><a href="#在server端对nginx进行测试" class="headerlink" title="在server端对nginx进行测试"></a>在server端对nginx进行测试</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# yum install -y zabbix-get</div><div class="line">[root@node-10 ~]#  zabbix_get -s 192.168.1.11  -p 10050 -k &quot;nginx.active&quot;</div><div class="line">1</div><div class="line">[root@node-10 ~]#  zabbix_get -s 192.168.1.11  -p 10050 -k &quot;nginx.accepts&quot;</div><div class="line">4839</div><div class="line">[root@node-10 ~]#  zabbix_get -s 192.168.1.11  -p 10050 -k &quot;nginx.requests&quot;</div><div class="line">4841</div><div class="line">[root@node-10 ~]#  zabbix_get -s 192.168.1.11  -p 10050 -k &quot;nginx.reading&quot;</div><div class="line">0</div><div class="line">[root@node-10 ~]#  zabbix_get -s 192.168.1.11  -p 10050 -k &quot;nginx.writing&quot;</div><div class="line">1</div><div class="line">[root@node-10 ~]#  zabbix_get -s 192.168.1.11  -p 10050 -k &quot;nginx.waiting&quot;</div><div class="line">0</div></pre></td></tr></table></figure>
<p>以上测试正确，我们还需要在zabbix-web页面上进行设置</p>
<h2 id="监控项添加"><a href="#监控项添加" class="headerlink" title="监控项添加"></a>监控项添加</h2><p>在主机模板上新添一个监控项：<br><img src="http://static.zybuluo.com/BruceTang/e7hxc6s39weeads3rnpnzq2p/image_1besjpivc17rmeqg121v1lb21q045f.png" alt="image_1besjpivc17rmeqg121v1lb21q045f.png-202.6kB"><br><img src="http://static.zybuluo.com/BruceTang/em6kqvgwt3ycbbgigflho70t/image_1besjsftu15mt11up99dr5m113e69.png" alt="image_1besjsftu15mt11up99dr5m113e69.png-178.7kB"><br><img src="http://static.zybuluo.com/BruceTang/ir2ngoxqvxbprxxfwqq23mq1/image_1besjtqfo2njidk1piq1savdkv73.png" alt="image_1besjtqfo2njidk1piq1savdkv73.png-139.1kB"><br>现在一个监控项已经添加好，剩余的直接克隆模板，修改就行<br>最终监控项结果<br><img src="http://static.zybuluo.com/BruceTang/wwx083y7bc6b66voaog1hka3/image_1besk0m01aus19m3a514ol1t5c7g.png" alt="image_1besk0m01aus19m3a514ol1t5c7g.png-266.7kB"></p>
<h3 id="图形添加"><a href="#图形添加" class="headerlink" title="图形添加"></a>图形添加</h3><p><img src="http://static.zybuluo.com/BruceTang/wm6mxp9j2qu4gvvuesjlsfkz/image_1besk2evb1cu71sjrilt3fc15vn8a.png" alt="image_1besk1ce41cdl1oast6p1i9t13687t.png-190.3kB"><br><img src="http://static.zybuluo.com/BruceTang/jxnf3b5cyl3xrtg5zsmrrxr3/image_1besk3o6c13dc1ugi1j931uul1sj38n.png" alt="image_1besk3o6c13dc1ugi1j931uul1sj38n.png-154.6kB"><br><img src="http://static.zybuluo.com/BruceTang/7ba752fts15h1m2elwtcbdyk/image_1besk4i0m17n01nct16co4lm1u3l94.png" alt="image_1besk4i0m17n01nct16co4lm1u3l94.png-312.6kB"><br>最终结果：<br><img src="http://static.zybuluo.com/BruceTang/n1vu0z9kg8sq298hjovfrnzh/image_1besk67081san1sh61u961uqv11ub9h.png" alt="image_1besk67081san1sh61u961uqv11ub9h.png-321.9kB"></p>
<p><strong>添加自定义监控项小结： *</strong><br>　　　1、添加用户自定义参数（在/etc/zabbix/zabbix.agent.d/定义了一个nginx_status.conf步骤如上）,<br>　　　2.添加用户自定义获取nginx状态的脚本（/usr/local/src/nginx_status.sh）<br>　　　2、重启zabbix-agent<br>　　　3、在Server端使用zabbix_get测试获取（命令如上）<br>　　　4、在web界面创建item（监控项）<br>　　　5、在web界面创建图形</p>
]]></content>
      
        <categories>
            
            <category> 运维监控 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> zabbix3.0 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[zabbix 3.0 基础介绍]]></title>
      <url>http://yoursite.com/2016/10/01/zabbix%203.0%20%E5%9F%BA%E7%A1%80%E4%BB%8B%E7%BB%8D%20%5B%E4%B8%80%5D/</url>
      <content type="html"><![CDATA[<h2 id="Zabbix介绍"><a href="#Zabbix介绍" class="headerlink" title="Zabbix介绍"></a>Zabbix介绍</h2><h3 id="zabbix-简介"><a href="#zabbix-简介" class="headerlink" title="zabbix 简介"></a>zabbix 简介</h3><p>　　Zabbix是一个高度集成的网络监控解决方案，可以提供企业级的开源分布式监控解决方案，由一个国外的团队持续维护更新，软件可以自由下载使用，运作团队靠提供收费的技术支持赢利<br>　　zabbix是一个基于Web界面的，提供分布式系统监控以及网络监视功能的企业级的开源解决方案。<br>　　zabbix能监视各种网络参数，保证服务器系统的安全运营，并提供灵活的通知机制以让系统管理员快速定位/解决存在的各种问题<br>　　zabbix主要由2部分构成zabbixserver和zabbixagent，可选组建zabbix proxyzabbix。　　<br>　　server可以通过SNMP，zabbixagent，fping端口监视等方法对远程服务器或网络状态完成监视，数据收集等功能。同时支持Linux以及Unix平台，Windows平台只能安装客户端<br><a id="more"></a></p>
<h3 id="zabbix功能"><a href="#zabbix功能" class="headerlink" title="zabbix功能"></a>zabbix功能</h3><p>　　①具备常见的商业监控软件所具备的功能（主机的性能监控、网络设备性能监控、数据库、性能监控、FTP 等通用协议监控、多种告警方式、详细的报表图表绘制）<br>　　②支持自动发现网络设备和服务器（可以通过配置自动发现服务器规则来实现）<br>　　③支持自动发现（low discovery）key 实现动态监控项的批量监控（需写脚本）<br>　　④支持分布式，能集中展示、管理分布式的监控点<br>　　⑤扩展性强，server 提供通用接口（api 功能），可以自己开发完善各类监控（根据相关接口编写程序实现）编写插件容易，可以自定义监控项，报警级别的设置。<br>　　⑥数据收集<br>　可用和性能检测<br>　支持snmp(包括trapping and polling)，IPMI，JMX，SSH，TELNET<br>　自定义的检测<br>　自定义收集数据的频率<br>　服务器/代理和客户端模式<br>　灵活的触发器<br>　可以定义非常灵活的问题阈值，称为触发器，从后端数据库的参考值<br>　高可定制的报警<br>　发送通知，可定制的报警升级，收件人，媒体类型<br>　通知可以使用宏变量有用的变量<br>　自动操作包括远程命令<br>　实时的绘图功能<br>　监控项实时的将数据绘制在图形上面<br>　WEB 监控能力<br>　ZABBIX 可以模拟鼠标点击了一个网站，并检查返回值和响应时间</p>
<h3 id="Api-功能"><a href="#Api-功能" class="headerlink" title="Api 功能"></a>Api 功能</h3><p>应用api功能，可以方便的和其他系统结合，包括手机客户端的使用。<br>更多功能请查看<br><a href="http://www.zabbix.com/documentation.php" target="_blank" rel="external">http://www.zabbix.com/documentation.php</a></p>
<h3 id="Zabbix版本"><a href="#Zabbix版本" class="headerlink" title="Zabbix版本"></a>Zabbix版本</h3><p>Zabbix 3.0 Manual<br>Zabbix 2.4 Manual<br>Zabbix 2.2 Manual<br>Zabbix 2.0 Manual<br>下载地址：<a href="http://www.zabbix.com/documentation.php" target="_blank" rel="external">http://www.zabbix.com/documentation.php</a><br>本次采用yum安装，安装zabbix3.0.使用Centos7</p>
<h3 id="Zabbix优缺点"><a href="#Zabbix优缺点" class="headerlink" title="Zabbix优缺点"></a>Zabbix优缺点</h3><p><strong>优点</strong><br>　1、开源，无软件成本投入<br>　2、Server 对设备性能要求低<br>　3、支持设备多，自带多种监控模板<br>　4、支持分布式集中管理，有自动发现功能，可以实现自动化监控<br>　5、开放式接口，扩展性强，插件编写容易<br>　6、当监控的item 比较多服务器队列比较大时可以采用被动状态，被监控客户端主动从<br>　7、server 端去下载需要监控的item 然后取数据上传到server 端。这种方式对服务器的负载比较小。<br>　8、Api 的支持，方便与其他系统结合<br><strong>缺点</strong><br>　　需在被监控主机上安装agent，所有数据都存在数据库里，产生的数据据很大,瓶颈主要在<code>数据库</code>。</p>
<h3 id="Zabbix监控原理"><a href="#Zabbix监控原理" class="headerlink" title="Zabbix监控原理"></a>Zabbix监控原理</h3><p><strong>Server</strong>：Zabbix Server需运行在LAMP（Linux+Apache+Mysql+PHP）环境下（或者LNMP），对硬件要求低。<br><strong>Agent</strong>：目前已有的agent基本支持市面常见的OS，包含Linux、HPX、Solaris、Sun、 windows<br><strong>SNMP：</strong>支持各类常见的网络设备 SNMP(Simple NetworkManagement Protocol,简单网络管理协议</p>
<h3 id="Zabbix监控过程逻辑图"><a href="#Zabbix监控过程逻辑图" class="headerlink" title="Zabbix监控过程逻辑图"></a>Zabbix监控过程逻辑图</h3><p><img src="http://static.zybuluo.com/abcdocker/3k6ikw8aqzewig8krhbbj7h5/1.png" alt="此处输入图片的描述"></p>
<h3 id="监控类型"><a href="#监控类型" class="headerlink" title="监控类型"></a>监控类型</h3><p><strong>硬件监控:</strong> 适用于物理机、远程管理卡（iDRAC），IPMI（只能平台管理接口） ipmitools:，MegaCli（查看Raid磁盘）<br><strong>系统监控:</strong> 监控cpt：lscpu、uptime、top、vmstat 1 、mpstat 1、htop<br><strong>监控内存:</strong> free -m<br><strong>监控硬盘:</strong> df -h、iotop<br><strong>监控网络：</strong> iftop、netstat、ss<br><strong>应用服务监控：</strong> tomcat、MySQL、nginx、apache、php、redis<br>更详细的监控类型可以参考:<a href="https://tangxiaoyue.github.io/2017/01/01/%E7%9B%91%E6%8E%A7%E4%BD%93%E7%B3%BB/" target="_blank" rel="external">https://tangxiaoyue.github.io/2017/01/01/%E7%9B%91%E6%8E%A7%E4%BD%93%E7%B3%BB/</a></p>
<h3 id="引入zabbix"><a href="#引入zabbix" class="headerlink" title="引入zabbix"></a>引入zabbix</h3><p>所有监控范畴，都可以整合到Zabbix中 :<br><code>硬件监控</code>：Zabbix、IPMI、lnterface<br><code>系统监控</code>：Zabbix、Agent、Interface<br><code>Java监控</code>：Zabbix、JMX、lnterface<br><code>网络设备监控</code>：Zabbix、SNMP、lnterface<br><code>应用服务监控</code>：Zabbix、Agent、UserParameter<br><code>MySQL数据库监控</code>：percona-monitoring-plulgins<br><code>URL监控</code>：Zabbix Web监控 </p>
<h2 id="Zabbix-环境配置"><a href="#Zabbix-环境配置" class="headerlink" title="Zabbix 环境配置"></a>Zabbix 环境配置</h2><h3 id="环境信息"><a href="#环境信息" class="headerlink" title="环境信息"></a>环境信息</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# cat /etc/redhat-release </div><div class="line">CentOS Linux release 7.0.1406 (Core) </div><div class="line">[root@localhost ~]# uname -r</div><div class="line">3.10.0-123.el7.x86_64</div><div class="line">[root@node-10 ~]# ifconfig|awk -F &apos; &apos; &apos;NR==2&#123;print $2&#125;&apos;</div><div class="line">192.168.1.10</div></pre></td></tr></table></figure>
<h2 id="yum安装zabbix-server"><a href="#yum安装zabbix-server" class="headerlink" title="yum安装zabbix-server"></a>yum安装zabbix-server</h2><p>阿里云yum源已经提供了zabbix3.0，因此我们需要使用官方yum源。官方yum源下载会比较慢<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# rpm -ivh    http://mirrors.aliyun.com/zabbix/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm</div></pre></td></tr></table></figure></p>
<p>问题：为什么要下载release版本的zabbix？<br>因为下载这个版本会在yum.repos.d下面生成一个zabbix.repo的文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# ll /etc/yum.repos.d/</div><div class="line">总用量 28</div><div class="line">-rw-r--r--. 1 root root 1612 7月   4 2014 CentOS-Base.repo</div><div class="line">-rw-r--r--. 1 root root  640 7月   4 2014 CentOS-Debuginfo.repo</div><div class="line">-rw-r--r--. 1 root root 1331 7月   4 2014 CentOS-Sources.repo</div><div class="line">-rw-r--r--. 1 root root  156 7月   4 2014 CentOS-Vault.repo</div><div class="line">-rw-r--r--. 1 root root  957 12月 28 01:37 epel.repo</div><div class="line">-rw-r--r--. 1 root root 1056 12月 28 01:37 epel-testing.repo</div><div class="line">-rw-r--r--. 1 root root  401 2月  15 2016 zabbix.repo</div></pre></td></tr></table></figure></p>
<h3 id="安装zabbix-server相关软件包"><a href="#安装zabbix-server相关软件包" class="headerlink" title="安装zabbix-server相关软件包"></a>安装zabbix-server相关软件包</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# yum install zabbix-server zabbix-web zabbix-server-mysql zabbix-web-mysql mariadb-server mariadb -y</div></pre></td></tr></table></figure>
<ul>
<li>提示：在Centos7中，mysql改名为mariadb<h3 id="安装zabbix-agent"><a href="#安装zabbix-agent" class="headerlink" title="安装zabbix-agent"></a>安装zabbix-agent</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# rpm -ivh http://repo.zabbix.com/zabbix/2.4/rhel/7/x86_64/zabbix-release-2.4-1.el7.noarch.rpm</div><div class="line">[root@node-10 ~]# yum install -y zabbix-agent</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="修改PHP时区设置"><a href="#修改PHP时区设置" class="headerlink" title="修改PHP时区设置"></a>修改PHP时区设置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# sed -i &apos;s@# php_value date.timezone Europe/Riga@php_value date.timezone Asia/Shanghai@g&apos; /etc/httpd/conf.d/zabbix.conf</div><div class="line">#要注意需要改的配置文件是/etc/httpd/conf.d/zabbix.conf而不是/etc/php.ini，</div></pre></td></tr></table></figure>
<h2 id="数据库设置"><a href="#数据库设置" class="headerlink" title="数据库设置"></a>数据库设置</h2><h3 id="启动数据库"><a href="#启动数据库" class="headerlink" title="启动数据库"></a>启动数据库</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# systemctl start mariadb</div></pre></td></tr></table></figure>
<h3 id="创建zabbix数据库及用户"><a href="#创建zabbix数据库及用户" class="headerlink" title="创建zabbix数据库及用户"></a>创建zabbix数据库及用户</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">mysql</div><div class="line">&gt; create database zabbix character set utf8 collate utf8_bin;</div><div class="line">&gt; grant all on zabbix.* to zabbix@&apos;localhost&apos; identified by &apos;123456&apos;;</div><div class="line">&gt; exit</div></pre></td></tr></table></figure>
<h3 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# cd /usr/share/doc/zabbix-server-mysql-3.0.9/</div><div class="line">[root@node-10 zabbix-server-mysql-3.0.9]# ll</div><div class="line">总用量 1872</div><div class="line">-rw-r--r--. 1 root root      98 4月  20 20:05 AUTHORS</div><div class="line">-rw-r--r--. 1 root root  718465 4月  20 20:05 ChangeLog</div><div class="line">-rw-r--r--. 1 root root   17990 4月  20 20:05 COPYING</div><div class="line">-rw-r--r--. 1 root root 1159237 4月  24 02:04 create.sql.gz</div><div class="line">-rw-r--r--. 1 root root      52 4月  20 20:05 NEWS</div><div class="line">-rw-r--r--. 1 root root     188 4月  20 20:05 README</div><div class="line">[root@node-10 zabbix-server-mysql-3.0.4]# zcat create.sql.gz |mysql -uzabbix -p123456 zabbix</div></pre></td></tr></table></figure>
<p>我们使用<code>zcat</code>，专门查看<code>sql.gz</code>包。和<code>cat</code>基本相似</p>
<h3 id="修改zabbix配置文件"><a href="#修改zabbix配置文件" class="headerlink" title="修改zabbix配置文件"></a>修改zabbix配置文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# vim /etc/zabbix/zabbix_server.conf </div><div class="line">DBHost=localhost    #数据库所在主机</div><div class="line">DBName=zabbix       #数据库名</div><div class="line">DBUser=zabbix       #数据库用户</div><div class="line">DBPassword=123456   #数据库密码</div></pre></td></tr></table></figure>
<h3 id="启动zabbix及apache"><a href="#启动zabbix及apache" class="headerlink" title="启动zabbix及apache"></a>启动zabbix及apache</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[root@localhost ~]# systemctl start zabbix-server</div><div class="line">[root@localhost ~]# systemctl start httpd</div><div class="line">注意：如果没有启动成功，要看一下是不是80端口被占用</div></pre></td></tr></table></figure>
<h3 id="Web界面安装master"><a href="#Web界面安装master" class="headerlink" title="Web界面安装master"></a>Web界面安装master</h3><p>访问地址：<a href="http://192.168.1.11/zabbix/setup.php" target="_blank" rel="external">http://192.168.1.11/zabbix/setup.php</a><br><img src="http://static.zybuluo.com/abcdocker/am14alnxj6pp1g6ih7gkohom/1.png" alt="此处输入图片的描述"><br>点击<code>Next step</code>进行安装<br><img src="http://static.zybuluo.com/abcdocker/g9f1uz2h9cpmg8hn13spxpyi/1.png" alt="此处输入图片的描述"><br>…<br>点击Finish<br><img src="http://static.zybuluo.com/abcdocker/227kxcx6p58dac0d0tr064xi/1.png" alt="此处输入图片的描述"></p>
<blockquote>
<p>提示：上去之后请立即修改密码</p>
</blockquote>
<h3 id="配置zabbix-agent端"><a href="#配置zabbix-agent端" class="headerlink" title="配置zabbix-agent端"></a>配置zabbix-agent端</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@localhost ~]# vim /etc/zabbix/zabbix_agentd.conf </div><div class="line">Server=127.0.0.1       修改Server端的IP地址（被动模式IP地址）</div><div class="line">ServerActive=127.0.0.1     主动模式，主动向server端报告</div><div class="line">[root@localhost ~]# systemctl start zabbix-agent</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# netstat -lntp</div><div class="line">Active Internet connections (only servers)</div><div class="line">Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    </div><div class="line">tcp        0      0 127.0.0.1:25            0.0.0.0:*               LISTEN      2434/master         </div><div class="line">tcp        0      0 0.0.0.0:10050           0.0.0.0:*               LISTEN      4103/zabbix_agentd  </div><div class="line">tcp        0      0 0.0.0.0:10051           0.0.0.0:*               LISTEN      3887/zabbix_server  </div><div class="line">tcp        0      0 0.0.0.0:3306            0.0.0.0:*               LISTEN      3800/mysqld         </div><div class="line">tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      1482/sshd           </div><div class="line">tcp6       0      0 ::1:25                  :::*                    LISTEN      2434/master         </div><div class="line">tcp6       0      0 :::10050                :::*                    LISTEN      4103/zabbix_agentd  </div><div class="line">tcp6       0      0 :::10051                :::*                    LISTEN      3887/zabbix_server  </div><div class="line">tcp6       0      0 :::80                   :::*                    LISTEN      3973/httpd          </div><div class="line">tcp6       0      0 :::22                   :::*                    LISTEN      1482/sshd</div></pre></td></tr></table></figure>
<h2 id="Web界面配置"><a href="#Web界面配置" class="headerlink" title="Web界面配置"></a>Web界面配置</h2><h3 id="修改密码语言界面风格"><a href="#修改密码语言界面风格" class="headerlink" title="修改密码语言界面风格"></a>修改密码语言界面风格</h3><p><img src="http://static.zybuluo.com/BruceTang/tn8r6ame2y2rq58kzw2q32mk/2.png" alt="2.png-177.5kB"><br><img src="http://static.zybuluo.com/BruceTang/2xr9i9a545o6ndd0vk5d7s2u/3.png" alt="3.png-106.2kB"><br><img src="http://static.zybuluo.com/BruceTang/04ebhowe4n5tbqz6zgg0kkxv/4.png" alt="4.png-131.6kB"><br><img src="http://static.zybuluo.com/BruceTang/45dy06yuqlgjnyjdx3tidjin/5.png" alt="5.png-115.3kB"></p>
<h3 id="设置中文字符集"><a href="#设置中文字符集" class="headerlink" title="设置中文字符集"></a>设置中文字符集</h3><p>语言设置成中文之后发现是图形下面的文字出现乱码，不能显示出中文<br><img src="http://static.zybuluo.com/BruceTang/uwrph70u7b8eaawsoithts2x/6.png" alt="6.png-278kB"></p>
<p>zabbix默认字体在/usr/share/zabbix/fonts目录下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@node-10 fonts]# cd /usr/share/zabbix/fonts</div><div class="line">[root@node-10 fonts]# ll</div><div class="line">总用量 0</div><div class="line">lrwxrwxrwx. 1 root root 33 4月  29 15:49 graphfont.ttf -&gt; /etc/alternatives/zabbix-web-font</div></pre></td></tr></table></figure></p>
<p>上传微软字体<br>可以在Windows这个目录里面找字体<br><img src="http://static.zybuluo.com/BruceTang/hhcsp1p5iro89vt4eqso39ar/7.png" alt="7.png-339.8kB"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[root@node-10 fonts]# yum install -y lrzsz</div><div class="line">[root@node-10 fonts]# rz -y</div><div class="line"></div><div class="line">[root@node-10 fonts]# ll</div><div class="line">总用量 35524</div><div class="line">lrwxrwxrwx. 1 root root       33 4月  29 15:49 graphfont.ttf -&gt; /etc/alternatives/zabbix-web-font</div><div class="line">-rw-r--r--. 1 root root 14602860 6月  11 2009 msyhbd.ttf</div><div class="line">-rw-r--r--. 1 root root 21767952 6月  11 2009 msyh.ttf</div></pre></td></tr></table></figure></p>
<p>修改zabbix的web页面文件/usr/share/zabbix/include/defines.inc.php<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]#  vim /usr/share/zabbix/include/defines.inc.php</div><div class="line"></div><div class="line">define(&apos;ZBX_GRAPH_FONT_NAME&apos;,           &apos;msyh&apos;); // font file name</div><div class="line">define(&apos;ZBX_FONT_NAME&apos;, &apos;msyh&apos;);</div></pre></td></tr></table></figure></p>
<p>其中msyh为字体的前缀不包含ttf后缀。刷新页面后，完美的字体重新，不再是乱码<br><img src="http://static.zybuluo.com/BruceTang/pwff8lydhc6uj3rkop9amq1e/8.png" alt="8.png-284.2kB"></p>
]]></content>
      
        <categories>
            
            <category> 运维监控 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> zabbix3.0 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[监控体系]]></title>
      <url>http://yoursite.com/2016/10/01/%E7%9B%91%E6%8E%A7%E4%BD%93%E7%B3%BB/</url>
      <content type="html"><![CDATA[<h3 id="监控对象"><a href="#监控对象" class="headerlink" title="监控对象"></a>监控对象</h3><p>1.监控对象的理解：CPU是怎么工作的,原理<br>2.监控对象的指标：CPU使用率，CPU负载，CPU个数，上下文切换<br>3.确定性能基准线：怎样才算故障？CPU负载多少才算高</p>
<a id="more"></a>
<h3 id="监控范围"><a href="#监控范围" class="headerlink" title="监控范围"></a>监控范围</h3><p>1.硬件监控服务器的硬件故障<br>2.操作系统监控CPU、内存、硬盘、IO、进程<br>3.应用服务监控nginx、mysql等服务<br>4.业务监控</p>
<h3 id="硬件监控"><a href="#硬件监控" class="headerlink" title="硬件监控"></a>硬件监控</h3><p>1.使用IPMI<br>2.机房巡检</p>
<p>远程控制卡：<br>DELL服务器：<code>IDRAC</code><br>HP服务器：<code>ILO</code>—-Linux就可以使用IPMI（依赖于BMC控制器）<br>IBM服务器：<code>IMM</code></p>
<p>Linux是管理<code>IPMI</code>工具<br><code>ipmitools</code>（监控和控制）</p>
<blockquote>
<p>1.硬件要支持<br>2.操作系统Linux IPMI</p>
</blockquote>
<p>ipmitool安装</p>
<pre><code>[root@tang ~]# yum install OpenIPMI ipmitool -y
[root@tang ~]# rpm -qa OpenIPMI ipmitool
OpenIPMI-2.0.19-15.el7.x86_64
ipmitool-1.8.15-7.el7.x86_64
</code></pre><p>使用IPMI有两种方式</p>
<pre><code>1.本地进行调用
2.远程调用（IP地址 用户名和密码）

[root@tang ~]# systemctl start ipmi    启动（以centos7为例）
</code></pre><blockquote>
<p>IPMI相关命令</p>
</blockquote>
<pre><code>[root@tang ~]# ipmitool --help
</code></pre><blockquote>
<p>IPMI配置网络，有两种方式：</p>
</blockquote>
<pre><code>1.ipmi over lan（大体意识是通过网络来进行连接）
2.独立（给服务器单独查一根网线）Dell服务器可以在小面板中设置IPMI（云主机不需要考虑IPMI）
</code></pre><h3 id="SNMP监控"><a href="#SNMP监控" class="headerlink" title="SNMP监控"></a>SNMP监控</h3><p>对于路由器和交换机:SNMP（简单网络管理协议）监控<br>配置SNMP：（可以参考监控宝来进行监控）</p>
<pre><code>[root@tang ~]# yum -y install net-snmp net-snmp-utils
[root@tang ~]# rpm -qa net-snmp net-snmp-utils
net-snmp-5.7.2-24.el7_3.2.x86_64
net-snmp-utils-5.7.2-24.el7_3.2.x86_64
</code></pre><p>如果不知道要安装什么软件包，可以使用yum list|grep snmp</p>
<p>SNMP配置文件路径：</p>
<pre><code>[root@tang ~]# ll /etc/snmp/
total 8
-rw-r--r-- 1 root root  28 Apr 18 21:45 snmpd.conf
-rw------- 1 root root 220 Apr 13 02:34 snmptrapd.conf
</code></pre><p>修改配置文件，备份修改：</p>
<pre><code>[root@tang snmp]# mv snmpd.conf snmpd.conf.org
[root@tang snmp]# cat snmpd.conf.org 
rocommunity tang 172.18.0.1   第二个为团体名，IP是要监控的服务端
</code></pre><p>我们被发采集的服务器需要开启snmp<br>被采集的服务器要允许snmp访问</p>
<p>开启服务</p>
<pre><code>[root@tang snmp]#  systemctl start snmpd
[root@tang snmp]# netstat -lntup    #snmp默认监听的是udp161端口
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    
tcp        0      0 0.0.0.0:9133            0.0.0.0:*               LISTEN      2478/bubi           
tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      771/sshd            
tcp        0      0 127.0.0.1:5432          0.0.0.0:*               LISTEN      1594/postmaster     
tcp        0      0 0.0.0.0:19333           0.0.0.0:*               LISTEN      2478/bubi           
tcp        0      0 127.0.0.1:199           0.0.0.0:*               LISTEN      19346/snmpd         
tcp6       0      0 :::3306                 :::*                    LISTEN      2383/mysqld         
udp        0      0 172.18.0.1:123          0.0.0.0:*                           760/ntpd            
udp        0      0 172.17.82.185:123       0.0.0.0:*                           760/ntpd            
udp        0      0 127.0.0.1:123           0.0.0.0:*                           760/ntpd            
udp        0      0 0.0.0.0:123             0.0.0.0:*                           760/ntpd            
udp        0      0 0.0.0.0:161             0.0.0.0:*                           19346/snmpd         
udp6       0      0 :::123                  :::*                                760/ntpd            
</code></pre><h3 id="SNMP相关知识"><a href="#SNMP相关知识" class="headerlink" title="SNMP相关知识"></a>SNMP相关知识</h3><ul>
<li>snmp原理图</li>
</ul>
<p><img src="http://static.zybuluo.com/abcdocker/2imo9lugq26ugfjcqi7aaxhg/1.png" alt="image"></p>
<blockquote>
<p>什么是MIB？</p>
</blockquote>
<p>MIB是描述被管理设备商的参数的数据结构。如前所述管理一个设备，就是利用snmp协议，通过网络对被管理的设备上的参数进行get和get操作。<br>    那么如何组织被管理设备上的参数呢？多数情况下，可以get和set的参数实在多得惊人，假如仅仅简单地线性罗列它们，操作会十分不便。<br>    想象一下把1000个参数列成一张表，需要使用的时候查询这样一张表会有多么困难啊？比如您打算在地球上找一个城市，”Ithaca”，如果没有归类和分级，则需要查找一张巨大的表格。<br>    但如果告诉您城市”Ithaca”是：南美洲国家圭亚那的北部城市”Ithaca”，那么就容易些了吧？<br>    被管理的设备相当复杂，拥有很多可以被管理的参数，需要对它们进行归类，分级。<br>    管理信息库(MIB)是一个具有分层特性的信息的集合，我们可以通过 SNMP 去存取它。<br>    MIB 的成员是一些被管理的对象(ManagedObject)，以对象标示符(ObjectIdentifiers)来区分它们。被管理的对象由一个或多个对象实例(ObjectInstances)组成，本质上，这些对象实例就是变量。<br>    在 MIB 的层次结构中，一个对象标示符唯一标识了被管理对象。MIB的层次结构可以被描述成无根名的树，树的级别被不同的组织所划分。如下图所示： </p>
<p>   <img src="http://static.zybuluo.com/abcdocker/p24aj4t6lb0iizva85uk8pct/2.png" alt="image"></p>
<p> 相应的数字表示（对象标识符OID，唯一标识一个MIB对象）<br> 很多能够被 SNMP 管理的对象都是由标准组织定义好的。比如系统磁盘的信息，用 OID ”1.3.6.1.4.1.2021.9” 表示。这串数字是国际标准化组织协商定义好的，大家都要去遵循它。<br> 当然，国际组织不可能预知未来，如果您要开发的设备有一些管理需求没有任何 RFC 定义过，那么您也可以编写自己的 MIB 文件来定义私有的 MIB 对象。<br> NET-SNMP 是一种开放源代码的 SNMP 协议实现。它支持 SNMP v1, SNMP v2c 与 SNMP v3，并可以使用 IPV4 及 IPV6 。也包含 SNMP Trap 的所有相关实现。<br> Net-snmp 包含了 snmp 实用程序集和完整的 snmp 开发库。<br>用户使用 net-snmp 提供的工具，可以完成很多关于 SNMP 的操作，具体说来，包括以下一些命令行应用程序：<br>一些应用程序可以用来从支持 SNMP 的设备获得数据。其中 snmpget, snmpgetnext 可以支持独立请求，比如：</p>
<p> <img src="http://static.zybuluo.com/abcdocker/r7hrbhcj5ixjsxqi7qxcgvko/3.png" alt="image"></p>
<blockquote>
<p>NET-SNMP 简介</p>
</blockquote>
<p> 在 Linux 系统中，我们可以选择 net-snmp 来处理绝大多数和 SNMP 相关的工作。<br>NET-SNMP 是一种开放源代码的 SNMP 协议实现。它支持 SNMP v1, SNMP v2c 与 SNMP v3，并可以使用 IPV4 及 IPV6 。也包含 SNMP Trap 的所有相关实现。Net-snmp 包含了 snmp 实用程序集和完整的 snmp 开发库。<br>用户使用 net-snmp 提供的工具，可以完成很多关于 SNMP 的操作，具体说来，包括以下一些命令行应用程序：<br>一些应用程序可以用来从支持 SNMP 的设备获得数据。其中 snmpget, snmpgetnext 可以支持独立请求，比如:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">% snmpget -v 1 -c demopublic test.net-snmp.org system.sysUpTime.0 </div><div class="line">system.sysUpTime.0 = Timeticks: (586731977) 67 days, 21:48:39.77</div></pre></td></tr></table></figure></p>
<p>该命令获得单个独立的 MIB 对象 system.sysUpTime.0 的值。</p>
<p>而 snmpwalk, snmptable, snmpdelta 则用来支持重复请求。</p>
<pre><code>% snmpwalk -v 2c -c demopublic test.net-snmp.org system 
SNMPv2-MIB::sysDescr.0 = HP-UX net-snmp B.10.20 A 9000/715 
SNMPv2-MIB::sysObjectID.0 = OID: enterprises.ucdavis.ucdSnmpAgent.hpux10 
SNMPv2-MIB::sysUpTime.0 = Timeticks: (586998396) 67 days, 22:33:03.96 
SNMPv2-MIB::sysContact.0 = Wes Hardaker wjhardaker@ucdavis.edu 
SNMPv2-MIB::sysName.0 = net-snmp
</code></pre><p>上面的命令返回所有 system 节点以下的 MIB 对象的值。<br>命令 snmpset 对支持 SNMP 的设备配置属性。如下例所示</p>
<pre><code>$ snmpget -v 1 -c demopublic test.net-snmp.org ucdDemoPublicString.0 
UCD-DEMO-MIB::ucdDemoPublicString.0 = &quot;hi there!&quot; 
$ snmpset -v 1 -c demopublic test.net-snmp.org ucdDemoPublicString.0 s &quot;Hello, world!&quot; 
UCD-DEMO-MIB::ucdDemoPublicString.0 = &quot;Hello, world!&quot; 
$ snmpget -v 1 -c demopublic test.net-snmp.org ucdDemoPublicString.0 
UCD-DEMO-MIB::ucdDemoPublicString.0 = &quot;Hello, world!&quot;
</code></pre><p>命令snmpdf, snmpnetstat, snmpstatus 可以从支持 SNMP 的设备获取特定的信息。比如下面的命令从目标系统上获得类似 netstat 的信息：</p>
<pre><code>% snmpnetstat -v 2c -c public -a testhost 
Active Internet (tcp) Connections (including servers) 
Proto Local Address Foreign Address (state) 
tcp *.echo *.* LISTEN 
tcp *.discard *.* LISTEN 
tcp *.daytime *.* LISTEN 
tcp *.chargen *.* LISTEN 
tcp *.ftp *.* LISTEN
tcp *.telnet *.* LISTEN 
tcp *.smtp *.* LISTEN 
Active Internet (udp) Connections 
Proto Local Address 
udp *.echo 
udp *.discard 
udp *.daytime 
udp *.chargen 
udp *.time
</code></pre><p>snmptranslate 命令将 MIB OIDs 的两种表现形式 ( 数字及文字 ) 相互转换。并显示 MIB 的内容与结构，如下所示：</p>
<pre><code>% snmptranslate .1.3.6.1.2.1.1.3.0 
    SNMPv2-MIB::sysUpTime.0 
% snmptranslate -On SNMPv2-MIB::sysUpTime.0 
    .1.3.6.1.2.1.1.3.0
</code></pre><p>Net-snmp还提供了一个基于 Tk/perl 的，图形化的 MIB 浏览器 tkmib。<br>首先调用函数 snmp_pdu_create 创建一个 SNMPv2 的 Trap PDU。然后调用 snmp_add_var 向该 PDU 中添加图三所示的三个部分。<br>sysUpTime 在 SNMPv2-MIB中定义，其OID为”1.3.6.1.2.1.1.3.0”。我们只需要通过 get_uptime() 函数获得该值，然后调用snmp_add_var将该变量加入刚才创建的 PDU中。</p>
<p>SNMP例子：查看系统第一分钟的负载</p>
<pre><code>[root@tang snmp]#  snmpget -v2c -c tang 172.17.82.185  1.3.6.1.4.1.2021.10.1.3.1
</code></pre><ul>
<li><p>-c是团体名，在配置文件中定义的，还有ip地址       </p>
<pre><code>UCD-SNMP-MIB::laLoad.1 = STRING: 0.00
[root@tang snmp]# cat /etc/snmp/snmpd.conf
rocommunity tang 172.17.82.185
</code></pre></li>
</ul>
<p>提示：我们cpu所有指标都有一个oid 后面我们定义的数字就是oid<br>例如cacti就是通过snmp来获取性能指标，在使用RRDTool来进行画图</p>
<blockquote>
<p>SNMP 2种常用模式</p>
</blockquote>
<p>1.GerRequest PDU<br>2.GetNextRequest PDU</p>
<pre><code>[root@localhost snmp]# snmpwalk -v2c -c tang 172.17.82.185 1.3.6.1.4.1.2021.10.1.3
UCD-SNMP-MIB::laLoad.1 = STRING: 0.00
UCD-SNMP-MIB::laLoad.2 = STRING: 0.01
UCD-SNMP-MIB::laLoad.3 = STRING: 0.05
[root@localhost snmp]# uptime 
 13:16:08 up  6:35,  2 users,  load average: 0.00, 0.01, 0.05
</code></pre><p>linux下常用Oid<br><a href="http://linux.chinaunix.net/techdoc/net/2008/08/21/1026818.shtml" target="_blank" rel="external">http://linux.chinaunix.net/techdoc/net/2008/08/21/1026818.shtml</a><br><a href="http://www.2cto.com/os/201211/170730.html" target="_blank" rel="external">http://www.2cto.com/os/201211/170730.html</a><br>提示：只需要在IP地址后面输入相对应的oid即可</p>
<h3 id="系统监控"><a href="#系统监控" class="headerlink" title="系统监控"></a>系统监控</h3><blockquote>
<p>CPU<br>内存<br>IO Input/Output(网络、磁盘)</p>
</blockquote>
<pre><code>企业面试题：如果系统负载达到200了，SSH连接不上，如何让SSH连接上
      解答：改变SSH的优先级
</code></pre><h4 id="CPU监控"><a href="#CPU监控" class="headerlink" title="CPU监控"></a>CPU监控</h4><pre><code>cpu三个重要概念：
1.上下文切换：CPU调度器实施的进程的切换过程，上下文切换
2.运行队列（负载）：运行队列，排队可以参考 我是一个进程文章（http://blog.csdn.net/nylx/article/details/51058389）
3.使用率

监控CPU需要确定服务类型：
1.IO密集型（数据库）
2.CPU密集型（web/mail）

确定性能的基准线：
1.运行队列：1-3个线程    基准：1CPU 4核 负载不超过12
2.CPU使用：65%-70%用户态利用率
           30%-35%内核态利用率
           0%-5%空闲
3.上下文切换：越少越好

所有的监控都要根据业务来考虑
</code></pre><h4 id="常见CPU监控工具"><a href="#常见CPU监控工具" class="headerlink" title="常见CPU监控工具"></a>常见CPU监控工具</h4><p><code>top sysstat mpstat</code></p>
<h5 id="top说明"><a href="#top说明" class="headerlink" title="top说明"></a>top说明</h5><p><img src="http://static.zybuluo.com/abcdocker/hecq3ii0fy0pq8cahuhxblun/4.png" alt="image"></p>
<p><strong>第一行</strong> <code>分别显示：系统当前时间 系统运行时间 当前用户登陆数 系统负载</code>。<br>　　系统负载（loadaverage），这里有三个数值，分别是系统最近<code>1分钟</code>，<code>5分钟</code>，<code>15分钟</code>的平均负载。<br>　　一般对于单个处理器来说，负载在0—1.00之间是正常的，超过1.00就要引起注意了。在多核处理器中，你的系统均值不应该高于处理器核心的总数。</p>
<p><strong>第二行</strong> 分别显示：<code>total</code>进程总数、 <code>running</code>正在运行的进程数、 <code>sleeping</code>睡眠的进程数、<code>stopped</code>停止的进程数、 <code>zombie</code>僵尸进程数。</p>
<p><strong>第三行</strong><br>    分别显示：<br>   <code>%us</code>用户空间占用CPU百分比、<br>    <code>%sy</code>内核空间占用CPU百分比、<br>    <code>%ni</code>用户进程空间内改变过优先级的进程占用CPU百分比、<br>    <code>%id</code>空闲CPU百分比、<br>    <code>%wa</code>等待输入输出（I/O）的CPU时间百分比 、<br>    <code>%hi</code>指的是cpu处理硬件中断的时间、%si指的是cpu处理软中断的时间 、<br>    <code>%st</code>用于有虚拟cpu的情况，用来指示被虚拟机偷掉的cpu时间。<br>    通常<code>id%</code>值可以反映一个系统cpu的闲忙程度。</p>
<p><strong>第四行</strong> MEM ：<code>total</code> 物理内存总量、 <code>used</code> 使用的物理内存总量、<code>free</code> 空闲内存总量、 <code>buffers</code> 用作内核缓存的内存量。</p>
<p><strong>第五行</strong> SWAP：<code>total</code> 交换区总量、 <code>used</code>使用的交换区总量、<code>free</code> 空闲交换区总量、 <code>cached</code>缓冲的交换区总量。<br><code>buffers</code>和<code>cached</code>的区别需要说明一下，<code>buffers</code>指的是块设备的读写缓冲区，cached指的是文件系统本身的页面缓存。它们都是linux操作系统底层的机制，目的就是为了加速对磁盘的访问</p>
<p><strong>第六行</strong> PID(进程号)、 <code>USER</code>（运行用户）、<code>PR</code>（优先级）、<code>NI</code>（任务nice值）、<code>VIRT</code>（虚拟内存用量）<code>VIRT=SWAP+RES</code> 、<code>RES</code>（物理内存用量）、<code>SHR</code>（共享内存用量）、<code>S（进程状态）、%CPU</code>（CPU占用比）、<code>%MEM</code>（物理内存占用比）、<code>TIME+</code>（累计CPU占 用时间)、　<code>COMMAND</code> 命令名/命令行。</p>
<p><strong>top命令的使用方法</strong>：<br>top [-] [d]</p>
<p>[q] [c] [C] [S]  [n]<br>运维必会！<br>参数说明<br>d指定每两次屏幕信息刷新之间的时间间隔。当然用户可以使用s交互命令来改变之。<br>p通过指定监控进程ID来仅仅监控某个进程的状态。<br>q该选项将使top没有任何延迟的进行刷新。如果调用程序有超级用户权限，那么top将以尽可能高的优先级运行。<br>S指定累计模式。<br>s使top命令在安全模式中运行。这将去除交互命令所带来的潜在危险。<br>i使top不显示任何闲置或者僵死进程。<br>c显示整个命令行而不只是显示命令名。</p>
<p>下面介绍在top命令执行过程中可以使用的一些交互命令<br>　　从使用角度来看，熟练的掌握这些命令比掌握选项还重要一些。<br>　　这些命令都是单字母的，如果在命令行选项中使用了s选项，则可能其中一些命令会被屏蔽掉。<br>Ctrl+L 擦除并且重写屏幕。<br>h或者? 显示帮助画面，给出一些简短的命令总结说明。<br>k 终止一个进程。系统将提示用户输入需要终止的进程PID，以及需要发送给该进程什么样的信号。一般的终止进程可以使用15信号；如果不能正常结束那就使用信号9强制结束该进程。默认值是信号15。在安全模式中此命令被屏蔽。<br>i 忽略闲置和僵死进程。这是一个开关式命令。<br>q 退出程序。<br>r 重新安排一个进程的优先级别。系统提示用户输入需要改变的进程PID以及需要设置的进程优先级值。输入一个正值将使优先级降低，反之则可以使该进程拥有更高的优先权。默认值是10。<br>s 改变两次刷新之间的延迟时间。系统将提示用户输入新的时间，单位为s。如果有小数，就换算成m s。输入0值则系统将不断刷新，默认值是5 s。需要注意的是如果设置太小的时间，很可能会引起不断刷新，从而根本来不及看清显示的情况，而且系统负载也会大大增加。<br>f或者F 从当前显示中添加或者删除项目。<br>o或者O 改变显示项目的顺序。<br>l 切换显示平均负载和启动时间信息。<br>m 切换显示内存信息。<br>t 切换显示进程和CPU状态信息。<br>c 切换显示命令名称和完整命令行。<br>M 根据驻留内存大小进行排序。<br>P 根据CPU使用百分比大小进行排序。<br>T 根据时间/累计时间进行排序。<br>W 将当前设置写入~/.toprc文件中。这是写top配置文件的推荐方法。<br>Shift+M 可按内存占用情况进行排序。</p>
<h5 id="sysstat-说明"><a href="#sysstat-说明" class="headerlink" title="sysstat 说明"></a>sysstat 说明</h5><pre><code>[root@tang ~]# yum install sysstat -y
[root@tang ~]# vmstat --help
usage: vmstat [-V] [-n] [delay [count]]
              -V prints version.
              -n causes the headers not to be reprinted regularly.
              -a print inactive/active page stats.
              -d prints disk statistics
              -D prints disk table
              -p prints disk partition statistics
              -s prints vm table
              -m prints slabinfo
              -t add timestamp to output
              -S unit size
              delay is the delay between updates in seconds. 
              unit size k:1000 K:1024 m:1000000 M:1048576 (default is K)
              count is the number of updates.
</code></pre><blockquote>
<p>例子：每隔1秒获取1次，次数不限</p>
</blockquote>
<pre><code>[root@tang snmp]# vmstat 1
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 4  0      0 926348 124344 624748    0    0     2     6  124  150  1  1 98  0  0
 0  0      0 926332 124344 624748    0    0     0     0 1252 2559  0  1 99  0  0
 0  0      0 926332 124344 624748    0    0     0     0 1260 2562  1  1 98  0  0
 0  0      0 926332 124344 624748    0    0     0     0 1256 2569  1  0 99  0  0

r表示CPU排队的情况，b代表 进程堵塞，等待io 
每隔1秒获取1次，次数10次

[root@tang snmp]# vmstat 1 10
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 4  0      0 926332 124344 624748    0    0     2     6  125  150  1  1 98  0  0
 0  0      0 926332 124344 624748    0    0     0     0 1260 2574  1  0 99  0  0
 0  0      0 926332 124344 624748    0    0     0     0 1253 2558  0  1 99  0  0
 0  0      0 926332 124344 624748    0    0     0     0 1279 2589  1  1 98  0  0
 0  0      0 926332 124344 624748    0    0     0     0 1272 2577  1  1 98  0  0
 0  0      0 926332 124344 624748    0    0     0     0 1272 2575  1  0 99  0  0
 0  0      0 926332 124344 624748    0    0     0     0 1267 2574  1  1 98  0  0
 0  0      0 926332 124344 624748    0    0     0     0 1269 2571  0  1 99  0  0
 0  0      0 926332 124344 624748    0    0     0     0 1289 2597  1  1 98  0  0
 0  0      0 926332 124344 624748    0    0     0     0 1279 2600  0  1 99  0  0
</code></pre><h5 id="mpstat说明"><a href="#mpstat说明" class="headerlink" title="mpstat说明"></a>mpstat说明</h5><p>查看所有CPU的平均值</p>
<pre><code>[root@tang snmp]# mpstat 1
Linux 3.10.0-514.10.2.el7.x86_64 (tang)     04/23/2017     _x86_64_    (1 CPU)

04:45:51 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
04:45:52 PM  all    1.01    0.00    1.01    0.00    0.00    0.00    0.00    0.00    0.00   97.98
04:45:53 PM  all    1.01    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   98.99
04:45:54 PM  all    1.01    0.00    1.01    0.00    0.00    0.00    0.00    0.00    0.00   97.98
04:45:55 PM  all    0.00    0.00    1.02    0.00    0.00    0.00    0.00    0.00    0.00   98.98

[root@tang snmp]# mpstat 1 10
Linux 3.10.0-514.10.2.el7.x86_64 (tang)     04/23/2017     _x86_64_    (1 CPU)

04:46:20 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
04:46:21 PM  all    1.02    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   98.98
04:46:22 PM  all    0.00    0.00    1.01    0.00    0.00    0.00    0.00    0.00    0.00   98.99
04:46:23 PM  all    1.01    0.00    1.01    0.00    0.00    0.00    0.00    0.00    0.00   97.98
04:46:24 PM  all    1.00    0.00    1.00    0.00    0.00    0.00    0.00    0.00    0.00   98.00
04:46:25 PM  all    2.02    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   97.98
04:46:26 PM  all    1.00    0.00    1.00    0.00    0.00    0.00    0.00    0.00    0.00   98.00
04:46:27 PM  all    1.01    0.00    1.01    0.00    0.00    0.00    0.00    0.00    0.00   97.98
04:46:28 PM  all    1.01    0.00    1.01    0.00    0.00    0.00    0.00    0.00    0.00   97.98
04:46:29 PM  all    1.00    0.00    1.00    0.00    0.00    0.00    0.00    0.00    0.00   98.00
04:46:30 PM  all    1.01    0.00    1.01    0.00    0.00    0.00    0.00    0.00    0.00   97.98
Average:     all    1.01    0.00    0.81    0.00    0.00    0.00    0.00    0.00    0.00   98.19
</code></pre><p>上述是CPU监控，CPU监控主要靠经验。因为业务不同指标不同，指标越低越好是不变的道理</p>
<h4 id="内存监控"><a href="#内存监控" class="headerlink" title="内存监控"></a>内存监控</h4><p>硬盘格式化后分成块（blog）<br>内存默认是页（大小4kb）读取按照页来进行读取<br>内存： <code>free</code> <code>vmstat</code></p>
<pre><code>[root@www ~]# free -m
             total       used       free     shared    buffers     cached
Mem:          1875       1338        537          0        173        523
-/+ buffers/cache:        640       1234
Swap:            0          0          0
</code></pre><p>提示：云主机是没有Swap分区的<br><code>total</code> 总内存<br><code>used</code> 已使用内存<br><code>free</code> 空闲内存<br><code>shared</code> 共享内存（进程间相互通信使用共享内存）<br><code>buffers</code> 缓冲<br><code>cached</code>缓存<br>Centos7 会有一个<code>available</code>，活动内存 </p>
<p>云服务器一般不分配swap分区，物理机能不使用交换分区就不使用交换分区</p>
<h5 id="vmstat命令"><a href="#vmstat命令" class="headerlink" title="vmstat命令"></a>vmstat命令</h5><pre><code>[root@www ~]# vmstat 1
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0      0 550628 177684 536324    0    0     1     6    7   46  1  0 98  0  0    
 0  0      0 550620 177684 536324    0    0     0    40  187  429  0  0 100  0  0
 0  0      0 550620 177684 536324    0    0     0     0  183  427  1  0 99  0  0    
 0  0      0 550620 177684 536324    0    0     0     0  197  436  0  1 99  0  0
</code></pre><p><code>swpd</code>交换分区的大小<br><code>free</code>可用的物理内存大小<br><code>buff</code> 缓冲区的大小<br><code>cache</code> 缓存区的大小<br><code>si</code> 数据从交换分区读取到内存的大小<br><code>so</code> 数据从内存到交换分区<br><code>bi</code> 从交换分区读到内存（block）<br><code>bo</code>内存写到硬盘的</p>
<p>内存达到多少报警呢？ <code>80%</code><br>正常是一个进程启动后会一直往上升，最后到达一个平稳期</p>
<h4 id="硬盘监控"><a href="#硬盘监控" class="headerlink" title="硬盘监控"></a>硬盘监控</h4><p>硬盘：IOPS IO’s Per Second iotop df -h iostat<br>　　顺序IO（快）<br>　　随机IO（慢） </p>
<blockquote>
<p>查看磁盘剩余空间</p>
</blockquote>
<pre><code>[root@tang ~]# df -h
Filesystem      Size  Used Avail Use% Mounted on
/dev/xvda1       40G  4.1G   34G  11% /
tmpfs           938M     0  938M   0% /dev/shm
</code></pre><p>```</p>
<blockquote>
<p>监控磁盘IO iotop</p>
</blockquote>
<pre><code>[root@www ~]# yum install iotop -y
</code></pre><p>iotop<br><img src="http://static.zybuluo.com/abcdocker/uqklmvh78n4k51q8cuukn4rb/1.png" alt="http://static.zybuluo.com/abcdocker/uqklmvh78n4k51q8cuukn4rb/1.png">  </p>
<p>可以使用dd命令生成一个文件夹进行测试<br>生成命令如下：</p>
<pre><code>[root@www ~]# dd if=/dev/zero of=/tmp/1.txt bs=1M count=1000
1000+0 records in
1000+0 records out
1048576000 bytes (1.0 GB) copied, 20.509 s, 51.1 MB/s
[root@www ~]# ls -lh /tmp/1.txt 
-rw-r--r-- 1 root root 1000M Aug 30 19:48 /tmp/1.txt
</code></pre><p>此时IO写入如下图<br><img src="http://static.zybuluo.com/abcdocker/qa2kribzw85j1w7hdt2zcs0n/2.png" alt="http://static.zybuluo.com/abcdocker/qa2kribzw85j1w7hdt2zcs0n/2.png"></p>
<p><code>iostat命令，可以看到那块磁盘，比iotop更加细致</code></p>
<pre><code>[root@tang ~]# iostat 1 2
Linux 2.6.32-431.23.3.el6.x86_64 (www)  08/30/2016  _x86_64_    (1 CPU)
avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           1.10    0.00    0.27    0.16    0.00   98.46
Device:            tps   Blk_read/s   Blk_wrtn/s   Blk_read   Blk_wrtn
xvda              1.51         2.26        17.09     986748    7467560
avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           1.02    0.00    0.00    0.00    0.00   98.98
Device:            tps   Blk_read/s   Blk_wrtn/s   Blk_read   Blk_wrtn
xvda              0.00         0.00         0.00          0   
</code></pre><p><code>tps</code> 设备每秒的传输次数（每秒多少的io请求）<br><code>Blk_read/s</code> 每秒从设备读取的数据量<br><code>Blk_wrtn/s</code> 每秒像设备写入的数据量<br><code>Blk_read</code>写入数据的总数<br><code>Blk_wrtn</code> 读取数据的总数</p>
<h4 id="网络监控"><a href="#网络监控" class="headerlink" title="网络监控"></a>网络监控</h4><h5 id="iftop说明"><a href="#iftop说明" class="headerlink" title="iftop说明"></a>iftop说明</h5><pre><code>[root@www ~]# yum install iftop -y
[root@www ~]# iftop -n    #-n不做域名解析
</code></pre><p><img src="http://static.zybuluo.com/abcdocker/rdwly3nsqifomp378oitvmfe/3.png" alt="http://static.zybuluo.com/abcdocker/rdwly3nsqifomp378oitvmfe/3.png"><br>正常监控只需要监控网卡带宽即可<br>其中网络监控是最复杂的，ping监控网络延迟网络丢包等。但是此类的网络监控只是监控自己到客户端是否丢包，并不能保证客户端到服务器这边不丢包<br>　其中就产生了如：<code>阿里测、奇云测、站长工具</code>等一系列多节点的监控工具</p>
<p>性能测试常用工具：<code>IBM nmon （nmon analyser---生成AIX性能报告的免费工具）</code><br><a href="http://nmon.sourceforge.net/pmwiki.php" target="_blank" rel="external">http://nmon.sourceforge.net/pmwiki.php</a> #下载地址（需要翻墙工具）<br>所以我们提供了百度云下载<br>链接：<a href="http://pan.baidu.com/s/1boXV6R9" target="_blank" rel="external">http://pan.baidu.com/s/1boXV6R9</a> 密码：sblf<br>只需要下载对应的版本，给执行权限。执行即可</p>
<pre><code>[root@tang tmp]# chmod +x nmon16e_x86_rhel72 
[root@tang tmp]# ./nmon16e_x86_rhel72
</code></pre><p><img src="http://static.zybuluo.com/abcdocker/zi2fr7i0glig9ad4r9qaz15i/4.png" alt="http://static.zybuluo.com/abcdocker/zi2fr7i0glig9ad4r9qaz15i/4.png"><br>我们可以直接输入一个c 一个m一个d。这个是实时的一个状态<br><img src="http://static.zybuluo.com/abcdocker/rx2i4p0yakya27f2aodjfa93/5.png" alt="http://static.zybuluo.com/abcdocker/rx2i4p0yakya27f2aodjfa93/5.png"></p>
<p>我们可以查看帮助</p>
<pre><code>[root@localhost tmp]# ./nmon16e_x86_rhel72 --help
./nmon16e_x86_rhel72: invalid option -- &apos;-&apos;
Hint for nmon16e_x86_rhel72 version 16e
    Full Help Info : nmon16e_x86_rhel72 -h
    On-screen Stats: nmon16e_x86_rhel72
    Data Collection: nmon16e_x86_rhel72 -f [-s &lt;seconds&gt;] [-c &lt;count&gt;] [-t|-T]
    Capacity Plan  : nmon16e_x86_rhel72 -x
Interactive-Mode:
    Read the Welcome screen &amp; at any time type: &quot;h&quot; for more help
    Type &quot;q&quot; to exit nmon
For Data-Collect-Mode
    -f            Must be the first option on the line (switches off interactive mode)
                  Saves data to a CSV Spreadsheet format .nmon file in then local directory
                  Note: -f sets a defaults -s300 -c288    which you can then modify
    Further Data Collection Options:
    -s &lt;seconds&gt;  time between data snapshots
    -c &lt;count&gt;    of snapshots before exiting
    -t            Includes Top Processes stats (-T also collects command arguments)
    -x            Capacity Planning=15 min snapshots for 1 day. (nmon -ft -s 900 -c 96)
---- End of Hints
</code></pre><p><code>-c</code>  采集的次数<br><code>-s</code>  采集的间隔时间<br><code>-f</code> 生成一个文件<br><code>-m</code>  指定生成文件位置<br>采集10次 间隔10秒</p>
<pre><code>[root@localhost tmp]# ./nmon16e_x86_rhel72 -c 10 -s 10 -f -m /tmp/
[root@localhost tmp]# ls
localhost_160831_0435.nmon  nmon16e_x86_rhel72
</code></pre><p>前面为主机名后面是日期（年月日时分）<br>因为测试可能需要，我们要制作成表格，所以现在将文件上传到桌面上</p>
<pre><code>[root@localhost tmp]# sz localhost_160831_0435.nmon 
</code></pre><p>我们打开下载的工具<br><img src="http://static.zybuluo.com/abcdocker/d4rown1bnx8bgk8wgu2rfu4f/6.png" alt="http://static.zybuluo.com/abcdocker/d4rown1bnx8bgk8wgu2rfu4f/6.png"></p>
<p>解压文件夹，打开nmon analyser v34a.xls<br><img src="http://static.zybuluo.com/abcdocker/g1ob74tdxdnbo5p71x95ot35/7.png" alt="http://static.zybuluo.com/abcdocker/g1ob74tdxdnbo5p71x95ot35/7.png"></p>
<p>点击Analyse nmon data找到我们刚刚复制出来的文件，就可以看到了。<br><img src="http://static.zybuluo.com/abcdocker/z1m3apomvrg8k1y3li8wpmcy/8.png" alt="http://static.zybuluo.com/abcdocker/z1m3apomvrg8k1y3li8wpmcy/8.png"></p>
<h3 id="应用服务监控"><a href="#应用服务监控" class="headerlink" title="应用服务监控"></a>应用服务监控</h3><p>举例：Nginx<br>安装nginx</p>
<pre><code>[root@localhost ~]# yum install -y gcc glibc gcc-c++ prce-devel openssl-devel
</code></pre><p>提示：nginx可以使用稳定版的最新版，因为安全性会不断的提高。如果是特别老的版本会有一些漏洞和功能<br>　　要想监控nginx需要在编译时添加如下参数</p>
<p><code>--with-http_stub_status_module</code></p>
<p>下载Nginx</p>
<pre><code>[root@localhost src]# wget http://nginx.org/download/nginx-1.10.1.tar.gz
</code></pre><p>解压，后面步骤太简单不说了<br>安装</p>
<pre><code>[root@localhost nginx-1.10.1]# useradd -s /sbin/nologin www
[root@localhost nginx-1.10.1]# ./configure --prefix=/usr/local/nginx-1.10.1 --user=www --group=www --with-http_ssl_module --with-http_stub_status_module
</code></pre><p><code>configure</code> 是一个shell脚本，执行它的作用是生成MAKEFILE（编译make需要）</p>
<pre><code>[root@localhost nginx-1.10.1]# make &amp;&amp; make install
[root@localhost nginx-1.10.1]# ll
total 676
drwxr-xr-x 6 1001 1001   4096 Aug 31 06:02 auto
-rw-r--r-- 1 1001 1001 262898 May 31 09:47 CHANGES
-rw-r--r-- 1 1001 1001 400701 May 31 09:47 CHANGES.ru
drwxr-xr-x 2 1001 1001   4096 Aug 31 06:02 conf
-rwxr-xr-x 1 1001 1001   2481 May 31 09:47 configure
drwxr-xr-x 4 1001 1001     68 Aug 31 06:02 contrib
drwxr-xr-x 2 1001 1001     38 Aug 31 06:02 html
-rw-r--r-- 1 1001 1001   1397 May 31 09:47 LICENSE
-rw-r--r-- 1 root root    404 Aug 31 07:46 Makefile
drwxr-xr-x 2 1001 1001     20 Aug 31 06:02 man
drwxr-xr-x 3 root root    119 Aug 31 07:46 objs
-rw-r--r-- 1 1001 1001     49 May 31 09:47 README
drwxr-xr-x 9 1001 1001     84 Aug 31 06:02 src
</code></pre><p><code>make是生成文件</code>，<code>make install</code>是将生成的文件拷贝到不同的地方<br>make install 完成之后可以直接将当前目录拷贝到其他服务器上，安装相同的依赖就可以进行使用。</p>
<pre><code>[root@localhost nginx-1.10.1]# ln -s /usr/local/nginx-1.10.1/ /usr/local/nginx
[root@localhost nginx-1.10.1]# netstat -lntp|grep nginx
tcp        0      0 0.0.0.0:80              0.0.0.0:*               LISTEN      7058/nginx: master  
</code></pre><p>修改nginx.conf配置文件</p>
<pre><code>location /status {
stub_status on;
access_log off;
    allow 192.168.56.0/24;
deny all;
}
</code></pre><p>设置只允许56网段访问，并开启日志和状态模块<br>这个比较基础，如果不知道怎么添加。可以参考www.nginx.org 状态模块<br>浏览器访问：<a href="http://192.168.56.11/status" target="_blank" rel="external">http://192.168.56.11/status</a></p>
<pre><code>Active connections: 1 
server accepts handled requests
 3 3 163 
Reading: 0 Writing: 1 Waiting: 0 
Active connections: 当前活跃的连接数 
</code></pre><p>3—-&gt; 一共处理了多少个链接（请求）<br>3—-&gt; 成功创建多少次握手<br>163–&gt; 总共创建了多少个请求<br>Reading:当前读取客户端heardr的数量<br>Writing:当前返回给客户端heardr的数量 　#如果这个指标飙升，说明是后面的节点挂掉了，例如数据库等。<br>Waiting:大体意思是已经处理完，等待下次请求的数量<br>提示：我们只需要关注活动链接即可</p>
<p><strong>监控最基础的功能</strong><br><strong><code>采集 存储 展示 告警</code></strong></p>
<p>　<strong>几款监控软件说明：</strong><br>    <code>Nagios+Cacti</code>Nagios报警功能比较强，但是画图比较弱（有插件） Cacti 画图比较强，报警比较弱（有插件）<br><code>Zabbix</code>可以直接监控IPMI、SNMP、JVM 这些监控项目别的软件本身干不了，插件除外 Zabbix分为Server—-&gt;Agent 有主动和被动模式<br><code>Gangla</code>　根本没听说过！</p>
]]></content>
      
        <categories>
            
            <category> 运维监控 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 运维监控 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[五分钟商学院--大纲]]></title>
      <url>http://yoursite.com/2016/09/25/%E4%BA%94%E5%88%86%E9%92%9F%E5%95%86%E5%AD%A6%E9%99%A2--%E5%A4%A7%E7%BA%B2/</url>
      <content type="html"><![CDATA[<p>商业四大体系合体。</p>
<p>1）商业，你与企业外部的关系；<br>2）管理，你与企业内部的关系；<br>3）个人，你与自己的关系；<br>4）以及提升前三者的：工具。    </p>
<a id="more"></a>
<h2 id="商业篇"><a href="#商业篇" class="headerlink" title="商业篇"></a>商业篇</h2><h3 id="消费心理学"><a href="#消费心理学" class="headerlink" title="消费心理学"></a>消费心理学</h3><p>1.心理账户<br>2.沉没成本<br>3.比例偏见<br>4.损失规避<br>5.价格锚点          </p>
<h3 id="商业世界五大基础逻辑"><a href="#商业世界五大基础逻辑" class="headerlink" title="商业世界五大基础逻辑"></a>商业世界五大基础逻辑</h3><p>6.流量之河<br>7.倍率之刀<br>8.价量之秤<br>9.风险之眼<br>10.规则之缝  </p>
<h3 id="互联网世界五大基本定律"><a href="#互联网世界五大基本定律" class="headerlink" title="互联网世界五大基本定律"></a>互联网世界五大基本定律</h3><p>11.信息对称<br>12.平台经济<br>13.边际成本<br>14.长尾理论<br>15.免费理论  </p>
<h3 id="行为经济学"><a href="#行为经济学" class="headerlink" title="行为经济学"></a>行为经济学</h3><p>16.结果偏见<br>17.适应性偏见<br>18.鸡蛋理论<br>19.概率偏见<br>20.凡勃伦效应</p>
<h3 id="微观经济学"><a href="#微观经济学" class="headerlink" title="微观经济学"></a>微观经济学</h3><p>21.供需理论<br>22.边际效用<br>23.机会成本<br>24.代理两难<br>25.科斯定理   </p>
<h3 id="宏观经济学"><a href="#宏观经济学" class="headerlink" title="宏观经济学"></a>宏观经济学</h3><p>26.节约悖论<br>27.张维迎林毅夫之争<br>28.人口抚养比<br>29.经济泡沫<br>30.福利经济  </p>
<h3 id="金融法律"><a href="#金融法律" class="headerlink" title="金融法律"></a>金融法律</h3><p>31.风险投资<br>32.公司的形态：有限责任，合伙企业，个人独资<br>33.期权（员工激励方案）<br>34.庞氏骗局<br>35.互联网金融   </p>
<h3 id="市场营销-Product"><a href="#市场营销-Product" class="headerlink" title="市场营销 Product"></a>市场营销 Product</h3><p>36.产品定位<br>37.自我认知<br>38.极致单品<br>39.三驾马车<br>40.最小可用品  </p>
<h3 id="市场营销-Price"><a href="#市场营销-Price" class="headerlink" title="市场营销 Price"></a>市场营销 Price</h3><p>41.渗透定价法<br>42.组合定价法<br>43.撇脂定价法<br>44.价格歧视<br>45.客户自定价   </p>
<h3 id="市场营销-Promotion"><a href="#市场营销-Promotion" class="headerlink" title="市场营销 Promotion"></a>市场营销 Promotion</h3><p>46.定位营销<br>47.饥饿营销<br>48.死亡之井<br>49.危机公关<br>50.独特的销售主张-USP   </p>
<h3 id="市场营销-Place"><a href="#市场营销-Place" class="headerlink" title="市场营销 Place"></a>市场营销 Place</h3><p>51.深度分销<br>52.直接销售<br>53.虚实结合<br>54.社区商务<br>55.反向定制  </p>
<h3 id="市场营销-互联网营销"><a href="#市场营销-互联网营销" class="headerlink" title="市场营销 互联网营销"></a>市场营销 互联网营销</h3><p>56.社群经济<br>57.口碑经济（POE理论）<br>58.粉丝经济<br>59.引爆点<br>60.红利理论  </p>
<h3 id="所有现象背后都有商业逻辑"><a href="#所有现象背后都有商业逻辑" class="headerlink" title="所有现象背后都有商业逻辑"></a>所有现象背后都有商业逻辑</h3><p>61.运动对赌<br>62.雇佣客户<br>63.服务行业美女越多，经济越不景气<br>64.狩猎式 vs 农耕式<br>65.稳定平衡态 vs 不稳定平衡态   </p>
<h2 id="管理篇"><a href="#管理篇" class="headerlink" title="管理篇"></a>管理篇</h2><h3 id="管理选人"><a href="#管理选人" class="headerlink" title="管理选人"></a>管理选人</h3><p>66.上下车法则<br>67.奥格尔维定律<br>68.首因效应/光环效应<br>69.特雷默定律<br>70.重视面试被拒的人   </p>
<h3 id="管理育人"><a href="#管理育人" class="headerlink" title="管理育人"></a>管理育人</h3><p>71.蘑菇定律<br>72.师傅制<br>73.情境领导II<br>74.鲶鱼效应<br>75.贝尼斯定理  </p>
<h3 id="管理用人"><a href="#管理用人" class="headerlink" title="管理用人"></a>管理用人</h3><p>76.不值得定律<br>77.懒蚂蚁效应<br>78.热炉法则<br>79.拜伦法则<br>80.波特定律  </p>
<h3 id="管理留人"><a href="#管理留人" class="headerlink" title="管理留人"></a>管理留人</h3><p>81.酒与污水定律<br>82.格雷欣法则（劣币驱逐良币）<br>83.雷尼尔效应<br>84.南风法则<br>85.离职面试  </p>
<h3 id="管理就是激励需求理论"><a href="#管理就是激励需求理论" class="headerlink" title="管理就是激励需求理论"></a>管理就是激励需求理论</h3><p>86.马斯洛人类需求五层次理论-生理<br>87.马斯洛人类需求五层次理论-安全<br>88.马斯洛人类需求五层次理论-归属<br>89.马斯洛人类需求五层次理论-尊重<br>90.马斯洛人类需求五层次理论-实现  </p>
<h3 id="管理就是激励其他理论"><a href="#管理就是激励其他理论" class="headerlink" title="管理就是激励其他理论"></a>管理就是激励其他理论</h3><p>91.卡诺满意度模型<br>92.赫兹伯格的双因素激励理论<br>93.亚佛斯德原则（期望理论）<br>94.马蝇效应<br>95.波什定律   </p>
<h3 id="从员工到经理"><a href="#从员工到经理" class="headerlink" title="从员工到经理"></a>从员工到经理</h3><p>96.古狄逊定理<br>97.吉格勒定理<br>98.刺猬法则<br>99.目标置换效应<br>100.篮球架子原理  </p>
<h3 id="管理1"><a href="#管理1" class="headerlink" title="管理1"></a>管理1</h3><p>101.崔西定律<br>102.蓝柏格定理<br>103.阿什定律<br>104.彼得斯定律<br>105.超限效应   </p>
<h3 id="管理2"><a href="#管理2" class="headerlink" title="管理2"></a>管理2</h3><p>106.奥卡姆剃刀定律<br>107.法约尔原则（责权利心法）<br>108.例外原则<br>109.洛克忠告<br>110.海恩法则   </p>
<h3 id="管理3"><a href="#管理3" class="headerlink" title="管理3"></a>管理3</h3><p>111.波特法则<br>112.卡贝定律<br>113.飞轮效应<br>114.墨菲定律<br>115.克里夫兰法则   </p>
<h3 id="团队合作"><a href="#团队合作" class="headerlink" title="团队合作"></a>团队合作</h3><p>116.球队，交响乐队，军队<br>117.木桶定律<br>118.多样性（异性效应）<br>119.苛希纳定律<br>120.蚁群效应  </p>
<h3 id="项目管理"><a href="#项目管理" class="headerlink" title="项目管理"></a>项目管理</h3><p>121.作战指挥室<br>122.关键路径<br>123.范围、时间、资源的金三角<br>124.风险管理（已知的未知风险）<br>125.权利来源：专业   </p>
<h3 id="管理常见病"><a href="#管理常见病" class="headerlink" title="管理常见病"></a>管理常见病</h3><p>126.破窗效应<br>127.旁观者效应<br>128.帕金森定律<br>129.彼得原理<br>130.手表定律  </p>
<h2 id="个人篇"><a href="#个人篇" class="headerlink" title="个人篇"></a>个人篇</h2><h3 id="高效能人士的七种习惯"><a href="#高效能人士的七种习惯" class="headerlink" title="高效能人士的七种习惯"></a>高效能人士的七种习惯</h3><p>131.范式转变<br>132.情感账户<br>133.积极主动<br>134.以终为始<br>135.要事第一  </p>
<h3 id="高效能人士的七种习惯-1"><a href="#高效能人士的七种习惯-1" class="headerlink" title="高效能人士的七种习惯"></a>高效能人士的七种习惯</h3><p>136.双赢思维<br>137.知彼解己<br>138.统合综效<br>139.不断更新<br>140.找到心声  </p>
<h3 id="时间管理"><a href="#时间管理" class="headerlink" title="时间管理"></a>时间管理</h3><p>141.时间成本<br>142.GTD<br>143.猴子理论<br>144.三八理论<br>145.番茄钟   </p>
<h3 id="职业素养"><a href="#职业素养" class="headerlink" title="职业素养"></a>职业素养</h3><p>146.如何打招呼<br>147.如何吃西餐<br>148.如何和老板一起坐车<br>149.如何搭配衣服<br>150.邮件礼仪   </p>
<h3 id="学习能力"><a href="#学习能力" class="headerlink" title="学习能力"></a>学习能力</h3><p>151.幸存者偏见<br>152.库博经验学习圈<br>153.知识、技能、态度<br>154.学习小组（私人董事会）<br>155.如何最快速的学习    </p>
<h3 id="思考能力"><a href="#思考能力" class="headerlink" title="思考能力"></a>思考能力</h3><p>156.六顶思考帽<br>157.批判性思维/辩证思维<br>158.系统思维-关联的、整体的、动态的<br>159.正向思维<br>160.逆向思维   </p>
<h3 id="逻辑思维"><a href="#逻辑思维" class="headerlink" title="逻辑思维"></a>逻辑思维</h3><p>161.偷换概念-同一律<br>162.自相矛盾-矛盾律<br>163.模棱两可-排中律<br>164.三段论<br>165.归纳法与黑天鹅事件   </p>
<h3 id="谈判能力"><a href="#谈判能力" class="headerlink" title="谈判能力"></a>谈判能力</h3><p>166.吉普赛陷阱<br>167.定位调整偏见<br>168.有限的权利 &amp; 不露面的人<br>169.战略延迟 &amp; 最终期限<br>170.吃惊 &amp; 撤退    </p>
<h3 id="情感能力"><a href="#情感能力" class="headerlink" title="情感能力"></a>情感能力</h3><p>171.元能力：同理心<br>172.元能力：自我认知（卢维斯定理）<br>173.元能力：自我控制<br>174.元能力：自我激励<br>175.元能力：人际关系处理   </p>
<h3 id="演讲能力"><a href="#演讲能力" class="headerlink" title="演讲能力"></a>演讲能力</h3><p>176.导游心法<br>177.注意力法则<br>178.空中加油<br>179.案例和幽默感<br>180.打透     </p>
<h3 id="沟通能力"><a href="#沟通能力" class="headerlink" title="沟通能力"></a>沟通能力</h3><p>181.快乐痛苦四原则<br>182.亨利法则<br>183.踢猫效应<br>184.电梯测验<br>185.如何问出好问题    </p>
<h3 id="创新能力"><a href="#创新能力" class="headerlink" title="创新能力"></a>创新能力</h3><p>186.创新者的窘境<br>187.人无我有，人有我优，人优我廉……<br>188.达维多定律<br>189.路径依赖<br>190.比伦定律   </p>
<h3 id="领导能力"><a href="#领导能力" class="headerlink" title="领导能力"></a>领导能力</h3><p>191.远（后喻文明）<br>192.小（科斯定理）<br>193.变（企业生命周期）<br>194.快（快鱼吃慢鱼）<br>195.专（网状激活系统）   </p>
<h2 id="战略篇"><a href="#战略篇" class="headerlink" title="战略篇"></a>战略篇</h2><h3 id="战略工具"><a href="#战略工具" class="headerlink" title="战略工具"></a>战略工具</h3><p>196.麦肯锡·MECE法<br>197.波特·五力模型<br>198.波士顿矩阵<br>199.金字塔原理<br>200.通用电器矩阵    </p>
<h3 id="战略工具-1"><a href="#战略工具-1" class="headerlink" title="战略工具"></a>战略工具</h3><p>201.正态分布理论<br>202.逻辑树/决策树<br>203.平衡计分表<br>204.SWOT模型<br>205.麦肯锡·七步成诗法    </p>
<h3 id="博弈工具"><a href="#博弈工具" class="headerlink" title="博弈工具"></a>博弈工具</h3><p>206.纳什均衡<br>207.囚徒困境<br>208.贝叶斯均衡<br>209.智猪博弈<br>210.公地悲剧     </p>
<h3 id="博弈工具-1"><a href="#博弈工具-1" class="headerlink" title="博弈工具"></a>博弈工具</h3><p>211.你分我拿<br>212.拍卖逻辑<br>213.零和游戏原理<br>214.拍卖美元<br>215.用餐者困境    </p>
<h3 id="决策工具"><a href="#决策工具" class="headerlink" title="决策工具"></a>决策工具</h3><p>216.儒佛尔定律<br>217.吉德林法则<br>218.布利丹效应<br>219.羊群效应<br>220.麦穗哲理     </p>
<h3 id="创新工具"><a href="#创新工具" class="headerlink" title="创新工具"></a>创新工具</h3><p>221.减法创新<br>222.除法创新<br>223.乘法创新<br>224.任务统筹策略<br>225.属性依存策略   </p>
<h3 id="管理工具"><a href="#管理工具" class="headerlink" title="管理工具"></a>管理工具</h3><p>226.OKR<br>227.MBTI人格理论（自我管理）<br>228.SMART原则（目标管理）<br>229.PDCA循环规则（项目管理）<br>230.5W2H法（目标管理）    </p>
<h3 id="思考工具"><a href="#思考工具" class="headerlink" title="思考工具"></a>思考工具</h3><p>231.头脑风暴法<br>232.思考工具：白板<br>233.思维导图<br>234.5WHY分析法<br>235.复盘     </p>
<h3 id="沟通工具"><a href="#沟通工具" class="headerlink" title="沟通工具"></a>沟通工具</h3><p>236.有效的1：1<br>237.罗伯特议事规则<br>238.白板墙、低隔板、下午茶和即时贴<br>239.拉波波特评论规则<br>240.结构沟通法     </p>
<h3 id="财务工具"><a href="#财务工具" class="headerlink" title="财务工具"></a>财务工具</h3><p>241.财务分析中的五力分析法<br>242.零基预算？<br>243.本福特定律<br>244.独立P&amp;L<br>245.计算企业价值     </p>
<h3 id="营销工具"><a href="#营销工具" class="headerlink" title="营销工具"></a>营销工具</h3><p>246.直播营销<br>247.Focus Group<br>248.STP<br>249.4C<br>250.4P   </p>
<h3 id="未来已来"><a href="#未来已来" class="headerlink" title="未来已来"></a>未来已来</h3><p>256.零边际成本社会<br>257.奇点临近<br>258.比特币<br>259.基因科技<br>260.人工智能   </p>
]]></content>
      
        <categories>
            
            <category> 读书 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 五分钟商学院 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Mysql优化系列--总结梳理]]></title>
      <url>http://yoursite.com/2016/03/12/Mysql%E4%BC%98%E5%8C%96%E7%B3%BB%E5%88%97--%E6%80%BB%E7%BB%93%E6%A2%B3%E7%90%86/</url>
      <content type="html"><![CDATA[<p>对于一个网站来说，在运行很长一段时间后，数据库瓶颈问题会越来越暴露出来。作为运维人员，对数据库做必要的优化十分重要！<br>    下面总结以往查阅到的以及自己工作中的一些优化操作经验，并根据OSI七层模型从下往上进行优化mysql数据库记录。<br><a id="more"></a></p>
<h3 id="物理层面"><a href="#物理层面" class="headerlink" title="物理层面"></a>物理层面</h3><pre><code>1、cpu:2-16个 2*4双四核，L1L2越大越好
2、内存:越大越好
3、磁盘:SAS或者固态 300G*12磁盘越多IO越高
raid 0&gt;10&gt;5&gt;1
4、网卡:千兆
5、slave的配置最好大于等于master
</code></pre><h3 id="系统配置"><a href="#系统配置" class="headerlink" title="系统配置"></a>系统配置</h3><pre><code>如下，配置系统内核参数/etc/sysctl.conf（配置后，使用sysctl -p使之生效）
net.ipv4.tcp_fin_timeout = 2
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_tw_recycle = 1
net.ipv4.tcp_syncookies = 1
net.ipv4.tcp_keepalive_time =600
net.ipv4.ip_local_port_range = 4000 65000
net.ipv4.tcp_max_syn_backlog = 16384
net.ipv4.tcp_max_tw_buckets = 36000
net.ipv4.route.gc_timeout = 100
net.ipv4.tcp_syn_retries = 1
net.ipv4.tcp_synack_retries = 1
net.core.somaxconn = 16384
net.core.netdev_max_backlog = 16384
net.ipv4.tcp_max_orphans = 16384

vm.swappiness=0      //尽量不使用swap
vm.dirty_backgroud_ratio 5-10 
vm.dirty_ratio          //上面的值的两倍 将操作系统的脏数据刷到磁
</code></pre><h3 id="mysql的安装"><a href="#mysql的安装" class="headerlink" title="mysql的安装"></a>mysql的安装</h3><p>MySQL数据库的线上环境安装，建议采取编译安装的方式，这样性能会有较大的提升。服务器系统则建议CentOS6.7 X86_64，源码包的编译参数会默认以Debug模式生成二进制代码，而Debug模式给MySQL带来的性能损失是比较大的，所以当我们编译准备安装的产品代码时，一定不要忘记使用–without-debug参数禁止Debug模式。如果把–with-mysqld-ldflags和–with-client-ld-flags两个编译参数设置为–all-static的话，可以告诉编译器以静态的方式编译，编译结果将得到最高的性能。使用静态编译和使用动态编译的代码相比，性能差距可能会达到5%至10%之多。在后面我会跟大家分享我们线上MySQL数据库的编译参数，大家可以参考下，然后根据自己的线上环境自行修改内容。</p>
<blockquote>
<p>下面是对mysql服务配置文件my.cnf的详解：</p>
</blockquote>
<pre><code>[client]
port = 3306
# 客户端端口号为3306
socket = /data/3306/mysql.sock
default-character-set = utf8
# 客户端字符集,(控制character_set_client、character_set_connection、character_set_results)
[mysql]
no-auto-rehash 
# 仅仅允许使用键值的updates和deletes
[mysqld] 
# 组包括了mysqld服务启动的参数，它涉及的方面很多，其中有MySQL的目录和文件，通信、网络、信息安全，内存管理、优化、查询缓存区，还有MySQL日志设置等。
user = mysql
# mysql_safe脚本使用MySQL运行用户(编译时--user=mysql指定),推荐使用mysql用户。
port = 3306
# MySQL服务运行时的端口号。建议更改默认端口,默认容易遭受攻击。
socket = /data/3306/mysql.sock 
# socket文件是在Linux/Unix环境下特有的，用户在Linux/Unix环境下客户端连接可以不通过TCP/IP网络而直接使用unix socket连接MySQL。
basedir = /application/mysql 
# mysql程序所存放路径,常用于存放mysql启动、配置文件、日志等
datadir = /data/3306/data 
# MySQL数据存放文件(极其重要)
character-set-server = utf8 
# 数据库和数据库表的默认字符集。(推荐utf8,以免导致乱码)
log-error=/data/3306/mysql.err
# mysql错误日志存放路径及名称(启动出现错误一定要看错误日志,百分之百都能通过错误日志排插解决。)
pid-file=/data/3306/mysql.pid 
# MySQL_pid文件记录的是当前mysqld进程的pid，pid亦即ProcessID。
skip-locking
# 避免MySQL的外部锁定，减少出错几率，增强稳定性。
skip-name-resolv
# 禁止MySQL对外部连接进行DNS解析，使用这一选项可以消除MySQL进行DNS解析的时候。但是需要注意的是，如果开启该选项，则所有远程主机连接授权都要使用IP地址方式了，否则MySQL将无法正常处理连接请求！
skip-networking 
# 开启该选项可以彻底关闭MySQL的TCP/IP连接方式，如果Web服务器是以远程连接的方式访问MySQL数据库服务器的，则不要开启该选项，否则无法正常连接！
open_files_limit = 1024
# MySQLd能打开文件的最大个数,如果出现too mant open files之类的就需要调整该值了。
back_log = 384 
# back_log参数是值指出在MySQL暂时停止响应新请求之前，短时间内的多少个请求可以被存在堆栈中。如果系统在短时间内有很多连接，则需要增加该参数的值，该参数值指定到来的TCP/IP连接的监听队列的大小。不同的操作系统在这个队列的大小上有自己的限制。如果试图将back_log设置得高于操作系统的限制将是无效的，其默认值为50.对于Linux系统而言，推荐设置为小于512的整数。
max_connections = 800
# 指定MySQL允许的最大连接进程数。如果在访问博客时经常出现 Too Many Connections的错误提示，则需要增大该参数值。
max_connect_errors = 6000 
# 设置每个主机的连接请求异常中断的最大次数，当超过该次数，MySQL服务器将禁止host的连接请求，直到MySQL服务器重启或通过flush hosts命令清空此host的相关信息。
wait_timeout = 120 
# 指定一个请求的最大连接时间，对于4GB左右内存的服务器来说，可以将其设置为5~10。
table_cache = 614K 
# table_cache指示表高速缓冲区的大小。当MySQL访问一个表时，如果在MySQL缓冲区还有空间，那么这个表就被打开并放入表缓冲区，这样做的好处是可以更快速地访问表中的内容。一般来说，可以查看数据库运行峰值时间的状态值Open_tables和Open_tables，用以判断是否需要增加table_cache的值，即如果Open_tables接近table_cache的时候，并且Opened_tables这个值在逐步增加，那就要考虑增加这个值的大小了。
external-locking = FALSE 
# MySQL选项可以避免外部锁定。True为开启。
max_allowed_packet =16M 
# 服务器一次能处理最大的查询包的值，也是服务器程序能够处理的最大查询
sort_buffer_size = 1M 
# 设置查询排序时所能使用的缓冲区大小，系统默认大小为2MB。
# 注意：该参数对应的分配内存是每个连接独占的，如果有100个连接，那么实际分配的总排序缓冲区大小为100 x6=600MB。所以，对于内存在4GB左右的服务器来说，推荐将其设置为6MB~8MB
join_buffer_size = 8M
# 联合查询操作所能使用的缓冲区大小，和sort_buffer_size一样，该参数对应的分配内存也是每个连接独享。
thread_cache_size = 64
# 设置Thread Cache池中可以缓存的连接线程最大数量，可设置为0~16384，默认为0.这个值表示可以重新利用保存在缓存中线程的数量，当断开连接时如果缓存中还有空间，那么客户端的线程将被放到缓存中;如果线程重新被请求，那么请求将从缓存中读取,如果缓存中是空的或者是新的请求，那么这个线程将被重新创建，如果有很多线程，增加这个值可以改善系统性能。通过比较Connections和Threads_created状态的变量，可以看到这个变量的作用。我们可以根据物理内存设置规则如下:1GB内存我们配置为8,2GB内存我们配置为16,3GB我们配置为32,4GB或4GB以上我们给此值为64或更大的值。
thread_concurrency = 8 
# 该参数取值为服务器逻辑CPU数量x 2，在本例中，服务器有两个物理CPU，而每个物理CPU又支持H.T超线程，所以实际取值为4 x 2 = 8。这也是双四核主流服务器的配置。
query_cache_size = 64M
# 指定MySQL查询缓冲区的大小。可以通过在MySQL控制台观察，如果Qcache_lowmem_prunes的值非常大，则表明经常出现缓冲不够的情况;如果Qcache_hits的值非常大，则表明查询缓冲使用得非常频繁。另外如果改值较小反而会影响效率，那么可以考虑不用查询缓冲。对于Qcache_free_blocks，如果该值非常大，则表明缓冲区中碎片很多。
query_cache_limit = 2M 
# 只有小于此设置值的结果才会被缓存
query_cache_min_res_unit = 2k 
# 设置查询缓存分配内存的最小单位，要适当第设置此参数，可以做到为减少内存快的申请和分配次数，但是设置过大可能导致内存碎片数值上升。默认值为4K，建议设置为1K~16K。
default_table_type = InnoDB 
# 默认表的类型为InnoDB
thread_stack = 256K 
# 设置MySQL每个线程的堆栈大小，默认值足够大，可满足普通操作。可设置范围为128KB至4GB，默认为192KB
#transaction_isolation = Level
# 数据库隔离级别 (READ UNCOMMITTED(读取未提交内容) READ COMMITTED(读取提交内容) REPEATABLE
READ(可重读) SERIALIZABLE(可串行化))
tmp_table_size = 64M 
# 设置内存临时表最大值。如果超过该值，则会将临时表写入磁盘，其范围1KB到4GB。
max_heap_table_size = 64M 
# 独立的内存表所允许的最大容量。
table_cache = 614
# 给经常访问的表分配的内存，物理内存越大，设置就越大。调大这个值，一般情况下可以降低磁盘IO，但相应的会占用更多的内存,这里设置为614。
table_open_cache = 512 
# 设置表高速缓存的数目。每个连接进来，都会至少打开一个表缓存。因此， table_cache 的大小应与 max_connections 的设置有关。例如，对于 200 个并行运行的连接，应该让表的缓存至少有 200 × N ，这里 N 是应用可以执行的查询的一个联接中表的最大数量。此外，还需要为临时表和文件保留一些额外的文件描述符。
long_query_time = 1 
# 慢查询的执行用时上限,默认设置是10s,推荐(1s~2s)
log_long_format 
# 没有使用索引的查询也会被记录。(推荐,根据业务来调整)
log-slow-queries = /data/3306/slow.log 
# 慢查询日志文件路径(如果开启慢查询,建议打开此日志)
log-bin = /data/3306/mysql-bin 
# logbin数据库的操作日志,例如update、delete、create等都会存储到binlog日志,通过logbin可以实现增量恢复
relay-log = /data/3306/relay-bin
# relay-log日志记录的是从服务器I/O线程将主服务器的二进制日志读取过来记录到从服务器本地文件,然后SQL线程会读取relay-log日志的内容并应用到从服务器
relay-log-info-file = /data/3306/relay-log.info 
# 从服务器用于记录中继日志相关信息的文件,默认名为数据目录中的relay-log.info。
binlog_cache_size = 4M 
# 在一个事务中binlog为了记录sql状态所持有的cache大小，如果你经常使用大的，多声明的事务，可以增加此值来获取更大的性能，所有从事务来的状态都被缓冲在binlog缓冲中，然后再提交后一次性写入到binlog中，如果事务比此值大，会使用磁盘上的临时文件来替代，此缓冲在每个链接的事务第一次更新状态时被创建。
max_binlog_cache_size = 8M 
# 最大的二进制Cache日志缓冲尺寸。
max_binlog_size = 1G 
# 二进制日志文件的最大长度(默认设置1GB)一个二进制文件信息超过了这个最大长度之前,MySQL服务器会自动提供一个新的二进制日志文件接续上。
expire_logs_days = 7 
# 超过7天的binlog,mysql程序自动删除(如果数据重要,建议不要开启该选项)
key_buffer_size = 256M 
# 指定用于索引的缓冲区大小，增加它可得到更好的索引处理性能。对于内存在4GB左右的服务器来说，该参数可设置为256MB或384MB。
# 注意：如果该参数值设置得过大反而会使服务器的整体效率降低！
read_buffer_size = 4M 
# 读查询操作所能使用的缓冲区大小。和sort_buffer_size一样，该参数对应的分配内存也是每个连接独享。
read_rnd_buffer_size = 16M
# 设置进行随机读的时候所使用的缓冲区。此参数和read_buffer_size所设置的Buffer相反，一个是顺序读的时候使用，一个是随机读的时候使用。但是两者都是针对与线程的设置，每个线程都可以产生两种Buffer中的任何一个。默认值256KB，最大值4GB。
bulk_insert_buffer_size = 8M 
# 如果经常性的需要使用批量插入的特殊语句来插入数据,可以适当调整参数至16MB~32MB,建议8MB。
myisam_sort_buffer_size = 8M
# 设置在REPAIR Table或用Create index创建索引或 Alter table的过程中排序索引所分配的缓冲区大小，可设置范围4Bytes至4GB，默认为8MB
lower_case_table_names = 1 
# 实现MySQL不区分大小。(发开需求-建议开启)
slave-skip-errors = 1032,1062 
# 从库可以跳过的错误数字值(mysql错误以数字代码反馈,全的mysql错误代码大全,以后会发布至博客)。
replicate-ignore-db=mysql 
# 在做主从的情况下,设置不需要同步的库。
server-id = 1 
# 表示本机的序列号为1,如果做主从，或者多实例,serverid一定不能相同。
myisam_sort_buffer_size = 128M
# 当需要对于执行REPAIR, OPTIMIZE, ALTER 语句重建索引时，MySQL会分配这个缓存，以及LOAD DATA INFILE会加载到一个新表，它会根据最大的配置认真的分配的每个线程。
myisam_max_sort_file_size = 10G
# 当重新建索引（REPAIR，ALTER，TABLE，或者LOAD，DATA，TNFILE）时，MySQL被允许使用临时文件的最大值。
myisam_repair_threads = 1
# 如果一个表拥有超过一个索引, MyISAM 可以通过并行排序使用超过一个线程去修复他们.
myisam_recover
# 自动检查和修复没有适当关闭的 MyISAM 表.
innodb_additional_mem_pool_size = 4M 
# 用来设置InnoDB存储的数据目录信息和其他内部数据结构的内存池大小。应用程序里的表越多，你需要在这里面分配越多的内存。对于一个相对稳定的应用，这个参数的大小也是相对稳定的，也没有必要预留非常大的值。如果InnoDB用广了这个池内的内存，InnoDB开始从操作系统分配内存，并且往MySQL错误日志写警告信息。默认为1MB，当发现错误日志中已经有相关的警告信息时，就应该适当的增加该参数的大小。
innodb_buffer_pool_size = 64M 
# InnoDB使用一个缓冲池来保存索引和原始数据，设置越大，在存取表里面数据时所需要的磁盘I/O越少。强烈建议不要武断地将InnoDB的Buffer Pool值配置为物理内存的50%~80%，应根据具体环境而定。
innodb_data_file_path = ibdata1:128M:autoextend 
# 设置配置一个可扩展大小的尺寸为128MB的单独文件，名为ibdata1.没有给出文件的位置，所以默认的是在MySQL的数据目录内。
innodb_file_io_threads = 4 
# InnoDB中的文件I/O线程。通常设置为4，如果是windows可以设置更大的值以提高磁盘I/O
innodb_thread_concurrency = 8 
# 你的服务器有几个CPU就设置为几，建议用默认设置，一般设为8。
innodb_flush_log_at_trx_commit = 1 
# 设置为0就等于innodb_log_buffer_size队列满后在统一存储，默认为1，也是最安全的设置。
innodb_log_buffer_size = 2M 
# 默认为1MB，通常设置为8~16MB就足够了。
innodb_log_file_size = 32M 
# 确定日志文件的大小，更大的设置可以提高性能，但也会增加恢复数据库的时间。
innodb_log_files_in_group = 3 
# 为提高性能,MySQL可以以循环方式将日志文件写到多个文件。推荐设置为3。
innodb_max_dirty_pages_pct = 90 
# InnoDB主线程刷新缓存池中的数据。
innodb_lock_wait_timeout = 120 
# InnoDB事务被回滚之前可以等待一个锁定的超时秒数。InnoDB在它自己的锁定表中自动检测事务死锁并且回滚事务。InnoDB用locak tables 语句注意到锁定设置。默认值是50秒。
innodb_file_per_table = 0 
# InnoDB为独立表空间模式，每个数据库的每个表都会生成一个数据空间。0关闭，1开启。
# 独立表空间优点：
# 1、每个表都有自己独立的表空间。
# 2 、每个表的数据和索引都会存在自己的表空间中。
# 3、可以实现单表在不同的数据库中移动。
# 4、空间可以回收（除drop table操作处，表空不能自己回收。）
[mysqldump]

quick

max_allowed_packet = 2M

# 设定在网络传输中一次消息传输量的最大值。系统默认值为1MB，最大值是1GB，必须设置为1024的倍数。单位为字节。
</code></pre><blockquote>
<p>一些建议：</p>
</blockquote>
<pre><code>强烈建议不要武断地将InnoDB的Buffer Pool值配置为物理内存的50%~80%，应根据具体环境而定。
如果key_reads太大，则应该把my.cnf中的key_buffer_size变大，保持key_reads/key_read_re-quests至少在1/100以上，越小越好。
如果qcache_lowmem_prunes很大，就要增加query_cache_size的值。
不过很多时候需要具体情况具体分析，其他参数的变更我们可以等MySQL上线稳定一段时间后在根据status值进行调整。
</code></pre><blockquote>
<p>配置范例:</p>
</blockquote>
<p>一份电子商务网站MySQL数据库调整后所运行的配置文件/etc/my.cnf(服务器为DELL R710、16GB内存、RAID10)，大家可以根据实际的MySQL数据库硬件情况进行调整配置文件如下：</p>
<pre><code>[client]
port = 3306
socket = /data/3306/mysql.sock
default-character-set = utf8
[mysqld]
user = mysql
port = 3306
character-set-server = utf8
socket = /data/3306/mysql.sock
basedir = /application/mysql
datadir = /data/3306/data
log-error=/data/3306/mysql_err.log
pid-file=/data/3306/mysql.pid
log_slave_updates = 1
log-bin = /data/3306/mysql-bin
binlog_format = mixed
binlog_cache_size = 4M
max_binlog_cache_size = 8M
max_binlog_size = 1G
expire_logs_days = 90
binlog-ignore - db = mysql
binlog-ignore - db = information_schema
key_buffer_size = 384M
sort_buffer_size = 2M
read_buffer_size = 2M
read_rnd_buffer_size = 16M
join_buffer_size = 2M
thread_cache_size = 8
query_cache_size = 32M
query_cache_limit = 2M
query_cache_min_res_unit = 2k
thread_concurrency = 32
table_cache = 614
table_open_cache = 512
open_files_limit = 10240
back_log = 600
max_connections = 5000
max_connect_errors = 6000
external-locking = FALSE
max_allowed_packet =16M
thread_stack = 192K
transaction_isolation = READ-COMMITTED
tmp_table_size = 256M
max_heap_table_size = 512M
bulk_insert_buffer_size = 64M
myisam_sort_buffer_size = 64M
myisam_max_sort_file_size = 10G
myisam_repair_threads = 1
myisam_recover
long_query_time = 2
slow_query_log
slow_query_log_file = /data/3306/slow.log
skip-name-resolv
skip-locking
skip-networking
server-id = 1
innodb_additional_mem_pool_size = 16M
innodb_buffer_pool_size = 512M
innodb_data_file_path = ibdata1:256M:autoextend
innodb_file_io_threads = 4
innodb_thread_concurrency = 8
innodb_flush_log_at_trx_commit = 2
innodb_log_buffer_size = 16M
innodb_log_file_size = 128M
innodb_log_files_in_group = 3
innodb_max_dirty_pages_pct = 90
innodb_lock_wait_timeout = 120
innodb_file_per_table = 0
[mysqldump]
quick
max_allowed_packet = 64M
[mysql]
no – auto - rehash
</code></pre><h3 id="存储引擎的选择"><a href="#存储引擎的选择" class="headerlink" title="存储引擎的选择"></a>存储引擎的选择</h3><p>关于存储引擎的选择请看博客：MySQL存储引擎之Myisam和Innodb总结性梳理</p>
<h3 id="线上优化调整"><a href="#线上优化调整" class="headerlink" title="线上优化调整"></a>线上优化调整</h3><blockquote>
<p>MySQL数据库上线后，可以等其稳定运行一段时间后再根据服务器的status状态进行适当优化，我们可以用如下命令列出MySQL服务器运行的各种状态值。通过命令：show global status; 也可以通过 show status like ‘查询%’;</p>
<h4 id="慢查询"><a href="#慢查询" class="headerlink" title="慢查询"></a>慢查询</h4><pre><code>有时我们为了定位系统中效率比较低下的Query语法，需要打开慢查询日志，也就是Slow Query log。打开慢查询日志的相关命令如下：
</code></pre></blockquote>
<pre><code>mysql&gt;show variables like &apos;%slow%&apos;;
+---------------------+-----------------------------------------+
|
Variable_name | Value |
+---------------------+-----------------------------------------+
|
log_slow_queries | ON |
|
slow_launch_time | 2 |
+---------------------+-----------------------------------------+
mysql&gt;show global status like &apos;%slow%&apos;;
+---------------------+-------+
|
Variable_name | Value |
+---------------------+-------+
|
Slow_launch_threads | 0 |
|
Slow_queries | 2128 |
+---------------------+-------+
</code></pre><p>打开慢查询日志可能会对系统性能有一点点影响，如果你的MySQL是主从结构，可以考虑打开其中一台从服务器的慢查询日志，这样既可以监控慢查询，对系统性能影响也会很小。另外，可以用MySQL自带的命令mysqldumpslow进行查询。比如：下面的命令可以查出访问次数最多的20个SQL语句：<br><code>mysqldumpslow -s c -t 20 host-slow.log</code></p>
<h4 id="连接数"><a href="#连接数" class="headerlink" title="连接数"></a>连接数</h4><p>我们如果经常遇见MySQL：ERROR1040：Too many connections的情况，一种情况是访问量确实很高，MySQL服务器扛不住了，这个时候就要考虑增加从服务器分散读压力，从架构层面。另外一种情况是MySQL配置文件中max_connections的值过小。来看一个例子。</p>
<pre><code>mysql&gt; show variables like &apos;max_connections&apos;;
+-----------------+-------+
|
Variable_name | Value |
+-----------------+-------+
|
max_connections | 800 |
+-----------------+-------+
</code></pre><blockquote>
<p>这台服务器最大连接数是256，然后查询一下该服务器响应的最大连接数；</p>
</blockquote>
<pre><code>mysql&gt; show global status like &apos;Max_used_connections&apos;;
+----------------------+-------+
|
Variable_name | Value |
+----------------------+-------+
|
Max_used_connections | 245 |
+----------------------+-------+
</code></pre><blockquote>
<p>MySQL服务器过去的最大连接数是245，没有达到服务器连接数的上线800，不会出现1040错误。</p>
</blockquote>
<p><code>Max_used_connections /max_connections * 100% = 85%</code><br>最大连接数占上限连接数的85%左右,如果发现比例在10%以下，则说明MySQL服务器连接数的上限设置得过高了。</p>
<h4 id="key-buffer-size"><a href="#key-buffer-size" class="headerlink" title="key_buffer_size"></a>key_buffer_size</h4><pre><code>key_buffer_size是设置MyISAM表索引缓存空间的大小，此参数对MyISAM表性能影响最大。下面是一台MyISAM为主要存储引擎服务器的配置：
mysql&gt; show variables like &apos;key_buffer_size&apos;;
+-----------------+-----------+
|
Variable_name | Value |
+-----------------+-----------+
|
key_buffer_size | 536870912 |
+-----------------+-----------+
</code></pre><blockquote>
<p>从上面可以看出，分配了512MB内存给key_buffer_size。再来看key_buffer_size的使用情况：</p>
</blockquote>
<pre><code>mysql&gt; show global status like &apos;key_read%&apos;;
+-------------------+--------------+
|
Variable_name | Value |
+-------------------+-------+
|
Key_read_requests | 27813678766 |
|
Key_reads | 6798830|
+-------------------+--------------+

一共有27813678766个索引读取请求，有6798830个请求在内存中没有找到，直接从硬盘读取索引。
key_cache_miss_rate = key_reads / key_read_requests * 100%
比如上面的数据，key_cache_miss_rate为0.0244%，4000%个索引读取请求才有一个直接读硬盘，效果已经很好了，key_cache_miss_rate在0.1%以下都很好，如果key_cache_miss_rate在0.01%以下的话，则说明key_buffer_size分配得过多，可以适当减少。
</code></pre><h4 id="临时表"><a href="#临时表" class="headerlink" title="临时表"></a>临时表</h4><pre><code>当执行语句时，关于已经被创建了隐含临时表的数量，我们可以用如下命令查询其具体情况：
mysql&gt; show global status like &apos;created_tmp%&apos;;
+-------------------------+----------+
|
Variable_name | Value |
+-------------------------+----------+
|
Created_tmp_disk_tables | 21119 |
|
Created_tmp_files | 6 |
|
Created_tmp_tables | 17715532 |
+-------------------------+----------+
</code></pre><blockquote>
<p>MySQL服务器对临时表的配置：</p>
</blockquote>
<pre><code>mysql&gt; show variables where Variable_name in (&apos;tmp_table_size&apos;,&apos;max_heap_table_size&apos;);
+---------------------+---------+
|
Variable_name | Value |
+---------------------+---------+
|
max_heap_table_size | 2097152 |
|
tmp_table_size | 2097152 |
+---------------------+---------+

每次创建临时表时，Created_tmp_table都会增加，如果磁盘上创建临时表，Created_tmp_disk_tables也会增加。Created_tmp_files表示MySQL服务创建的临时文件数，比较理想的配置是：
Created_tmp_disk_tables / Created_tmp_files *100% &lt;= 25%
比如上面的服务器：
Created_tmp_disk_tables / Created_tmp_files *100% =1.20%，这个值就很棒了。
</code></pre><h4 id="打开表的情况"><a href="#打开表的情况" class="headerlink" title="打开表的情况"></a>打开表的情况</h4><pre><code>Open_tables表示打开表的数量，Opened_tables表示打开过的表数量，我们可以用如下命令查看其具体情况：
mysql&gt; show global status like &apos;open%tables%&apos;;
+---------------+-------+
|
Variable_name | Value |
+---------------+-------+
|
Open_tables | 351 |
|
Opened_tables | 1455 |
</code></pre><blockquote>
<p>查询下服务器table_open_cache;</p>
</blockquote>
<pre><code>mysql&gt; show variables like &apos;table_open_cache&apos;;
+------------------+-------+
|
Variable_name | Value |
+------------------+-------+
|
table_open_cache | 2048 |
+------------------+-------+
如果Opened_tables数量过大，说明配置中table_open_cache的值可能太小。
比较合适的值为：
open_tables / opened_tables* 100% &gt; = 85%
open_tables / table_open_cache* 100% &lt; = 95%
</code></pre><h4 id="进程使用情况"><a href="#进程使用情况" class="headerlink" title="进程使用情况"></a>进程使用情况</h4><pre><code>如果我们在MySQL服务器的配置文件中设置了thread_cache_size，当客户端断开时，服务器处理此客户请求的线程将会缓存起来以响应一下客户而不是销毁(前提是缓存数未达上线)Thread_created表示创建过的线程数，我们可以用如下命令查看：
mysql&gt; show global status like &apos;thread%&apos;;
+-------------------+-------+
|
Variable_name | Value |
+-------------------+-------+
|
Threads_cached | 40|
|
Threads_connected | 1 |
|
Threads_created | 330 |
|
Threads_running | 1 |
+-------------------+-------+
</code></pre><blockquote>
<p>查询服务器thread_cache_size配置如下：</p>
</blockquote>
<pre><code>mysql&gt; show variables like &apos;thread_cache_size&apos;;
+-------------------+-------+
|
Variable_name | Value |
+-------------------+-------+
|
thread_cache_size | 100 |
+-------------------+-------+
如果发现Threads_created的值过大的话，表明MySQL服务器一直在创建线程，这也是比较耗费资源的，可以适当增大配置文件中thread_cache_size的值。
</code></pre><h4 id="查询缓存-query-cache"><a href="#查询缓存-query-cache" class="headerlink" title="查询缓存(query cache)"></a>查询缓存(query cache)</h4><blockquote>
<p>它主要涉及两个参数，<code>query_cache_size</code>是设置<code>MySQL的Query Cache</code>大小，query_cache_type是设置使用查询缓存的类型，我们可以用如下命令查看其具体情况：</p>
</blockquote>
<pre><code>mysql&gt; show global status like &apos;qcache%&apos;;
+-------------------------+-----------+
|
Variable_name | Value |
+-------------------------+-----------+
|
Qcache_free_blocks | 22756 |
|
Qcache_free_memory | 76764704 |
|
Qcache_hits | 213028692 |
|
Qcache_inserts | 208894227 |
|
Qcache_lowmem_prunes | 4010916 |
|
Qcache_not_cached | 13385031 |
|
Qcache_queries_in_cache | 43560 |
|
Qcache_total_blocks | 111212 |
+-------------------------+-----------+
</code></pre><blockquote>
<p>MySQL查询缓存变量的相关解释如下：</p>
</blockquote>
<p><code>Qcache_free_blocks：</code> 缓存中相领内存快的个数。数目大说明可能有碎片。<br><code>flush query</code> cache会对缓存中的碎片进行整理，从而得到一个空间块。<br><code>Qcache_free_memory</code>：缓存中的空闲空间。<br><code>Qcache_hits</code>：多少次命中。通过这个参数可以查看到Query Cache的基本效果。<br><code>Qcache_inserts</code>：插入次数，没插入一次查询时就增加1。命中次数除以插入次数就是命中比率。<br><code>Qcache_lowmem_prunes</code>：多少条Query因为内存不足而被清楚出Query Cache。通过Qcache_lowmem_prunes和Query_free_memory相互结合，能 够更清楚地了解到系统中Query Cache的内存大小是否真的足够，是否非常频繁地出现因为内存不足而有Query被换出的情况。<br><code>Qcache_not_cached</code>：不适合进行缓存的查询数量，通常是由于这些查询不是select语句或用了now()之类的函数。<br><code>Qcache_queries_in_cach</code>：当前缓存的查询和响应数量。<br><code>Qcache_total_blocks</code>：缓存中块的数量。</p>
<blockquote>
<p>query_cache的配置命令：</p>
</blockquote>
<pre><code>mysql&gt; show variables like &apos;query_cache%&apos;;
+------------------------------+---------+
|
Variable_name | Value |
+------------------------------+---------+
|
query_cache_limit | 1048576 |
|
query_cache_min_res_unit | 2048 |
|
query_cache_size | 2097152 |
|
query_cache_type | ON |
|
query_cache_wlock_invalidate | OFF |
+------------------------------+---------+
</code></pre><blockquote>
<p>字段解释如下：</p>
</blockquote>
<p><code>query_cache_limit</code>：超过此大小的查询将不缓存。<br><code>query_cache_min_res_unit</code>：缓存块的最小值。<br><code>query_cache_size</code>：查询缓存大小。<br><code>query_cache_type</code>：缓存类型，决定缓存什么样的查询，示例中表示不缓存select sql_no_cache查询。<br><code>query_cache_wlock_invalidat</code>：表示当有其他客户端正在对MyISAM表进行写操作，读请求是要等WRITE LOCK释放资源后再查询还是允许直接从Query Cache中读取结果，默认为OFF（可以直接从Query Cache中取得结果。）<br><code>query_cache_min_res_unit</code>的配置是一柄双刃剑，默认是4KB，设置值大对大数据查询有好处，但如果你的查询都是小数据查询，就容易造成内存碎片和浪费。</p>
<p>查询缓存碎片率 = <code>Qcache_free_blocks /Qcache_total_blocks * 100%</code><br>如果查询碎片率超过20%，可以用 <code>flush query cache</code> 整理缓存碎片，或者试试减少query_cache_min_res_unit，如果你查询都是小数据库的话。<br>查询缓存利用率 = <code>(Qcache_free_size – Qcache_free_memory)/query_cache_size * 100%</code><br>查询缓存利用率在25%一下的话说明<code>query_cache_size</code>设置得过大，可适当减少;查询缓存利用率在80%以上而且<code>Qcache_lowmem_prunes &gt; 50</code>的话则说明<code>query_cache_size</code>可能有点小，不然就是碎片太多。</p>
<p>查询命中率 = <code>(Qcache_hits - Qcache_insert)/Qcache)hits * 100%</code><br>示例服务器中的查询缓存碎片率等于20%左右，查询缓存利用率在50%，查询命中率在2%，说明命中率很差，可能写操作比较频繁，而且可能有些碎片。</p>
<h4 id="排序使用情况"><a href="#排序使用情况" class="headerlink" title="排序使用情况"></a>排序使用情况</h4><p>它表示系统中对数据进行排序时所用的Buffer，我们可以用如下命令查看：</p>
<pre><code>mysql&gt; show global status like &apos;sort%&apos;;
+-------------------+----------+
|
Variable_name | Value |
+-------------------+----------+
|
Sort_merge_passes | 10 |
|
Sort_range | 37431240 |
|
Sort_rows | 6738691532 |
|
Sort_scan | 1823485 |
+-------------------+----------+
</code></pre><blockquote>
<p>Sort_merge_passes包括如下步骤：MySQL首先会尝试在内存中做排序，使用的内存大小由系统变量sort_buffer_size来决定，如果它不够大则把所有的记录都读在内存中，而MySQL则会把每次在内存中排序的结果存到临时文件中，等MySQL找到所有记录之后，再把临时文件中的记录做一次排序。这次再排序就会增加sort_merge_passes。实际上，MySQL会用另外一个临时文件来存储再次排序的结果，所以我们通常会看sort_merge_passes增加的数值是建临时文件数的两倍。因为用到了临时文件，所以速度可能会比较慢，增大sort_buffer_size会减少sort_merge_passes和创建临时文件的次数，但盲目地增大sort_buffer_size并不一定能提高速度。</p>
</blockquote>
<h4 id="文件打开数-open-files"><a href="#文件打开数-open-files" class="headerlink" title="文件打开数(open_files)"></a>文件打开数(open_files)</h4><p>我们现在处理MySQL故障时，发现当Open_files大于open_files_limit值时，MySQL数据库就会发生卡住的现象，导致Nginx服务器打不开相应页面。这个问题大家在工作中应注意，我们可以用如下命令查看其具体情况：<br>    show global status like ‘open_files’;<br>    +—————+——-+<br>    |<br>    Variable_name | Value |<br>    +—————+——-+<br>    |<br>    Open_files | 1481 |<br>    +—————+——-+<br>    mysql&gt; show global status like ‘open_files_limit’;<br>    +——————+——-+<br>    |<br>    Variable_name | Value |<br>    +——————+——–+<br>    |<br>    Open_files_limit | 4509 |<br>    +——————+——–+</p>
<p>比较合适的设置是：<code>Open_files / Open_files_limit * 100% &lt; = 75%</code></p>
<h4 id="InnoDB-buffer-pool-cache合理设置"><a href="#InnoDB-buffer-pool-cache合理设置" class="headerlink" title="InnoDB_buffer_pool_cache合理设置"></a>InnoDB_buffer_pool_cache合理设置</h4><p>InnoDB存储引擎的缓存机制和MyISAM的最大区别就在于，InnoDB不仅仅缓存索引，同时还会缓存实际的数据。此参数用来设置InnoDB最主要的Buffer的大小，也就是缓存用户表及索引数据的最主要缓存空间，对InnoDB整体性能影响也最大。<br>无论是MySQL官方手册还是网络上许多人分享的InnoDB优化建议，都是简单地建议将此值设置为整个系统物理内存的50%~80%。这种做法其实不妥，我们应根据实际的运行场景来正确设置此项参数。</p>
<p>很多时候我们会发现，通过参数设置进行性能优化所带来的性能提升，并不如许多人想象的那样会产生质的飞跃，除非是之前的设置存在严重不合理的情况。我们不能将性能调优完全依托与通过DBA在数据库上线后进行参数调整，而应该在系统设计和开发阶段就尽可能减少性能问题。(重点在于前期架构合理的设计及开发的程序合理)</p>
<h3 id="MySQL数据库的可扩展架构方案（即高可用方案）"><a href="#MySQL数据库的可扩展架构方案（即高可用方案）" class="headerlink" title="MySQL数据库的可扩展架构方案（即高可用方案）"></a>MySQL数据库的可扩展架构方案（即高可用方案）</h3><blockquote>
<p>可参考：mysql高可用方案总结性说明<br>如果凭借MySQL的优化任无法顶住压力，这个时候我们就必须考虑MySQL的可扩展性架构了(有人称为MySQL集群)它有以下明显的优势：</p>
</blockquote>
<p>1）成本低，很容易通过价格低廉Pc server搭建出一个处理能力非常强大的计算机集群。<br>2）不太容易遇到瓶颈，因为很容易通过添加主机来增加处理能力。<br>3）单节点故障对系统的整体影响较小。</p>
<h4 id="主从复制解决方案"><a href="#主从复制解决方案" class="headerlink" title="主从复制解决方案"></a>主从复制解决方案</h4><p>这是MySQL自身提供的一种高可用解决方案，数据同步方法采用的是MySQL replication技术。MySQL replication就是从服务器到主服务器拉取二进制日志文件，然后再将日志文件解析成相应的SQL在从服务器上重新执行一遍主服务器的操作，通过这种方式保证数据的一致性。<br>为了达到更高的可用性，在实际的应用环境中，一般都是采用MySQL replication技术配合高可用集群软件keepalived来实现自动failover，这种方式可以实现95.000%的SLA。<br><img src="http://images2015.cnblogs.com/blog/827552/201607/827552-20160705175153514-1750548117.png" alt="image"></p>
<blockquote>
<p>在实际应用场景中，MySQL Replication是使用最为广泛的一种提高系统扩展性的设计手段。众多的MySQL使用者通过Replication功能提升系统的扩展性后，通过 简单的增加价格低廉的硬件设备成倍 甚至成数量级地提高了原有系统的性能，是广大MySQL中低端使用者非常喜欢的功能之一，也是许多MySQL使用者选择MySQL最为重要的原因。<br>比较常规的MySQL Replication架构也有好几种，这里分别简单说明下：</p>
</blockquote>
<p><code>MySQL Replication架构一</code>：常规复制架构–Master-slaves<br>是由一个Master复制到一个或多个Salve的架构模式，主要用于读压力大的应用数据库端廉价扩展解决方案，读写分离，Master主要负责写方面的压力。<br>MySQL Replication架构二：级联复制架构<br>即Master-Slaves-Slaves,这个也是为了防止Slaves的读压力过大，而配置一层二级 Slaves，很容易解决Master端因为附属slave太多而成为瓶劲的风险。<br><code>MySQL Replication架构三</code>：Dual Master与级联复制结合架构<br>即Master-Master-Slaves，最大的好处是既可以避免主Master的写操作受到Slave集群的复制带来的影响，而且保证了主Master的单点故障。<br>MySQL Replication的不足：<br>如果Master主机硬件故障无法恢复，则可能造成部分未传送到slave端的数据丢失。所以大家应该根据自己目前的网络 规划，选择自己合理的Mysql架构方案，跟自己的MySQL DBA和程序员多沟涌，多备份(备份我至少会做到本地和异地双备份)，多测试，数据的事是最大的事，出不得半点差错，切记切记</p>
<h4 id="MMM-MHA高可用解决方案"><a href="#MMM-MHA高可用解决方案" class="headerlink" title="MMM/MHA高可用解决方案"></a>MMM/MHA高可用解决方案</h4><p>MMM提供了MySQL主主复制配置的监控、故障转移和管理的一套可伸缩的脚本套件。在MMM高可用方案中，典型的应用是双主多从架构，通过MySQL replication技术可以实现两个服务器互为主从，且在任何时候只有一个节点可以被写入，避免了多点写入的数据冲突。同时，当可写的主节点故障时，MMM套件可以立刻监控到，然后将服务自动切换到另一个主节点，继续提供服务，从而实现MySQL的高可用。<br><img src="http://images2015.cnblogs.com/blog/827552/201607/827552-20160705175154874-6474073.png" alt="image"></p>
<h4 id="Heartbeat-SAN高可用解决方案"><a href="#Heartbeat-SAN高可用解决方案" class="headerlink" title="Heartbeat/SAN高可用解决方案"></a>Heartbeat/SAN高可用解决方案</h4><p>在这个方案中，处理failover的方式是高可用集群软件Heartbeat，它监控和管理各个节点间连接的网络，并监控集群服务，<br>当节点出现故障或者服务不可用时，自动在其他节点启动集群服务。在数据共享方面，通过SAN（Storage Area Network）存储来共享数据，这种方案可以实现99.990%的SLA。<br><img src="http://images2015.cnblogs.com/blog/827552/201607/827552-20160705175157358-1766002481.png" alt="image"></p>
<h4 id="Heartbeat-DRBD高可用解决方案"><a href="#Heartbeat-DRBD高可用解决方案" class="headerlink" title="Heartbeat/DRBD高可用解决方案"></a>Heartbeat/DRBD高可用解决方案</h4><p>此方案处理failover的方式上依旧采用Heartbeat，不同的是，在数据共享方面，采用了基于块级别的数据同步软件DRBD来实现。<br>DRBD是一个用软件实现的、无共享的、服务器之间镜像块设备内容的存储复制解决方案。和SAN网络不同，它并不共享存储，而是通过服务器之间的网络复制数据。<br><img src="http://images2015.cnblogs.com/blog/827552/201607/827552-20160705175158249-1222151770.png" alt="image"></p>
<h4 id="percona-xtradb-cluster"><a href="#percona-xtradb-cluster" class="headerlink" title="percona xtradb cluster"></a>percona xtradb cluster</h4><p>Percona XtraDB Cluster（简称PXC集群）提供了MySQL高可用的一种实现方法。<br>1）集群是有节点组成的，推荐配置至少3个节点，但是也可以运行在2个节点上。<br>2）每个节点都是普通的mysql/percona服务器，可以将现有的数据库服务器组成集群，反之，也可以将集群拆分成单独的服务器。<br>3）每个节点都包含完整的数据副本。<br>PXC集群主要由两部分组成：Percona Server with XtraDB和Write Set Replication patches（使用了Galera library，一个通用的用于事务型应用的同步、多主复制插件）。<br><img src="http://images2015.cnblogs.com/blog/827552/201607/827552-20160705175158905-477494981.png" alt="image"></p>
<blockquote>
<p>MYSQL经典应用架构</p>
</blockquote>
<p><img src="http://images2015.cnblogs.com/blog/827552/201607/827552-20160705175200296-241603992.png" alt="image"></p>
<p>其中：Dbm157是mysql主，dbm158是mysql主的备机，dbs159/160/161是mysql从。<br>MySQL写操作一般采用基于heartbeat+DRBD+MySQL搭建高可用集群的方案。通过heartbeat实现对mysql主进行状态监测，而DRBD实现dbm157数据同步到dbm158。<br>读操作普遍采用基于LVS+Keepalived搭建高可用高扩展集群的方案。前端AS应用通过提高的读VIP连接LVS，LVS有keepliaved做成高可用模式，实现互备。<br>最后，mysql主的从节点dbs159/160/161通过mysql主从复制功能同步mysql主的数据，通过lvs功能提供给前端AS应用进行读操作，并实现负载均衡。</p>
]]></content>
      
        <categories>
            
            <category> Mysql </category>
            
        </categories>
        
        
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MySQ binlog三种模式及设置方法]]></title>
      <url>http://yoursite.com/2016/03/12/MySQ%20binlog%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F%E5%8F%8A%E8%AE%BE%E7%BD%AE%E6%96%B9%E6%B3%95/</url>
      <content type="html"><![CDATA[<h1 id="MySQ-binlog三种模式及设置方法"><a href="#MySQ-binlog三种模式及设置方法" class="headerlink" title="MySQ binlog三种模式及设置方法"></a>MySQ binlog三种模式及设置方法</h1><h2 id="Row-Level-行模式"><a href="#Row-Level-行模式" class="headerlink" title="Row Level 行模式"></a>Row Level 行模式</h2><pre><code>日志中会记录每一行数 据被修改的形式，然后在slave端再对相同的数据进行修改 
</code></pre><a id="more"></a>
<pre><code>优点：在row level模式下，bin-log中可以不记录执行的sql语句的上下文相关的信息，仅仅只需要记录那一条被修改。所以rowlevel的日志内容会非常清楚的记录下每一行数据修改的细节。
不会出现某些特定的情况下的存储过程或function，以及trigger的调用和触发无法被正确复制的问题

缺点：row level，所有的执行的语句当记录到日志中的时候，都将以每行记录的修改来记录，会产生大量的日志内容。
</code></pre><h2 id="Statement-Level（默认"><a href="#Statement-Level（默认" class="headerlink" title="Statement Level（默认"></a>Statement Level（默认</h2><pre><code>每一条会修改数据的sql都会记录到master的bin-log中。slave在复制的时候sql进程会解析成和原来master端执行过的相同的sql来再次执行 

优点：statement level下的优点首先就是解决了row level下的缺点，不需要记录每一行数据的变化，减少bin-log日志量，节约IO，提高性能，因为它只需要在Master上锁执行的语句的细节，以及执行语句的上下文的信息。

缺点：由于只记录语句，所以，在statement level下 已经发现了有不少情况会造成MySQL的复制出现问题，主要是修改数据的时候使用了某些定的函数或者功能的时候会出现。
</code></pre><h2 id="Mixed-自动模式"><a href="#Mixed-自动模式" class="headerlink" title="Mixed 自动模式"></a>Mixed 自动模式</h2><pre><code>在Mixed模式下，MySQL会根据执行的每一条具体的sql语句来区分对待记录的日志格式，也就是在Statement和Row之间选择一种。
如果sql语句确实就是update或者delete等修改数据的语句，那么还是会记录所有行的变更。
</code></pre><h2 id="企业场景如何选择binlog模式"><a href="#企业场景如何选择binlog模式" class="headerlink" title="企业场景如何选择binlog模式"></a>企业场景如何选择binlog模式</h2><pre><code>1、互联网公司，使用MySQL的功能相对少（存储过程、触发器、函数） 

选择默认的语句模式，Statement Level（默认） 
2、公司如果用到使用MySQL的特殊功能（存储过程、触发器、函数） 
则选择Mixed模式

3、公司如果用到使用MySQL的特殊功能（存储过程、触发器、函数）又希望数据最大化一直，此时最好选择Row level模式
</code></pre><h2 id="行模式和语句模式的区别"><a href="#行模式和语句模式的区别" class="headerlink" title="行模式和语句模式的区别"></a>行模式和语句模式的区别</h2><pre><code>1.语句模式： 
100万条记录 
只需1条delete * from test；就可以删除100万条记录

2.row模式 
100万条记录 
记录100万条删除命令
</code></pre>]]></content>
      
        <categories>
            
            <category> Mysql </category>
            
        </categories>
        
        
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Mysqladmin命令总结]]></title>
      <url>http://yoursite.com/2016/03/11/Mysqladmin%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93/</url>
      <content type="html"><![CDATA[<pre><code>mysqladmin 工具的使用格式：
mysqladmin [option] command [command option] command ......
</code></pre><a id="more"></a>
<pre><code>参数选项：
-c number 自动运行次数统计，必须和 -i 一起使用
-i number 间隔多长时间重复执行

0）每个两秒查看一次服务器的状态，总共重复5次。
[root@test-huanqiu ~]# mysqladmin -uroot -p -i 2 -c 5 status


1）查看服务器的状况：status
[root@test-huanqiu ~]# mysqladmin -uroot -p status

2）修改root 密码：
[root@test-huanqiu ~]# mysqladmin -u root -p原密码 password &apos;newpassword&apos;

3）检查mysqlserver是否可用：
[root@test-huanqiu ~]# mysqladmin -uroot -p ping

4）查询服务器的版本
[root@test-huanqiu ~]# mysqladmin -uroot -p version

5）查看服务器状态的当前值：
[root@test-huanqiu ~]# mysqladmin -uroot -p extended-status

6）查询服务器系统变量值：
[root@test-huanqiu ~]# mysqladmin -uroot -p variables

7）显示服务器所有运行的进程：
[root@test-huanqiu ~]# mysqladmin -uroot -p processlist
[root@test-huanqiu ~]# mysqladmin -uroot -p-i 1 processlist   

8）创建数据库
[root@test-huanqiu ~]# mysqladmin -uroot -p create daba-test//每秒刷新一次

9）显示服务器上的所有数据库
[root@test-huanqiu ~]# mysqlshow -uroot -p

10）显示数据库daba-test下有些什么表：
[root@test-huanqiu ~]# mysqlshow -uroot -p daba-test

11）统计daba-test 下数据库表列的汇总
[root@test-huanqiu ~]# mysqlshow -uroot -p daba-test -v

12）统计daba-test 下数据库表的列数和行数
[root@test-huanqiu ~]# mysqlshow -uroot -p daba-test -v -v

13）删除数据库 daba-test
[root@test-huanqiu ~]# mysqladmin -uroot -p drop daba-test

14）重载权限信息
[root@test-huanqiu ~]# mysqladmin -uroot -p reload

15）刷新所有表缓存，并关闭和打开log
[root@test-huanqiu ~]# mysqladmin -uroot -p refresh

16）使用安全模式关闭数据库
[root@test-huanqiu ~]# mysqladmin -uroot -p shutdown

17）刷新命令mysqladmin flush commands
[root@test-huanqiu ~]# mysqladmin -u root -ptmppassword flush-hosts
[root@test-huanqiu ~]# mysqladmin -u root -ptmppassword flush-logs
[root@test-huanqiu ~]# mysqladmin -u root -ptmppassword flush-privileges
[root@test-huanqiu ~]# mysqladmin -u root -ptmppassword flush-status
[root@test-huanqiu ~]# mysqladmin -u root -ptmppassword flush-tables
[root@test-huanqiu ~]# mysqladmin -u root -ptmppassword flush-threads

18）mysqladmin 执行kill 进程：
[root@test-huanqiu ~]# mysqladmin -uroot -p processlist
[root@test-huanqiu ~]# mysqladmin -uroot -p kill idnum

19）停止和启动MySQL replication on a slave server
[root@test-huanqiu ~]# mysqladmin -u root -p stop-slave
[root@test-huanqiu ~]# mysqladmin -u root -p start-slave

20）同时执行多个命令
[root@test-huanqiu ~]# mysqladmin -u root -p process status version
</code></pre>]]></content>
      
        <categories>
            
            <category> Mysql </category>
            
        </categories>
        
        
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
        
    </entry>
    
  
  
</search>
