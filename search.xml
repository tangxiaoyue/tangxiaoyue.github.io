<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
    
    <entry>
      <title><![CDATA[100个大数据名词和术语汇总]]></title>
      <url>http://yoursite.com/2017/05/05/100%E4%B8%AA%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%90%8D%E8%AF%8D%E5%92%8C%E6%9C%AF%E8%AF%AD%E6%B1%87%E6%80%BB/</url>
      <content type="html"><![CDATA[<p>数据的出现带来了许多新的术语，但这些术语往往比较难以理解。因此，我们通过本文给出一个常用的大数据术语表，抛砖引玉，供大家深入了解，部分定义参考了相应的博客文章。</p>
<a id="more"></a>
<h4 id="A"><a href="#A" class="headerlink" title="A"></a><strong>A</strong></h4><p><code>聚合 (Aggregation)</code> – 搜索、合并、显示数据的过程<br><code>算法 (Algorithms)</code> – 可以完成某种数据分析的数学公式<br><code>分析法 (Analytics)</code> – 用于发现数据的内在涵义<br><code>异常检测 (Anomaly detection)</code>– 在数据集中搜索与预期模式或行为不匹配的数据项。除了“Anomalies”,用来表示异常的词有以下几种：outliers, exceptions, surprises, contaminants.他们通常可提供关键的可执行信息<br><code>匿名化 (Anonymization)</code> – 使数据匿名，即移除所有与个人隐私相关的数据<br><code>应用 (Application)</code>– 实现某种特定功能的计算机软件<br><code>人工智能 (Artificial Intelligence)</code> – 研发智能机器和智能软件，这些智能设备能够感知周遭的环境，并根据要求作出相应的反应，甚至能自我学习。</p>
<h4 id="B"><a href="#B" class="headerlink" title="B"></a><strong>B</strong></h4><p><code>行为分析法 (Behavioural Analytics)</code> – 这种分析法是根据用户的行为如“怎么做”，“为什么这么做”，以及“做了什么”来得出结论，而不是仅仅针对人物和时间的一门分析学科，它着眼于数据中的人性化模式<br><code>大数据科学家 (Big Data Scientist)</code> – 能够设计大数据算法使得大数据变得有用的人<br><code>大数据创业公司 (Big data startup)</code> – 指研发最新大数据技术的新兴公司<br><code>生物测定术 (Biometrics)</code> – 根据个人的特征进行身份识别<br><code>B字节 (BB: Brontobytes)</code> – 约等于1000 YB(Yottabytes)，相当于未来数字化宇宙的大小。1 B字节包含了27个0！<br><code>商业智能 (Business Intelligence)</code> – 是一系列理论、方法学和过程，使得数据更容易被理解</p>
<h4 id="C"><a href="#C" class="headerlink" title="C"></a><strong>C</strong></h4><p><code>分类分析 (Classification analysis)</code> – 从数据中获得重要的相关性信息的系统化过程; 这类数据也被称为元数据(meta data),是描述数据的数据<br><code>云计算 (Cloud computing)</code> – 构建在网络上的分布式计算系统，数据是存储于机房外的（即云端）<br><code>聚类分析 (Clustering analysis)</code> – 它是将相似的对象聚合在一起，每类相似的对象组合成一个聚类(也叫作簇)的过程。这种分析方法的目的在于分析数据间的差异和相似性<br><code>冷数据存储 (Cold data storage)</code> – 在低功耗服务器上存储那些几乎不被使用的旧数据。但这些数据检索起来将会很耗时<br><code>对比分析 (Comparative analysis)</code> – 在非常大的数据集中进行模式匹配时，进行一步步的对比和计算过程得到分析结果<br><code>复杂结构的数据 (Complex structured data)</code> – 由两个或多个复杂而相互关联部分组成的数据，这类数据不能简单地由结构化查询语言或工具(SQL)解析<br><code>计算机产生的数据 (Computer generated data)</code> – 如日志文件这类由计算机生成的数据<br><code>并发 (Concurrency)</code> – 同时执行多个任务或运行多个进程<br><code>相关性分析 (Correlation analysis)</code> – 是一种数据分析方法，用于分析变量之间是否存在正相关，或者负相关<br><code>客户关系管理 (CRM: Customer Relationship Management)</code>– 用于管理销售、业务过程的一种技术，大数据将影响公司的客户关系管理的策略</p>
<h4 id="D"><a href="#D" class="headerlink" title="D"></a><strong>D</strong></h4><p><code>仪表板 (Dashboard)</code> – 使用算法分析数据，并将结果用图表方式显示于仪表板中<br><code>数据聚合工具 (Data aggregation tools)</code> – 将分散于众多数据源的数据转化成一个全新数据源的过程<br><code>数据分析师 (Data analyst)</code> – 从事数据分析、建模、清理、处理的专业人员<br><code>数据库 (Database)</code> – 一个以某种特定的技术来存储数据集合的仓库<br><code>数据库即服务 (Database-as-a-Service)</code> – 部署在云端的数据库，即用即付，例如亚马逊云服务 (AWS: Amazon Web Services)<br><code>数据库管理系统 (DBMS: Database Management System)</code> – 收集、存储数据，并提供数据的访问<br><code>数据中心 (Data centre)</code> – 一个实体地点，放置了用来存储数据的服务器<br><code>数据清洗 (Data cleansing)</code> – 对数据进行重新审查和校验的过程，目的在于删除重复信息、纠正存在的错误，并提供数据一致性<br><code>数据管理员 (Data custodian)</code> – 负责维护数据存储所需技术环境的专业技术人员<br><code>数据道德准则 (Data ethical guidelines)</code> – 这些准则有助于组织机构使其数据透明化，保证数据的简洁、安全及隐私<br><code>数据订阅 (Data feed)</code> – 一种数据流，例如Twitter订阅和RSS<br><code>数据集市 (Data marketplace)</code> – 进行数据集买卖的在线交易场所<br><code>数据挖掘 (Data mining)</code> – 从数据集中发掘特定模式或信息的过程<br><code>数据建模 (Data modelling)</code> – 使用数据建模技术来分析数据对象，以此洞悉数据的内在涵义<br><code>数据集 (Data set)</code> – 大量数据的集合<br><code>数据虚拟化 (Data virtualization)</code> – 数据整合的过程，以此获得更多的数据信息，这个过程通常会引入其他技术，例如数据库，应用程序，文件系统，网页技术，大数据技术等等<br><code>去身份识别 (De-identification)</code> – 也称为匿名化(anonymization)，确保个人不会通过数据被识别<br><code>判别分析 (Discriminant analysis)</code> – 将数据分类；按不同的分类方式，可将数据分配到不同的群组，类别或者目录。是一种统计分析法，可以对数据中某些群组或集群的已知信息进行分析，并从中获取分类规则。<br><code>分布式文件系统 (Distributed File System)</code> – 提供简化的，高可用的方式来存储、分析、处理数据的系统<br><code>文件存贮数据库 (Document Store Databases)</code> – 又称为文档数据库(document-oriented database), 为存储、管理、恢复文档数据而专门设计的数据库，这类文档数据也称为半结构化数据</p>
<h4 id="E"><a href="#E" class="headerlink" title="E"></a><strong>E</strong></h4><p><code>探索性分析 (Exploratory analysis)</code> – 在没有标准的流程或方法的情况下从数据中发掘模式。是一种发掘数据和数据集主要特性的一种方法<br><code>E字节 (EB: Exabytes)</code> – 约等于1000 PB(petabytes), 约等于1百万 GB。如今全球每天所制造的新信息量大约为1 EB<br><code>提取-转换-加载 (ETL: Extract, Transform and Load)</code> – 是一种用于数据库或者数据仓库的处理过程，天善学院有国内唯一的最全的 ETL 学习课程。即从各种不同的数据源提取(E)数据，并转换(T)成能满足业务需要的数据，最后将其加载(L)到数据库</p>
<h4 id="F"><a href="#F" class="headerlink" title="F"></a><strong>F</strong></h4><p><code>故障切换 (Failover)</code> – 当系统中某个服务器发生故障时，能自动地将运行任务切换到另一个可用服务器或节点上<br><code>容错设计 (Fault-tolerant design)</code> – 一个支持容错设计的系统应该能够做到当某一部分出现故障也能继续运行</p>
<h4 id="G"><a href="#G" class="headerlink" title="G"></a><strong>G</strong></h4><p><code>游戏化 (Gamification)</code> – 在其他非游戏领域中运用游戏的思维和机制，这种方法可以以一种十分友好的方式进行数据的创建和侦测，非常有效。<br><code>图形数据库 (Graph Databases)</code> – 运用图形结构(例如，一组有限的有序对，或者某种实体)来存储数据，这种图形存储结构包括边缘、属性和节点。它提供了相邻节点间的自由索引功能，也就是说，数据库中每个元素间都与其他相邻元素直接关联。<br><code>网格计算 (Grid computing)</code> – 将许多分布在不同地点的计算机连接在一起，用以处理某个特定问题，通常是通过云将计算机相连在一起。</p>
<h4 id="H"><a href="#H" class="headerlink" title="H"></a><strong>H</strong></h4><p><code>Hadoop</code>– 一个开源的分布式系统基础框架，可用于开发分布式程序，进行大数据的运算与存储。<br><code>Hadoop 数据库 (HBase)</code> – 一个开源的、非关系型、分布式数据库，与Hadoop框架共同使用<br>HDFS – Hadoop 分布式文件系统 (Hadoop Distributed File System)；是一个被设计成适合运行在通用硬件(commodity hardware)上的分布式文件系统<br><code>高性能计算 (HPC: High-Performance-Computing)</code>– 使用超级计算机来解决极其复杂的计算问题</p>
<h4 id="I"><a href="#I" class="headerlink" title="I"></a><strong>I</strong></h4><p><code>内存数据库 (IMDB: In-memory)</code> – 一种数据库管理系统，与普通数据库管理系统不同之处在于，它用主存来存储数据，而非硬盘。其特点在于能高速地进行数据的处理和存取。<br><code>物联网 (Internet of Things)</code>– 在普通的设备中装上传感器，使这些设备能够在任何时间任何地点与网络相连。</p>
<h4 id="J"><a href="#J" class="headerlink" title="J"></a><strong>J</strong></h4><p><code>法律上的数据一致性 (Juridical data compliance)</code> – 当你使用的云计算解决方案，将你的数据存储于不同的国家或不同的大陆时，就会与这个概念扯上关系了。你需要留意这些存储在不同国家的数据是否符合当地的法律。</p>
<h4 id="K"><a href="#K" class="headerlink" title="K"></a><strong>K</strong></h4><p><code>键值数据库 (KeyValue Databases)</code> – 数据的存储方式是使用一个特定的键，指向一个特定的数据记录，这种方式使得数据的查找更加方便快捷。键值数据库中所存的数据通常为编程语言中基本数据类型的数据。</p>
<h4 id="L"><a href="#L" class="headerlink" title="L"></a><strong>L</strong></h4><p><code>延迟 (Latency)</code> – 表示系统时间的延迟<br><code>遗留系统 (Legacy system)</code> – 是一种旧的应用程序，或是旧的技术，或是旧的计算系统，现在已经不再支持了。<br><code>负载均衡 (Load balancing)</code> – 将工作量分配到多台电脑或服务器上，以获得最优结果和最大的系统利用率。<br><code>位置信息 (Location data)</code> – GPS信息，即地理位置信息。<br><code>日志文件 (Log file)</code> – 由计算机系统自动生成的文件，记录系统的运行过程。</p>
<h4 id="M"><a href="#M" class="headerlink" title="M"></a><strong>M</strong></h4><p><code>M2M数据 (Machine2Machine data)</code> – 两台或多台机器间交流与传输的内容<br><code>机器数据 (Machine data)</code>– 由传感器或算法在机器上产生的数据<br><code>机器学习 (Machine learning)</code> – 人工智能的一部分，指的是机器能够从它们所完成的任务中进行自我学习，通过长期的累积实现自我改进。<br><code>MapReduce</code> – 是处理大规模数据的一种软件框架(Map: 映射，Reduce: 归纳)。<br><code>大规模并行处理 (MPP: Massively Parallel Processing)</code> – 同时使用多个处理器(或多台计算机) 处理同一个计算任务。<br><code>元数据 (Metadata)</code> – 被称为描述数据的数据，即描述数据数据属性(数据是什么)的信息。<br><code>MongoDB</code> – 一种开源的非关系型数据库(NoSQL database)<br><code>多维数据库 (Multi-Dimensional Databases)</code> – 用于优化数据联机分析处理(OLAP)程序，优化数据仓库的一种数据库。<br><code>多值数据库 (MultiValue Databases)</code> – 是一种非关系型数据库(NoSQL), 一种特殊的多维数据库：能处理3个维度的数据。主要针对非常长的字符串，能够完美地处理HTML和XML中的字串。</p>
<h4 id="N"><a href="#N" class="headerlink" title="N"></a><strong>N</strong></h4><p><code>自然语言处理 (Natural Language Processing)</code> – 是计算机科学的一个分支领域，它研究如何实现计算机与人类语言之间的交互。<br><code>网络分析 (Network analysis)</code> – 分析网络或图论中节点间的关系，即分析网络中节点间的连接和强度关系。<br><code>NewSQL</code> – 一个优雅的、定义良好的数据库系统，比SQL更易学习和使用，比NoSQL更晚提出的新型数据库<br><code>NoSQL</code> – 顾名思义，就是“不使用SQL”的数据库。这类数据库泛指传统关系型数据库以外的其他类型的数据库。这类数据库有更强的一致性，能处理超大规模和高并发的数据。</p>
<h4 id="O"><a href="#O" class="headerlink" title="O"></a><strong>O</strong></h4><p><code>对象数据库 (Object Databases)</code> – (也称为面象对象数据库)以对象的形式存储数据，用于面向对象编程。它不同于关系型数据库和图形数据库，大部分对象数据库都提供一种查询语言，允许使用声明式编程(declarative programming)访问对象.<br><code>基于对象图像分析 (Object-based Image Analysis)</code> – 数字图像分析方法是对每一个像素的数据进行分析，而基于对象的图像分析方法则只分析相关像素的数据，这些相关像素被称为对象或图像对象。<br><code>操作型数据库 (Operational Databases)</code> – 这类数据库可以完成一个组织机构的常规操作，对商业运营非常重要，一般使用在线事务处理，允许用户访问 、收集、检索公司内部的具体信息。<br><code>优化分析 (Optimization analysis)</code> – 在产品设计周期依靠算法来实现的优化过程，在这一过程中，公司可以设计各种各样的产品并测试这些产品是否满足预设值。<br><code>本体论 (Ontology)</code> – 表示知识本体，用于定义一个领域中的概念集及概念之间的关系的一种哲学思想。(译者注: 数据被提高到哲学的高度，被赋予了世界本体的意义，成为一个独立的客观数据世界)<br><code>异常值检测 (Outlier detection)</code> – 异常值是指严重偏离一个数据集或一个数据组合总平均值的对象，该对象与数据集中的其他它相去甚远，因此，异常值的出现意味着系统发生问题，需要对此另加分析。</p>
<h4 id="P"><a href="#P" class="headerlink" title="P"></a><strong>P</strong></h4><p><code>模式识别 (Pattern Recognition)</code> – 通过算法来识别数据中的模式，并对同一数据源中的新数据作出预测<br><code>P字节 (PB: Petabytes)</code> – 约等于1000 TB(terabytes), 约等于1百万 GB (gigabytes)。欧洲核子研究中心(CERN)大型强子对撞机每秒产生的粒子个数就约为1 PB<br><code>平台即服务 (PaaS: Platform-as-a-Service)</code>– 为云计算解决方案提供所有必需的基础平台的一种服务<br><code>预测分析 (Predictive analysis)</code> – 大数据分析方法中最有价值的一种分析方法，这种方法有助于预测个人未来(近期)的行为，例如某人很可能会买某些商品，可能会访问某些网站，做某些事情或者产生某种行为。通过使用各种不同的数据集，例如历史数据，事务数据，社交数据，或者客户的个人信息数据，来识别风险和机遇<br><code>隐私 (Privacy)</code>– 把具有可识别出个人信息的数据与其他数据分离开，以确保用户隐私。<br><code>公共数据 (Public data)</code> – 由公共基金创建的公共信息或公共数据集。</p>
<h4 id="Q"><a href="#Q" class="headerlink" title="Q"></a><strong>Q</strong></h4><p><code>数字化自我 (Quantified Self)</code> – 使用应用程序跟踪用户一天的一举一动，从而更好地理解其相关的行为<br><code>查询 (Query)</code> – 查找某个问题答案的相关信息</p>
<h4 id="R"><a href="#R" class="headerlink" title="R"></a><strong>R</strong></h4><p><code>再识别 (Re-identification)</code>– 将多个数据集合并在一起，从匿名化的数据中识别出个人信息<br><code>回归分析 (Regression analysis)</code> – 确定两个变量间的依赖关系。这种方法假设两个变量之间存在单向的因果关系(译者注：自变量，因变量，二者不可互换)<br><code>RFID</code> – 射频识别; 这种识别技术使用一种无线非接触式射频电磁场传感器来传输数据<br><code>实时数据 (Real-time data)</code> – 指在几毫秒内被创建、处理、存储、分析并显示的数据<br><code>推荐引擎 (Recommendation engine)</code>– 推荐引擎算法根据用户之前的购买行为或其他购买行为向用户推荐某种产品<br><code>路径分析 (Routing analysis)</code> – 针对某种运输方法通过使用多种不同的变量分析从而找到一条最优路径，以达到降低燃料费用，提高效率的目的</p>
<h4 id="S"><a href="#S" class="headerlink" title="S"></a><strong>S</strong></h4><p><code>半结构化数据 (Semi-structured data)</code> – 半结构化数据并不具有结构化数据严格的存储结构，但它可以使用标签或其他形式的标记方式以保证数据的层次结构<br><code>情感分析 (Sentiment Analysis)</code> – 通过算法分析出人们是如何看待某些话题<br><code>信号分析 (Signal analysis)</code> – 指通过度量随时间或空间变化的物理量来分析产品的性能。特别是使用传感器数据。<br><code>相似性搜索 (Similarity searches)</code> – 在数据库中查询最相似的对象，这里所说的数据对象可以是任意类型的数据<br><code>仿真分析 (Simulation analysis)</code>– 仿真是指模拟真实环境中进程或系统的操作。仿真分析可以在仿真时考虑多种不同的变量，确保产品性能达到最优<br><code>智能网格 (Smart grid)</code> – 是指在能源网中使用传感器实时监控其运行状态，有助于提高效率<br><code>软件即服务 (SaaS: Software-as-a-Service)</code>– 基于Web的通过浏览器使用的一种应用软件<br><code>空间分析 (Spatial analysis)</code> – 空间分析法分析地理信息或拓扑信息这类空间数据，从中得出分布在地理空间中的数据的模式和规律<br><code>SQL</code> – 在关系型数据库中，用于检索数据的一种编程语言<br><code>构化数据 (Structured data)</code> -可以组织成行列结构，可识别的数据。这类数据通常是一条记录，或者一个文件，或者是被正确标记过的数据中的某一个字段，并且可以被精确地定位到。</p>
<h4 id="T"><a href="#T" class="headerlink" title="T"></a><strong>T</strong></h4><p><code>T字节 (TB: Terabytes)</code> – 约等于1000 GB(gigabytes)。1 TB容量可以存储约300小时的高清视频。<br><code>时序分析 (Time series analysis)</code> – 分析在重复测量时间里获得的定义良好的数据。分析的数据必须是良好定义的，并且要取自相同时间间隔的连续时间点。<br><code>拓扑数据分析 (Topological Data Analysis)</code>– 拓扑数据分析主要关注三点：复合数据模型、集群的识别、以及数据的统计学意义。<br><code>交易数据 (Transactional data)</code> – 随时间变化的动态数据<br><code>透明性 (Transparency)</code> – 消费者想要知道他们的数据有什么作用、被作何处理，而组织机构则把这些信息都透明化了。</p>
<h4 id="U"><a href="#U" class="headerlink" title="U"></a><strong>U</strong></h4><p><code>非结构化数据 (Un-structured data)</code> – 非结构化数据一般被认为是大量纯文本数据，其中还可能包含日期，数字和实例。</p>
<h4 id="V"><a href="#V" class="headerlink" title="V"></a><strong>V</strong></h4><p><code>价值 (Value)</code>– (译者注：大数据4V特点之一) 所有可用的数据，能为组织机构、社会、消费者创造出巨大的价值。这意味着各大企业及整个产业都将从大数据中获益。<br><code>可变性</code>(Variability) – 也就是说，数据的含义总是在（快速）变化的。例如，一个词在相同的推文中可以有完全不同的意思。<br><code>多样 (Variety)</code> – (译者注：大数据4V特点之一) 数据总是以各种不同的形式呈现，如结构化数据，半结构化数据，非结构化数据，甚至还有复杂结构化数据<br><code>高速 (Velocity)</code> – (译者注：大数据4V特点之一) 在大数据时代，数据的创建、存储、分析、虚拟化都要求被高速处理。<br><code>真实性 (Veracity)</code> – 组织机构需要确保数据的真实性，才能保证数据分析的正确性。因此，真实性(Veracity)是指数据的正确性。<br><code>可视化 (Visualization)</code> – 只有正确的可视化，原始数据才可被投入使用。这里的“可视化”并非普通的图型或饼图，可视化指是的复杂的图表，图表中包含大量的数据信息，但可以被很容易地理解和阅读。<br><code>大量 (Volume)</code> – (译者注：大数据4V特点之一) 指数据量，范围从Megabytes至Brontobytes</p>
<h4 id="W"><a href="#W" class="headerlink" title="W"></a><strong>W</strong></h4><p><code>天气数据 (Weather data)</code> – 是一种重要的开放公共数据来源，如果与其他数据来源合成在一起，可以为相关组织机构提供深入分析的依据</p>
<h4 id="X"><a href="#X" class="headerlink" title="X"></a><strong>X</strong></h4><p><code>XML数据库 (XML Databases)</code> – XML数据库是一种以XML格式存储数据的数据库。XML数据库通常与面向文档型数据库相关联，开发人员可以对XML数据库的数据进行查询，导出以及按指定的格式序列化</p>
<h4 id="Y"><a href="#Y" class="headerlink" title="Y"></a><strong>Y</strong></h4><p><code>Y字节 (Yottabytes)</code> – 约等于1000 ZB (Zettabytes), 约等于250万亿张DVD的数据容量。现今，整个数字化宇宙的数据量为1 YB, 并且将每18年翻一番。</p>
<h4 id="Z"><a href="#Z" class="headerlink" title="Z"></a><strong>Z</strong></h4><p><code>Z字节 (ZB: Zettabytes)</code> – 约等于1000 EB (Exabytes), 约等于1百万 TB。据预测，到2016年全球范围内每天网络上通过的信息大约能达到1 ZB。</p>
<p>附：存储容量单位换算表</p>
<pre><code>1 Bit (比特) = Binary Digit

8 Bits = 1 Byte (字节)

1,000 Bytes = 1 Kilobyte

1,000 Kilobytes = 1 Megabyte

1,000 Megabytes = 1 Gigabyte

1,000 Gigabytes = 1 Terabyte

1,000 Terabytes = 1 Petabyte

1,000 Petabytes = 1 Exabyte

1,000 Exabytes = 1 Zettabyte

1,000 Zettabytes = 1 Yottabyte

1,000 Yottabytes = 1 Brontobyte

1,000 Brontobytes = 1 Geopbyte
</code></pre>]]></content>
      
        <categories>
            
            <category> Linux基础 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux基础 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[常用端口梳理]]></title>
      <url>http://yoursite.com/2017/05/02/%E5%B8%B8%E7%94%A8%E7%AB%AF%E5%8F%A3%E6%A2%B3%E7%90%86/</url>
      <content type="html"><![CDATA[<p>大家在学习计算机的时候，对于最常用的几个端口比如80端口肯定有很深的印象，但是对于其他一些不是那么常用的端口可能就没那么了解。所以，在一些使用频率相对较高的端口上，很容易会引发一些由于陌生而出现的错误，或者被黑客利用某些端口进行入侵。对于这件事情，大部分人都很头疼——最多可达65535个的端口，让人怎么记？<br>别怕，这次专门给大家整理了一些比较常见端口信息，遇到问题，一查就好！</p>
<a id="more"></a>
<pre><code>注意：一个计算机最多有65535个端口，端口不能重复。
常用端口号： 
IIS（HTTP）：80 
SQLServer：1433 
Oracle：1521 
MySQL：3306 
FTP：21 
SSH：22 
Tomcat：8080
常用和不常用端口一览表

端口：0 
服务：Reserved 
说明：通常用于分析操作系统。这一方法能够工作是因为在一些系统中“0”是无效端口，当你试图使用通常的闭合端口连接它时将产生不同的结果。一种典型的扫描，使用IP地址为0.0.0.0，设置ACK位并在以太网层广播。 

端口：1 
服务：tcpmux 
说明：这显示有人在寻找SGI 
Irix机器。Irix是实现tcpmux的主要提供者，默认情况下tcpmux在这种系统中被打开。Irix机器在发布是含有几个默认的无密码的帐户，如：IP、GUEST 
UUCP、NUUCP、DEMOS 
、TUTOR、DIAG、OUTOFBOX等。许多管理员在安装后忘记删除这些帐户。因此HACKER在INTERNET上搜索tcpmux并利用这些帐户。

端口：7 
服务：Echo 
说明：能看到许多人搜索Fraggle放大器时，发送到X.X.X.0和X.X.X.255的信息。 

端口：19 
服务：Character 
Generator 
说明：这是一种仅仅发送字符的服务。UDP版本将会在收到UDP包后回应含有垃圾字符的包。TCP连接时会发送含有垃圾字符的数据流直到连接关闭。HACKER利用IP欺骗可以发动DoS攻击。伪造两个chargen服务器之间的UDP包。同样Fraggle 
DoS攻击向目标地址的这个端口广播一个带有伪造受害者IP的数据包，受害者为了回应这些数据而过载。

端口：21 
服务：FTP 
说明：FTP服务器所开放的端口，用于上传、下载。最常见的攻击者用于寻找打开anonymous的FTP服务器的方法。这些服务器带有可读写的目录。木马Doly 
Trojan、Fore、Invisible FTP、WebEx、WinCrash和Blade 
Runner所开放的端口。

端口：22 
服务：Ssh 
说明：PcAnywhere建立的TCP和这一端口的连接可能是为了寻找ssh。这一服务有许多弱点，如果配置成特定的模式，许多使用RSAREF库的版本就会有不少的漏洞存在。

端口：23 
服务：Telnet 
说明：远程登录，入侵者在搜索远程登录UNIX的服务。大多数情况下扫描这一端口是为了找到机器运行的操作系统。还有使用其他技术，入侵者也会找到密码。木马Tiny 
Telnet 
Server就开放这个端口。

端口：25 
服务：SMTP 
说明：SMTP服务器所开放的端口，用于发送邮件。入侵者寻找SMTP服务器是为了传递他们的SPAM。入侵者的帐户被关闭，他们需要连接到高带宽的E-MAIL服务器上，将简单的信息传递到不同的地址。木马Antigen、Email 
Password Sender、Haebu Coceda、Shtrilitz 
Stealth、WinPC、WinSpy都开放这个端口。

端口：31 
服务：MSG 
Authentication 
说明：木马Master Paradise、Hackers 
Paradise开放此端口。

端口：42 
服务：WINS 
Replication 
说明：WINS复制

端口：53 
服务：Domain Name 
Server（DNS） 
说明：DNS服务器所开放的端口，入侵者可能是试图进行区域传递（TCP），欺骗DNS（UDP）或隐藏其他的通信。因此防火墙常常过滤或记录此端口。

端口：67 
服务：Bootstrap 
Protocol Server 
说明：通过DSL和Cable 
modem的防火墙常会看见大量发送到广播地址255.255.255.255的数据。这些机器在向DHCP服务器请求一个地址。HACKER常进入它们，分配一个地址把自己作为局部路由器而发起大量中间人（man-in-middle）攻击。客户端向68端口广播请求配置，服务器向67端口广播回应请求。这种回应使用广播是因为客户端还不知道可以发送的IP地址。
DHCP (UDP ports 67 and 68)

端口：69 
服务：Trival 
File 
Transfer 
说明：许多服务器与bootp一起提供这项服务，便于从系统下载启动代码。但是它们常常由于错误配置而使入侵者能从系统中窃取任何文件。它们也可用于系统写入文件。 

端口：79 
服务：Finger 
Server 
说明：入侵者用于获得用户信息，查询操作系统，探测已知的缓冲区溢出错误，回应从自己机器到其他机器Finger扫描。

端口：80 
服务：HTTP 
说明：用于网页浏览。木马Executor开放此端口。

端口：99 
服务：Metagram 
Relay 
说明：后门程序ncx99开放此端口。

端口：102 
服务：Message transfer 
agent(MTA)-X.400 over TCP/IP 
说明：消息传输代理。

端口：109 
服务：Post Office 
Protocol 
-Version3 
说明：POP3服务器开放此端口，用于接收邮件，客户端访问服务器端的邮件服务。POP3服务有许多公认的弱点。关于用户名和密码交换缓冲区溢出的弱点至少有20个，这意味着入侵者可以在真正登陆前进入系统。成功登陆后还有其他缓冲区溢出错误。

端口：110 
服务：SUN公司的RPC服务所有端口 
说明：常见RPC服务有rpc.mountd、NFS、rpc.statd、rpc.csmd、rpc.ttybd、amd等

端口：113 
服务：Authentication 
Service 
说明：这是一个许多计算机上运行的协议，用于鉴别TCP连接的用户。使用标准的这种服务可以获得许多计算机的信息。但是它可作为许多服务的记录器，尤其是FTP、POP、IMAP、SMTP和IRC等服务。通常如果有许多客户通过防火墙访问这些服务，将会看到许多这个端口的连接请求。记住，如果阻断这个端口客户端会感觉到在防火墙另一边与E-MAIL服务器的缓慢连接。许多防火墙支持TCP连接的阻断过程中发回RST。这将会停止缓慢的连接。

端口：119 
服务：Network 
News Transfer 
Protocol 
说明：NEWS新闻组传输协议，承载USENET通信。这个端口的连接通常是人们在寻找USENET服务器。多数ISP限制，只有他们的客户才能访问他们的新闻组服务器。打开新闻组服务器将允许发/读任何人的帖子，访问被限制的新闻组服务器，匿名发帖或发送SPAM。

端口：135 
服务：Location 
Service 
说明：Microsoft在这个端口运行DCE RPC end-point mapper为它的DCOM服务。这与UNIX 
111端口的功能很相似。使用DCOM和RPC的服务利用计算机上的end-point 
mapper注册它们的位置。远端客户连接到计算机时，它们查找end-point 
mapper找到服务的位置。HACKER扫描计算机的这个端口是为了找到这个计算机上运行Exchange 
Server吗？什么版本？还有些DOS攻击直接针对这个端口。

端口：137、138、139 
服务：NETBIOS Name 
Service 
说明：其中137、138是UDP端口，当通过网上邻居传输文件时用这个端口。而139端口通过这个端口进入的连接试图获得NetBIOS/SMB服务。这个协议被用于windows文件和打印机共享和SAMBA。还有WINS 
Regisrtation也用它。 

端口：143 
服务：Interim Mail Access Protocol 
v2 
说明：和POP3的安全问题一样，许多IMAP服务器存在有缓冲区溢出漏洞。记住：一种Linux蠕虫（admv0rm）会通过这个端口繁殖，因此许多这个端口的扫描来自不知情的已经被感染的用户。当REDHAT在他们的LINUX发布版本中默认允许IMAP后，这些漏洞变的很流行。这一端口还被用于IMAP2，但并不流行。

端口：161 
服务：SNMP 
说明：SNMP允许远程管理设备。所有配置和运行信息的储存在数据库中，通过SNMP可获得这些信息。许多管理员的错误配置将被暴露在Internet。Cackers将试图使用默认的密码public、private访问系统。他们可能会试验所有可能的组合。SNMP包可能会被错误的指向用户的网络。

端口：177 
服务：X 
Display Manager Control 
Protocol 
说明：许多入侵者通过它访问X-windows操作台，它同时需要打开6000端口。

端口：389 
服务：LDAP、ILS 
说明：轻型目录访问协议和NetMeeting 
Internet Locator 
Server共用这一端口。

端口：443 
服务：Https 
说明：网页浏览端口，能提供加密和通过安全端口传输的另一种HTTP。

端口：456 
服务：[NULL] 
说明：木马HACKERS 
PARADISE开放此端口。

端口：513 
服务：Login,remote login 
说明：是从使用cable 
modem或DSL登陆到子网中的UNIX计算机发出的广播。这些人为入侵者进入他们的系统提供了信息。

端口：544 
服务：[NULL] 
说明：kerberos kshell

端口：548 
服务：Macintosh,File 
Services(AFP/IP) 
说明：Macintosh,文件服务。

端口：553 
服务：CORBA IIOP 
（UDP） 
说明：使用cable 
modem、DSL或VLAN将会看到这个端口的广播。CORBA是一种面向对象的RPC系统。入侵者可以利用这些信息进入系统。

端口：555 
服务：DSF 
说明：木马PhAse1.0、Stealth 
Spy、IniKiller开放此端口。

端口：568 
服务：Membership DPA 
说明：成员资格 
DPA。

端口：569 
服务：Membership MSN 
说明：成员资格 
MSN。

端口：635 
服务：mountd 
说明：Linux的mountd 
Bug。这是扫描的一个流行BUG。大多数对这个端口的扫描是基于UDP的，但是基于TCP的mountd有所增加（mountd同时运行于两个端口）。记住mountd可运行于任何端口（到底是哪个端口，需要在端口111做portmap查询），只是Linux默认端口是635，就像NFS通常运行于2049端口。

端口：636 
服务：LDAP 
说明：SSL（Secure 
Sockets layer）

端口：666 
服务：Doom Id Software 
说明：木马Attack FTP、Satanz 
Backdoor开放此端口

端口：993 
服务：IMAP 
说明：SSL（Secure Sockets 
layer）

端口：1001、1011 
服务：[NULL] 
说明：木马Silencer、WebEx开放1001端口。木马Doly 
Trojan开放1011端口。

端口：1024 
服务：Reserved 
说明：它是动态端口的开始，许多程序并不在乎用哪个端口连接网络，它们请求系统为它们分配下一个闲置端口。基于这一点分配从端口1024开始。这就是说第一个向系统发出请求的会分配到1024端口。你可以重启机器，打开Telnet，再打开一个窗口运行natstat 
-a 将会看到Telnet被分配1024端口。还有SQL 
session也用此端口和5000端口。

端口：1025、1033 
服务：1025：network blackjack 
1033：[NULL] 
说明：木马netspy开放这2个端口。

端口：1080 
服务：SOCKS 
说明：这一协议以通道方式穿过防火墙，允许防火墙后面的人通过一个IP地址访问INTERNET。理论上它应该只允许内部的通信向外到达INTERNET。但是由于错误的配置，它会允许位于防火墙外部的攻击穿过防火墙。WinGate常会发生这种错误，在加入IRC聊天室时常会看到这种情况。

端口：1170 
服务：[NULL] 
说明：木马Streaming 
Audio Trojan、Psyber Stream 
Server、Voice开放此端口。

端口：1234、1243、6711、6776 
服务：[NULL] 
说明：木马SubSeven2.0、Ultors 
Trojan开放1234、6776端口。木马SubSeven1.0/1.9开放1243、6711、6776端口。

端口：1245 
服务：[NULL] 
说明：木马Vodoo开放此端口。

端口：1433 
服务：SQL 
说明：Microsoft的SQL服务开放的端口。

端口：1492 
服务：stone-design-1 
说明：木马FTP99CMP开放此端口。

端口：1500 
服务：RPC 
client fixed port session 
queries 
说明：RPC客户固定端口会话查询

端口：1503 
服务：NetMeeting 
T.120 
说明：NetMeeting 
T.120

端口：1524 
服务：ingress 
说明：许多攻击脚本将安装一个后门SHELL于这个端口，尤其是针对SUN系统中Sendmail和RPC服务漏洞的脚本。如果刚安装了防火墙就看到在这个端口上的连接企图，很可能是上述原因。可以试试Telnet到用户的计算机上的这个端口，看看它是否会给你一个SHELL。连接到600/pcserver也存在这个问题。

端口：1600 
服务：issd 
说明：木马Shivka-Burka开放此端口。

端口：1720 
服务：NetMeeting 
说明：NetMeeting 
H.233 call Setup。

端口：1731 
服务：NetMeeting Audio Call 
Control 
说明：NetMeeting音频调用控制。

端口：1807 
服务：[NULL] 
说明：木马SpySender开放此端口。

端口：1981 
服务：[NULL] 
说明：木马ShockRave开放此端口。

端口：1999 
服务：cisco 
identification 
port 
说明：木马BackDoor开放此端口。

端口：2000 
服务：[NULL] 
说明：木马GirlFriend 
1.3、Millenium 1.0开放此端口。

端口：2001 
服务：[NULL] 
说明：木马Millenium 1.0、Trojan 
Cow开放此端口。

端口：2023 
服务：xinuexpansion 4 
说明：木马Pass 
Ripper开放此端口。

端口：2049 
服务：NFS 
说明：NFS程序常运行于这个端口。通常需要访问Portmapper查询这个服务运行于哪个端口。

端口：2115 
服务：[NULL] 
说明：木马Bugs开放此端口。

端口：2140、3150 
服务：[NULL] 
说明：木马Deep 
Throat 1.0/3.0开放此端口。

端口：2500 
服务：RPC client using a fixed port session 
replication 
说明：应用固定端口会话复制的RPC客户

端口：2583 
服务：[NULL] 
说明：木马Wincrash 
2.0开放此端口。

端口：2801 
服务：[NULL] 
说明：木马Phineas 
Phucker开放此端口。

端口：3024、4092 
服务：[NULL] 
说明：木马WinCrash开放此端口。

端口：3128 
服务：squid 
说明：这是squid 
HTTP代理服务器的默认端口。攻击者扫描这个端口是为了搜寻一个代理服务器而匿名访问Internet。也会看到搜索其他代理服务器的端口8000、8001、8080、8888。扫描这个端口的另一个原因是用户正在进入聊天室。其他用户也会检验这个端口以确定用户的机器是否支持代理。

端口：3129 
服务：[NULL] 
说明：木马Master 
Paradise开放此端口。

端口：3150 
服务：[NULL] 
说明：木马The 
Invasor开放此端口。

端口：3210、4321 
服务：[NULL] 
说明：木马SchoolBus开放此端口

端口：3333 
服务：dec-notes 
说明：木马Prosiak开放此端口

端口：3389 
服务：超级终端 
说明：WINDOWS 
2000终端开放此端口。

端口：3700 
服务：[NULL] 
说明：木马Portal of 
Doom开放此端口

端口：3996、4060 
服务：[NULL] 
说明：木马RemoteAnything开放此端口

端口：4000 
服务：QQ客户端 
说明：腾讯QQ客户端开放此端口。

端口：4092 
服务：[NULL] 
说明：木马WinCrash开放此端口。

端口：4590 
服务：[NULL] 
说明：木马ICQTrojan开放此端口。

端口：5000、5001、5321、50505 
服务：[NULL] 
说明：木马blazer5开放5000端口。木马Sockets 
de 
Troie开放5000、5001、5321、50505端口。

端口：5400、5401、5402 
服务：[NULL] 
说明：木马Blade 
Runner开放此端口。

端口：5550 
服务：[NULL] 
说明：木马xtcp开放此端口。

端口：5569 
服务：[NULL] 
说明：木马Robo-Hack开放此端口。

端口：5632 
服务：pcAnywere 
说明：有时会看到很多这个端口的扫描，这依赖于用户所在的位置。当用户打开pcAnywere时，它会自动扫描局域网C类网以寻找可能的代理（这里的代理是指agent而不是proxy）。入侵者也会寻找开放这种服务的计算机。，所以应该查看这种扫描的源地址。一些搜寻pcAnywere的扫描包常含端口22的UDP数据包。

端口：5742 
服务：[NULL] 
说明：木马WinCrash1.03开放此端口。

端口：6267 
服务：[NULL] 
说明：木马广外女生开放此端口。

端口：6400 
服务：[NULL] 
说明：木马The 
tHing开放此端口。

端口：6670、6671 
服务：[NULL] 
说明：木马Deep Throat开放6670端口。而Deep 
Throat 
3.0开放6671端口。

端口：6883 
服务：[NULL] 
说明：木马DeltaSource开放此端口。

端口：6969 
服务：[NULL] 
说明：木马Gatecrasher、Priority开放此端口。

端口：6970 
服务：RealAudio 
说明：RealAudio客户将从服务器的6970-7170的UDP端口接收音频数据流。这是由TCP-7070端口外向控制连接设置的。

端口：7000 
服务：[NULL] 
说明：木马Remote 
Grab开放此端口。

端口：7300、7301、7306、7307、7308 
服务：[NULL] 
说明：木马NetMonitor开放此端口。另外NetSpy1.0也开放7306端口。

端口：7323 
服务：[NULL] 
说明：Sygate服务器端。

端口：7626 
服务：[NULL] 
说明：木马Giscier开放此端口。

端口：7789 
服务：[NULL] 
说明：木马ICKiller开放此端口。

端口：8000 
服务：OICQ 
说明：腾讯QQ服务器端开放此端口。

端口：8010 
服务：Wingate 
说明：Wingate代理开放此端口。

端口：8080 
服务：代理端口 
说明：WWW代理开放此端口。

端口：9400、9401、9402 
服务：[NULL] 
说明：木马Incommand 
1.0开放此端口。

端口：9872、9873、9874、9875、10067、10167 
服务：[NULL] 
说明：木马Portal 
of 
Doom开放此端口。

端口：9989 
服务：[NULL] 
说明：木马iNi-Killer开放此端口。

端口：11000 
服务：[NULL] 
说明：木马SennaSpy开放此端口。

端口：11223 
服务：[NULL] 
说明：木马Progenic 
trojan开放此端口。

端口：12076、61466 
服务：[NULL] 
说明：木马Telecommando开放此端口。

端口：12223 
服务：[NULL] 
说明：木马Hack’99 
KeyLogger开放此端口。

端口：12345、12346 
服务：[NULL] 
说明：木马NetBus1.60/1.70、GabanBus开放此端口。

端口：12361 
服务：[NULL] 
说明：木马Whack-a-mole开放此端口。

端口：13223 
服务：PowWow 
说明：PowWow是Tribal 
Voice的聊天程序。它允许用户在此端口打开私人聊天的连接。这一程序对于建立连接非常具有攻击性。它会驻扎在这个TCP端口等回应。造成类似心跳间隔的连接请求。如果一个拨号用户从另一个聊天者手中继承了IP地址就会发生好象有很多不同的人在测试这个端口的情况。这一协议使用OPNG作为其连接请求的前4个字节。

端口：16969 
服务：[NULL] 
说明：木马Priority开放此端口。

端口：17027 
服务：Conducent 
说明：这是一个外向连接。这是由于公司内部有人安装了带有Conducent”adbot”的共享软件。Conducent”adbot”是为共享软件显示广告服务的。使用这种服务的一种流行的软件是Pkware。

端口：19191 
服务：[NULL] 
说明：木马蓝色火焰开放此端口。

端口：20000、20001 
服务：[NULL] 
说明：木马Millennium开放此端口。

端口：20034 
服务：[NULL] 
说明：木马NetBus 
Pro开放此端口。

端口：21554 
服务：[NULL] 
说明：木马GirlFriend开放此端口。

端口：22222 
服务：[NULL] 
说明：木马Prosiak开放此端口。

端口：23456 
服务：[NULL] 
说明：木马Evil 
FTP、Ugly 
FTP开放此端口。

端口：26274、47262 
服务：[NULL] 
说明：木马Delta开放此端口。

端口：27374 
服务：[NULL] 
说明：木马Subseven 
2.1开放此端口。

端口：30100 
服务：[NULL] 
说明：木马NetSphere开放此端口。

端口：30303 
服务：[NULL] 
说明：木马Socket23开放此端口。

端口：30999 
服务：[NULL] 
说明：木马Kuang开放此端口。

端口：31337、31338 
服务：[NULL] 
说明：木马BO(Back 
Orifice)开放此端口。另外木马DeepBO也开放31338端口。

端口：31339 
服务：[NULL] 
说明：木马NetSpy 
DK开放此端口。

端口：31666 
服务：[NULL] 
说明：木马BOWhack开放此端口。

端口：33333 
服务：[NULL] 
说明：木马Prosiak开放此端口。

端口：34324 
服务：[NULL] 
说明：木马Tiny 
Telnet Server、BigGluck、TN开放此端口。

端口：40412 
服务：[NULL] 
说明：木马The 
Spy开放此端口。

端口：40421、40422、40423、40426、 
服务：[NULL] 
说明：木马Masters 
Paradise开放此端口。

端口：43210、54321 
服务：[NULL] 
说明：木马SchoolBus 
1.0/2.0开放此端口。

端口：44445 
服务：[NULL] 
说明：木马Happypig开放此端口。

端口：50766 
服务：[NULL] 
说明：木马Fore开放此端口。

端口：53001 
服务：[NULL] 
说明：木马Remote 
Windows Shutdown开放此端口。

端口：65000 
服务：[NULL] 
说明：木马Devil 
1.03开放此端口。

端口：88 
说明：Kerberos 
krb5。另外TCP的88端口也是这个用途。

端口：137 
说明：SQL Named Pipes encryption over other 
protocols name lookup(其他协议名称查找上的SQL命名管道加密技术)和SQL RPC encryption over other 
protocols name lookup(其他协议名称查找上的SQL RPC加密技术)和Wins NetBT name service(WINS 
NetBT名称服务)和Wins Proxy都用这个端口。

端口：161 
说明：Simple Network Management 
Protocol(SMTP)（简单网络管理协议）。

端口：162 
说明：SNMP 
Trap（SNMP陷阱）

端口：445 
说明：Common Internet File 
System(CIFS)（公共Internet文件系统）

端口：464 
说明：Kerberos 
kpasswd(v5)。另外TCP的464端口也是这个用途。

端口：500 
说明：Internet Key 
Exchange(IKE)（Internet密钥交换）

端口：1645、1812 
说明：Remot Authentication 
Dial-In User Service(RADIUS)authentication(Routing and Remote 
Access)(远程认证拨号用户服务)

端口：1646、1813 
说明：RADIUS accounting(Routing and 
Remote Access)(RADIUS记帐（路由和远程访问）)

端口：1701 
说明：Layer Two Tunneling 
Protocol(L2TP)(第2层隧道协议)

端口：1801、3527 
说明：Microsoft Message Queue 
Server(Microsoft消息队列服务器)。还有TCP的135、1801、2101、2103、2105也是同样的用途。

端口：2504 
说明：Network 
Load Balancing(网络平衡负荷)

网络层—数据包的包格式里面有个很重要的字段叫做协议号。比如在传输层如果是TCP连接，那么在网络层IP包里面的协议号就将会有个值是6，如果是UDP的话那个值就是17—传输层。
传输层—通过接口关联(端口的字段叫做端口)—应用层。 
用netstat –an 可以查看本机开放的端口号。 

代理服务器常用端口

（1）. HTTP协议代理服务器常用端口号：80/8080/3128/8081/9080 
（2）. SOCKS代理协议服务器常用端口号：1080 
（3）. FTP（文件传输）协议代理服务器常用端口号：21 
（4）. Telnet（远程登录）协议代理服务器常用端口：23
HTTP服务器，默认的端口号为80/tcp（木马Executor开放此端口）； 
HTTPS（securely transferring web pages）服务器，默认的端口号为443/tcp 443/udp； 
Telnet（不安全的文本传送），默认端口号为23/tcp（木马Tiny Telnet Server所开放的端口）； 
FTP，默认的端口号为21/tcp（木马Doly Trojan、Fore、Invisible FTP、WebEx、WinCrash和Blade Runner所开放的端口）； 
TFTP（Trivial File Transfer Protocol ），默认的端口号为69/udp； 
SSH（安全登录）、SCP（文件传输）、端口重定向，默认的端口号为22/tcp； 
SMTP Simple Mail Transfer Protocol (E-mail)，默认的端口号为25/tcp（木马Antigen、Email Password Sender、Haebu Coceda、Shtrilitz Stealth、WinPC、WinSpy都开放这个端口）； 
POP3 Post Office Protocol (E-mail) ，默认的端口号为110/tcp； 
WebLogic，默认的端口号为7001； 
Webshpere应用程序，默认的端口号为9080； 
webshpere管理工具，默认的端口号为9090； 
JBOSS，默认的端口号为8080； 
TOMCAT，默认的端口号为8080； 
WIN2003远程登陆，默认的端口号为3389； 
Symantec AV/Filter for MSE ,默认端口号为 8081； 
Oracle 数据库，默认的端口号为1521； 
ORACLE EMCTL，默认的端口号为1158； 
Oracle XDB（ XML 数据库），默认的端口号为8080； 
Oracle XDB FTP服务，默认的端口号为2100； 
MS SQL*SERVER数据库server，默认的端口号为1433/tcp 1433/udp； 
MS SQL*SERVER数据库monitor，默认的端口号为1434/tcp 1434/udp； 
QQ，默认的端口号为1080/udp
TcpMux0 1 Tcp端口服务多路复用器 
Echo 1 7 回送(echo回送所有的接收数据)
Discard2 9 删除(静态删除所有接受的数据) 
Systat3 11 当前用户 
Daytime 13 白天 
Quotd 17 每天的引用 
Chargen 19 产生字符 
Ftp-data 20 
文件传送(默认数据) 
Ftp 21 文件传送(控制端口) 
Telnet 23 远程通信网
Smtp 25 简单邮件传输协议 
Time 37 时间 
Nicname 43 谁
Domain 53 域名服务器 
Bootps 67 引导程序协议服务器 
Bootpc 68 
引导程序协议客户 
Tftp 69 普通文件传输协议 
Gopher 70 Gopher
Finger 79 拨号 
WWW-http 80 WWW-Http 
Kerberos 88 
Kerberos 
Pop2 109 邮政协议版本2 
Pop3 110 邮政协议版本3
Sunrpc 111 Sun运端程序呼叫 
nntp 119 网络新闻传输协议 
Ntp 123 网络时间协议
Netbios-ns 137 网络基本输入输出系统命名服务 
Netbios-ns 138 
网络基本输入输出系统数据报服务 
Netbios-ssn 139 网络基本输入输出系统期间服务 
Imap2 143 
中间邮件访问协议V2 
Snmp 161 简单网络管理协议 
Bgp 179 边界网关协议
Syslog 514 系统登陆器
</code></pre><p>本文来自：<a href="http://mageedu.blog.51cto.com/4265610/1921073" target="_blank" rel="external">http://mageedu.blog.51cto.com/4265610/1921073</a></p>
]]></content>
      
        <categories>
            
            <category> Linux基础 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux基础 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[十大企业级Linux服务器安全防护要点]]></title>
      <url>http://yoursite.com/2017/03/27/%E5%8D%81%E5%A4%A7%E4%BC%81%E4%B8%9A%E7%BA%A7Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%89%E5%85%A8%E9%98%B2%E6%8A%A4%E8%A6%81%E7%82%B9/</url>
      <content type="html"><![CDATA[<p>随着开源系统Linux的盛行，其在大中型企业的应用也在逐渐普及，很多企业的应用服务都是构筑在其之上，例如Web服务、数据库服务、集群服务等等。</p>
<p>因此，Linux的安全性就成为了企业构筑安全应用的一个基础，是重中之重，如何对其进行安全防护是企业需要解决的一个基础性问题，基于此，本文将给出十大企业级Linux服务器安全防护的要点。</p>
<a id="more"></a>
<h3 id="强化：密码管理"><a href="#强化：密码管理" class="headerlink" title="强化：密码管理"></a>强化：密码管理</h3><p>设定登录密码是一项非常重要的安全措施，如果用户的密码设定不合适，就很容易被破译，尤其是拥有超级用户使用权限的用户，如果没有良好的密码，将给系统造成很大的安全漏洞。</p>
<p>目前密码破解程序大多采用字典攻击以及暴力攻击手段，而其中用户密码设定不当，则极易受到字典攻击的威胁。很多用户喜欢用自己的英文名、生日或者账户等信息来设定密码，这样，黑客可能通过字典攻击或者是社会工程的手段来破解密码。所以建议用户在设定密码的过程中，应尽量使用非字典中出现的组合字符，并且采用数字与字符相结合、大小写相结合的密码设置方式，增加密码被黑客破解的难度。而且，也可以使用定期修改密码、使密码定期作废的方式，来保护自己的登录密码。</p>
<p>在多用户系统中，如果强迫每个用户选择不易猜出的密码，将大大提高系统的安全性。但如果passwd程序无法强迫每个上机用户使用恰当的密码，要确保密码的安全度，就只能依靠密码破解程序了。实际上，密码破解程序是黑客工具箱中的一种工具，它将常用的密码或者是英文字典中所有可能用来作密码的字都用程序加密成密码字，然后将其与Linux系统的/etc/passwd密码文件或/etc/shadow影子文件相比较，如果发现有吻合的密码，就可以求得明码了。在网络上可以找到很多密码破解程序，比较有名的程序是crack和john the ripper.用户可以自己先执行密码破解程序，找出容易被黑客破解的密码，先行改正总比被黑客破解要有利。</p>
<h3 id="限定：网络服务管理"><a href="#限定：网络服务管理" class="headerlink" title="限定：网络服务管理"></a>限定：网络服务管理</h3><p>早期的Linux版本中，每一个不同的网络服务都有一个服务程序(守护进程，Daemon)在后台运行，后来的版本用统一的/etc/inetd服务器程序担此重任。Inetd是Internetdaemon的缩写，它同时监视多个网络端口，一旦接收到外界传来的连接信息，就执行相应的TCP或UDP网络服务。由于受inetd的统一指挥，因此Linux中的大部分TCP或UDP服务都是在/etc/inetd.conf文件中设定。所以取消不必要服务的第一步就是检查/etc/inetd.conf文件，在不要的服务前加上“#”号。</p>
<p>一般来说，除了http、smtp、telnet和ftp之外，其他服务都应该取消，诸如简单文件传输协议tftp、网络邮件存储及接收所用的imap/ipop传输协议、寻找和搜索资料用的gopher以及用于时间同步的daytime和time等。还有一些报告系统状态的服务，如finger、efinger、systat和netstat等，虽然对系统查错和寻找用户非常有用，但也给黑客提供了方便之门。例如，黑客可以利用finger服务查找用户的电话、使用目录以及其他重要信息。因此，很多Linux系统将这些服务全部取消或部分取消，以增强系统的安全性。Inetd除了利用/etc/inetd.conf设置系统服务项之外，还利用/etc/services文件查找各项服务所使用的端口。因此，用户必须仔细检查该文件中各端口的设定，以免有安全上的漏洞。</p>
<p>在后继的Linux版本中(比如Red Hat Linux7.2之后)，取而代之的是采用xinetd进行网络服务的管理。</p>
<p>当然，具体取消哪些服务不能一概而论，需要根据实际的应用情况来定，但是系统管理员需要做到心中有数，因为一旦系统出现安全问题，才能做到有步骤、有条不紊地进行查漏和补救工作，这点比较重要。</p>
<h3 id="严格审计：系统登录用户管理"><a href="#严格审计：系统登录用户管理" class="headerlink" title="严格审计：系统登录用户管理"></a>严格审计：系统登录用户管理</h3><p>在进入Linux系统之前，所有用户都需要登录，也就是说，用户需要输入用户账号和密码，只有它们通过系统验证之后，用户才能进入系统。</p>
<p>与其他Unix操作系统一样，Linux一般将密码加密之后，存放在/etc/passwd文件中。Linux系统上的所有用户都可以读到/etc/passwd文件，虽然文件中保存的密码已经经过加密，但仍然不太安全。因为一般的用户可以利用现成的密码破译工具，以穷举法猜测出密码。比较安全的方法是设定影子文件/etc/shadow，只允许有特殊权限的用户阅读该文件。</p>
<p>在Linux系统中，如果要采用影子文件，必须将所有的公用程序重新编译，才能支持影子文件。这种方法比较麻烦，比较简便的方法是采用插入式验证模块(PAM)。很多Linux系统都带有Linux的工具程序PAM，它是一种身份验证机制，可以用来动态地改变身份验证的方法和要求，而不要求重新编译其他公用程序。这是因为PAM采用封闭包的方式，将所有与身份验证有关的逻辑全部隐藏在模块内，因此它是采用影子档案的最佳帮手。</p>
<p>此外，PAM还有很多安全功能：它可以将传统的DES加密方法改写为其他功能更强的加密方法，以确保用户密码不会轻易地遭人破译;它可以设定每个用户使用电脑资源的上限;它甚至可以设定用户的上机时间和地点。</p>
<p>Linux系统管理人员只需花费几小时去安装和设定PAM，就能大大提高Linux系统的安全性，把很多攻击阻挡在系统之外。</p>
<h3 id="设定：用户账号安全等级管理"><a href="#设定：用户账号安全等级管理" class="headerlink" title="设定：用户账号安全等级管理"></a>设定：用户账号安全等级管理</h3><p>除密码之外，用户账号也有安全等级，这是因为在Linux上每个账号可以被赋予不同的权限，因此在建立一个新用户ID时，系统管理员应该根据需要赋予该账号不同的权限，并且归并到不同的用户组中。</p>
<p>在Linux系统中的部分文件中，可以设定允许上机和不允许上机人员的名单。其中，允许上机人员名单在/etc/hosts.allow中设置，不允许上机人员名单在/etc/hosts.deny中设置。此外，Linux将自动把允许进入或不允许进入的结果记录到/var/log/secure文件中，系统管理员可以据此查出可疑的进入记录。</p>
<p>每个账号ID应该有专人负责。在企业中，如果负责某个ID的职员离职，管理员应立即从系统中删除该账号。很多入侵事件都是借用了那些很久不用的账号。</p>
<p>在用户账号之中，黑客最喜欢具有root权限的账号，这种超级用户有权修改或删除各种系统设置，可以在系统中畅行无阻。因此，在给任何账号赋予root权限之前，都必须仔细考虑。</p>
<p>Linux系统中的/etc/securetty文件包含了一组能够以root账号登录的终端机名称。例如，在RedHatLinux系统中，该文件的初始值仅允许本地虚拟控制台(rtys)以root权限登录，而不允许远程用户以root权限登录。最好不要修改该文件，如果一定要从远程登录为root权限，最好是先以普通账号登录，然后利用su命令升级为超级用户。</p>
<h3 id="谨慎使用：“r系列”远程程序管理"><a href="#谨慎使用：“r系列”远程程序管理" class="headerlink" title="谨慎使用：“r系列”远程程序管理"></a>谨慎使用：“r系列”远程程序管理</h3><p>在Linux系统中有一系列r字头的公用程序，比如rlogin，rcp等等。它们非常容易被黑客用来入侵我们的系统，因而非常危险，因此绝对不要将root账号开放给这些公用程序。由于这些公用程序都是用。rhosts文件或者hosts.equiv文件核准进入的，因此一定要确保root账号不包括在这些文件之内。</p>
<p>由于r等远程指令是黑客们用来攻击系统的较好途径，因此很多安全工具都是针对这一安全漏洞而设计的。例如，PAM工具就可以用来将r字头公用程序有效地禁止掉，它在/etc/pam.d/rlogin文件中加上登录必须先核准的指令，使整个系统的用户都不能使用自己home目录下的。rhosts文件。</p>
<h3 id="限制：root用户权限管理"><a href="#限制：root用户权限管理" class="headerlink" title="限制：root用户权限管理"></a>限制：root用户权限管理</h3><p>Root一直是Linux保护的重点，由于它权力无限，因此最好不要轻易将超级用户授权出去。但是，有些程序的安装和维护工作必须要求有超级用户的权限，在这种情况下，可以利用其他工具让这类用户有部分超级用户的权限。sudo就是这样的工具。</p>
<p>sudo程序允许一般用户经过组态设定后，以用户自己的密码再登录一次，取得超级用户的权限，但只能执行有限的几个指令。例如，应用sudo后，可以让管理磁带备份的管理人员每天按时登录到系统中，取得超级用户权限去执行文档备份工作，但却没有特权去作其他只有超级用户才能作的工作。</p>
<p>sudo不但限制了用户的权限，而且还将每次使用sudo所执行的指令记录下来，不管该指令的执行是成功还是失败。在大型企业中，有时候有许多人同时管理Linux系统的各个不同部分，每个管理人员都有用sudo授权给某些用户超级用户权限的能力，从sudo的日志中，可以追踪到谁做了什么以及改动了系统的哪些部分。</p>
<p>值得注意的是，sudo并不能限制所有的用户行为，尤其是当某些简单的指令没有设置限定时，就有可能被黑客滥用。例如，一般用来显示文件内容的/etc/cat指令，如果有了超级用户的权限，黑客就可以用它修改或删除一些重要的文件。</p>
<h3 id="追踪黑客踪迹：日志管理"><a href="#追踪黑客踪迹：日志管理" class="headerlink" title="追踪黑客踪迹：日志管理"></a>追踪黑客踪迹：日志管理</h3><p>当用户仔细设定了各种与Linux相关的配置(最常用日志管理选项)，并且安装了必要的安全防护工具之后，Linux操作系统的安全性的确大为提高，但是却并不能保证防止那些比较熟练的网络黑客的入侵。</p>
<p>在平时，网络管理人员要经常提高警惕，随时注意各种可疑状况，并且按时检查各种系统日志文件，包括一般信息日志、网络连接日志、文件传输日志以及用户登录日志等。在检查这些日志时，要注意是否有不合常理的时间记载。例如：</p>
<p>正常用户在半夜三更登录;</p>
<p>不正常的日志记录，比如日志只记录了一半就切断了，或者整个日志文件被删除了;</p>
<p>用户从陌生的网址进入系统;</p>
<p>因密码错误或用户账号错误被摈弃在外的日志记录，尤其是那些一再连续尝试进入失败，但却有一定模式的试错法;</p>
<p>非法使用或不正当使用超级用户权限su的指令;</p>
<p>重新开机或重新启动各项服务的记录。</p>
<p>上述这些问题都需要系统管理员随时留意系统登录的用户状况以及查看相应日志文件，许多背离正常行为的蛛丝马迹都应当引起高度注意。</p>
<h3 id="横向扩展：综合防御管理"><a href="#横向扩展：综合防御管理" class="headerlink" title="横向扩展：综合防御管理"></a>横向扩展：综合防御管理</h3><p>防火墙、IDS等防护技术已经成功地应用到网络安全的各个领域，而且都有非常成熟的产品。</p>
<p>在Linux系统来说，有一个自带的Netfilter/Iptables防火墙框架，通过合理地配置其也能起到主机防火墙的功效。在Linux系统中也有相应的轻量级的网络入侵检测系统Snort以及主机入侵检测系统LIDS(Linux Intrusion Detection System)，使用它们可以快速、高效地进行防护。</p>
<p>需要提醒注意的是：在大多数的应用情境下，我们需要综合使用这两项技术，因为防火墙相当于安全防护的第一层，它仅仅通过简单地比较IP地址/端口对来过滤网络流量，而IDS更加具体，它需要通过具体的数据包(部分或者全部)来过滤网络流量，是安全防护的第二层。综合使用它们，能够做到互补，并且发挥各自的优势，最终实现综合防御。</p>
<h3 id="评测：漏洞追踪及管理"><a href="#评测：漏洞追踪及管理" class="headerlink" title="评测：漏洞追踪及管理"></a>评测：漏洞追踪及管理</h3><p>Linux作为一种优秀的开源软件，其自身的发展也日新月异，同时，其存在的问题也会在日后的应用中慢慢暴露出来。黑客对新技术的关注从一定程度上来说要高于我们防护人员，所以要想在网络攻防的战争中处于有利地位，保护Linux系统的安全，就要求我们要保持高度的警惕性和对新技术的高度关注。用户特别是使用Linux作为关键业务系统的系统管理员们，需要通过Linux的一些权威网站和论坛上尽快地获取有关该系统的一些新技术以及一些新的系统漏洞的信息，进行漏洞扫描、渗透测试等系统化的相关配套工作，做到防范于未然，提早行动，在漏洞出现后甚至是出现前的最短时间内封堵系统的漏洞，并且在实践中不断地提高安全防护的技能，这样才是一个比较的解决办法和出路。</p>
<h3 id="保持更新：补丁管理"><a href="#保持更新：补丁管理" class="headerlink" title="保持更新：补丁管理"></a>保持更新：补丁管理</h3><p>Linux作为一种优秀的开源软件，其稳定性、安全性和可用性有极为可靠的保证，世界上的Linux高手共同维护着个优秀的产品，因而起流通渠道很多，而且经常有更新的程序和系统补丁出现，因此，为了加强系统安全，一定要经常更新系统内核。</p>
<p>Kernel是Linux操作系统的核心，它常驻内存，用于加载操作系统的其他部分，并实现操作系统的基本功能。由于Kernel控制计算机和网络的各种功能，因此，它的安全性对整个系统安全至关重要。早期的Kernel版本存在许多众所周知的安全漏洞，而且也不太稳定，只有2.0.x以上的版本才比较稳定和安全(一般说来，内核版本号为偶数的相对稳定，而为奇数的则一般为测试版本，用户们使用时要多留意)，新版本的运行效率也有很大改观。在设定Kernel的功能时，只选择必要的功能，千万不要所有功能照单全收，否则会使Kernel变得很大，既占用系统资源，也给黑客留下可乘之机。</p>
<p>在Internet上常常有最新的安全修补程序，Linux系统管理员应该消息灵通，经常光顾安全新闻组，查阅新的修补程序。</p>
<p>本文来自：<a href="http://mageedu.blog.51cto.com/4265610/1910600" target="_blank" rel="external">http://mageedu.blog.51cto.com/4265610/1910600</a></p>
]]></content>
      
        <categories>
            
            <category> Linux基础 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux基础 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Docker高级（1）--架构总览]]></title>
      <url>http://yoursite.com/2017/03/12/Docker%E9%AB%98%E7%BA%A7%EF%BC%881%EF%BC%89--%E6%9E%B6%E6%9E%84%E6%80%BB%E8%A7%88/</url>
      <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><h3 id="Docker简介"><a href="#Docker简介" class="headerlink" title="Docker简介"></a>Docker简介</h3><p>&#8194;&#8194;&#8194;&#8194;Docker是Docker公司开源的一个基于轻量级虚拟化技术的容器引擎项目,整个项目基于Go语言开发，并遵从Apache 2.0协议。<br><a id="more"></a></p>
<p>&#8194;&#8194;&#8194;&#8194;目前，Docker可以在容器内部快速自动化部署应用，并可以通过内核虚拟化技术（namespaces及cgroups等）来提供容器的资源隔离与安全保障等。由于Docker通过操作系统层的虚拟化实现隔离，所以Docker容器在运行时，不需要类似虚拟机（VM）额外的操作系统开销，提高资源利用率，并且提升诸如IO等方面的性能。<br>&#8194;&#8194;&#8194;&#8194;由于众多新颖的特性以及项目本身的开放性，Docker在不到两年的时间里迅速获得诸多厂商的青睐，其中更是包括Google、Microsoft、VMware等业界行业领导者。Google在今年六月份推出了Kubernetes，提供Docker容器的调度服务，而今年8月Microsoft宣布Azure上支持Kubernetes，随后传统虚拟化巨头VMware宣布与Docker强强合作。今年9月中旬，Docker更是获得4000万美元的C轮融资，以推动分布式应用方面的发展。<br>&#8194;&#8194;&#8194;&#8194;从目前的形势来看，Docker的前景一片大好。本系列文章从源码的角度出发，详细介绍Docker的架构、Docker的运行以及Docker的卓越特性。本文是Docker源码分析系列的第一篇­­­——Docker架构篇。</p>
<h3 id="Docker版本信息"><a href="#Docker版本信息" class="headerlink" title="Docker版本信息"></a>Docker版本信息</h3><p>&#8194;&#8194;&#8194;&#8194;本文关于Docker架构的分析都是基于Docker的源码与Docker相应版本的运行结果，其中Docker为最新的1.2版本。</p>
<h2 id="Docker架构分析内容安排"><a href="#Docker架构分析内容安排" class="headerlink" title="Docker架构分析内容安排"></a>Docker架构分析内容安排</h2><p>&#8194;&#8194;&#8194;&#8194;本文的目的是：在理解Docker源代码的基础上，分析Docker架构。分析过程中主要按照以下三个步骤进行：<br>  ● Docker的总架构图展示<br>  ● Docker架构图内部各模块功能与实现分析<br>  ● 以Docker命令的执行为例，进行Docker运行流程阐述</p>
<h2 id="Docker总架构图"><a href="#Docker总架构图" class="headerlink" title="Docker总架构图"></a>Docker总架构图</h2><p>&#8194;&#8194;&#8194;&#8194;学习Docker的源码并不是一个枯燥的过程，反而可以从中理解Docker架构的设计原理。Docker对使用者来讲是一个C/S模式的架构，而Docker的后端是一个非常松耦合的架构，模块各司其职，并有机组合，支撑Docker的运行。<br>在此，先附上Docker总架构，如图3.1。<br><img src="http://static.zybuluo.com/BruceTang/fwvm0m4xch6xlf4zxi0u1eht/3.1.jpeg" alt="3.1.jpeg-238.3kB"><br>&#8194;&#8194;&#8194;&#8194;如图3.1，不难看出，用户是使用Docker Client与Docker Daemon建立通信，并发送请求给后者。<br>&#8194;&#8194;&#8194;&#8194;而Docker Daemon作为Docker架构中的主体部分，首先提供Server的功能使其可以接受Docker Client的请求；而后Engine执行Docker内部的一系列工作，每一项工作都是以一个Job的形式的存在。<br>&#8194;&#8194;&#8194;&#8194;Job的运行过程中，当需要容器镜像时，则从Docker Registry中下载镜像，并通过镜像管理驱动graphdriver将下载镜像以Graph的形式存储；当需要为Docker创建网络环境时，通过网络管理驱动networkdriver创建并配置Docker容器网络环境；当需要限制Docker容器运行资源或执行用户指令等操作时，则通过execdriver来完成。<br>&#8194;&#8194;&#8194;&#8194;而libcontainer是一项独立的容器管理包，networkdriver以及execdriver都是通过libcontainer来实现具体对容器进行的操作。<br>&#8194;&#8194;&#8194;&#8194;当执行完运行容器的命令后，一个实际的Docker容器就处于运行状态，该容器拥有独立的文件系统，独立并且安全的运行环境等。</p>
<h2 id="Docker架构内各模块的功能与实现分析"><a href="#Docker架构内各模块的功能与实现分析" class="headerlink" title="Docker架构内各模块的功能与实现分析"></a>Docker架构内各模块的功能与实现分析</h2><p>&#8194;&#8194;&#8194;&#8194;接下来，我们将从Docker总架构图入手，抽离出架构内各个模块，并对各个模块进行更为细化的架构分析与功能阐述。主要的模块有：Docker Client、Docker Daemon、Docker Registry、Graph、Driver、libcontainer以及Docker container。</p>
<h3 id="Docker-Client"><a href="#Docker-Client" class="headerlink" title="Docker Client"></a>Docker Client</h3><p>&#8194;&#8194;&#8194;&#8194;Docker Client是Docker架构中用户用来和Docker Daemon建立通信的客户端。用户使用的可执行文件为docker，通过docker命令行工具可以发起众多管理container的请求。<br>&#8194;&#8194;&#8194;&#8194;Docker Client可以通过以下三种方式和Docker Daemon建立通信：tcp://host:port，unix://path_to_socket和fd://socketfd。为了简单起见，本文一律使用第一种方式作为讲述两者通信的原型。与此同时，与Docker &#8194;&#8194;&#8194;&#8194;Daemon建立连接并传输请求的时候，Docker Client可以通过设置命令行flag参数的形式设置安全传输层协议(TLS)的有关参数，保证传输的安全性。<br>&#8194;&#8194;&#8194;&#8194;Docker Client发送容器管理请求后，由Docker Daemon接受并处理请求，当Docker Client接收到返回的请求相应并简单处理后，Docker Client一次完整的生命周期就结束了。当需要继续发送容器管理请求时，用户必须再次通过docker可执行文件创建Docker Client。</p>
<h3 id="Docker-Daemon"><a href="#Docker-Daemon" class="headerlink" title="Docker Daemon"></a>Docker Daemon</h3><p>&#8194;&#8194;&#8194;&#8194;Docker Daemon是Docker架构中一个常驻在后台的系统进程，功能是：接受并处理Docker Client发送的请求。该守护进程在后台启动了一个Server，Server负责接受Docker &#8194;&#8194;&#8194;&#8194;Client发送的请求；接受请求后，Server通过路由与分发调度，找到相应的Handler来执行请求。<br>&#8194;&#8194;&#8194;&#8194;Docker Daemon启动所使用的可执行文件也为docker，与Docker Client启动所使用的可执行文件docker相同。在docker命令执行时，通过传入的参数来判别Docker Daemon与Docker Client。<br>&#8194;&#8194;&#8194;&#8194;Docker Daemon的架构，大致可以分为以下三部分：Docker Server、Engine和Job。Daemon架构如图4.1。<br>  &#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194; 图4.1 Docker Daemon架构示意图<br>  <img src="http://static.zybuluo.com/BruceTang/jzln1v9ufcecae7y9giqqvbj/4.1.jpeg" alt="4.1.jpeg-173.9kB"></p>
<h3 id="Docker-Server"><a href="#Docker-Server" class="headerlink" title="Docker Server"></a>Docker Server</h3><p> &#8194;&#8194;&#8194;&#8194; Docker Server在Docker架构中是专门服务于Docker Client的server。该server的功能是：接受并调度分发Docker Client发送的请求。Docker Server的架构如图4.2。<br> &#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194; 图4.2 Docker Server架构示意图<br> <img src="http://static.zybuluo.com/BruceTang/epr8qkhqg5gwn6ctk70lur7d/4.2.jpeg" alt="4.2.jpeg-157.5kB"></p>
<p> &#8194;&#8194;&#8194;&#8194;在Docker的启动过程中，通过包gorilla/mux，创建了一个mux.Router，提供请求的路由功能。在Golang中，gorilla/mux是一个强大的URL路由器以及调度分发器。该mux.Router中添加了众多的路由项，每一个路由项由HTTP请求方法（PUT、POST、GET或DELETE）、URL、Handler三部分组成。<br>&#8194;&#8194;&#8194;&#8194;若Docker Client通过HTTP的形式访问Docker &#8194;&#8194;&#8194;&#8194;Daemon，创建完mux.Router之后，Docker将Server的监听地址以及mux.Router作为参数，创建一个httpSrv=http.Server{}，最终执行httpSrv.Serve()为请求服务。<br>&#8194;&#8194;&#8194;&#8194;在Server的服务过程中，Server在listener上接受Docker Client的访问请求，并创建一个全新的goroutine来服务该请求。在goroutine中，首先读取请求内容，然后做解析工作，接着找到相应的路由项，随后调用相应的Handler来处理该请求，最后Handler处理完请求之后回复该请求。<br>&#8194;&#8194;&#8194;&#8194;需要注意的是：Docker Server的运行在Docker的启动过程中，是靠一个名为”serveapi”的job的运行来完成的。原则上，Docker Server的运行是众多job中的一个，但是为了强调Docker Server的重要性以及为后续job服务的重要特性，将该”serveapi”的job单独抽离出来分析，理解为Docker Server。</p>
<h3 id="Engine"><a href="#Engine" class="headerlink" title="Engine"></a>Engine</h3><p>&#8194;&#8194;&#8194;&#8194;Engine是Docker架构中的运行引擎，同时也Docker运行的核心模块。它扮演Docker container存储仓库的角色，并且通过执行job的方式来操纵管理这些容器。<br>&#8194;&#8194;&#8194;&#8194;在Engine数据结构的设计与实现过程中，有一个handler对象。该handler对象存储的都是关于众多特定job的handler处理访问。举例说明，Engine的handler对象中有一项为：{“create”: daemon.ContainerCreate,}，则说明当名为”create”的job在运行时，执行的是daemon.ContainerCreate的handler</p>
<h3 id="Job"><a href="#Job" class="headerlink" title="Job"></a>Job</h3><p>&#8194;&#8194;&#8194;&#8194;一个Job可以认为是Docker架构中Engine内部最基本的工作执行单元。Docker可以做的每一项工作，都可以抽象为一个job。例如：在容器内部运行一个进程，这是一个job；创建一个新的容器，这是一个job，从Internet上下载一个文档，这是一个job；包括之前在Docker Server部分说过的，创建Server服务于HTTP的API，这也是一个job，等等。<br>&#8194;&#8194;&#8194;&#8194;Job的设计者，把Job设计得与Unix进程相仿。比如说：Job有一个名称，有参数，有环境变量，有标准的输入输出，有错误处理，有返回状态等</p>
<h3 id="Docker-Registry"><a href="#Docker-Registry" class="headerlink" title="Docker Registry"></a>Docker Registry</h3><p>&#8194;&#8194;&#8194;&#8194;Docker Registry是一个存储容器镜像的仓库。而容器镜像是在容器被创建时，被加载用来初始化容器的文件架构与目录。<br>&#8194;&#8194;&#8194;&#8194;在Docker的运行过程中，Docker Daemon会与Docker Registry通信，并实现搜索镜像、下载镜像、上传镜像三个功能，这三个功能对应的job名称分别为”search”，”pull” 与 “push”。<br>&#8194;&#8194;&#8194;&#8194;其中，在Docker架构中，Docker可以使用公有的Docker Registry，即大家熟知的Docker Hub，如此一来，Docker获取容器镜像文件时，必须通过互联网访问Docker Hub；同时Docker也允许用户构建本地私有的Docker Registry，这样可以保证容器镜像的获取在内网完成</p>
<h3 id="Graph"><a href="#Graph" class="headerlink" title="Graph"></a>Graph</h3><p>&#8194;&#8194;&#8194;&#8194;Graph在Docker架构中扮演已下载容器镜像的保管者，以及已下载容器镜像之间关系的记录者。一方面，Graph存储着本地具有版本信息的文件系统镜像，另一方面也通过GraphDB记录着所有文件系统镜像彼此之间的关系。Graph的架构如图4.3。<br>&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;&#8194;图4.3 Graph架构示意图<br><img src="http://static.zybuluo.com/BruceTang/f2c2esg9j8i2y21kdth25zmm/4.3.jpeg" alt="4.3.jpeg-217.7kB"><br>&#8194;&#8194;&#8194;&#8194;其中，GraphDB是一个构建在SQLite之上的小型图数据库，实现了节点的命名以及节点之间关联关系的记录。它仅仅实现了大多数图数据库所拥有的一个小的子集，但是提供了简单的接口表示节点之间的关系。<br>&#8194;&#8194;&#8194;&#8194;同时在Graph的本地目录中，关于每一个的容器镜像，具体存储的信息有：该容器镜像的元数据，容器镜像的大小信息，以及该容器镜像所代表的具体rootfs</p>
<h3 id="Driver"><a href="#Driver" class="headerlink" title="Driver"></a>Driver</h3><p>&#8194;&#8194;&#8194;&#8194;Driver是Docker架构中的驱动模块。通过Driver驱动，Docker可以实现对Docker容器执行环境的定制。由于Docker运行的生命周期中，并非用户所有的操作都是针对Docker容器的管理，另外还有关于Docker运行信息的获取，Graph的存储与记录等。<br>&#8194;&#8194;&#8194;&#8194;因此，为了将Docker容器的管理从Docker Daemon内部业务逻辑中区分开来，设计了Driver层驱动来接管所有这部分请求。<br>&#8194;&#8194;&#8194;&#8194;在Docker Driver的实现中，可以分为以下三类驱动：graphdriver、networkdriver和execdriver。<br>&#8194;&#8194;&#8194;&#8194;graphdriver主要用于完成容器镜像的管理，包括存储与获取。即当用户需要下载指定的容器镜像时，graphdriver将容器镜像存储在本地的指定目录；同时当用户需要使用指定的容器镜像来创建容器的rootfs时，graphdriver从本地镜像存储目录中获取指定的容器镜像。<br>&#8194;&#8194;&#8194;&#8194;在graphdriver的初始化过程之前，有4种文件系统或类文件系统在其内部注册，它们分别是aufs、btrfs、vfs和devmapper。而Docker在初始化之时，通过获取系统环境变量”DOCKER_DRIVER”来提取所使用driver的指定类型。而之后所有的graph操作，都使用该driver来执行。<br>graphdriver的架构如图4.4：<br><img src="http://static.zybuluo.com/BruceTang/u6ldju10lxgsc2ieh08wjuj7/4.4.jpeg" alt="4.4.jpeg-144kB"></p>
<p>&#8194;&#8194;&#8194;&#8194;networkdriver的用途是完成Docker容器网络环境的配置，其中包括Docker启动时为Docker环境创建网桥；Docker容器创建时为其创建专属虚拟网卡设备；以及为Docker容器分配IP、端口并与宿主机做端口映射，设置容器防火墙策略等。networkdriver的架构如图4.5：</p>
<p>&#8194;&#8194;&#8194;&#8194;execdriver作为Docker容器的执行驱动，负责创建容器运行命名空间，负责容器资源使用的统计与限制，负责容器内部进程的真正运行等。在execdriver的实现过程中，原先可以使用LXC驱动调用LXC的接口，来操纵容器的配置以及生命周期，而现在execdriver默认使用native驱动，不依赖于LXC。具体体现在Daemon启动过程中加载的ExecDriverflag参数，该参数在配置文件已经被设为”native”。这可以认为是Docker在1.2版本上一个很大的改变，或者说Docker实现跨平台的一个先兆。execdriver架构如图4.6：<br><img src="http://static.zybuluo.com/BruceTang/x701lqh7cz8idszumchpftk7/4.6.jpeg" alt="4.6.jpeg-95.8kB"></p>
<h3 id="libcontainer"><a href="#libcontainer" class="headerlink" title="libcontainer"></a>libcontainer</h3><p>&#8194;&#8194;&#8194;&#8194;libcontainer是Docker架构中一个使用Go语言设计实现的库，设计初衷是希望该库可以不依靠任何依赖，直接访问内核中与容器相关的API。<br>正是由于libcontainer的存在，Docker可以直接调用libcontainer，而最终操纵容器的namespace、cgroups、apparmor、网络设备以及防火墙规则等。这一系列操作的完成都不需要依赖LXC或者其他包。libcontainer架构如图4.7<br><img src="http://static.zybuluo.com/BruceTang/yewf5xufgahy74p9gkiot5bu/4.7.jpeg" alt="4.7.jpeg-128.9kB"></p>
<p>&#8194;&#8194;&#8194;&#8194;另外，libcontainer提供了一整套标准的接口来满足上层对容器管理的需求。或者说，libcontainer屏蔽了Docker上层对容器的直接管理。又由于libcontainer使用Go这种跨平台的语言开发实现，且本身又可以被上层多种不同的编程语言访问，因此很难说，未来的Docker就一定会紧紧地和Linux捆绑在一起。而于此同时，Microsoft在其著名云计算平台Azure中，也添加了对Docker的支持，可见Docker的开放程度与业界的火热度。<br>&#8194;&#8194;&#8194;&#8194;暂不谈Docker，由于libcontainer的功能以及其本身与系统的松耦合特性，很有可能会在其他以容器为原型的平台出现，同时也很有可能催生出云计算领域全新的项目。</p>
<h3 id="Docker-container"><a href="#Docker-container" class="headerlink" title="Docker container"></a>Docker container</h3><p>&#8194;&#8194;&#8194;&#8194;Docker container（Docker容器）是Docker架构中服务交付的最终体现形式。<br>Docker按照用户的需求与指令，订制相应的Docker容器：<br>  ● 用户通过指定容器镜像，使得Docker容器可以自定义rootfs等文件系统；<br>  ● 用户通过指定计算资源的配额，使得Docker容器使用指定的计算资源；<br>  ● 用户通过配置网络及其安全策略，使得Docker容器拥有独立且安全的网络环境；<br>  ● 用户通过指定运行的命令，使得Docker容器执行指定的工作。<br>Docker容器示意图如图4.8：</p>
<p><img src="http://static.zybuluo.com/BruceTang/l0st9jymm96ifjkilt2xvk3c/4.8.jpeg" alt="4.8.jpeg-172.2kB"></p>
<h2 id="Docker运行案例分析"><a href="#Docker运行案例分析" class="headerlink" title="Docker运行案例分析"></a>Docker运行案例分析</h2><p>上一章节着重于Docker架构中各个部分的介绍。本章的内容，将以串联Docker各模块来简要分析，分析原型为Docker中的docker pull与docker run两个命令。</p>
<h3 id="docker-pull"><a href="#docker-pull" class="headerlink" title="docker pull"></a>docker pull</h3><p>&#8194;&#8194;&#8194;&amp;#8194docker pull命令的作用为：从Docker Registry中下载指定的容器镜像，并存储在本地的Graph中，以备后续创建Docker容器时的使用。docker pull命令执行流程如图5.1。<br><img src="http://static.zybuluo.com/BruceTang/je37t67jpqe4d8wi7e0quo86/5.1.jpeg" alt="5.1.jpeg-453.6kB"></p>
<p>如图，图中标记的红色箭头表示docker pull命令在发起后，Docker所做的一系列运行。以下逐一分析这些步骤。<br>(1) Docker Client接受docker pull命令，解析完请求以及收集完请求参数之后，发送一个HTTP请求给Docker Server，HTTP请求方法为POST，请求URL为”/images/create? “+”xxx”；<br>(2) Docker Server接受以上HTTP请求，并交给mux.Router，mux.Router通过URL以及请求方法来确定执行该请求的具体handler；<br>(3) mux.Router将请求路由分发至相应的handler，具体为PostImagesCreate；<br>(4) 在PostImageCreate这个handler之中，一个名为”pull”的job被创建，并开始执行；<br>(5) 名为”pull”的job在执行过程中，执行pullRepository操作，即从Docker Registry中下载相应的一个或者多个image；<br>(6) 名为”pull”的job将下载的image交给graphdriver；<br>(7) graphdriver负责将image进行存储，一方创建graph对象，另一方面在GraphDB中记录image之间的关系。</p>
<h3 id="docker-run"><a href="#docker-run" class="headerlink" title="docker run"></a>docker run</h3><p>&#8194;&#8194;&#8194;docker run命令的作用是在一个全新的Docker容器内部运行一条指令。Docker在执行这条命令的时候，所做工作可以分为两部分：第一，创建Docker容器所需的rootfs；第二，创建容器的网络等运行环境，并真正运行用户指令。因此，在整个执行流程中，Docker Client给Docker Server发送了两次HTTP请求，第二次请求的发起取决于第一次请求的返回状态。Docker run命令执行流程如图5.2。<br><img src="http://static.zybuluo.com/BruceTang/81m0w55hy9f79tmo0d2f6fyb/5.2.jpeg" alt="5.2.jpeg-670.6kB"><br>如图，图中标记的红色箭头表示docker run命令在发起后，Docker所做的一系列运行。以下逐一分析这些步骤。<br>(1) Docker Client接受docker run命令，解析完请求以及收集完请求参数之后，发送一个HTTP请求给Docker Server，HTTP请求方法为POST，请求URL为”/containers/create? “+”xxx”；<br>(2) Docker Server接受以上HTTP请求，并交给mux.Router，mux.Router通过URL以及请求方法来确定执行该请求的具体handler；<br>(3) mux.Router将请求路由分发至相应的handler，具体为PostContainersCreate；<br>(4) 在PostImageCreate这个handler之中，一个名为”create”的job被创建，并开始让该job运行；<br>(5) 名为”create”的job在运行过程中，执行Container.Create操作，该操作需要获取容器镜像来为Docker容器创建rootfs，即调用graphdriver；<br>(6) graphdriver从Graph中获取创建Docker容器rootfs所需要的所有的镜像；<br>(7) graphdriver将rootfs所有镜像，加载安装至Docker容器指定的文件目录下；<br>(8) 若以上操作全部正常执行，没有返回错误或异常，则Docker Client收到Docker Server返回状态之后，发起第二次HTTP请求。请求方法为”POST”，请求URL为”/containers/“+container_ID+”/start”；<br>(9) Docker Server接受以上HTTP请求，并交给mux.Router，mux.Router通过URL以及请求方法来确定执行该请求的具体handler；<br>(10)mux.Router将请求路由分发至相应的handler，具体为PostContainersStart；<br>(11)在PostContainersStart这个handler之中，名为”start”的job被创建，并开始执行；<br>(12)名为”start”的job执行完初步的配置工作后，开始配置与创建网络环境，调用networkdriver；<br>(13)networkdriver需要为指定的Docker容器创建网络接口设备，并为其分配IP，port，以及设置防火墙规则，相应的操作转交至libcontainer中的netlink包来完成；<br>(14)netlink完成Docker容器的网络环境配置与创建；<br>(15)返回至名为”start”的job，执行完一些辅助性操作后，job开始执行用户指令，调用execdriver；<br>(16)execdriver被调用，初始化Docker容器内部的运行环境，如命名空间，资源控制与隔离，以及用户命令的执行，相应的操作转交至libcontainer来完成；<br>(17)libcontainer被调用，完成Docker容器内部的运行环境初始化，并最终执行用户要求启动的命令。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文从Docker 1.2的源码入手，分析抽象出Docker的架构图，并对该架构图中的各个模块进行功能与实现的分析，最后通过两个docker命令展示了Docker内部的运行。<br>通过对Docker架构的学习，可以全面深化对Docker设计、功能与价值的理解。同时在借助Docker实现用户定制的分布式系统时，也能更好地找到已有平台与Docker较为理想的契合点。另外，熟悉Docker现有架构以及设计思想，也能对云计算PaaS领域带来更多的启发，催生出更多实践与创新。</p>
]]></content>
      
        <categories>
            
            <category> Docker </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Docker 基础（7）--数据管理]]></title>
      <url>http://yoursite.com/2017/03/11/Docker%20%E5%9F%BA%E7%A1%80%EF%BC%887%EF%BC%89--%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86/</url>
      <content type="html"><![CDATA[<h4 id="挂载本地目录到容器里"><a href="#挂载本地目录到容器里" class="headerlink" title="挂载本地目录到容器里"></a>挂载本地目录到容器里</h4><pre><code>[root@tang /]# mkdir /data/docker -p
root@tang docker]# mkdir docker_01
[root@tang docker]# docker run -it -h docker_01 --name docker_01 -v /data/docker/docker_01/:/docker_01 centos bash
[root@docker_01 /]# cd /docker_01/        
[root@docker_01 docker_01]# touch docker_01.txt
</code></pre><a id="more"></a>
<pre><code>[root@docker_01 docker_01]# exit
exit
[root@tang docker]# cd /data/docker/docker_01/
[root@tang docker_01]# ll
total 0
-rw-r--r-- 1 root root 0 Apr  3 08:03 docker_01.txt

[root@tang docker_01]# cd ..
[root@tang docker]# mkdir docker_02
[root@tang docker]# docker run -it -h docker_02 --name docker_02 -v /data/docker/docker_02/:/docker_02 centos bash
[root@docker_02 /]# cd /docker_02/
[root@docker_02 docker_02]# mkdir docker_02.txt
[root@docker_02 docker_02]# exit
exit
[root@tang docker]# cd docker_02/
[root@tang docker_02]# ll
total 4
drwxr-xr-x 2 root root 4096 Apr  3 08:05 docker_02.txt

提示：    
      -v: 指定挂载目录
      : : 前面的为本地目录
      : : 后面到为容器里的目录
      即使将删除这个容器,文件也不会丢失.
</code></pre><h4 id="挂载数据卷-多个容器挂载宿主机的同一个目录"><a href="#挂载数据卷-多个容器挂载宿主机的同一个目录" class="headerlink" title="挂载数据卷(多个容器挂载宿主机的同一个目录)"></a>挂载数据卷(多个容器挂载宿主机的同一个目录)</h4><pre><code>[root@tang data]# docker run -it -h docker_03 --name docker_03
--volumes-from docker_01 centos bash
[root@docker_03 /]# cd /docker_01/
[root@docker_03 docker_01]# ll
total 0
-rw-r--r-- 1 root root 0 Apr  3 00:03 docker_01.txt
[root@docker_03 docker_01]# df -h|grep docker_01
/dev/vda1                           99G  5.4G   88G   6% /docker_01
[root@docker_03 docker_01]# echo &quot;This is Doceker_3&quot; &gt; /docker_01/3.txt
[root@docker_03 docker_01]# ll
total 4
-rw-r--r-- 1 root root 18 Apr  3 00:26 3.txt
-rw-r--r-- 1 root root  0 Apr  3 00:03 docker_01.txt
[root@tang ~]# docker start docker_01
docker_01
[root@tang ~]# docker-enter docker_01
[root@docker_01 ~]# cd /docker_01/
[root@docker_01 docker_01]# ll
total 4
-rw-r--r-- 1 root root 18 Apr  3 00:26 3.txt
-rw-r--r-- 1 root root  0 Apr  3 00:03 docker_01.txt
</code></pre><h4 id="自定义数据卷容器"><a href="#自定义数据卷容器" class="headerlink" title="自定义数据卷容器"></a>自定义数据卷容器</h4><pre><code>[root@tang ~]# docker run -itd -h node --name node -v /data centos bash
056ac10e28855c3d29a94fe552711e6a712a5670e6e9c43c4b79270cbc6b0a0f
                #这里的/data是容器node的/data目录,而不是宿主机的/data目录

[root@tang ~]# docker-enter node
[root@node ~]#  touch /data/1 /data/2 /data/3
[root@node ~]# cd /data/
[root@node data]# ll
total 0
-rw-r--r-- 1 root root 0 Apr  3 01:00 1
-rw-r--r-- 1 root root 0 Apr  3 01:00 2
-rw-r--r-- 1 root root 0 Apr  3 01:00 3
[root@node data]# exit
logout
[root@tang ~]# docker run -itd -h node1 --name node1 --volumes-from node centos bash
2965a8f1184a7a1cbd26ef07e4b3d201fa17e5b68a52c619d6292da75c85d117
[root@tang ~]# docker-enter node1
[root@node1 ~]# cd /data/
[root@node1 data]# ll
total 0
-rw-r--r-- 1 root root 0 Apr  3 01:00 1
-rw-r--r-- 1 root root 0 Apr  3 01:00 2
-rw-r--r-- 1 root root 0 Apr  3 01:00 3
[root@node1 data]# touch 4
[root@node data]# ll
total 0
-rw-r--r-- 1 root root 0 Apr  3 01:00 1
-rw-r--r-- 1 root root 0 Apr  3 01:00 2
-rw-r--r-- 1 root root 0 Apr  3 01:00 3
-rw-r--r-- 1 root root 0 Apr  3 01:02 4
</code></pre><h4 id="数据卷的备份"><a href="#数据卷的备份" class="headerlink" title="数据卷的备份"></a>数据卷的备份</h4><pre><code>[root@docker ~]# mkdir /docker_data_backup
[root@docker ~]# docker run -itd -h tang --name tang -v /docker_data_backup/:/backup centos bash
250da7a47222e52c5a5d387ff8ce816a72b221ffb8d481739c4c68073507fe
[root@docker ~]# docker-enter tang
[root@tang ~]# mkdir /data
[root@tang ~]# touch /data/{1,2,3,4}
[root@tang ~]# tar cvf /backup/data.tar /data/
[root@tang ~]# cd /backup/
[root@tang backup]# ll
total 12
-rw-r--r-- 1 root root 10240 Apr  3 01:30 data.tar
[root@tang backup]# exit
logout
[root@docker ~]# cd /docker_data_backup/
[root@docker docker_data_backup]# ll
total 12
-rw-r--r-- 1 root root 10240 Apr  3 09:30 data.tar
</code></pre><h4 id="数据卷的恢复"><a href="#数据卷的恢复" class="headerlink" title="数据卷的恢复"></a>数据卷的恢复</h4><pre><code>[root@docker ~]# mkdir /docker_data_backup
[root@docker ~]# docker run -itd -h tang --name tang -v /docker_data_backup/:/backup centos bash
3728f6b0a6e5b47f904de0474db7d4479f33e87740906e1539eca385c3fab04d
[root@docker ~]# docker-enter tang
[root@tang ~]# mkdir /tools/
[root@tang ~]# touch /tools/{1,2,3,4}
[root@tang ~]# tar zcvf /backup/tools.tar /tools/
/tools/
/tools/1
/tools/2
/tools/3
/tools/4
[root@tang ~]# ll /backup/
total 4
-rw-r--r-- 1 root root 162 Apr  3 02:08 tools.tar
[root@tang ~]# exit
logout

[root@docker ~]# docker run -itd -h tang1 --name tang1 -v /tang1 centos bash
7ec371bb67f136234878771c227c4245a0ccf6c986e8c94a412d6c4111852a2b
[root@docker ~]# docker run -itd -h tang2 --name tang2 --volumes-from tang1 -v /docker_data_backup/:/backup centos bash
53e4cea1c45f3c081a6dd95b935f906aa037e6ed2170b6249a913ccd6fb4c119
[root@docker ~]# docker-enter tang2
[root@tang2 ~]# ll /backup/
total 4
-rw-r--r-- 1 root root 162 Apr  3 02:08 tools.tar
[root@tang2 tang1]# tar xvf /backup/tools.tar -C /tang1
[root@tang2 tang1]# exit
logout
[root@docker ~]# docker-enter tang1
[root@tang1 ~]# cd /tang1/
[root@tang1 tang1]# ll
total 4
drwxr-xr-x 2 root root 4096 Apr  3 02:07 tools
</code></pre>]]></content>
      
        <categories>
            
            <category> Docker </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Docker 基础（6）--仓库管理]]></title>
      <url>http://yoursite.com/2017/03/11/Docker%20%E5%9F%BA%E7%A1%80%EF%BC%886%EF%BC%89--%E4%BB%93%E5%BA%93%E7%AE%A1%E7%90%86/</url>
      <content type="html"><![CDATA[<blockquote>
<p>Docker的仓库是DockerHub，类似于github，github有一个开源的软件叫gitlab。Docker也有一个开源软件docker registry</p>
</blockquote>
<a id="more"></a>
<pre><code>[root@tang ~]# docker pull registry

[root@tang ~]# docker images
REPOSITORY           TAG                 IMAGE ID            CREATED             SIZE
docker.io/centos     latest              98d35105a391        2 weeks ago         192.5 MB
docker.io/registry   latest              047218491f8c        4 weeks ago         33.17 MB

默认占用5000端口，我们查看是否存在5000端口
[root@tang ~]# netstat -lntup | grep 5000

运行容器
[root@tang ~]# docker run -d -p 5000:5000 registry
f002089ab95474290853a2a24b86cb0adbb5848c4a468175304b59b27d6e3b0e

提示：docker比较老的版本运行起来就可以运行，1.7之后都不可以
</code></pre>]]></content>
      
        <categories>
            
            <category> Docker </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Docker 基础（9）--Dockerfile]]></title>
      <url>http://yoursite.com/2017/03/11/Docker%20%E5%9F%BA%E7%A1%80%EF%BC%889%EF%BC%89--Dockerfile/</url>
      <content type="html"><![CDATA[<h2 id="使用Dockerfile构建nginx"><a href="#使用Dockerfile构建nginx" class="headerlink" title="使用Dockerfile构建nginx"></a>使用Dockerfile构建nginx</h2><pre><code>Dockerfile是由一行命令和语句组成的



Dockerfile构建步骤：

[root@tang /]# mkdir /dockerfile/nginx -p
我们要在nginx目录上自动化创建一个nginx镜像
</code></pre><a id="more"></a>
<pre><code>注意：D需要大写，当我们构建dockerfile的时候，docker默认会在我们当前目录读取一个名为Dockerfile的文件。这时候的D必须大写

[root@tang nginx]# cat Dockerfile 
# This Dockerfile
# My Name is TangXiaoyue
# Base image
FROM centos

# Maintainer
MAINTAINE tang 1060336375@qq.com

#Commands
RUN rpm -ivh http://mirrors.aliyun.com/epel/epel-release-latest-7.noarch.rpm
RUN yum install -y nginx &amp;&amp; yum clean all
RUN echo &quot;daemon off;&quot; &gt;&gt;/etc/nginx/nginx.conf
ADD index.html /usr/share/nginx/html/index.html
EXPOSE 80
CMD [&quot;nginx&quot;]


#井号代表注释
#Base image  除了注释的第一行，必须是FROM，意思就是我们需要告诉dockerfile基础镜像是什么
#Maintainer 维护信息

#Commands 命令

#ADD index.html 这个文件需要我们在当前目录下有才可以，我们配置我们可以准备好，然后使用ADD命令进行添加或修改
EXPOSE 对外端口号
CMD [“nginx”] 它要启动的命令是nginx （就算是nginx服务）




我们写好dockerfile还需要一个index.html
[root@tang nginx]#  echo TangXiaoyue &gt;index.html
[root@tang nginx]# ll
total 8
-rw-r--r-- 1 root root 364 Apr  2 20:50 Dockerfile
-rw-r--r-- 1 root root  12 Apr  2 20:52 index.html

使用docker build进行构建
[root@tang ~]# docker build -t nginx_test:v1 /dockerfile/nginx/
[root@tang ~]# docker images
REPOSITORY           TAG                 IMAGE ID            CREATED             SIZE
nginx_test           v1                  bc69ee414a0f        17 seconds ago      280.7 MB


启动镜像
[root@tang ~]# docker run --name nginx_test -d -p 82:80 nginx_test:v1
7a02c27a0a04d34eec8f858e35848416b95572dbb1f485310caee5c185d2e426

[root@tang ~]# curl 127.0.0.1:82
TangXiaoyue
</code></pre><h2 id="Dockerfile参数解释"><a href="#Dockerfile参数解释" class="headerlink" title="Dockerfile参数解释"></a>Dockerfile参数解释</h2><h3 id="FROM"><a href="#FROM" class="headerlink" title="FROM"></a>FROM</h3><pre><code>格式：FROM&lt;image&gt;或FROM&lt;image&gt;:&lt;tag&gt;。

解释：FROM是Dockerfile里的第一条指令（必须是），后面跟有效的镜像名（如果该镜像你的本地仓库没有则会从远程仓库Pull取）。
然后后面的其它指令FROM的镜像中执行。
</code></pre><h3 id="MAINTAINER"><a href="#MAINTAINER" class="headerlink" title="MAINTAINER"></a>MAINTAINER</h3><pre><code>格式：MAINTAINER &lt;name&gt;

    解释：指定维护者信息。
</code></pre><h3 id="RUN"><a href="#RUN" class="headerlink" title="RUN"></a>RUN</h3><pre><code>格式：RUN &lt;command&gt;或 RUN[&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]。

    解释：运行命令，命令较长使可以使用\来换行。推荐使用上面数组的格式
</code></pre><h3 id="CMD"><a href="#CMD" class="headerlink" title="CMD"></a>CMD</h3><pre><code>格式：
CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] 使用 exec 执行，推荐方式；
CMD command param1 param2 在 /bin/sh 中执行，提供给需要交互的应用；
CMD [&quot;param1&quot;,&quot;param2&quot;] 提供给ENTRYPOINT的默认参数；

解释： 
CMD指定容器启动是执行的命令，每个Dockerfile只能有一条CMD命令，如果指定了多条，只有最后一条会被执行。
如果你在启动容器的时候也指定的命令，那么会覆盖Dockerfile构建的镜像里面的CMD命令。
</code></pre><h3 id="ENTRYPOINT"><a href="#ENTRYPOINT" class="headerlink" title="ENTRYPOINT"></a>ENTRYPOINT</h3><pre><code>格式：
   ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;,&quot;param2&quot;]
   ENTRYPOINT command param1 param2（shell中执行）。

解释：和CMD类似都是配置容器启动后执行的命令，并且不可被 docker run 提供的参数覆盖。 

每个 Dockerfile 中只能有一个ENTRYPOINT，当指定多个时，只有最后一个起效。
ENTRYPOINT没有CMD的可替换特性，也就是你启动容器的时候增加运行的命令不会覆盖ENTRYPOINT指定的命令。 
　
所以生产实践中我们可以同时使用ENTRYPOINT和CMD， 

例如：
    ENTRYPOINT [&quot;/usr/bin/rethinkdb&quot;]
    CMD [&quot;--help&quot;]
</code></pre><h3 id="USER"><a href="#USER" class="headerlink" title="USER"></a>USER</h3><pre><code>格式：USER daemon

    解释：指定运行容器时的用户名和UID，后续的RUN指令也会使用这里指定的用户。
</code></pre><h3 id="EXPOSE"><a href="#EXPOSE" class="headerlink" title="EXPOSE"></a>EXPOSE</h3><pre><code>格式：EXPOSE&lt;port&gt; [&lt;port&gt;...]

解释：设置Docker容器内部暴露的端口号，如果需要外部访问，还需要启动容器时增加-p或者-P参数进行分配。
</code></pre><h3 id="ENV"><a href="#ENV" class="headerlink" title="ENV"></a>ENV</h3><pre><code>格式：ENV&lt;key&gt; &lt;value&gt;
ENV &lt;key&gt;=&lt;value&gt; ...

    解释：设置环境变量，可以在RUN之前使用，然后RUN命令时调用，容器启动时这些环境变量都会被指定
</code></pre><h3 id="ADD"><a href="#ADD" class="headerlink" title="ADD"></a>ADD</h3><pre><code>格式：
   ADD &lt;src&gt;... &lt;dest&gt;
   ADD [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;]

    解释：
        将指定的&lt;src&gt;复制到容器文件系统中的&lt;dest&gt; 
           所有拷贝到container中的文件和文件夹权限为0755,uid和gid为0 
        如果文件是可识别的压缩格式，则docker会帮忙解压缩
</code></pre><h3 id="VOLUME"><a href="#VOLUME" class="headerlink" title="VOLUME"></a>VOLUME</h3><pre><code>格式：VOLUME [&quot;/data&quot;]

    解释：可以将本地文件夹或者其他container的文件夹挂载到container中。
</code></pre><h3 id="WORKDIR"><a href="#WORKDIR" class="headerlink" title="WORKDIR"></a>WORKDIR</h3><pre><code>格式：WORKDIR/path/to/workdir

    解释：切换目录，为后续的RUN、CMD、ENTRYPOINT 指令配置工作目录。 
    可以多次切换(相当于cd命令)， 
    也可以使用多个WORKDIR 指令，后续命令如果参数是相对路径，则会基于之前命令指定的路径。例如:

    WORKDIR /a
    WORKDIR b
    WORKDIR c
    RUN pwd
    则最终路径为 /a/b/c。
</code></pre><h3 id="ONBUILD"><a href="#ONBUILD" class="headerlink" title="ONBUILD"></a>ONBUILD</h3><pre><code>ONBUILD 指定的命令在构建镜像时并不执行，而是在它的子镜像中执行
</code></pre><h3 id="ARG"><a href="#ARG" class="headerlink" title="ARG"></a>ARG</h3><pre><code>格式：ARG&lt;name&gt;[=&lt;default value&gt;]

    解释：ARG指定了一个变量在docker build的时候使用，
         可以使用--build-arg &lt;varname&gt;=&lt;value&gt;来指定参数的值，不过如果构建的时候不指定就会报错。
</code></pre>]]></content>
      
        <categories>
            
            <category> Docker </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Docker 基础（8）--网络管理]]></title>
      <url>http://yoursite.com/2017/03/11/Docker%20%E5%9F%BA%E7%A1%80%EF%BC%888%EF%BC%89--%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86/</url>
      <content type="html"><![CDATA[<h3 id="Docker四种网络模式"><a href="#Docker四种网络模式" class="headerlink" title="Docker四种网络模式"></a>Docker四种网络模式</h3><h4 id="第一种网络模式host"><a href="#第一种网络模式host" class="headerlink" title="第一种网络模式host"></a>第一种网络模式host</h4><pre><code>host模式: 使用--net=host指定docker使用的网络实际上和宿主机一样,在容器内看到的网卡ip是宿主机上的ip.
</code></pre><a id="more"></a>
<pre><code>[root@docker ~]# docker run -itd -h node1 --name node1 --net=host centos bash
406cdb306f3c350b6f5344048ae25426f1df3f6863162c0b3a91e3dcd48eba
[root@docker ~]# ifconfig |awk -F &apos; &apos;  &apos;NR==10{print$2}&apos;
172.17.82.185
[root@docker ~]# docker-enter node1    #进去之后修改主机名，因为主机名个宿主机一样，貌似-h也指定不了主机名
[root@node1 ~]# yum install -y net-tools
[root@node1 ~]# ifconfig |awk -F &apos; &apos;  &apos;NR==10{print$2}&apos;
172.17.82.185
</code></pre><h4 id="第二种网络模式container"><a href="#第二种网络模式container" class="headerlink" title="第二种网络模式container"></a>第二种网络模式container</h4><pre><code>container模式: 使用--net=container:container_id/container_name多个容器使用共同的网络,看到的ip是一样的.


[root@docker ~]# docker run -itd -h node2 --name node2  --net=container:node1 centos bash     #此处不能指定主机名创建，否则失败
/usr/bin/docker-current: Error response from daemon: Conflicting options: hostname and the network mode.
See &apos;/usr/bin/docker-current run --help&apos;
[root@docker ~]# docker run -itd  --name node2 --net=container:node1 centos bash
0fc16c4a055cf0035c1241ba6cce6c5ad0c711f2ef13e0589c3254f19a96b271
[root@docker ~]# docker-enter node2
[root@node2 ~]# yum install -y net-tools
[root@node2 ~]# ifconfig |awk -F &apos; &apos;  &apos;NR==10{print$2}&apos;    #和node1的ip一样，也和宿主机的ip一样（node1使用的是--net=host模式）
172.17.82.185
</code></pre><h4 id="第三种网络模式none"><a href="#第三种网络模式none" class="headerlink" title="第三种网络模式none"></a>第三种网络模式none</h4><pre><code>none模式: 使用--net=none, 这种模式下,不会配置任何网络

[root@docker ~]# docker run -itd -h node3 --name node3 --net=none centos
c1f4bd859566f11517248718a94456066d16ad66748a2c78743881e450d4ca09
[root@docker ~]# docker-enter node3
[root@node3 ~]# ping www.baidu.com
ping: www.baidu.com: Name or service not known
</code></pre><h4 id="第四种网络模式bridge"><a href="#第四种网络模式bridge" class="headerlink" title="第四种网络模式bridge"></a>第四种网络模式bridge</h4><pre><code>bridge模式: 使用--net=bridge.创建完容器默认为这种网络模式.类似与vmware的nat网络模式.

[root@docker ~]# docker run -itd -h node4 --name node4 --net=bridge centos bash
fc4f817e741f22615d0cdbab6608877d268ea15be6ba790cae5706d03871ac41
</code></pre><h3 id="外部访问容器"><a href="#外部访问容器" class="headerlink" title="外部访问容器"></a>外部访问容器</h3><pre><code>[root@docker ~]# docker run -itd -h node1 --name node1 centos bash
27df97f0e77e745660ee7b9c8b318c64f63e6aa632db3d3b0c44c4e0f4006124
[root@docker ~]# docker-enter node1
[root@node1 ~]# rpm -ivh http://mirrors.aliyun.com/epel/epel-release-latest-7.noarch.rpm
[root@node1 ~]# yum install -y nginx
[root@docker ~]# docker commit -m &quot;nginx&quot; -a &quot;tang&quot; 27df97f0e77e nginx:v1
    #此处仅容器做为镜像，主要是减少以后重复性的工作，不需要新建一个容器在部署nginx

[root@docker ~]# docker run -itd -h nginx --name nginx -p 81:80 nginx:v1 bash      #-p 端口映射，射到宿主机81端口上
a5dd375e829d05734a935d5f41723841568b543822a64a4ec277480f5f552e41
[root@docker ~]# docker-enter nginx
Last login: Mon Apr  3 07:00:51 UTC 2017
[root@nginx ~]# /usr/sbin/nginx 
[root@nginx ~]# echo &quot;TangXiaoyue&quot; &gt; /usr/share/nginx/html/1.html
[root@nginx ~]# curl 127.0.0.1/1.html
TangXiaoyue
[root@nginx ~]# exit
logout
[root@docker ~]#  curl 127.0.0.1:81/1.html
TangXiaoyue
</code></pre><h3 id="容器互联"><a href="#容器互联" class="headerlink" title="容器互联"></a>容器互联</h3><pre><code>1.安装mysql
[root@docker ~]# docker run --privileged -itd -h node1 --name node1 centos /sbin/init
fd547b535ff3af19bf36b219f542864962d60480a8d56836db30c20f079ec43f
[root@docker ~]# docker-enter node1
[root@node1 ~]# yum install -y wget
[root@node1 ~]# wget http://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpm
[root@node1 ~]# rpm -ivh mysql-community-release-el7-5.noarch.rpm
[root@node1 ~]# yum install mysql-community-server
[root@node1 ~]# systemctl start mysql.service
[root@node1 ~]# mysql -uroot
&gt;set password for &apos;root&apos;@&apos;localhost&apos; = password(&apos;123456&apos;);

2.制作mysql镜像
[root@docker ~]# docker commit -m &quot;mysql&quot; -a &quot;tang&quot; fd547b535ff3 mysql:v1
sha256:21af416e70b0302163e4aa279118afdd96a0c8590487268a3d26920caf6c5d1a
[root@docker ~]# docker images
REPOSITORY           TAG                 IMAGE ID            CREATED             SIZE
mysql                v1                  21af416e70b0        4 seconds ago       797.3 MB


[root@docker ~]# docker run --privileged -itd -h mysql --name mysql mysql:v1 /sbin/init
8d71a34516a2c05a7ea63fde5773785360d1301509d687797eec5ead62a01d55


3.以mysql、nginx镜像分别创建两个容器并端口映射
[root@docker ~]# docker run -itd -h nginx --name nginx -p 10080:80 --link mysql:db nginx:v1 bash
8aea6116f67c9760b8f4d3de08251b28af839b9e2195860ad4b24d54833c286a
[root@docker ~]# docker-enter nginx
Last login: Mon Apr  3 07:00:51 UTC 2017
[root@nginx ~]# yum install -y telnet
[root@nginx ~]# telnet db 3306
Trying 172.18.0.3...
Connected to db.
Escape character is &apos;^]&apos;.
CHost &apos;172.18.0.4&apos; is not allowed to connect to this MySQL serverConnection closed by foreign host.
[root@nginx ~]# cat /etc/hosts
172.18.0.3    db mysql mysql
172.18.0.4    nginx
</code></pre><h3 id="配置网桥-centos7"><a href="#配置网桥-centos7" class="headerlink" title="配置网桥(centos7)"></a>配置网桥(centos7)</h3>]]></content>
      
        <categories>
            
            <category> Docker </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Docker问题梳理--持续更新]]></title>
      <url>http://yoursite.com/2017/03/11/Docker%E9%97%AE%E9%A2%98%E6%A2%B3%E7%90%86/</url>
      <content type="html"><![CDATA[<h3 id="关于systemctl无法启动服务的问题处理"><a href="#关于systemctl无法启动服务的问题处理" class="headerlink" title="关于systemctl无法启动服务的问题处理"></a>关于systemctl无法启动服务的问题处理</h3><pre><code>问题：

使用systemctl启动服务的时候出现以下异常：

Failed to get D-Bus connection: Operation not permitted 


解决：

docker run --privileged -itd -h node1 --name node1 centos /sbin/init
</code></pre>]]></content>
      
        <categories>
            
            <category> Docker </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Docker 基础（2）--命令]]></title>
      <url>http://yoursite.com/2017/03/11/Docker%E5%9F%BA%E7%A1%80%EF%BC%882%EF%BC%89--%E5%91%BD%E4%BB%A4/</url>
      <content type="html"><![CDATA[<h3 id="安装下载"><a href="#安装下载" class="headerlink" title="安装下载"></a>安装下载</h3><pre><code>yum install -y docker                                    #下载
systemctl start docker                                    #启动
systemctl enable docker                                    #自启动
</code></pre><a id="more"></a>
<h3 id="镜像操作"><a href="#镜像操作" class="headerlink" title="镜像操作"></a>镜像操作</h3><pre><code>docker search  images                                    #搜索镜像
docker pull images                                    #下载镜像
docker    images                                    #查看镜像
docker tag centos6  centos6_x86                                    #镜像改名
docker save image&gt;/opt/images.tar.gz                                    #导出镜像
docker load&lt;/opt/images.tar.gz                                    #导入镜像
docker load --input /opt/images.tar.gz                                            #导入镜像
docker rmi images_id                                                            #删除镜像
docker rmi $(docker images -q)                                                    #删除所有镜像
</code></pre><h3 id="容器操作"><a href="#容器操作" class="headerlink" title="容器操作"></a>容器操作</h3><pre><code>docker ps -a                                                                    #查看容器
docker run centos /bin/echo &quot;hehe&quot;                                                #首次创建一个容器
docekr run -h tang --name tang -t -i centos /bin/bah                            #创建一个以tang为名的容器；
                                                                                    --name：指定容器名    
                                                                                    -t：分配一个tty终端    
                                                                                    -i：容器的标准输出保持打开状态 
                                                                                    -h:指定主机名
docker create -it --name centos1 centos                                            #使用create创建容器
docekr stop ID（name）                                                            #停止容器
docker start ID（name）                                                            #启动容器
docker attach ID（name）                                                            #进入容器
docker exec -it ID(name)  /bin/bash
docker rm  ID（name）                                                            #删除容器    
                                                                                    -f：强制删除容器，包括在运行的
                                                                                #exec和attach总结: 
                                                                                    attach登陆容器后,退出时容器会关闭. 
                                                                                    推荐使用exec进入容器
docker rm $(docker ps -a -q)                                                    #删除所有容器
</code></pre><h3 id="映射"><a href="#映射" class="headerlink" title="映射"></a>映射</h3><pre><code>docker run --name nginx -d -P nginx                                                #随机映射 
docker run --name nginx -d -p 81:80 nginx                                         #指定映射
docker run -it --name nginx -p 80:80 nginx /bin/bash                            #指定映射
</code></pre><h3 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h3><pre><code>docker logs ID（name）                                                            #查看日志
</code></pre><h3 id="数据管理"><a href="#数据管理" class="headerlink" title="数据管理"></a>数据管理</h3><pre><code>docker run -it --name tang -v /data centos                                         #默认挂载目录
docekr inspect ID(name)                                                            #查看容器信息
                                                                                    ==查看mounts模块
docekr run -it --name tang -v /data:/data centos                                   #指定挂载目录
docker run -it --name tang -v /data:/data:rw centos                                 #指定权限挂载
                                                                                    ==rw：读写
docker run -it --name tang -v /data:/data:ro centos                             #指定权限挂载
                                                                                ==ro：只读
docker run -it --name tang  ~/.bash_history:/.bash_history centos                #记录历史记录
</code></pre><h3 id="数据卷容器"><a href="#数据卷容器" class="headerlink" title="数据卷容器"></a>数据卷容器</h3><pre><code>docker run -d --name nfs -v /data:/data centos                                     #启动nfs容器，挂在一个卷，
                                            -d：直接在后台执行
docker run -it --name test1 --volumes-from nfs centos                            #启动test1容器，挂载到nfs的数据卷容器上
docker run -it --name test2 --volumes-from nfs centos                             #启动test2容器，挂载到nfs的数据卷容器上
                                        #test1和test2的/data数据可以共享
</code></pre><h3 id="手动制作镜像"><a href="#手动制作镜像" class="headerlink" title="手动制作镜像"></a>手动制作镜像</h3><pre><code>docker run -it --name mynginx centos                                            #基础centos进行创建容器mynginx
</code></pre><h2 id="在mynginx容器内安装nginx"><a href="#在mynginx容器内安装nginx" class="headerlink" title="在mynginx容器内安装nginx"></a>在mynginx容器内安装nginx</h2><pre><code>rpm -ivh http://mirrors.aliyun.com/epel/epel-release-latest-7.noarch.rpm
yum install -y nginx
docker commit -m &quot;my nginx&quot; f9c7dfb6f552 tang/mynginx:v1                        #提交镜像，
                                            ==同时打一个标签叫mynginx:v1
                                            ==tang相当于你向github上提交的用户名
docker run -it --anme nginxv1 tang/mynginx:v1                                    #基于镜像tang/mynginx:v1创建容器nginxv1
```
</code></pre>]]></content>
      
        <categories>
            
            <category> Docker </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Docker 基础（3）--容器登入]]></title>
      <url>http://yoursite.com/2017/03/11/Docker%20%E5%9F%BA%E7%A1%80%EF%BC%883%EF%BC%89--%E5%AE%B9%E5%99%A8%E7%99%BB%E5%85%A5/</url>
      <content type="html"><![CDATA[<h3 id="docker-enter登入容器"><a href="#docker-enter登入容器" class="headerlink" title="docker-enter登入容器"></a>docker-enter登入容器</h3><blockquote>
<p>强烈推荐使用此种方法：简单、方便</p>
</blockquote>
<pre><code>下载.bashrc_docker，并将内容放到.bashrc中。

这个文件中定义了很多方便使用Docker的命令，比如docker-pid可以获取某个容器的 PID；
而 docker-enter 可以进入容器或直接在容器内执行命令
</code></pre><a id="more"></a>
<pre><code>[root@tang ~]# wget -P ~ https://github.com/yeasy/docker_practice/raw/master/_local/.bashrc_docker

[root@tang ~]# echo &quot;[ -f ~/.bashrc_docker ] &amp;&amp; . ~/.bashrc_docker&quot; &gt;&gt; ~/.bashrc; source ~/.bashrc


[root@tang ~]# docker-
docker-containerd               docker-ctr-current              docker-pid
docker-containerd-current       docker-current                  docker-storage-setup
docker-containerd-shim          docker-enter                    
docker-containerd-shim-current  docker-ip 

[root@tang ~]# docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
e657e9214a57        centos              &quot;/bin/bash&quot;         24 minutes ago      Up 23 minutes                           tang

[root@tang ~]# docker-pid tang
19271

[root@tang ~]# nsenter --target 19271  --mount --uts --ipc --net --pid  #此种方法进入容器以下会讲到
[root@test /]# exit
logout

[root@tang ~]# docker-ip tang
172.18.0.2

直接使用docker-enter命令进入容器，非常方便！
[root@tang ~]# docker-enter tang
Last login: Sun Apr  2 06:38:47 UTC 2017

[root@test ~]# exit
logout

[root@tang ~]# docker ps   #退出登陆窗口后，容器还在
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
e657e9214a57        centos              &quot;/bin/bash&quot;         26 minutes ago      Up 9 seconds                            tang

注意：以在容器的上下文中运行任意命令！即在宿主机上执行容器里的命令

[root@tang ~]# docker-enter tang uptime
 07:06:28 up 1 day, 22:44,  0 users,  load average: 0.00, 0.01, 0.05

注意：在宿主机上使用docker-enter命令执行容器中的命令时，最好后面加上--符号，这样容器里的所有存在的命令都可以正常执行。
[root@tang ~]# docker-enter tang -- uptime

 07:06:59 up 1 day, 22:45,  0 users,  load average: 0.00, 0.01, 0.05

[root@tang ~]# docker-enter tang -- df -h
Filesystem                                                                                         Size  Used Avail Use% Mounted on
/dev/mapper/docker-253:1-2024335-661487685eb1f6a356157463d60db20caa2c1fb3ac273de680c367e3b12dabab   10G  238M  9.8G   3% /
tmpfs                                                                                              920M     0  920M   0% /dev
tmpfs                                                                                              920M     0  920M   0% /sys/fs/cgroup
/dev/vda1                                                                                           99G  4.7G   89G   5% /etc/hosts
shm                                                                                                 64M     0   64M   0% /dev/shm

[root@tang ~]# cat /etc/redhat-release 
CentOS Linux release 7.2.1511 (Core) 

[root@tang ~]# docker-enter tang -- cat /etc/redhat-release 
CentOS Linux release 7.3.1611 (Core)
</code></pre><h3 id="nsenter登入容器"><a href="#nsenter登入容器" class="headerlink" title="nsenter登入容器"></a>nsenter登入容器</h3><pre><code>使用外部工具nsenter登陆容器，该工具和docker exec命令的效果差不多。

使用nsenter或dockerexec，都可以在容器的上下文（严格地说，是命名空间）中运行任意命令！


==nsenter安装：
[root@tang ~]#  yum install util-linux -y 


==nsenter使用：
[root@tang ~]# docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
e657e9214a57        centos              &quot;/bin/bash&quot;         50 minutes ago      Up 24 minutes                           tang

[root@tang ~]# docker inspect -f &quot;{{ .State.Pid }}&quot; tang
19271

[root@tang ~]# nsenter -t 19271  -m -u -i -n -p

解释nsenter指令中进程id之后的参数的含义：

–mount参数是进去到mount namespace中 
–uts参数是进入到uts namespace中 
–ipc参数是进入到System V IPC namaspace中 
–net参数是进入到network namespace中 
–pid参数是进入到pid namespace中 
–user参数是进入到user namespace中

[root@tang ~]#  nsenter --help

Usage:
 nsenter [options] &lt;program&gt; [&lt;argument&gt;...]

Run a program with namespaces of other processes.

Options:
 -t, --target &lt;pid&gt;     target process to get namespaces from
 -m, --mount[=&lt;file&gt;]   enter mount namespace
 -u, --uts[=&lt;file&gt;]     enter UTS namespace (hostname etc)
 -i, --ipc[=&lt;file&gt;]     enter System V IPC namespace
 -n, --net[=&lt;file&gt;]     enter network namespace
 -p, --pid[=&lt;file&gt;]     enter pid namespace
 -U, --user[=&lt;file&gt;]    enter user namespace
 -S, --setuid &lt;uid&gt;     set uid in entered namespace
 -G, --setgid &lt;gid&gt;     set gid in entered namespace
     --preserve-credentials do not touch uids or gids
 -r, --root[=&lt;dir&gt;]     set the root directory
 -w, --wd[=&lt;dir&gt;]       set the working directory
 -F, --no-fork          do not fork before exec ing &lt;program&gt;
 -Z, --follow-context   set SELinux context according to --target PID
 -h, --help     display this help and exit
 -V, --version  output version information and exit

我们进入容器中查看进程 
以下是以nsenter启动的进程
[root@test /]# ps aux
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root         1  0.0  0.0  11768  1684 ?        Ss+  07:03   0:00 /bin/bash
root        77  0.0  0.1  15200  1988 ?        S    07:31   0:00 -bash
root        90  0.0  0.0  50872  1816 ?        R+   07:31   0:00 ps aux

/bin/bash是我们运行容器产生的进程
-bash 是我们使用nsenter产生的，这样如果我们退出容器，容器就不会退出，因为-bash还在运行

[root@test /]# exit
logout

[root@tang ~]# docker ps 
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
e657e9214a57        centos              &quot;/bin/bash&quot;         55 minutes ago      Up 29 minutes                           tang

因为每次进入容器都需要输入那两条命令，所以我们可以写一个脚本来获取。 

==脚本内容如下：
[root@tang opt]# cat docker_in.sh 
#!/bin/bash
# Use nsenter to access docker
docker_in(){
  NAME_ID=$1
  PID=$(docker inspect -f &quot;{{ .State.Pid }}&quot; $NAME_ID)
  nsenter -t $PID -m -u -i -n -p
}
docker_in $1

[root@tang opt]# chmod +x docker_in.sh 
[root@tang opt]# ./docker_in.sh tang
[root@test /]# ps -ef
UID        PID  PPID  C STIME TTY          TIME CMD
root         1     0  0 07:03 ?        00:00:00 /bin/bash
root        91     0  0 07:34 ?        00:00:00 -bash
root       104    91  0 07:34 ?        00:00:00 ps -ef
[root@test /]# exit
logout
[root@tang opt]# docker exec tang ps -ef
UID        PID  PPID  C STIME TTY          TIME CMD
root         1     0  0 07:03 ?        00:00:00 /bin/bash
root       105     0  0 07:35 ?        00:00:00 ps -ef


我们还可以使用exec进入docker容器中

[root@tang opt]# docker exec -it tang /bin/bash
</code></pre><h3 id="start-ai登入容器"><a href="#start-ai登入容器" class="headerlink" title="start -ai登入容器"></a>start -ai登入容器</h3><pre><code>对于一个已关闭的容器的登陆，可以使用&quot;docker start -ai container&quot;登陆。这种其实就是先启动容器，然后再进入容器内。

[root@tang ~]# docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                      PORTS               NAMES
e657e9214a57        centos              &quot;/bin/bash&quot;         About an hour ago   Exited (0) 53 seconds ago                       tang

[root@tang ~]# docker start -ai tang   #-a -i 都可以
[root@test /]# exit
exit
[root@tang ~]# docker start -i tang
[root@tang ~]# docker start -a tang
</code></pre><h3 id="docker-exec登入容器"><a href="#docker-exec登入容器" class="headerlink" title="docker exec登入容器"></a>docker exec登入容器</h3><pre><code>使用自带命令docker exec登陆容器

命令格式：docker exec -ti container_id /bin/bash

[root@tang ~]# docker ps    #前提是容器已经启动
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
e657e9214a57        centos              &quot;/bin/bash&quot;         About an hour ago   Up 2 minutes                            tang
[root@tang ~]# docker exec -it tang /bin/bash
[root@test /]# exit
</code></pre><h3 id="docker-attach登入容器"><a href="#docker-attach登入容器" class="headerlink" title="docker attach登入容器"></a>docker attach登入容器</h3><pre><code>使用自带命令docker attach登陆容器。

命令格式：docker attach container_id

[root@tang ~]# docker ps   #前提容器已经启动了
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
e657e9214a57        centos              &quot;/bin/bash&quot;         About an hour ago   Up 5 minutes                            tang
[root@tang ~]# docker attach tang
[root@test /]# exit
</code></pre><h3 id="ssh登入容器"><a href="#ssh登入容器" class="headerlink" title="ssh登入容器"></a>ssh登入容器</h3><pre><code>使用ssh登陆容器。这种方法需要在容器中启动sshd，存在开销和攻击面增大的问题。同时也违反了Docker所倡导的一个容器一个进程的原则

ssh登入会专门写一篇文章介绍。这里就不叙述了
</code></pre>]]></content>
      
        <categories>
            
            <category> Docker </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Docker 基础（4）--镜像管理]]></title>
      <url>http://yoursite.com/2017/03/11/Docker%20%E5%9F%BA%E7%A1%80%EF%BC%884%EF%BC%89--%E9%95%9C%E5%83%8F%E7%AE%A1%E7%90%86/</url>
      <content type="html"><![CDATA[<h3 id="使用容器生成镜像"><a href="#使用容器生成镜像" class="headerlink" title="使用容器生成镜像"></a>使用容器生成镜像</h3><pre><code>[root@tang ~]# docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
</code></pre>  <a id="more"></a>
<pre><code>[root@tang ~]# docker run -it -h nginx --name nginx  centos  /bin/bash

[root@nginx /]# rpm -ivh
http://mirrors.aliyun.com/epel/epel-release-latest-7.noarch.rpm

[root@nginx /]# yum install -y nginx

[root@tang ~]# docker ps -a 
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                      PORTS               NAMES
e46c71171306        centos              &quot;/bin/bash&quot;         2 minutes ago       Exited (0) 40 seconds ago                       nginx

[root@tang ~]# docker commit -m &quot;my nginx&quot; -a &quot;tang&quot; e46c71171306 new_nginx:v1
sha256:c15ceb0a6871e3a56e3b22d67254d09b2e03a8ae909719a6dea0daaf937940ef

    -m: 改动信息
    -a: 作者信息
    e46c71171306: 这一串为容器ID
    new_nginx:01 新镜像的名字

[root@tang ~]# docker images
REPOSITORY           TAG                 IMAGE ID            CREATED              SIZE
new_nginx            v1                  c15ceb0a6871        About a minute ago   355 MB
docker.io/centos     latest              98d35105a391        2 weeks ago          192.5 MB
docker.io/registry   latest              047218491f8c        4 weeks ago          33.17 MB
</code></pre><h3 id="基于本地模块创建镜像"><a href="#基于本地模块创建镜像" class="headerlink" title="基于本地模块创建镜像"></a>基于本地模块创建镜像</h3><pre><code>模版获取,直接到openva官网下载(https://openvz.org/Download/template/precreated)

[root@tang opt]# wget http://download.openvz.org/template/precreated/centos-6-x86_64-minimal.tar.gz

[root@tang opt]# cat centos-6-x86_64-minimal.tar.gz |docker import - centos6
sha256:3d2aed457a111b136bdb9178d6203cb4bb0116501f7a4847088d7593c0930a8c

[root@tang opt]# docker images
REPOSITORY           TAG                 IMAGE ID            CREATED             SIZE
centos6      
</code></pre><h3 id="镜像导出-导入"><a href="#镜像导出-导入" class="headerlink" title="镜像导出/导入"></a>镜像导出/导入</h3><pre><code>[root@tang opt]# docker save centos6 &gt;/opt/centos6.tar.gz   #导出

[root@tang opt]# ll
total 1539880
-rw-r--r-- 1 root root 565194752 Apr  2 16:19 centos6.tar.gz

[root@tang opt]# docker rmi centos6
Untagged: centos6:latest
Deleted: sha256:3d2aed457a111b136bdb9178d6203cb4bb0116501f7a4847088d7593c0930a8c
Deleted: sha256:dbcc6b3893af5f0b45e06f2934f73f5dc34f2e9e54fc4d50a51cc47195f19089

[root@tang opt]# docker load &lt; /opt/centos6.tar.gz              #导入
[root@tang opt]# docker load --input /opt/centos6.tar.gz        #导入

#以上两种导入方法都可以

[root@tang opt]# docker tag centos6  centos6_x86                #改名
</code></pre><h3 id="将镜像上传到dockerhub官网"><a href="#将镜像上传到dockerhub官网" class="headerlink" title="将镜像上传到dockerhub官网"></a>将镜像上传到dockerhub官网</h3><pre><code>需要提前注册dockerhub账号

1. docker hub 帐号在本地验证登陆:

[root@tang opt]# docker login
Login with your Docker ID to push and pull images from Docker Hub. If you don&apos;t have a Docker ID, head over to https://hub.docker.com to create one.
Username: tangxiaoyue
Password: 
Login Succeeded

2. docker push 镜像到docker hub 的仓库
docker push
&lt;hub-user&gt;/&lt;repo-name&gt;:&lt;tag&gt;

[root@tang ~]# docker tag centos tangxiaoyue/centos_tang:latest

[root@tang ~]# docker push tangxiaoyue/centos_tang
The push refers to a repository [docker.io/tangxiaoyue/centos_tang]
9b198ff9ff5b: Mounted from library/centos 
latest: digest: sha256:be5b4a93f116a57ab3fd454ada72421eac892a3a4925627ac9a44f65fcd69cf8 size: 529
</code></pre>]]></content>
      
        <categories>
            
            <category> Docker </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[XtraBackup主从复制及备份]]></title>
      <url>http://yoursite.com/2017/03/11/XtraBackup%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%8F%8A%E5%A4%87%E4%BB%BD/</url>
      <content type="html"><![CDATA[<h4 id="XtraBackup备份"><a href="#XtraBackup备份" class="headerlink" title="XtraBackup备份"></a>XtraBackup备份</h4><pre><code>1、yum安装mysql（以centos7为例）
</code></pre><a id="more"></a>
<pre><code>###主从操作一致

#查看操作系统版本：
[root@node2 ~]# cat /etc/redhat-release
CentOS Linux release 7.0.1406 (Core)

#关闭防火墙和seLinux
[root@node2 ~]# systemctl stop firewalld
[root@node2 ~]# sed -i &quot;s#SELINUX=enforcing#SELINUX=disabled#g&quot; /etc/selinux/config
[root@node2 ~]# setenforce 0

#yum安装mysql
wget http://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpm
rpm -ivh mysql-community-release-el7-5.noarch.rpm
yum install mysql-community-server
systemctl start mysql.service
mysql -uroot
&gt;set password for &apos;root&apos;@&apos;localhost&apos; = password(&apos;123456&apos;);

###配置主从
主：
vim /etc/my.cnf
[mysqld]
log-bin = mysql-bin
server-id=1

从：
vim /etc/my.cnf
[mysqld]
log-bin = mysql-bin
server-id=2

2、安装xtrabackup备份软件（主从进行安装）
wget https://www.percona.com/downloads/XtraBackup/Percona-XtraBackup-2.3.4/binary/redhat/6/x86_64/percona-xtrabackup-2.3.4-1.el6.x86_64.rpm
yum install -y epel-release
yum localinstall percona-xtrabackup-2.3.4-1.el6.x86_64.rpm
yum install -y perl-Time-HiRes

#查看版本
&gt;select version();

#查看前默认的存储引擎
&gt;show variables like &apos;%storage_engine%&apos;;


3、导入数据（为了模拟比较真实可以往主库导入数据）（主库操作）
#导入bubi_api数据库
[root@node2 opt]# mysql -uroot -ppassword &lt; bubi_api.sql #
查看数据大小 
&gt; use information_schema;
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A

Database changed
&gt; select concat(round(sum(data_length/1024/1024),2),&apos;MB&apos;) as data from tables;
+----------+
| data |
+----------+
| 194.94MB |
+----------+
1 row in set (0.04 sec)

4、数据库备份（主操作）
###备份
[root@node2 opt]# mkdir /extrabackup
[root@node2 opt]# innobackupex --defaults-file=/etc/my.cnf --socket=/var/lib/mysql/mysql.sock --user=root --password=bubi --parallel=4 /mnt/resource/extrabackup
###出现completed OK! 表示备份成功

语法解释：–user=数据库用户
–password=数据库密码
–socket=指定socket
–default-file=指定配置文件
- 最后面是存放位

###保持事务一致（主操作）
[root@node2 2017-02-17_14-45-11]# innobackupex --defaults-file=/etc/my.cnf --socket=/var/lib/mysql/mysql.sock --user=root --password=123456 --parallel=4 --apply-log /extrabackup/2017-02-17_14-45-11/
###出现completed OK!表示事务保持了一致，可以用于恢复




二、mysql主从同步操作
1、传输数据、将/extrabackup/2017-02-17_14-45-11/拷贝到从库
[root@node2 extrabackup]# scp -r 2017-02-17_14-45-11 root@192.168.1.13:/extrabackup/

2、从库恢复数据
[root@node3 extrabackup]# ll
总用量 0
drwx------. 4 root root 47 2月 17 14:47 2017-02-17_14-45-11

#停止mysql
[root@node3 extrabackup]# systemctl stop mysql

#清空mysql data目录
[root@node3 extrabackup]# cd /var/lib/mysql
[root@node3 mysql]# mv * /opt/mysqlbak/

#数据恢复
innobackupex --defaults-file=/etc/my.cnf --socket=/var/lib/mysql/mysql.sock --user=root --password=123456 --copy-back /extrabackup/2017-02-17_11-49-35/
###出现completed OK! 表示恢复成功

#还原权限
[root@node3 mysql]# cd ..
[root@node3 lib]# chown mysql:mysql mysql -R

#重启mysql并查看数据的大小
[root@node3 lib]# systemctl start mysql
[root@node3 lib]# ps -ef | grep mysql
mysql 8173 1 0 14:59 ? 00:00:00 /bin/sh /usr/bin/mysqld_safe --basedir=/usr
mysql 8338 8173 3 14:59 ? 00:00:00 /usr/sbin/mysqld --basedir=/usr --datadir=/var/lib/mysql --plugin-dir=/usr/lib64/mysql/plugin --log-error=/var/log/mysqld.log --pid-file=/var/run/mysqld/mysqld.pid --socket=/var/lib/mysql/mysql.sock
root 8364 5840 0 15:00 pts/0 00:00:00 grep --color=auto mysql

&gt; use information_schema;
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A

Database changed
mysql&gt;    
+----------+
| data |
+----------+
| 194.94MB |
+----------+
1 row in set (0.26 sec)

###数据主从大小都一样

3、mysql主从同步操作
###主库授权
&gt; GRANT REPLICATION SLAVE ON *.* TO &apos;rep&apos;@&apos;192.168.1.13&apos; IDENTIFIED BY &apos;123456&apos;;
&gt;FLUSH PRIVILEGES;

###从库开启同步
[root@node3 mysql]# cat /extrabackup/2017-02-17_14-45-11/xtrabackup_binlog_info
mysql-bin.000001 171510867

CHANGE MASTER TO
MASTER_HOST=&apos;10.25.159.23&apos;,
MASTER_USER=&apos;rep&apos;,
MASTER_PASSWORD=&apos;db0226&apos;,
MASTER_PORT=3306,
MASTER_LOG_FILE=&apos;mysql-bin.000003&apos;,
MASTER_LOG_POS=982559769;

####在还没同步之前我们可以在主库继续增加入一个库，验证不锁表是否可以同步
mysql&gt; show databases;
+--------------------+
| Database |
+--------------------+
| information_schema |
| bubi_api |
| mysql |
| performance_schema |
| tang |
+--------------------+
5 rows in set (0.00 sec)

#####开启主从同步
&gt;flush logs;
&gt; start slave; ###从库操作
&gt; show slave status\G
Slave_IO_Running: Yes
Slave_SQL_Running: Yes

##查看从库数据
mysql&gt; show databases;
+--------------------+
| Database |
+--------------------+
| information_schema |
| bubi_api |
| mysql |
| performance_schema |
| tang |
+--------------------+
5 rows in set (0.00 sec)

注意：
1、当从库停掉了（宕机还没测试）。主库继续写入数据，从库开启时，会自动同步




##########mysql命令
#查看binlog是否开启
&gt;show binary logs;

#查看serverid
&gt;show variables like &apos;server_id&apos;;

#查看binlog模式
&gt;show variables like &apos;%log%&apos;;


&gt;/dev/null 2&gt;&amp;1
</code></pre>]]></content>
      
        <categories>
            
            <category> Mysql </category>
            
        </categories>
        
        
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Docker 基础（5）--容器管理]]></title>
      <url>http://yoursite.com/2017/03/11/Docker%20%E5%9F%BA%E7%A1%80%EF%BC%885%EF%BC%89--%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/</url>
      <content type="html"><![CDATA[<h4 id="查看启动的容器"><a href="#查看启动的容器" class="headerlink" title="查看启动的容器"></a>查看启动的容器</h4><pre><code>[root@tang ~]# docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
2f8c14f16e03        centos              &quot;/bin/bash&quot;         5 minutes ago       Up 2 minutes                            tang
</code></pre>  <a id="more"></a>
<h4 id="查看所有的容器-包括启动、停止"><a href="#查看所有的容器-包括启动、停止" class="headerlink" title="查看所有的容器(包括启动、停止)"></a>查看所有的容器(包括启动、停止)</h4><pre><code>[root@tang ~]# docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                      PORTS               NAMES
e5d7ccb9522c        centos              &quot;/bin/bash&quot;         15 seconds ago      Exited (0) 12 seconds ago                       tang1
2f8c14f16e03        centos              &quot;/bin/bash&quot;         3 minutes ago       Up 1 seconds                                    tang

Exited:表示该容器已经退出。没有启动
</code></pre><h4 id="创建容器-create、run-、进入容器"><a href="#创建容器-create、run-、进入容器" class="headerlink" title="创建容器(create、run)、进入容器"></a>创建容器(create、run)、进入容器</h4><pre><code>[root@tang ~]# docker images
REPOSITORY           TAG                 IMAGE ID            CREATED             SIZE
docker.io/centos     latest              98d35105a391        2 weeks ago         192.5 MB
docker.io/registry   latest              047218491f8c        4 weeks ago         33.17 MB

[root@tang ~]# docker create -it --name tang_create centos /bin/bash                     #使用create创建容器
3b316839ea357a3fe47fcae3488d6f491882ecb8c954412c502cbd6dcf9e2478

[root@tang ~]# docker run -it --name tang_run centos /bin/bash                          #使用run创建容器
[root@b5dbba42703a /]# exit
exit
</code></pre><h4 id="启动停止容器"><a href="#启动停止容器" class="headerlink" title="启动停止容器"></a>启动停止容器</h4><pre><code>[root@tang ~]# docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES

[root@tang ~]# docker start tang_run                #start启动容器
tang_run

[root@tang ~]# docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
b5dbba42703a        centos              &quot;/bin/bash&quot;         4 minutes ago       Up 14 seconds                           tang_run

[root@tang ~]# docker stop tang_run                 #stop停止容器
tang_run
[root@tang ~]# docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
</code></pre><h4 id="创建容器-指定容器名"><a href="#创建容器-指定容器名" class="headerlink" title="创建容器,指定容器名"></a>创建容器,指定容器名</h4><pre><code>[root@tang ~]# docker run -itd -h tang_run --name tang centos /bin/bash
8afe717f82718214056a61e3881552338d5c911d272a80342edec063b5048
        -d: 容器退出后不关闭容器.
        -h:指定主机名
</code></pre><h4 id="删除容器-镜像"><a href="#删除容器-镜像" class="headerlink" title="删除容器/镜像"></a>删除容器/镜像</h4><pre><code>[root@tang ~]# docker rm tang                               #删除容器
[root@tang ~]# docker rm -f tang                            #强制删除容器，不管是否在运行
[root@tang ~]# docker rm $(docker ps -a -q)                 #删除所有容器
</code></pre><h4 id="导出容器-可迁移到其它机器-导入容器"><a href="#导出容器-可迁移到其它机器-导入容器" class="headerlink" title="导出容器(可迁移到其它机器)/导入容器"></a>导出容器(可迁移到其它机器)/导入容器</h4><pre><code>[root@tang ~]# docker export tang &gt;/opt/tang.tar            #导出容器
[root@tang ~]# docker rm tang
tang
[root@tang ~]# cat /opt/tang.tar |docker import - tang      #恢复的只是一个镜像，需要通过镜像创建容器
[root@tang ~]# docker images
REPOSITORY           TAG                 IMAGE ID            CREATED             SIZE
tang                 latest              393d449b1ed4        44 seconds ago      192.5 MB


提示：如果在之前那个容器内创建的文件，导出，导入之后容器内的文件是不变的
</code></pre>]]></content>
      
        <categories>
            
            <category> Docker </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Markdown语法大全]]></title>
      <url>http://yoursite.com/2017/03/11/Markdown%E8%AF%AD%E6%B3%95%E5%A4%A7%E5%85%A8/</url>
      <content type="html"><![CDATA[<p><strong>题记：随着Markdown语言的热度不断提升，越来越多的人喜欢使用Markdown这种简洁、便宜的语言来编辑自己的blog、文章。下面笔者就一些简单常用的Markdown语句进行介绍，希望对大家在进行Markdown语言编辑自己的文章时有所帮助。</strong></p>
<a id="more"></a>
<h2 id="1-斜体和粗体"><a href="#1-斜体和粗体" class="headerlink" title="1.斜体和粗体"></a>1.斜体和粗体</h2><blockquote>
<p>代码：</p>
</blockquote>
<pre><code>1. *斜体*或_斜体_
2. **粗体**
3. ***加粗斜体***
</code></pre><blockquote>
<p>显示效果：</p>
</blockquote>
<ul>
<li><em>这是一段斜体</em>   </li>
<li><strong>这是一段粗体</strong>   </li>
<li><strong><em>这是一段加粗斜体</em></strong>   </li>
</ul>
<h2 id="2-分级标题"><a href="#2-分级标题" class="headerlink" title="2.分级标题"></a>2.分级标题</h2><blockquote>
<p>第一种写法： </p>
</blockquote>
<pre><code>1.这是一个一级标题   
2.================
3.   
4. 这是一个一级标题   
5. --------------------------
</code></pre><blockquote>
<p>第二种写法：</p>
</blockquote>
<pre><code># 一级标题
## 二级标题
### 三级标题
#### 四级标题
##### 五级标题
###### 六级标题
</code></pre><h2 id="3-超链接"><a href="#3-超链接" class="headerlink" title="3.超链接"></a>3.超链接</h2><h3 id="行内式"><a href="#行内式" class="headerlink" title="行内式"></a>行内式</h3><blockquote>
<p>代码：</p>
</blockquote>
<pre><code>1.欢迎来到[梵居闹市](http:// blog.leanote.com/freewalk)     
2.  
3.欢迎来到[梵居闹市](http:// blog.leanote.com/freewalk &quot;梵居闹市&quot;)   
</code></pre><blockquote>
<p>显示效果：</p>
</blockquote>
<p>欢迎来到<a href="http://blog.leanote.com/freewalk" target="_blank" rel="external">梵居闹市</a><br>欢迎来到<a href="http://blog.leanote.com/freewalk" title="梵居闹市" target="_blank" rel="external">梵居闹市</a></p>
<h3 id="参考式"><a href="#参考式" class="headerlink" title="参考式"></a>参考式</h3><blockquote>
<p>代码：   </p>
</blockquote>
<pre><code>我经常去的几个网站[Google][1]、[Leanote][2]以及[自己的博客][3]    
[Leanote 笔记][2]是一个不错的[网站][]。     
[1]: http://www. google.com &quot;Google&quot;  
[2]:http://www. leanote.com &quot;Leanote&quot;
[3]:http://http:/ /blog.leanote.com/freewalk &quot;梵居闹市&quot;       
[网站]:http: //http://blog.leanote.com/freewalk
</code></pre><blockquote>
<p>显示效果：    </p>
</blockquote>
<p>我经常去的几个网站<a href="Markdown是一种纯文本标记语言">Google</a>、<a href="http://www.leanote.com" title="Leanote" target="_blank" rel="external">Leanote</a>以及<a href="http://http://blog.leanote.com/freewalk" title="梵居闹市" target="_blank" rel="external">自己的博客</a><br><a href="http://www.leanote.com" title="Leanote" target="_blank" rel="external">Leanote 笔记</a>是一个不错的<a href="http://http://blog.leanote.com/freewalk" target="_blank" rel="external">网站</a>。</p>
<h3 id="自动链接"><a href="#自动链接" class="headerlink" title="自动链接"></a>自动链接</h3><blockquote>
<p>代码： </p>
</blockquote>
<pre><code>&lt;http://example.com/&gt;   
&lt;address@example.com&gt;
</code></pre><blockquote>
<p>显示效果：</p>
</blockquote>
<p><a href="http://example.com/" target="_blank" rel="external">http://example.com/</a><br><a href="&#109;&#x61;&#x69;&#108;&#x74;&#x6f;&#58;&#x61;&#x64;&#100;&#114;&#101;&#x73;&#x73;&#64;&#101;&#120;&#97;&#109;&#112;&#x6c;&#x65;&#x2e;&#99;&#111;&#x6d;">&#x61;&#x64;&#100;&#114;&#101;&#x73;&#x73;&#64;&#101;&#120;&#97;&#109;&#112;&#x6c;&#x65;&#x2e;&#99;&#111;&#x6d;</a></p>
<h2 id="4-锚点"><a href="#4-锚点" class="headerlink" title="4.锚点"></a>4.锚点</h2><blockquote>
<p>代码：  </p>
</blockquote>
<pre><code>跳转到[目录](#index)
</code></pre><blockquote>
<p>显示效果：</p>
</blockquote>
<p>跳转到<a href="#index">目录</a></p>
<h2 id="5-列表"><a href="#5-列表" class="headerlink" title="5.列表"></a>5.列表</h2><h3 id="无序列表"><a href="#无序列表" class="headerlink" title="无序列表"></a>无序列表</h3><ul>
<li><p>使用 *，+，- 表示无序列表。</p>
<blockquote>
<p>代码：  </p>
</blockquote>
<ul>
<li>无序列表项 一</li>
<li>无序列表项 二</li>
<li>无序列表项 三<blockquote>
<p>显示效果：</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<ul>
<li>无序列表项 一</li>
<li>无序列表项 二</li>
<li>无序列表项 三</li>
</ul>
<h3 id="有序列表"><a href="#有序列表" class="headerlink" title="有序列表"></a>有序列表</h3><blockquote>
<p>代码：</p>
</blockquote>
<pre><code>1. 有序列表项 一
2. 有序列表项 二
3. 有序列表项 三
</code></pre><blockquote>
<p>显示效果：</p>
</blockquote>
<ol>
<li>有序列表项 一</li>
<li>有序列表项 二</li>
<li>有序列表项 三</li>
</ol>
<h3 id="列表缩进"><a href="#列表缩进" class="headerlink" title="列表缩进"></a>列表缩进</h3><blockquote>
<p>代码：</p>
</blockquote>
<pre><code>*   轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。
那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。 
软泥上的青荇， 油油的在水底招摇； 在康河的柔波里， 我甘心做一条水草！ 
*   那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。 
寻梦？撑一支长篙， 向青草更青处漫溯； 满载一船星辉， 在星辉斑斓里放歌。 
但我不能放歌， 悄悄是别离的笙箫； 夏虫也为我沉默， 沉默是今晚的康桥！ 
悄悄的我走了， 正如我悄悄的来； 我挥一挥衣袖， 不带走一片云彩
</code></pre><blockquote>
<p>显示效果：</p>
</blockquote>
<ul>
<li>轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。<br>那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。<br>软泥上的青荇， 油油的在水底招摇； 在康河的柔波里， 我甘心做一条水草！ </li>
<li>那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。<br>寻梦？撑一支长篙， 向青草更青处漫溯； 满载一船星辉， 在星辉斑斓里放歌。<br>但我不能放歌， 悄悄是别离的笙箫； 夏虫也为我沉默， 沉默是今晚的康桥！<br>悄悄的我走了， 正如我悄悄的来； 我挥一挥衣袖， 不带走一片云彩</li>
</ul>
<h3 id="包含段落的列表"><a href="#包含段落的列表" class="headerlink" title="包含段落的列表"></a>包含段落的列表</h3><blockquote>
<p>代码：</p>
</blockquote>
<pre><code>*   轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。
那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。 
软泥上的青荇， 油油的在水底招摇； 在康河的柔波里， 我甘心做一条水草！

     那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。 
寻梦？撑一支长篙， 向青草更青处漫溯； 满载一船星辉， 在星辉斑斓里放歌。 
但我不能放歌， 悄悄是别离的笙箫； 夏虫也为我沉默， 沉默是今晚的康桥！


*    悄悄的我走了， 正如我悄悄的来； 我挥一挥衣袖， 不带走一片云彩。
</code></pre><blockquote>
<p>显示效果：</p>
</blockquote>
<ul>
<li><p>轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。<br>那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。<br>软泥上的青荇， 油油的在水底招摇； 在康河的柔波里， 我甘心做一条水草！</p>
<p> 那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。<br>寻梦？撑一支长篙， 向青草更青处漫溯； 满载一船星辉， 在星辉斑斓里放歌。<br>但我不能放歌， 悄悄是别离的笙箫； 夏虫也为我沉默， 沉默是今晚的康桥！ </p>
</li>
<li>悄悄的我走了， 正如我悄悄的来； 我挥一挥衣袖， 不带走一片云彩。</li>
</ul>
<h3 id="包含引用的列表"><a href="#包含引用的列表" class="headerlink" title="包含引用的列表"></a>包含引用的列表</h3><blockquote>
<p>代码：</p>
</blockquote>
<pre><code>*  阅读的方法:（一个空格）
    &gt; 打开书本。
    &gt; 打开电灯。
</code></pre><blockquote>
<p>显示效果：</p>
</blockquote>
<ul>
<li>阅读的方法:<blockquote>
<p>打开书本。<br>打开电灯。</p>
</blockquote>
</li>
</ul>
<h3 id="包含代码区块的引用"><a href="#包含代码区块的引用" class="headerlink" title="包含代码区块的引用"></a>包含代码区块的引用</h3><p><strong>语法说明：</strong><br>如果要放代码区块的话，该区块就需要缩进两次，也就是 8 个空格或是 2 个制表符：   </p>
<ul>
<li><p>一列表项包含一个列表区块： </p>
<pre><code>&lt;代码写在这&gt;
</code></pre></li>
</ul>
<h3 id="一个特殊情况"><a href="#一个特殊情况" class="headerlink" title="一个特殊情况"></a>一个特殊情况</h3><p>在特殊情况下，项目列表很可能会不小心产生，像是下面这样的写法：     </p>
<pre><code>1986. What a great season.
</code></pre><p>会显示成：     </p>
<ol>
<li>What a great season.</li>
</ol>
<p>换句话说，也就是在行首出现数字-句点-空白，要避免这样的状况，你可以在句点前面加上反斜杠：      </p>
<pre><code>1986\. What a great season.
</code></pre><p>会显示成：<br>1986. What a great season.</p>
<h2 id="6-引用"><a href="#6-引用" class="headerlink" title="6. 引用"></a>6. 引用</h2><ul>
<li><p>代码：</p>
<pre><code>&gt; 这是一个有两段文字的引用,
&gt; 无意义的占行文字1.
&gt; 无意义的占行文字2.
&gt; 
&gt; 无意义的占行文字3.
&gt; 无意义的占行文字4
</code></pre></li>
<li>显示效果：  </li>
</ul>
<blockquote>
<p>这是一个有两段文字的引用,<br>无意义的占行文字1.<br>无意义的占行文字2.     </p>
<p>无意义的占行文字3.<br>无意义的占行文字4.     </p>
</blockquote>
<h3 id="引用的多层嵌套"><a href="#引用的多层嵌套" class="headerlink" title="引用的多层嵌套"></a>引用的多层嵌套</h3><ul>
<li><p>代码：</p>
<pre><code>&gt;&gt;&gt; 请问 Markdwon 怎么用？ - 小白

&gt;&gt; 自己看教程！ - 愤青

&gt; 教程在哪？ - 小白
</code></pre></li>
<li>显示效果：</li>
</ul>
<blockquote>
<blockquote>
<blockquote>
<p>请问 Markdwon 怎么用？ - 小白</p>
</blockquote>
<p>自己看教程！ - 愤青</p>
</blockquote>
<p>教程在哪？ - 小白</p>
</blockquote>
<h3 id="引用其它要素"><a href="#引用其它要素" class="headerlink" title="引用其它要素"></a>引用其它要素</h3><ul>
<li><p>代码：</p>
<pre><code>&gt; 1.   这是第一行列表项。
&gt; 2.   这是第二行列表项。
&gt; 
&gt; 给出一些例子代码：
&gt; 
&gt;     return shell_exec(&quot;echo $input | $markdown_script&quot;);
</code></pre></li>
<li>显示效果：</li>
</ul>
<blockquote>
<ol>
<li>这是第一行列表项。</li>
<li>这是第二行列表项。</li>
</ol>
<p>给出一些例子代码：</p>
<pre><code>return shell_exec(&quot;echo $input | $markdown_script&quot;);
</code></pre></blockquote>
<h2 id="7-插入图像"><a href="#7-插入图像" class="headerlink" title="7. 插入图像"></a>7. 插入图像</h2><h3 id="行内式-1"><a href="#行内式-1" class="headerlink" title="行内式"></a>行内式</h3><ul>
<li><p>代码： </p>
<pre><code>高圆圆： 
![高圆圆](ht tp://pic2016.5442.com:82/2015/1117/16/7.jpg%21960.jpg &quot;高圆圆&quot;)
</code></pre></li>
</ul>
<ul>
<li>显示效果</li>
</ul>
<p>高圆圆：<br><img src="http://pic2016.5442.com:82/2015/1117/16/7.jpg%21960.jpg" alt="高圆圆" title="高圆圆"></p>
<h2 id="8-内容目录"><a href="#8-内容目录" class="headerlink" title="8. 内容目录"></a>8. 内容目录</h2><ul>
<li>markdownpad居然不支持该语法，我就呵呵了.<blockquote>
<p>代码：</p>
</blockquote>
</li>
</ul>
<pre><code>[TOC]0.目录   
[TOC]1. 斜体和粗体          
[TOC]2. 分级标题
[TOC]3. 超链接
[TOC]     行内式
[TOC]     参考式
[TOC]    自动链接
[TOC]4. 锚点
</code></pre><h2 id="9-注脚"><a href="#9-注脚" class="headerlink" title="9. 注脚"></a>9. 注脚</h2><blockquote>
<p>代码：</p>
</blockquote>
<pre><code>使用 Markdown[1]可以效率的书写文档,你可以使用 Leanote[Le] 编辑器进行书写。

[1]:Markdown是一种纯文本标记语言

[Le]:开源笔记平台，支持Markdown和笔记直接发为博文
</code></pre><blockquote>
<p>显示效果：</p>
</blockquote>
<p>使用 Markdown<a href="Markdown是一种纯文本标记语言">1</a>可以效率的书写文档,你可以使用 Leanote<a href="开源笔记平台，支持Markdown和笔记直接发为博文">Le</a> 编辑器进行书写。       </p>
<p><br></p>
<p><br></p>
<p>   <strong>原文链接：<a href="http://blog.leanote.com/post/freewalk/Markdown-语法手册" target="_blank" rel="external">http://blog.leanote.com/post/freewalk/Markdown-语法手册</a></strong></p>
]]></content>
      
        <categories>
            
            <category> 博客搭建 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 博客搭建 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hexo常用命令]]></title>
      <url>http://yoursite.com/2017/03/11/Hexo%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
      <content type="html"><![CDATA[<p><strong><em>Hexo部署步骤</em></strong></p>
<pre><code>npm install    
npm install hexo-deployer-git --save   
hexo new &quot;新页面&quot;    
hexo clean   
hexo generate
hexo deploy    
</code></pre><a id="more"></a>
<p> <br></p>
<p><strong><em>Hexo常用命令</em></strong></p>
<pre><code>hexo new &quot;postName&quot;                 #新建文章     
hexo new page &quot;pageName&quot;             #新建页面   
hexo generate                         #生成静态页面至public目录    
hexo server                            #开启预览访问端口（默认端口4000，&apos;ctrl + c&apos;关闭server）    
hexo deploy                         #将.deploy目录部署到GitHub       
hexo help                             #查看帮助
hexo version                        #查看Hexo的版本
</code></pre><p><br></p>
<p><strong><em>复合命令</em></strong></p>
<pre><code>hexo deploy -g #生成加部署   
hexo server -g #生成加预览    
</code></pre><p>命令的简写为：</p>
<pre><code>hexo n == hexo new    
hexo g == hexo generate   
hexo s == hexo server   
hexo d == hexo deploy   
</code></pre>]]></content>
      
        <categories>
            
            <category> 博客搭建 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 博客搭建 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MongoDB（1）--简介]]></title>
      <url>http://yoursite.com/2017/01/02/MongoDB%EF%BC%881%EF%BC%89--%E7%AE%80%E4%BB%8B/</url>
      <content type="html"><![CDATA[<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>MongoDB 是一个跨平台的，面向文档的开源数据库，并领先的 NoSQL 数据库。 MongoDB是由c++语言编写。提供高性能，高可用性和可扩展性方便。 MongoDB 工作在收集和文件的概念。</p>
<h3 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h3><p>数据库是一个物理容器集合。每个数据库都有自己的一套文件系统上的文件。一个单一的MongoDB服务器通常有多个数据库。</p>
<a id="more"></a>
<h3 id="集合"><a href="#集合" class="headerlink" title="集合"></a>集合</h3><p>集合是一组MongoDB的文档。它相当于一个RDBMS表。收集存在于一个单一的数据库。集合不执行模式。集合内的文档可以有不同的领域。通常情况下，一个集合中的所有文件是相同或相关的目的。 </p>
<h3 id="文档"><a href="#文档" class="headerlink" title="文档"></a>文档</h3><p>文档是一组键 - 值对。文件动态模式。动态模式是指，在相同集合中的文档不需要具有相同的字段或结构组的公共字段的集合的文档，可以容纳不同类型的数据。</p>
<p>下面给出的表显示RDBMS术语使用 MongoDB 的关系<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">RDBMS	        MongoDB</div><div class="line">Database    	Database</div><div class="line">Table	        Collection</div><div class="line">Tuple/Row	    Document</div><div class="line">column	        Field</div><div class="line">Table Join  	Embedded Documents</div><div class="line">Primary Key	    Primary Key (Default key _id provided by mongodb itself)</div><div class="line">    数据库服务器和客户端</div><div class="line">Mysqld/Oracle	mongod</div><div class="line">mysql/sqlplus	mongo</div></pre></td></tr></table></figure></p>
<p>示例文档<br>下面给出的示例显示了一个博客网站，这简直是一个逗号分隔的键值对文档结构。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">   _id: ObjectId(7df78ad8902c)</div><div class="line">   title: &apos;MongoDB Overview&apos;, </div><div class="line">   description: &apos;MongoDB is no sql database&apos;,</div><div class="line">   by: &apos;yiibai.com&apos;,</div><div class="line">   url: &apos;http://www.yiibai.com&apos;,</div><div class="line">   tags: [&apos;mongodb&apos;, &apos;database&apos;, &apos;NoSQL&apos;],</div><div class="line">   likes: 100, </div><div class="line">   comments: [	</div><div class="line">      &#123;</div><div class="line">         user:&apos;user1&apos;,</div><div class="line">         message: &apos;My first comment&apos;,</div><div class="line">         dateCreated: new Date(2011,1,20,2,15),</div><div class="line">         like: 0 </div><div class="line">      &#125;,</div><div class="line">      &#123;</div><div class="line">         user:&apos;user2&apos;,</div><div class="line">         message: &apos;My second comments&apos;,</div><div class="line">         dateCreated: new Date(2011,1,25,7,45),</div><div class="line">         like: 5</div><div class="line">      &#125;</div><div class="line">   ]</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>_id是一个12字节的十六进制数，保证每一份文件的唯一性。您可以提供_id同时插入文档。如果没有提供，那么MongoDB的每个文档提供了一个独特的ID。这12个字节，前4个字节为当前时间戳，未来3个字节的机器ID，接下来的2个字节的进程id MongoDB的服务器及剩余3个字节是简单的增量值。</p>
<h3 id="MongoDB比RDBMS的优势"><a href="#MongoDB比RDBMS的优势" class="headerlink" title="MongoDB比RDBMS的优势"></a>MongoDB比RDBMS的优势</h3><p>1.架构：MongoDB是文档型数据库，其中一个集合保存不同的不同的文件。字段的数量，内容和该文件的大小可以是不同于从一个文件复制到另一个。<br>2.一个单一的对象，结构相对清晰<br>3.没有复杂的连接<br>4.深查询能力。 MongoDB支持动态查询使用基于文档的查询语言，如SQL几乎一样强大的文件<br>5.调优<br>6.易于规模化：MongoDB是易于扩展<br>7.不需要数据库对象的应用程序对象转换/映射<br>8.使用内部存储器存储（窗口）工作组，从而实现更快的数据存取</p>
<h3 id="为什么要使用MongoDB"><a href="#为什么要使用MongoDB" class="headerlink" title="为什么要使用MongoDB"></a>为什么要使用MongoDB</h3><p>1.JSON风格文件的形式，面向文档存储：数据存储<br>2.对任何属性可索引<br>3.复制和高可用性<br>4.自动分片<br>5.丰富的查询<br>6.快速就地更新<br>7.MongoDB的专业技术支持</p>
<h3 id="MongoDB应用领域"><a href="#MongoDB应用领域" class="headerlink" title="MongoDB应用领域"></a>MongoDB应用领域</h3><p>1.大数据<br>2.内容管理和交付<br>3.移动和社交基础设施<br>5.用户数据管理<br>6.数据平台</p>
]]></content>
      
        <categories>
            
            <category> MongoDB </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MongoDB </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[运维与自动化发展(1)]]></title>
      <url>http://yoursite.com/2017/01/01/%E8%BF%90%E7%BB%B4%E4%B8%8E%E8%87%AA%E5%8A%A8%E5%8C%96%E5%8F%91%E5%B1%95/</url>
      <content type="html"><![CDATA[<h3 id="一、运维学习和发展的一个线路"><a href="#一、运维学习和发展的一个线路" class="headerlink" title="一、运维学习和发展的一个线路"></a>一、运维学习和发展的一个线路</h3><pre><code>1.搭建服务（部署并运行起来）

2.用好服务（监控、管理、优化）
</code></pre><a id="more"></a>
<pre><code>3.自动化（服务直接的关联和协同工作）

4.产品设计（如何设计一个监控系统）

云计算的核心竞争力是运维！

系统架构师（还有偏管理系统架构师）：网络 系统 数据库 开发 云计算 自动化 运维管理 服务管理 项目管理 测试 业务
==比较难学的开发和业务（相对于运维来说）


专注于某一领域：资深、科学家
</code></pre><h3 id="二、运维知识体系"><a href="#二、运维知识体系" class="headerlink" title="二、运维知识体系"></a>二、运维知识体系</h3><pre><code>赵班长运维知识体系：https://www.unixhot.com/page/ops


运维工作内容分类：

监控运维（7X24运维值班、故障处理）
应用运维（业务熟悉、服务部署、项目上线、业务部署、版本管理、灰度发布、日志收集、应用监控）



安全运维（整体的安全方案、规范、漏洞检测、安全防护等）


系统运维（架构层面的分布式缓存、分布式文件系统、环境规划（测试、开发、生产）、架构设计、性能优化）
基础服务运维（包含运维开发）（内部DNS、负载均衡、系统监控、资产管理、运维平台）


基础设施运维（系统初始化、网络维护）
机房运维（负责设备上下架、巡检、保修、硬件监控）
</code></pre><h3 id="三、运维自动化发展"><a href="#三、运维自动化发展" class="headerlink" title="三、运维自动化发展"></a>三、运维自动化发展</h3><pre><code>发展层级：
    智能化
    服务化、api化
    Web化、平台化
    标准化、工具化
</code></pre><h4 id="1-标准化"><a href="#1-标准化" class="headerlink" title="1.标准化"></a>1.标准化</h4><pre><code>物理设备层面：
    1.服务器标签化、设备负责人、设备采购详情、设备摆放标准（例如：负载均衡两台机器不能放同一机柜）。
    2.网络划分、远程控制卡、网卡端口
    3.服务器机型、硬盘、内存统一。根据业务分类
    4.资产命名规范、编号规范、类型规范
    5.监控标准

操作系统层面：
    1.操作系统版本
    2.系统初始化（DNS、NTP、内存参数调优、rsyslog、主机名规范）
    3.基础Agent配备（zabbix Agent、logstach Agent、saltstack monitor）
    4.系统监控标准（cpu、内存、硬盘、网络、进程）

应用服务层面：
    1.Web服务器选型（apache、nginx）
    2.进程启动用户、端口监听规范、日志收集规范（访问日志、错误日志、运行日志）
    3.配置管理（配置文件规范、脚本规范）
    4.架构规范（nginx+keepalived、lvs+keepalived等等）
    5.部署规范（位置、包命名等）

运维操作层面：
    1.机房巡检流程（周期、内容、报修流程）
    2.业务部署流程（先测试、后生成。回滚）
    3.故障处理流程（紧急处理、故障升级）
    4.工作日志标准（如何编写工作日志）
    5.业务上线流程（1.项目发起人 2.系统安装 3.部署nginx 4.解析域名 5.测试 6.加监控 7.备份）
    6.业务下线流程（1.谁发起 2.数据如何处理 3.服务器回收 4.系统是否重装）
    7.运维安全规范（密码复杂度、更改周期、vpn使用规范、服务器登入规范）



    标准化（规范化、流程化、文档化） 目标：文档化
</code></pre><h4 id="2-工具化"><a href="#2-工具化" class="headerlink" title="2.工具化"></a>2.工具化</h4><pre><code>1.shell脚本（功能性（流程）、坚持性、报表性）
2.开源工具：Zabbix ELKstack SaltStack  cobbler

目标：
    1.促进标准化的实施
    2.将重复的操作，简单化
    3.将多次操作，流程化
    4.减少人为操作的低效和降低故障率

工具化和标准化是好基友！！！

痛点：
    1.你至少要ssh到服务器执行，可能犯错
    2.多个脚本有执行顺序的时候，可能犯错
    3.权限不好管理，日志没法统计。
    4.无法避免手工操作

    例子：比如某天我们要对一台数据库从库进行版本升级。那么要求进行评估：

        停机的影响：3:00晚上有定时任务链接该数据库，做数据报表统计。

        1.凌晨3:00我们所有系统的定时任务有哪些 crontab
        2.这些croneab哪些连接我们要停止的从库
        3.哪些可以停，哪些不能停（修改到主库），哪些可以后补
        4.这些需要后补的脚本哪个业务，谁加的，什么时候加的
</code></pre><h4 id="3-Web化（运维操作平台）"><a href="#3-Web化（运维操作平台）" class="headerlink" title="3.Web化（运维操作平台）"></a>3.Web化（运维操作平台）</h4><pre><code>1.做成Web界面
2.权限控制
3.日志记录
4.弱化流程
5.不用ssh到服务器，减少人为操作造成的故障
</code></pre><h4 id="4-服务化（API化）"><a href="#4-服务化（API化）" class="headerlink" title="4.服务化（API化）"></a>4.服务化（API化）</h4><pre><code>DNS Web管理             bind-DLZ   dns-api
负载均衡Web管理         slb-api
Job管理平台             job-api
监控Web管理  zabbix     zabbix-api
操作系统安装平台        cobbler-api
部署平台                deploy-api
配置管理平台            saltstack-api
自动化测试平台          test-api


1.调用cobbler-api安装操作系统
2.调用saltstack-api进行系统初始化
3.调用dns-api解析主机名
4.调用zabbix-api将新上线机器加上监控
5.再次调用saltstack-api部署软件（安装Nginx+php）
6.调用deploy-api     将当前版本的代码部署到服务器上
7.调用test-api 测试当前服务器运行十分正常
8.调用slb-api 将该节点加入集群
</code></pre><h4 id="5-智能化"><a href="#5-智能化" class="headerlink" title="5.智能化"></a>5.智能化</h4><blockquote>
<p>智能化的自动化扩容、缩容、服务降级、故障自愈</p>
</blockquote>
<pre><code>触发机制--&gt;决策系统（决策树）


一、自动化扩容

1.zabbix触发Action
触发：
    1.当某个集群的访问量超过最大的支撑量，比如10000
        1.1.cpu使用率达到多少
    2.并持续5分钟
    3.不是攻击
    4.资源池有可用资源
        4.1.当前网络带宽使用率
        4.2.如果公有云-钱够不够
    5.当前后端服务支撑量是否超过阈值，如果超过应该后端先扩容
    6.数据库是否可以支撑当前并发
    7.当前自动化扩展队列，是否有正在扩容的节点
    8.其它业务相关的

决策之前：先判断buffer是否有最近X小时，已经移除的之前创建的虚拟机。并查询软件版本是否和当前一致，如果一致，跳过2 3 4步骤。如果不一致，跳过2 3步骤


2.Openstack 创建虚拟机

3.Saltstack配置环境---监控

4.部署系统当前代码

5.测试服务是否可用（注意间隔和次数）

6.加入集群

7.通知（短信、邮件、花费时间）


二、自动化缩容

1.触发条件和决策
2.从集群中移除节点---先关闭监控--移除
3.通知
4.移除的节点存放在buffer里面
5.buffer里面超过一天的虚拟机，自动关闭，存放于某去
6.某区的虚拟机，每7天清理删除


1.部署openstack
2.在openstack上创建虚拟机
3.在虚拟机上部署Mesos+docker+Marathon
4.自动化创建Docker容器进行自动化扩容
</code></pre><h3 id="四-基于ITIL的运维管理体系"><a href="#四-基于ITIL的运维管理体系" class="headerlink" title="四. 基于ITIL的运维管理体系"></a>四. 基于ITIL的运维管理体系</h3><h4 id="1-ITIL-简介"><a href="#1-ITIL-简介" class="headerlink" title="1. ITIL 简介"></a>1. ITIL 简介</h4><pre><code>什么是服务：
    服务是向客户提供的一种手段，使客户不用承担特定的成本和风险就可以获得所期望的结果。

什么是服务管理：
    服务管理是一套特定的组织能力，以服务的形式为客户提供价值

ITSM 和ITIL 的关系：
    1.现有ITSM，后有ITIL。
    2.因为ITIL，ITSM得到关注和发扬
    3.ITIL是ITIM的最佳时间.ITIL为ITSM创建了一组核心流程和专有名词
    4.ITIL并不是ITSM的全部，ITIL只是告诉我们，什么该做，但没有说具体该怎么做。而对ITSM而言，这些都是ITSM的范围。

ITIL是：
    ITIL即IT基础架构库（Information Technology Infrastructure Library）。

    英国商务办公司从20世纪80年代开始开发的一套IT管理方法。

    已成为事实上的行业标准，并以其为中心在全球形成了完整的产业。

    任何单位和个人都可以免费试用的“公共框架”。

    实际上是一系由所谓“最佳实践”形成图书。

    一个可以直接使用的标准。

ITIL的目的：
    1.将IT管理工作标准化，模式化，减少人为误操作带来的隐患
    2.通过服务目录，服务报告，告诉业务部门，我们可以做什么，做了什么
    3.通过系列流程，只是库减轻对英雄式工程师的以来，把经验积累下来。
    4.通过对流程的管控，减少成本，降低风险，提供客户满意度

ITIL和ISO 20000
    ITIL自发布以来，一直被业界认为是IT服务管理领域事实上的管理标准，直到2000年11月，英国标准协会（BSI）正式发布了以ITIL为核心的国家标准BS15000；
    随后，2005年5月，国际标准化组织（ISO）快速通道的方式批准通过了ISO2000的标准协议，并于12月15日正式发布了ISO20000标准。

ITIL和ISO20000区别

ITIL                                                ISO2000
提供最佳实践指导                                提供衡量ITSM的指标
没有固定的能力衡量指标                          全球统一
对人员进行认证                                  对机构进行认证
咨询机构提供他们眼中的ITSM成熟度结果              关注于服务提供的独立认证，从IT服务管理体系的角度出发

ITSM内容
    管什么（管理对象）
    怎么管（管理方法）
    管得咋样（成熟度）

IT service CMM

初始级：
    被动相应，没有文档记录，几乎没有过程，是经过定义的 ；
    各项目经验无法重用，以来与个人的努力和永雄主义

可重复级：
    建立了基本的服务管理过程；
    所有项目有默认的规则，但未文档化，系统化；
    产品或服务化无清晰的目标和策略；

定义级：
    已将IT服务过程文档化，标准化，并综合成标准服务过程；
    根据客户需求调整服务产品和服务战略；
    适当的工具和信息报告；

管理级：
    受监督、测量的IT服务体系；
    根据业务战略调整服务体系；

优化级（PDCA）：
    持续改进的IT服务体系；
    IT与业务指标建立关系；
    IT与业务协作改进流程；


成为运维经理：
    1.技术，运维只是体系
    2.服务管理ITIL
      项目管理PMP
    3.做人
</code></pre><h3 id="五-ITIL-服务运营"><a href="#五-ITIL-服务运营" class="headerlink" title="五. ITIL 服务运营"></a>五. ITIL 服务运营</h3><pre><code>ITIL v3 将ITIL理论分成五部分：
    1.服务战略
    2.服务设计
    3.服务转换
    4.服务运营
    5.持续服务改进
</code></pre><p>ITIL v3 核心模块<br><img src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1492912887&amp;di=7a98f884c0ce6d774f12c86b44c38cd2&amp;imgtype=jpg&amp;er=1&amp;src=http%3A%2F%2Fgroup.vsharing.com%2FUploads%2FUserDirs%2F3%2F1000%2F399697%2FITIL%2520V3%25E4%25B8%258EITIL%2520V2%25E7%259A%2584%25E4%25BB%25B7%25E5%2580%25BC%25E5%25B7%25AE%25E5%25BC%2582%25EF%25BC%2588%25E5%259B%25BE%25E4%25B8%2580%25EF%25BC%2589.jpg" alt="image"></p>
<pre><code>服务运营：
SLA：服务级别协议
OLA：运营水平协议
CSF：关键成功因素
KPI：关键绩效指标

客户要求——SLA——OLA——CSF——KPI——月报

服务台：

    作为IT服务支持团队的一线支持，其首要目标是为用户和IT组织之间建立沟通的纽带；
    确保用户的故障请求和服务请求能够以最快的速度得到满足，并确保用户满意。

服务台作用：
    1.路由器
    2.监视器
    3.单一联系点
    4.客服窗口
    5.广播台
    6.过滤器
</code></pre><h3 id="六-服务运营-故障管理"><a href="#六-服务运营-故障管理" class="headerlink" title="六. 服务运营-故障管理"></a>六. 服务运营-故障管理</h3><pre><code>1.故障管理的目标：

    故障管理的目标是尽可能快的恢复正常的服务运营，将故障对业务运营的负面影响减少到最低。
    并确保到达最好的服务质量和可用性水平。

2.故障优先级：
--紧急度
--影响度



3.故障输入输出：

    故障管理流程输入
        故障请求提交
        故障单记录模板
        故障单填写模板
        故障分类规则
        故障优先级确定规则
        故障升级规则
        故障处理时间规则
        故障关闭规则

    故障管理流程输出：
        故障历史记录
        故障分类汇总统计表
        故障处理用户满意度

4.故障管理的绩效指标（KPI）

    一线支持解决的事故百分比
    无升级的平均呼叫时长
    分配错误的事故百分比
    在目标时间之内，按照优先级解决的事故百分比
    二线支持平均响应时间
    事故平均解决时间
    重新分配的事故百分比
    归类错误的事故百分比
    绕过一线支持的呼叫百分比
    客户满意度
    服务请求呼叫百分比
    一次解决正确的事故百分比
    主动解决的事故百分比

5.服务运营-问题管理

问题管理的目标：
    问题管理的主要目标是预防问题产生及由此引发的故障，消除重复的出现故障，并对不能预防的故障尽量减低其对业务的影响

问题管理对业务的价值：

    提供IT服务的可用性
    提高业务和IT人员的生成效率
    减少无效的规避措施或修补措施的开支
    减少在救火或解决重复故障方面的成本
    有助于知识库的积累
</code></pre>]]></content>
      
        <categories>
            
            <category> 运维自动化 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 运维自动化 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Linux下防御DDOS攻击的操作梳理]]></title>
      <url>http://yoursite.com/2016/12/11/Linux%E4%B8%8B%E9%98%B2%E5%BE%A1DDOS%E6%94%BB%E5%87%BB%E7%9A%84%E6%93%8D%E4%BD%9C%E6%A2%B3%E7%90%86/</url>
      <content type="html"><![CDATA[<h3 id="DDOS介绍"><a href="#DDOS介绍" class="headerlink" title="DDOS介绍"></a>DDOS介绍</h3><p>DDOS的全称是Distributed Denial of Service，即”分布式拒绝服务攻击”，是指击者利用大量“肉鸡”对攻击目标发动大量的正常或非正常请求、耗尽目标主机资源或网络资源，从而使被攻击的主机不能为合法用户提供服务。</p>
<p>DDOS攻击的本质是：<br>利用木桶原理，寻找利用系统应用的瓶颈；阻塞和耗尽；当前问题：用户的带宽小于攻击的规模，噪声访问带宽成为木桶的短板。</p>
<p>可以参考下面的例子理解下DDOS攻击。<br>1）某饭店可以容纳100人同时就餐，某日有个商家恶意竞争，雇佣了200人来这个饭店坐着不吃不喝，导致饭店满满当当无法正常营业。（DDOS攻击成功）<br>2）老板当即大怒，派人把不吃不喝影响正常营业的人全都轰了出去，且不再让他们进来捣乱，饭店恢复了正常营业。（添加规则和黑名单进行DDOS防御，防御成功）<br>3）主动攻击的商家心存不满，这次请了五千人逐批次来捣乱，导致该饭店再次无法正常营业。（增加DDOS流量，改变攻击方式）<br>4）饭店把那些捣乱的人轰出去只后，另一批接踵而来。此时老板将饭店营业规模扩大，该饭店可同时容纳1万人就餐，5000人同时来捣乱饭店营业也不会受到影响。（增加硬防与其抗衡）</p>
<p>DDOS攻击只不过是一个概称，其下有各种攻击方式，比如:”CC攻击、SYN攻击、NTP攻击、TCP攻击、DNS攻击等等”，现在DDOS发展变得越来越可怕，NTP服务放大攻击渐渐成为主流了，这意味着可以将每秒的攻击流量放大几百倍，比如每秒1G的SYN碎片攻击换成NTP放大攻击，就成为了200G或者更多。</p>
<a id="more"></a>
<h4 id="NTP放大攻击"><a href="#NTP放大攻击" class="headerlink" title="NTP放大攻击"></a>NTP放大攻击</h4><p>什么是NTP服务？<br>网络时间协议NTP（Network Time Protocol）是用于互联网中时间同步的标准互联网协议。NTP服务器通过NTP服务向网络上的计算机或其他设备提供标准的授时服务，以保证这些服务系统的时钟能够同步。通常NTP服务使用UDP 123端口提供标准服务。</p>
<p>什么是NTP服务放大攻击？<br>标准NTP 服务提供了一个 monlist查询功能，也被称为MON_GETLIST，该功能主要用于监控 NTP 服务器的服务状况，当用户端向NTP服务提交monlist查询时，NTP 服务器会向查询端返回与NTP 服务器进行过时间同步的最后 600 个客户端的 IP，响应包按照每 6 个 IP 进行分割，最多有 100 个响应包。由于NTP服务使用UDP协议，攻击者可以伪造源发地址向NTP服务进行monlist查询，这将导致NTP服务器向被伪造的目标发送大量的UDP数据包，理论上这种恶意导向的攻击流量可以放大到伪造查询流量的100倍。</p>
<p>NTP是用UDP传输的，所以可以伪造源地址。NTP协议中有一类查询指令，用短小的指令即可令服务器返回很长的信息，放大攻击就是基于这类指令的。<br>比如：<br>小明以吴一帆的名义问李雷”我们班有哪些人？” ,李雷就回答吴一帆说”有谁谁谁和谁谁谁……”””(几百字),那么小明就以8个字的成本，令吴一帆收到了几百字的信息，所以叫做放大攻击。<br>(也就是说：对方服务器是个话唠，你以小明的身份问他一个问题，他回答小明一千句，结果小明崩溃了）</p>
<p>网络上一般NTP服务器都有很大的带宽，攻击者可能只需要1Mbps的上传带宽欺骗NTP服务器，即可给目标服务器带来几百上千Mbps的攻击流量，达到借刀杀人的效果。<br>所以现在新的ntpd已经可以通过配置文件，关掉除时间同步以外的查询功能。而时间同步的查询和返回大小相同(没记错的话)，所以没办法用作放大攻击。</p>
<p>如何查看是否遭受NTP放大攻击？<br>如果网络上检测到大流量的UDP 123端口的数据，就可以确认正在遭受此类攻击。</p>
<p>如何防范NTP放大攻击？<br>1)升级服务程序版本<br>将系统中的NTP服务升级到 ntpd 4.2.7p26 或之后的版本，因为 ntpd 4.2.7p26 版本后，服务默认是关闭monlist查询功能的。</p>
<p>2)关闭服务的monlist查询功能：<br>首先查询问题主机的REQ_MON_GETLIST和REQ_MON_GETLIST_1请求是否可用。具体操作方法：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"># ntpq -c rv&lt;localhost/remotehost&gt;</div><div class="line"># ntpdc -c sysinfo&lt;localhost/remotehost&gt;</div><div class="line"># ntpdc -n -c monlist&lt;localhost/remotehost&gt;</div></pre></td></tr></table></figure></p>
<p>如果上述功能可用，可尝试通过修改ntp.conf文件解决问题，具体操作建议是在上述配置文件中增加下面的配置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">IPV4: restrict default kod nomodify notrap nopeer noquery</div><div class="line">IPv6: restrict -6 default kod nomodify notrap nopeer noquery</div></pre></td></tr></table></figure></p>
<p>允许发起时间同步的IP，与本服务器进行时间同步，但是不允许修改ntp服务信息，也不允许查询服务器的状态信息（如monlist）*/</p>
<p>另外，还可以配置限制访问命令，如：</p>
<p><code>restrict default noquery</code>   #允许普通的请求者进行时间同步，但是不允许查询ntp服务信息*/</p>
<p>修改并保存配置文件之后，请重启ntpd服务。</p>
<h3 id="重大的DDOS攻击案例"><a href="#重大的DDOS攻击案例" class="headerlink" title="重大的DDOS攻击案例"></a>重大的DDOS攻击案例</h3><p>）2000年2月，包括雅虎、CNN、亚马逊、eBay、<a href="http://Buy.com、ZDNet，以及E*Trade和Datek等网站均遭受到了DDOS攻击，并致使部分网站瘫痪。" target="_blank" rel="external">http://Buy.com、ZDNet，以及E*Trade和Datek等网站均遭受到了DDOS攻击，并致使部分网站瘫痪。</a><br>2）2007年5月，爱沙尼亚三周内遭遇三轮DDOS攻击,总统府、议会、几乎全部政府部门、主要政党、主要媒体和2家大银行和通讯公司的网站均陷入瘫痪，为此北约顶级反网络恐怖主义专家前往该国救援。<br>3）2009年519断网事件导致南方六省运营商服务器全部崩溃，电信在南方六省的网络基本瘫痪。2009年7月，韩国主要网站三天内遭遇三轮猛烈的DDOS攻击，韩国宣布提前成立网络司令部。<br>4）比较著名的案例还有有：<br>  全球三大游戏平台：暴雪战网、Valve Steam和EA Origin遭到大规模DDoS攻击，致使大批玩家无法登录与进行游戏。随后名为DERP的黑客组织声称对此次大规模的DDoS攻击行动负责。</p>
<h3 id="DDOS攻击的简单防护措施"><a href="#DDOS攻击的简单防护措施" class="headerlink" title="DDOS攻击的简单防护措施"></a>DDOS攻击的简单防护措施</h3><p>1）关闭不必要的服务和端口；<br>2）限制同一时间内打开的syn半连接数目；<br>3）缩短syn半连接的超时时间；<br>4）及时安装系统补丁；<br>5）禁止对主机非开放服务的访问；<br>6）启用防火墙防DDOS属性。硬件防火墙价格比较昂贵，可以考虑利用Linux系统本身提供的防火墙功能来防御。<br>7）另外也可以安装相应的防护软件，这里强烈建议安装安全狗软件,防护性能不错，并且免费。<br>8）购买DDOS防御产品，比如阿里云盾的DDOS防御中的高防IP，这个使用起来，效果也很给力。</p>
<h3 id="linux下预防DDOS攻击的操作"><a href="#linux下预防DDOS攻击的操作" class="headerlink" title="linux下预防DDOS攻击的操作"></a>linux下预防DDOS攻击的操作</h3><p>Linux服务器在运行过程中可能会受到黑客攻击，常见的攻击方式有SYN，DDOS等。<br>通过更换IP，查找被攻击的站点可能避开攻击，但是中断服务的时间比较长。比较彻底的解决方法是添置硬件防火墙，但是硬件防火墙价格比较昂贵。可以考虑利用Linux系统本身提供的防火墙功能来防御。<br>SYN攻击是利用TCP/IP协议3次握手的原理，发送大量的建立连接的网络包，但不实际建立连接，最终导致被攻击服务器的网络队列被占满，无法被正常用户访问。<br>Linux内核提供了若干SYN相关的配置，加大SYN队列长度可以容纳更多等待连接的网络连接数，打开SYN Cookie功能可以阻止部分SYN攻击，降低重试次数也有一定效果。<br>而DDOS则是通过使网络过载来干扰甚至阻断正常的网络通讯，通过向服务器提交大量请求，使服务器超负荷，阻断某一用户访问服务器阻断某服务与特定系统或个人的通讯。可以通过配置防火墙或者使用脚本工具来防范DDOS攻击；</p>
<h4 id="优化sysctl内核参数"><a href="#优化sysctl内核参数" class="headerlink" title="优化sysctl内核参数"></a>优化sysctl内核参数</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">[root@test3-237 ~]# vim /etc/sysctl.conf</div><div class="line">......</div><div class="line">net.ipv4.tcp_max_syn_backlog = 4096      #表示SYN队列的长度，加大队列长度可以容纳更多等待连接的网络连接数</div><div class="line">net.ipv4.tcp_syncookies = 1              #表示开启SYN Cookies功能。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭，1表示打开；</div><div class="line">net.ipv4.tcp_synack_retries = 2          #下面这两行表示定义SYN重试次数</div><div class="line">net.ipv4.tcp_syn_retries = 2      </div><div class="line"> </div><div class="line">#提高TCP连接能力</div><div class="line">net.ipv4.tcp_rmem = 32768</div><div class="line">net.ipv4.tcp_wmem = 32768</div><div class="line">net.ipv4.tcp_sack = 0     #打开tcp_sack功能，1表示&quot;关闭&quot;，0表示&quot;打开&quot;</div><div class="line"> </div><div class="line">......</div><div class="line"> </div><div class="line"> </div><div class="line">[root@test3-237 ~]# sysctl -p    #使上面配置生效</div></pre></td></tr></table></figure>
<h4 id="iptables防火墙预防"><a href="#iptables防火墙预防" class="headerlink" title="iptables防火墙预防"></a>iptables防火墙预防</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div></pre></td><td class="code"><pre><div class="line">先查看服务器上连接web端口（比如80端口）的哪个ip是最多的，如果发现可疑ip，就果断将其断开与服务器连接</div><div class="line"> </div><div class="line">查看80端口的连接情况</div><div class="line">[root@test3-237 ~]# netstat -an | grep &quot;:80&quot; | grep ESTABLISHED</div><div class="line"> </div><div class="line">下面的命令表示获取服务器上ESTABLISHED连接数最多的前10个ip，排除了内部ip段192.168|127.0开头的。</div><div class="line">[root@test3-237 ~]# /bin/netstat -na|grep ESTABLISHED|awk &apos;&#123;print $5&#125;&apos;|awk -F: &apos;&#123;print $1&#125;&apos;|sort|uniq -c|sort -rn|head -10|grep -v -E &apos;192.168|127.0&apos;</div><div class="line">      4001 140.205.140.205</div><div class="line">      2388 124.65.197.154</div><div class="line">      1807 111.205.224.15</div><div class="line">      18 10.51.58.16</div><div class="line">      .......</div><div class="line"> </div><div class="line">将上面140.205.140.205、124.65.197.154、111.205.224.15的这三个ip的包丢弃</div><div class="line">[root@test3-237 ~]# iptables -A INPUT -s 140.205.140.205 -p tcp -j DROP</div><div class="line">[root@test3-237 ~]# iptables -A INPUT -s 124.65.197.154 -p tcp -j DROP</div><div class="line">[root@test3-237 ~]# iptables -A INPUT -s 111.205.224.15 -p tcp -j DROP</div><div class="line">[root@test3-237 ~]# service iptables save</div><div class="line">[root@test3-237 ~]# service iptables restart</div><div class="line"> </div><div class="line">不过上面的方法对于伪造源IP地址的SYN FLOOD攻击就无效了！</div><div class="line"> </div><div class="line">-------------------------------------其他预防攻击的设置-------------------------------------</div><div class="line">防止同步包洪水（Sync Flood），缩短SYN-Timeout时间：</div><div class="line">[root@test3-237 ~]# iptables -A FORWARD -p tcp --syn -m limit --limit 1/s -j ACCEPT</div><div class="line">[root@test3-237 ~]# iptables -A INPUT -i eth0 -m limit --limit 1/sec --limit-burst 5 -j ACCEPT</div><div class="line"> </div><div class="line">其中：</div><div class="line">--limit 1/s 限制syn并发数每秒1次，可以根据自己的需要修改防止各种端口扫描</div><div class="line">[root@test3-237 ~]# iptables -A FORWARD -p tcp --tcp-flags SYN,ACK,FIN,RST RST -m limit --limit 1/s -j ACCEPT</div><div class="line"> </div><div class="line">Ping洪水攻击（Ping of Death）</div><div class="line">[root@test3-237 ~]# iptables -A FORWARD -p icmp --icmp-type echo-request -m limit --limit 1/s -j ACCEPT</div><div class="line"> </div><div class="line"> </div><div class="line">控制单个IP的最大并发连接数。</div><div class="line">如下设置表示：允许单个IP的最大连接数为 30</div><div class="line">[root@test3-237 ~]# iptables -I INPUT -p tcp --dport 80 -m connlimit --connlimit-above 30 -j REJECT</div><div class="line"> </div><div class="line">控制单个IP在一定的时间（比如60秒）内允许新建立的连接数。</div><div class="line">如下设置表示：单个IP在60秒内只允许最多新建30个连接</div><div class="line">[root@test3-237 ~]# iptables -A INPUT -p tcp --dport 80 -m recent --name BAD_HTTP_ACCESS --update --seconds 60 --hitcount 30 -j REJECT</div><div class="line">[root@test3-237 ~]# iptables -A INPUT -p tcp --dport 80 -m recent --name BAD_HTTP_ACCESS --set -j ACCEPT</div><div class="line">---------------------------------------------------------------------------------------------------</div><div class="line">如果出现报错：</div><div class="line">iptables: Invalid argument. Run `dmesg&apos; for more information.</div><div class="line"> </div><div class="line">解决办法：</div><div class="line">增加 xt_recent模块的参数值即可，默认是20</div><div class="line">[root@test3-237 ~]# cat /sys/module/xt_recent/parameters/ip_pkt_list_tot</div><div class="line">20</div><div class="line">[root@test3-237 ~]# echo 50 &gt; /sys/module/xt_recent/parameters/ip_pkt_list_tot</div><div class="line">[root@test3-237 ~]# cat /sys/module/xt_recent/parameters/ip_pkt_list_tot</div><div class="line">50</div><div class="line">---------------------------------------------------------------------------------------------------</div><div class="line"> </div><div class="line">禁止ping（即禁止从外部ping这台服务器）：</div><div class="line">[root@test3-237 ~]# echo 1 &gt; /proc/sys/net/ipv4/icmp_echo_ignore_all</div><div class="line"> </div><div class="line">用iptables屏蔽IP（如下禁止213.8.166.237连接本机的80端口）</div><div class="line">[root@test3-237 ~]# iptables -A INPUT -s 213.8.166.227 -p tcp -m tcp -m state --state NEW --dport 80 --syn -j REJECT</div><div class="line"> </div><div class="line">允许某ip连接（如下允许13.78.66.27连接本机的80端口）</div><div class="line">[root@test3-237 ~]# iptables -A INPUT -s 13.78.66.27 -p tcp -m tcp -m state --state NEW --dport 80 --syn -j ACCEPT</div></pre></td></tr></table></figure>
<h4 id="使用DDoS-deflate脚本自动屏蔽攻击ip"><a href="#使用DDoS-deflate脚本自动屏蔽攻击ip" class="headerlink" title="使用DDoS deflate脚本自动屏蔽攻击ip"></a>使用DDoS deflate脚本自动屏蔽攻击ip</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div></pre></td><td class="code"><pre><div class="line">DDoS deflate是一款免费的用来防御和减轻DDoS攻击的脚本。它通过netstat监测跟踪创建大量网络连接的IP地址，在检测到某个结点超过预设的限制时，该程序会通过APF或IPTABLES禁止或阻挡这些IP.</div><div class="line">DDoS deflate其实是一个Shell脚本，使用netstat和iptables工具，对那些链接数过多的IP进行封锁，能有效防止通用的恶意扫描器，但它并不是真正有效的DDoS防御工具。</div><div class="line"> </div><div class="line">DDoS deflate工作过程描述：</div><div class="line">同一个IP链接到服务器的连接数到达设置的伐值后，所有超过伐值的IP将被屏蔽，同时把屏蔽的IP写入ignore.ip.list文件中，与此同时会在tmp中生成一个脚本文件，这个脚本文件马上被执行，但是一</div><div class="line">运行就遇到sleep预设的秒，当睡眠了这么多的时间后，解除被屏蔽的IP，同时把之前写入ignore.ip.list文件中的这个被封锁的IP删除，然后删除临时生成的文件。</div><div class="line">一个事实：如果被屏蔽的IP手工解屏蔽，那么如果这个IP继续产生攻击，那么脚本将不会再次屏蔽它（因为加入到了ignore.ip.list），直到在预设的时间之后才能起作用，加入到了ignore.ip.list中的</div><div class="line">IP是检测的时候忽略的IP。可以把IP写入到这个文件以避免这些IP被堵塞，已经堵塞了的IP也会加入到ignore.ip.list中，但堵塞了预定时间后会从它之中删除。</div><div class="line"> </div><div class="line">如何确认是否受到DDOS攻击？</div><div class="line">[root@test3-237 ~]# netstat -ntu | awk &apos;&#123;print $5&#125;&apos; | cut -d: -f1 | sort | uniq -c | sort -n</div><div class="line">      1 Address</div><div class="line">      1 servers)</div><div class="line">      2 103.10.86.5</div><div class="line">      4 117.36.231.253</div><div class="line">      4 19.62.46.24</div><div class="line">      6 29.140.22.18</div><div class="line">      8 220.181.161.131   </div><div class="line">      2911 167.215.42.88</div><div class="line"> </div><div class="line">每个IP几个、十几个或几十个连接数都还算比较正常，如果像上面成百上千肯定就不正常了。比如上面的167.215.42.88，这个ip的连接有2911个！这个看起来就很像是被攻击了！</div><div class="line"> </div><div class="line">下面就说下通过DDoS deflate脚本来自动屏蔽DDOS攻击的ip</div><div class="line">1）下载DDoS deflate安装脚本，并执行安装。</div><div class="line">[root@test3-237 ~]# wget http://www.inetbase.com/scripts/ddos/install.sh</div><div class="line">[root@test3-237 ~]# chmod 0700 install.sh</div><div class="line">[root@test3-237 ~]# ./install.sh</div><div class="line"> </div><div class="line">--------------------------------------------------------------------------</div><div class="line">卸载DDos default的操作如下：</div><div class="line"># wget http://www.inetbase.com/scripts/ddos/uninstall.ddos</div><div class="line"># chmod 0700 uninstall.ddos</div><div class="line"># ./uninstall.ddos</div><div class="line">--------------------------------------------------------------------------</div><div class="line"> </div><div class="line">2）配置DDoS deflate下面是DDoS deflate的默认配置位于/usr/local/ddos/ddos.conf ，内容如下：</div><div class="line">[root@test3-237 ~]# cat /usr/local/ddos/ddos.conf</div><div class="line">##### Paths of the script and other files</div><div class="line">PROGDIR=&quot;/usr/local/ddos&quot;</div><div class="line">PROG=&quot;/usr/local/ddos/ddos.sh&quot;</div><div class="line">IGNORE_IP_LIST=&quot;/usr/local/ddos/ignore.ip.list&quot;         //IP地址白名单</div><div class="line">CRON=&quot;/etc/cron.d/ddos.cron&quot;                            //定时执行程序</div><div class="line">APF=&quot;/etc/apf/apf&quot;</div><div class="line">IPT=&quot;/sbin/iptables&quot;</div><div class="line"> </div><div class="line">##### frequency in minutes for running the script</div><div class="line">##### Caution: Every time this setting is changed, run the script with --cron</div><div class="line">#####          option so that the new frequency takes effect</div><div class="line">FREQ=1                        //检查时间间隔，默认1分钟。设置检测时间间隔，默认是分钟，由于系统使用crontab功能，最小单位是分钟</div><div class="line"> </div><div class="line">##### How many connections define a bad IP? Indicate that below.</div><div class="line">NO_OF_CONNECTIONS=150             //最大连接数，超过这个数IP就会被屏蔽，一般默认即可。默认是150，这是一个经验值，如果服务器性能比较高，可以设置200以上，以避免误杀</div><div class="line"> </div><div class="line">##### APF_BAN=1 (Make sure your APF version is atleast 0.96)</div><div class="line">##### APF_BAN=0 (Uses iptables for banning ips instead of APF)</div><div class="line">APF_BAN=0                      //使用APF还是iptables屏蔽IP。推荐使用iptables,将APF_BAN的值改为0即可。设置为1表示使用APF，如果使用APF则需要先安装，centos中默认就没有安装</div><div class="line"> </div><div class="line">##### KILL=0 (Bad IPs are&apos;nt banned, good for interactive execution of script)</div><div class="line">##### KILL=1 (Recommended setting)</div><div class="line">KILL=1                        //是否屏蔽IP，默认即可</div><div class="line"> </div><div class="line">##### An email is sent to the following address when an IP is banned.</div><div class="line">##### Blank would suppress sending of mails</div><div class="line">EMAIL_TO=&quot;root&quot;              //当IP被屏蔽时给指定邮箱发送邮件，推荐使用，换成自己的邮箱即可。如果不希望发送邮件，设置为空，即EMAIL_TO=&quot;&quot;</div><div class="line"> </div><div class="line">##### Number of seconds the banned ip should remain in blacklist.</div><div class="line">BAN_PERIOD=600              //禁用IP时间（锁定ip的时间），默认600秒，可根据情况调整</div><div class="line"> </div><div class="line"> </div><div class="line">需要注意的是：</div><div class="line">DDos default安装完成后在/usr/local/ddos目录下产生了ddos.conf、ddos.sh、ignore.ip.list和LICENSE这四个文件，其中：</div><div class="line">ddos.conf是配置文件，ddos.sh是一个Shell文件，ignore.ip.list是存放忽略IP的文件，LICENSE是版权声明文件，安装完成后还在/etc/cron.d/下生产了ddos.cron文件，内容如下：</div><div class="line"> </div><div class="line">[root@test3-237 ~]# cat /etc/cron.d/ddos.cron</div><div class="line">SHELL=/bin/sh</div><div class="line">0-59/1 * * * * root /usr/local/ddos/ddos.sh &gt;/dev/null 2&gt;&amp;1</div><div class="line"> </div><div class="line">意思是每隔一分钟执行一下/usr/local/ddos/ddos.sh，这个脚本是关键！</div><div class="line">这个cron任务是依赖ddos.conf文件中的NO_OF_CONNECTIONS变量产生的，如果修改了此值，可以通过运行如下命令更新（实际也是在安装是运行了如下命令）：</div><div class="line">[root@test3-237 ~]# /usr/local/ddos/ddos.sh -c</div><div class="line">Stopping crond:                                            [  OK  ]</div><div class="line">Starting crond:                                            [  OK  ]</div><div class="line">Stopping crond:                                            [  OK  ]</div><div class="line">Starting crond:                                            [  OK  ]</div><div class="line"> </div><div class="line">或者</div><div class="line">[root@test3-237 ~]# /usr/local/ddos/ddos.sh --cron</div><div class="line">Stopping crond:                                            [  OK  ]</div><div class="line">Starting crond:                                            [  OK  ]</div><div class="line">Stopping crond:                                            [  OK  ]</div><div class="line">Starting crond:                                            [  OK  ]</div><div class="line"> </div><div class="line"> </div><div class="line">3）DDos default选项</div><div class="line"># /usr/local/ddos/ddos.sh -h       #查看选项</div><div class="line"># /usr/local/ddos/ddos.sh -k n     #杀掉连接数大于n的连接。n默认为配置文件的NO_OF_CONNECTIONS</div><div class="line">  比如：</div><div class="line">  [root@test3-237 ~]# /usr/local/ddos/ddos.sh -k 150</div><div class="line">      2 103.110.186.75</div><div class="line">      1 servers)</div><div class="line">      1 Address</div><div class="line"># /usr/local/ddos/ddos.sh -c       #按照配置文件创建一个执行计划。使得ddos.conf文件配置后生效</div></pre></td></tr></table></figure>
<h4 id="防御DDOS攻击的shell脚本"><a href="#防御DDOS攻击的shell脚本" class="headerlink" title="防御DDOS攻击的shell脚本"></a>防御DDOS攻击的shell脚本</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">Linux服务器中一旦受到DDOS的攻击（比如IDC机房服务器被攻击了，关机，拔网线，降流量），目前只能通过封IP来源来暂时解决。</div><div class="line">然而IP来源变化多端，光靠手工来添加简直是恶梦，所以还是想办法写个shell脚本来定时处理，这才是比较靠谱的办法。</div><div class="line"> </div><div class="line">[root@test3-237 ~]# mkdir /root/bin</div><div class="line">[root@test1-237 ~]# cat /root/bin/dropip.sh    //此脚本自动提取攻击ip，然后自动屏蔽</div><div class="line">#!/bin/bash</div><div class="line">/bin/netstat -na|grep ESTABLISHED|awk &apos;&#123;print $5&#125;&apos;|awk -F: &apos;&#123;print $1&#125;&apos;|sort|uniq -c|sort -rn|head -10|grep -v -E &apos;192.168|127.0&apos;|awk &apos;&#123;if ($2!=null &amp;&amp; $1&gt;4) &#123;print $2&#125;&#125;&apos;&gt;/tmp/dropip</div><div class="line">for i in $(cat /tmp/dropip)</div><div class="line">do</div><div class="line">/sbin/iptables -A INPUT -s $i -j DROP</div><div class="line">echo “$i kill at `date`”&gt;&gt;/var/log/ddos</div><div class="line">done</div><div class="line"> </div><div class="line">以上脚本中最重要的是第二行，即：</div><div class="line">获取ESTABLISHED连接数最多的前10个ip并写入临时文件/tmp/dropip,排除了内部ip段192.168|127.0开头的.通过for循环将dropip里面的ip通过iptables全部drop掉，然后写到日志文件/var/log/ddos。</div><div class="line"> </div><div class="line"> </div><div class="line">给脚本添加执行权限</div><div class="line">[root@test1-237 ~]# chmod +x /root/bin/dropip.sh</div><div class="line"> </div><div class="line">添加到计划任务，每分钟执行一次</div><div class="line">[root@test1-237 ~]#crontab -e</div><div class="line">*/1 * * * * /root/bin/dropip.sh</div><div class="line"> </div><div class="line">----------------------------------------------------------------------------------------</div><div class="line">下面是针对连接数屏蔽IP</div><div class="line">#!/bin/sh </div><div class="line">/bin/netstat -ant |grep 80 |awk &apos;&#123;print $5&#125;&apos; |awk -F&quot;:&quot; &apos;&#123;print $1&#125;&apos; |sort |uniq -c |sort -rn |grep -v -E &apos;192.168|127.0&apos; |awk &apos;&#123;if ($2!=null &amp;&amp; $1&gt;50)&#125;&apos; &gt; /root/drop_ip.txt </div><div class="line">for i in `cat /root/drop_ip.txt` </div><div class="line">do </div><div class="line">/sbin/iptables -I INPUT -s $i -j DROP; </div><div class="line">done</div></pre></td></tr></table></figure>
<h4 id="使用safedog（安全狗）软件防御DDOS攻击"><a href="#使用safedog（安全狗）软件防御DDOS攻击" class="headerlink" title="使用safedog（安全狗）软件防御DDOS攻击"></a>使用safedog（安全狗）软件防御DDOS攻击</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">[root@test3-237 ~]# setenforce 0     //关闭selinux，否则不能安装成功</div><div class="line">[root@test3-237 ~]# getenforce       //永久关闭selinux需要配置/etc/sysconfig/selinux文件，并重启机器生效！！</div><div class="line">Permissive</div><div class="line"> </div><div class="line">安装（nginx版）安全狗（safedog）</div><div class="line">[root@test3-237 ~]# wget http://safedog.cn/safedogwz_linux_Nginx64.tar.gz</div><div class="line">[root@test3-237 ~]# tar -zvxf safedogwz_linux_Nginx64.tar.gz</div><div class="line">[root@test3-237 ~]# cd safedogwz_linux_Nginx64</div><div class="line">[root@test3-237 safedogwz_linux_Nginx64]# chmod 755 install.py</div><div class="line">[root@bastion-IDC safedogwz_linux_Nginx64]# ls</div><div class="line">install_files  install.py  uninstall.py</div><div class="line">[root@test3-237 safedogwz_linux_Nginx64]# ./install.py -A          //卸载安全狗就用uninstall.py</div><div class="line">.......</div><div class="line">  step 3.5, start service...                                                                      [ok]</div><div class="line">  step 3.6, save safedog install info...                                                          [ok]</div><div class="line">   Tips:</div><div class="line">  (1)Run the command to setup Server Defense Module: sdui</div><div class="line">  (2)Explore more features by tapping the command to join Cloud Management Center (fuyun.safedog.cn) with your account:  sdcloud -h</div><div class="line"> </div><div class="line">If you need any help about installation,please tap the command: ./install.py -h</div><div class="line">Install Completely!</div><div class="line"> </div><div class="line"> </div><div class="line">温馨提示：</div><div class="line">1）安装完成后，记得一定要重新启动Nginx服务，网站安全狗软件即可生效。</div><div class="line">2）运行时,安装脚本默认将自动获取Nginx服务的安装路径；若自动获取失败则将提示输入Nginx服务的安装路径（绝对路径），需要根据所安装的Nginx的目录，填写真实的安装路径。</div><div class="line">3）当出现提示：Are you sure to uninstall?[y/n]时，输入y</div></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> Linux基础 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux基础 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Postgresql（1）--简介]]></title>
      <url>http://yoursite.com/2016/12/02/Postgresql%EF%BC%881%EF%BC%89--%E7%AE%80%E4%BB%8B/</url>
      <content type="html"><![CDATA[<h3 id="何为PostgreSQL"><a href="#何为PostgreSQL" class="headerlink" title="何为PostgreSQL"></a>何为PostgreSQL</h3><p>PostgreSQL是以加州大学伯克利分校计算机系开发的POSTGRES,Version4.2为基础的对象关系型数据库管理系统(ORDBMS)。POSTGRES开创的许多概念在很久以后才出现在商业数据库中。<br>PostgreSQL是最初伯克利代码的一个开放源码的继承者。它支持大部分SQL标准并且提供了许多其它现代特性：</p>
<a id="more"></a>
<p>1.复杂查询<br>2.外键<br>3.触发器<br>4.可更新的视图<br>5.事务完整性<br>6.多版本并发控制</p>
<p>另外，PostgreSQL可以用许多方法进行扩展，比如通过增加新的：<br>1.数据类型<br>2.函数<br>3.操作符<br>4.聚合函数<br>5.索引方法<br>6.过程语言</p>
<p>并且，因为许可证的灵活，任何人都可以以任何目的免费使用、修改、分发PostgreSQL，不管是私用、商用、还是学术研究使用。</p>
<h3 id="选用理由"><a href="#选用理由" class="headerlink" title="选用理由"></a>选用理由</h3><p>(1)PostgreSQL支持用多种编程语言编写存程过程和函数<br>(2)PostgreSQL支持非常强大的用户自定义数据类型功能</p>
<h3 id="PostgreSQL资源"><a href="#PostgreSQL资源" class="headerlink" title="PostgreSQL资源"></a>PostgreSQL资源</h3><p>（1）Plantet PostgreSQL （<a href="http://planet.postgresql.org）是PostgreSQL技术博客文章的汇聚站点，其中包含从PostgreSQL核心开发人员到普通用户编写" target="_blank" rel="external">http://planet.postgresql.org）是PostgreSQL技术博客文章的汇聚站点，其中包含从PostgreSQL核心开发人员到普通用户编写</a><br>的各类文章，包括新特性演汉及对现有功能的使用说明<br>（2）PostgreSQL Wiki（<a href="https://wiki.postgresql.org）提供对PostgreSQL各个方面的使用技巧说明，以及从其他数据库移值到PostgreSQL的方法" target="_blank" rel="external">https://wiki.postgresql.org）提供对PostgreSQL各个方面的使用技巧说明，以及从其他数据库移值到PostgreSQL的方法</a><br>（3）PostgreSQL Books(<a href="https://www.postgresql.org/docs/books/)提供有关PostgreSQL的书箱列表信息；" target="_blank" rel="external">https://www.postgresql.org/docs/books/)提供有关PostgreSQL的书箱列表信息；</a></p>
<h3 id="PostgreSQL管理工具"><a href="#PostgreSQL管理工具" class="headerlink" title="PostgreSQL管理工具"></a>PostgreSQL管理工具</h3><p>postgresql常用管理工具有四种：psql、pgAdmin,phpPgAdmin和Adminer。PostgreSQL的核心开发团队维护着前三种。</p>
<p>（1）psql是一种用于执行查询的命令行工具<br>（2）pgAdmin是一种广泛使用的开源PostgreSQL图形界面管理工具<br>（3）phpPgAdmin基于Web页面的管理工具</p>
<p><code>PostgreSQL默认侦听端口 5432</code></p>
<h3 id="PostgreSQL数据库对象"><a href="#PostgreSQL数据库对象" class="headerlink" title="PostgreSQL数据库对象"></a>PostgreSQL数据库对象</h3><p>(1)服务<br>在大多数操作系统上，PostgreSQL是作为一种服务（或者叫守护进程）安装的。多个PostgreSQL服务可以运行于同一台物理服务器上，但它们的侦听端口不能<br>重复，也不能共享一个数据存储目录。</p>
<p>(2)database<br>每个PostgreSQL服务可以包含多个独立的database</p>
<p>(3)schema<br>database的下一层逻辑结构就是schema</p>
<p>(4)catalog<br>catalog是系统级的schema,用于存储系统函数和系统元数据。每个database创建好以后默认都会含有两个catalog：<br>一个名为pg_catalog,用于存储PostgreSQL系统自带的函数，表，系统视图，数据类型转换器以及数据类型定义等元数据<br>另一个是information_schema,用于存储ANSI标准中所要求提供的元数据查询视图，这些视图遵从ANSI SQL标准的要求，以提定的格式向外界提供PostgreSQL</p>
<p>元数据信息<br>PostgreSQL information_schema中最常用的视图一般有以下几个：<br>columns视图：列出了数据库中的所有表列<br>tables视图：列出数据库中的所有表（包括视图）<br>view视图：列出所有视图以及用于构建或重新构建该视图的关联SQL</p>
<p>（5）变量<br>（6）扩展包<br>（7）表<br>在Postgresql中，表首先属于某个schema,而schema又属于某个database,这样就构成了一种三级存储结构<br>Postgresql的表支持两种强大的功能，<br>第一种是表继承，即一张表可以有父表和子表<br>第二种是创建一张表的同时，系统会自动为此表创建一种对应的自定义数据类型<br>（8）外部表和外部数据封装器<br>通过外部表可以直接在本地数据库中访问来自外部数据源的数据<br>外部表映射关系的建立是通过配置外部数据封装器（Foreign Data Wrapper，FDW）实现的。FDW是PostgreSQL和外部数据源之间的一架魔法桥，可实现两边<br>数据的互联互通。<br>（9）表空间<br>表空间是用于存储数据的物理空间<br>（10）视图<br>（11）函数<br>（12）内置编程语言<br>（13）运算符<br>（14）数据类型<br>（15）数据类型转换器<br>（16）序列<br>（1）行或记录<br>（17）触发器<br>（18）规则</p>
]]></content>
      
        <categories>
            
            <category> Postgresql </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Postgresql </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[细说firewalld和iptables]]></title>
      <url>http://yoursite.com/2016/11/10/%E7%BB%86%E8%AF%B4firewalld%E5%92%8Ciptables/</url>
      <content type="html"><![CDATA[<p>在CentOS7里有几种防火墙共存：firewalld、iptables、ebtables，默认是使用firewalld来管理netfilter子系统，不过底层调用的命令仍然是iptables等。</p>
<a id="more"></a>
<h2 id="firewalld跟iptables对比"><a href="#firewalld跟iptables对比" class="headerlink" title="firewalld跟iptables对比"></a>firewalld跟iptables对比</h2><p>firewalld跟iptables比起来至少有两大好处：<br>1、firewalld可以动态修改单条规则，而不需要像iptables那样，在修改了规则后必须得全部刷新才可以生效；<br>2、firewalld在使用上要比iptables人性化很多，即使不明白“五张表五条链”而且对TCP/IP协议也不理解也可以实现大部分功能。<br>firewalld跟iptables比起来，不好的地方是每个服务都需要去设置才能放行，因为默认是拒绝。而iptables里默认是每个服务是允许，需要拒绝的才去限制。</p>
<p>firewalld自身并不具备防火墙的功能，而是和iptables一样需要通过内核的netfilter来实现，也就是说firewalld和 iptables一样，他们的作用都是用于维护规则，而真正使用规则干活的是内核的netfilter，只不过firewalld和iptables的结构以及使用方法不一样罢了。</p>
<p>一个重要的概念：区域管理<br>通过将网络划分成不同的区域，制定出不同区域之间的访问控制策略来控制不同程序区域间传送的数据流。例如，互联网是不可信任的区域，而内部网络是高度信任的区域。网络安全模型可以在安装，初次启动和首次建立网络连接时选择初始化。该模型描述了主机所连接的整个网络环境的可信级别，并定义了新连接的处理方式。有如下几种不同的初始化区域：<br>阻塞区域（block）：任何传入的网络数据包都将被阻止。<br>工作区域（work）：相信网络上的其他计算机，不会损害你的计算机。<br>家庭区域（home）：相信网络上的其他计算机，不会损害你的计算机。<br>公共区域（public）：不相信网络上的任何计算机，只有选择接受传入的网络连接。<br>隔离区域（DMZ）：隔离区域也称为非军事区域，内外网络之间增加的一层网络，起到缓冲作用。对于隔离区域，只有选择接受传入的网络连接。<br>信任区域（trusted）：所有的网络连接都可以接受。<br>丢弃区域（drop）：任何传入的网络连接都被拒绝。<br>内部区域（internal）：信任网络上的其他计算机，不会损害你的计算机。只有选择接受传入的网络连接。<br>外部区域（external）：不相信网络上的其他计算机，不会损害你的计算机。只有选择接受传入的网络连接。</p>
<p>注：FirewallD的默认区域是public。<br>firewalld默认提供了九个zone配置文件：block.xml、dmz.xml、drop.xml、external.xml、 home.xml、internal.xml、public.xml、trusted.xml、work.xml，他们都保存在“/usr/lib /firewalld/zones/”目录下。<br>配置方法</p>
<p>firewalld的配置方法主要有三种：firewall-config、firewall-cmd<code>和</code>直接编辑xml文件，其中<br>firewall-config是图形化工具，firewall-cmd是命令行工具，而对于linux来说大家应该更习惯使用命令行方式的操作，所以 firewall-config我们就不给大家介绍了。</p>
<h2 id="firewalld使用："><a href="#firewalld使用：" class="headerlink" title="firewalld使用："></a>firewalld使用：</h2><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><pre><code>yum install firewalld firewall-config
</code></pre><h3 id="运行、停止、禁用"><a href="#运行、停止、禁用" class="headerlink" title="运行、停止、禁用"></a>运行、停止、禁用</h3><pre><code>启动：
systemctl start  firewalld

查看状态：
systemctl status firewalld 或者 firewall-cmd --state
停止：
systemctl disable firewalld

禁用：
systemctl stop firewalld
systemctl mask firewalld
systemctl unmask firewalld
</code></pre><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><pre><code>查看版本：firewall-cmd --version
查看帮助：firewall-cmd --help
显示状态：firewall-cmd --state
查看区域信息: firewall-cmd --get-active-zones
查看指定接口所属区域：firewall-cmd --get-zone-of-interface=eth0
拒绝所有包：firewall-cmd --panic-on
取消拒绝状态：firewall-cmd --panic-off
查看是否拒绝：firewall-cmd --query-panic
</code></pre><h3 id="更新防火墙规则"><a href="#更新防火墙规则" class="headerlink" title="更新防火墙规则"></a>更新防火墙规则</h3><pre><code>#firewall-cmd --reload
#firewall-cmd --complete-reload

两者的区别就是第一个无需断开连接，就是firewalld特性之一动态添加规则，第二个需要断开连接，类似重启服务

将接口添加到区域，默认接口都在public
#firewall-cmd --zone=public --add-interface=eth0
永久生效再加上 --permanent 然后reload防火墙

设置默认接口区域
#firewall-cmd --set-default-zone=public
立即生效无需重启
</code></pre><h3 id="打开端口"><a href="#打开端口" class="headerlink" title="打开端口"></a>打开端口</h3><pre><code>查看所有打开的端口：
# firewall-cmd --zone=dmz --list-ports
加入一个端口到区域：
# firewall-cmd --zone=dmz --add-port=8080/tcp
若要永久生效方法同上

打开一个服务，类似于将端口可视化，服务需要在配置文件中添加，/etc/firewalld 目录下有services文件夹，这个不详细说了，详情参考文档
# firewall-cmd --zone=work --add-service=smtp

移除服务
# firewall-cmd --zone=work --remove-service=smtp

还有端口转发功能、自定义复杂规则功能、lockdown


iptables 是与最新的 3.5 版本 Linux 内核集成的 IP 信息包过滤系统。如果 Linux 系统连接到因特网或 LAN、服务器或连接 LAN 和因特网的代理服务器， 则该系统有利于在 Linux 系统上更好地控制 IP 信息包过滤和防火墙配置。
</code></pre><h2 id="iptables-基本命令使用举例"><a href="#iptables-基本命令使用举例" class="headerlink" title="iptables 基本命令使用举例"></a>iptables 基本命令使用举例</h2><h3 id="链及NAT的基本操作"><a href="#链及NAT的基本操作" class="headerlink" title="链及NAT的基本操作"></a>链及NAT的基本操作</h3><h4 id="清除所有的规则。"><a href="#清除所有的规则。" class="headerlink" title="清除所有的规则。"></a>清除所有的规则。</h4><pre><code>1）清除预设表filter中所有规则链中的规则。
 iptables -F
2）清除预设表filter中使用者自定链中的规则。
iptables -X
iptables -Z
3)清除NAT表规则
#iptables -F -t nat
4)NAT表的显示
iptables -t nat -nL
</code></pre><h4 id="设置链的默认策略。一般有两种方法。"><a href="#设置链的默认策略。一般有两种方法。" class="headerlink" title="设置链的默认策略。一般有两种方法。"></a>设置链的默认策略。一般有两种方法。</h4><pre><code>1）首先允许所有的包，然后再禁止有危险的包通过放火墙。
iptables -P INPUT ACCEPT
iptables -P OUTPUT ACCEPT
iptables -P FORWARD ACCEPT

2）首先禁止所有的包，然后根据需要的服务允许特定的包通过防火墙。
iptables -P INPUT DROP
iptables -P OUTPUT DROP
iptables -P FORWARD DROP
</code></pre><h4 id="列出表-链中的所有规则。默认只列出filter表。"><a href="#列出表-链中的所有规则。默认只列出filter表。" class="headerlink" title="列出表/链中的所有规则。默认只列出filter表。"></a>列出表/链中的所有规则。默认只列出filter表。</h4><pre><code>iptables -L
</code></pre><p>####向链中添加规则。下面的语句用于开放网络接口：<br>    iptables -A INPUT -i lo -j ACCEPT<br>    iptables -A OUTPUT -o lo -j ACCEPT<br>    iptables -A INPUT -i eth0 -j ACEPT<br>    iptables -A OUTPUT -o eth1 -j ACCEPT<br>    iptables -A FORWARD -i eth1 -j ACCEPT<br>    iptables -A FORWARD -0 eth1 -j ACCEPT</p>
<pre><code>注意:由于本地进程不会经过FORWARD链，因此回环接口lo只在INPUT和OUTPUT两个链上作用。
</code></pre><h4 id="使用者自定义链。"><a href="#使用者自定义链。" class="headerlink" title="使用者自定义链。"></a>使用者自定义链。</h4><pre><code>iptables -N custom
iptables -A custom -s 0/0 -d 0/0 -p icmp -j DROP
iptables -A INPUT -s 0/0 -d 0/0 -j DROP
</code></pre><h3 id="设置基本的规则匹配"><a href="#设置基本的规则匹配" class="headerlink" title="设置基本的规则匹配"></a>设置基本的规则匹配</h3><h4 id="指定协议匹配。"><a href="#指定协议匹配。" class="headerlink" title="指定协议匹配。"></a>指定协议匹配。</h4><pre><code>1）匹配指定协议。
iptables -A INPUT -p tcp
2）匹配指定协议之外的所有协议。
iptables -A INPUT -p !tcp
</code></pre><h4 id="指定地址匹配。"><a href="#指定地址匹配。" class="headerlink" title="指定地址匹配。"></a>指定地址匹配。</h4><pre><code>1）指定匹配的主机。
iptables -A INPUT -s 192.168.0.18
2）指定匹配的网络。
iptables -A INPUT -s 192.168.2.0/24
3）匹配指定主机之外的地址。
iptables -A FORWARD -s !192.168.0.19
4）匹配指定网络之外的网络。
iptables -A FORWARD -s ! 192.168.3.0/24
</code></pre><h4 id="指定网络接口匹配。"><a href="#指定网络接口匹配。" class="headerlink" title="指定网络接口匹配。"></a>指定网络接口匹配。</h4><pre><code>1）指定单一的网络接口匹配。
iptables -A INPUT -i eth0
iptables -A FORWARD -o eth0
2）指定同类型的网络接口匹配。
iptables -A FORWARD -o ppp+
</code></pre><h4 id="指定端口匹配。"><a href="#指定端口匹配。" class="headerlink" title="指定端口匹配。"></a>指定端口匹配。</h4><pre><code>1）指定单一端口匹配。
iptables -A INPUT -p tcp --sport www
iptables -A INPUT -p udp –dport 53
2）匹配指定端口之外的端口。
iptables -A INPUT -p tcp –dport !22
3）匹配端口范围。
iptables -A INPUT -p tcp –sport 22:80
4）匹配ICMP端口和ICMP类型。
iptables -A INOUT -p icmp –icimp-type 8
5）指定ip碎片。
每个网络接口都有一个MTU（最大传输单元），这个参数定义了可以通过的数据包的最大尺寸。如果一个数据包大于这个参数值时，系统会将其划分成更小的数据包
（称为ip碎片）来传输，而接受方则对这些ip碎片再进行重组以还原整个包。这样会导致一个问题：当系统将大数据包划分成ip碎片传输时，第一个碎片含有
完整的包头信息（IP+TCP、UDP和ICMP），但是后续的碎片只有包头的部分信息（如源地址、目的地址）。因此，检查后面的ip碎片的头部（象有
TCP、UDP和ICMP一样）是不可能的。假如有这样的一条规则：
iptables -A FORWARD -p tcp -s 192.168.1.0/24 -d 192.168.2.100 –dport 80 -j ACCEPT

并且这时的FORWARD的policy为DROP时，系统只会让第一个ip碎片通过，而余下的碎片因为包头信息不完整而无法通过。可以通过—fragment/-f 选项来指定第二个及以后的ip碎片解决上述问题。
iptables -A FORWARD -f -s 192.168.1.0/24 -d 192.168.2.100 -j ACCEPT

注意现在有许多进行ip碎片攻击的实例，如DoS攻击，因此允许ip碎片通过是有安全隐患的，对于这一点可以采用iptables的匹配扩展来进行限制。
</code></pre><h3 id="设置扩展的规则匹配（举例已忽略目标动作）"><a href="#设置扩展的规则匹配（举例已忽略目标动作）" class="headerlink" title="设置扩展的规则匹配（举例已忽略目标动作）"></a>设置扩展的规则匹配（举例已忽略目标动作）</h3><h4 id="多端口匹配。"><a href="#多端口匹配。" class="headerlink" title="多端口匹配。"></a>多端口匹配。</h4><pre><code>1）匹配多个源端口。
iptables -A INPUT -p tcp -m multiport –sport 22,53,80,110
2）匹配多个目的端口。
iptables -A INPUT -p tcp -m multiport –dpoort 22,53,80
3）匹配多端口(无论是源端口还是目的端口）
iptables -A INPUT -p tcp -m multiport –port 22,53,80,110
</code></pre><h4 id="指定TCP匹配扩展"><a href="#指定TCP匹配扩展" class="headerlink" title="指定TCP匹配扩展"></a>指定TCP匹配扩展</h4><pre><code>使用 –tcp-flags 选项可以根据tcp包的标志位进行过滤。
iptables -A INPUT -p tcp –tcp-flags SYN,FIN,ACK SYN
iptables -A FROWARD -p tcp –tcp-flags ALL SYN,ACK
上实例中第一个表示SYN、ACK、FIN的标志都检查，但是只有SYN匹配。第二个表示ALL（SYN，ACK，FIN，RST，URG，PSH）的标志都检查，但是只有设置了SYN和ACK的匹配。
iptables -A FORWARD -p tcp --syn
选项—syn相当于”--tcp-flags SYN,RST,ACK SYN”的简写。
</code></pre><h4 id="limit速率匹配扩展。"><a href="#limit速率匹配扩展。" class="headerlink" title="limit速率匹配扩展。"></a>limit速率匹配扩展。</h4><pre><code>1）指定单位时间内允许通过的数据包个数，单位时间可以是/second、/minute、/hour、/day或使用第一个子母。
iptables -A INPUT -m limit --limit 300/hour

2 )指定触发事件的阀值。
iptables -A INPUT -m limit –limit-burst 10 
用来比对一次同时涌入的封包是否超过10个，超过此上限的包将直接丢弃。

3）同时指定速率限制和触发阀值。
iptables -A INPUT -p icmp -m limit –-limit 3/m –limit-burst 3
表示每分钟允许的最大包数量为限制速率（本例为3）加上当前的触发阀值burst数。任何情况下，都可保证3个数据包通过，触发阀值burst相当于允许额外的包数量。 

4）基于状态的匹配扩展（连接跟踪）
每个网络连接包括以下信息：源地址、目标地址、源端口、目的端口，称为套接字对（socket pairs）；协议类型、连接状态（TCP协议）
和超时时间等。防火墙把这些信息称为状态（stateful）。状态包过滤防火墙能在内存中维护一个跟踪状态的表，比简单包过滤防火墙具有更大的安全性，命令格式如下： 
iptables -m state –-state [!]state [,state,state,state]
其中，state表是一个逗号分割的列表，用来指定连接状态，4种：
&gt;NEW: 该包想要开始一个新的连接（重新连接或连接重定向）
&gt;RELATED:该包是属于某个已经建立的连接所建立的新连接。举例：
FTP的数据传输连接和控制连接之间就是RELATED关系。
&gt;ESTABLISHED：该包属于某个已经建立的连接。
&gt;INVALID:该包不匹配于任何连接，通常这些包被DROP。
例如：
（1）在INPUT链添加一条规则，匹配已经建立的连接或由已经建立的连接所建立的新连接。即匹配所有的TCP回应包。
iptables -A INPUT -m state –state RELATED,ESTABLISHED
（2）在INPUT链链添加一条规则，匹配所有从非eth0接口来的连接请求包。
iptables -A INPUT -m state -–state NEW -i !eth0

又如，对于ftp连接可以使用下面的连接跟踪：
（1）被动（Passive）ftp连接模式。
iptables -A INPUT -p tcp --sport 1024: --dport 1024: -m state –-state ESTABLISHED -j ACCEPT
iptables -A OUTPUT -p tcp --sport 1024: --dport 1024: -m 
state -–state ESTABLISHED,RELATED -j ACCEPT
（2）主动（Active）ftp连接模式
iptables -A INNPUT -p tcp --sport 20 -m state –-state ESTABLISHED,RELATED -j ACCEPT
iptables -A OUTPUT -p tcp –OUTPUT -p tcp –dport 20 -m state --state ESTABLISHED -j ACCEPT
</code></pre>]]></content>
      
        <categories>
            
            <category> 网络知识 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 网络知识 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Nginx域名访问的白名单配置梳理]]></title>
      <url>http://yoursite.com/2016/10/11/Nginx%E5%9F%9F%E5%90%8D%E8%AE%BF%E9%97%AE%E7%9A%84%E7%99%BD%E5%90%8D%E5%8D%95%E9%85%8D%E7%BD%AE%E6%A2%B3%E7%90%86/</url>
      <content type="html"><![CDATA[<p>在日常运维工作中，会碰到这样的需求：设置网站访问只对某些ip开放，其他ip的客户端都不能访问。可以通过下面四种方法来达到这种效果：<br>1）针对nginx域名配置所启用的端口(比如80端口)在iptables里做白名单，比如只允许100.110.15.16、100.110.15.17、100.110.15.18访问.但是这样就把nginx的所有80端口的域名访问都做了限制，范围比较大！</p>
<a id="more"></a>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[root@china ~]# vim /etc/sysconfig/iptables</div><div class="line">......</div><div class="line">-A INPUT -s 100.110.15.16 -p tcp -m state --state NEW -m tcp --dport 80 -j ACCEPT</div><div class="line">-A INPUT -s 100.110.15.17 -p tcp -m state --state NEW -m tcp --dport 80 -j ACCEPT</div><div class="line">-A INPUT -s 100.110.15.18 -p tcp -m state --state NEW -m tcp --dport 80 -j ACCEPT</div></pre></td></tr></table></figure>
<p>2）如果只是针对nginx下的某一个域名进行访问的白名单限制，那么可以在nginx的配置文件里进行设置，利用$remote_addr参数进行访问的分发限制，如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div></pre></td><td class="code"><pre><div class="line">[root@china vhosts]# cat testwww.wangshibo.com.conf</div><div class="line">server &#123;</div><div class="line">        listen       80;</div><div class="line">        server_name  testwww.wangshibo.com;</div><div class="line">        root /var/www/vhosts/testwww.wangshibo.com/httpdocs/main;</div><div class="line"> </div><div class="line"> </div><div class="line">        access_log  /var/www/vhosts/testwww.wangshibo.com/logs/access.log  main;</div><div class="line">        error_log  /var/www/vhosts/testwww.wangshibo.com/logs/error.log;</div><div class="line"> </div><div class="line"> </div><div class="line">        ##白名单设置，只允许下面三个来源ip的客户端以及本地能访问该站。主要是下面这三行</div><div class="line">        if ($remote_addr !~ ^(100.110.15.16|100.110.15.17|100.110.15.18|127.0.0.1)) &#123;</div><div class="line">         rewrite ^.*$ /maintence.php last;</div><div class="line">        &#125;</div><div class="line"> </div><div class="line">        location / &#123;</div><div class="line">            try_files $uri $uri/ @router;</div><div class="line">            index  index.php;</div><div class="line">        &#125;</div><div class="line">     </div><div class="line"> </div><div class="line">        error_page   500 502 503 504  /50x.html;</div><div class="line"> </div><div class="line">        location @router &#123;</div><div class="line">            rewrite ^.*$ /index.php last;</div><div class="line">        &#125;</div><div class="line"> </div><div class="line"> </div><div class="line">        location ~ \.php$ &#123;</div><div class="line">            fastcgi_pass   127.0.0.1:9001;</div><div class="line">            fastcgi_read_timeout 30;</div><div class="line">            fastcgi_index  index.php;</div><div class="line">            fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;</div><div class="line">            #include        fastcgi_params;</div><div class="line">            include        fastcgi.conf;</div><div class="line">        &#125;</div><div class="line"> </div><div class="line">    &#125;</div><div class="line"> </div><div class="line"> </div><div class="line">错误页面内容设置：</div><div class="line">[root@china vhosts]# cat /var/www/vhosts/testwww.wangshibo.com/main/maintence.html</div><div class="line">&lt;html&gt;</div><div class="line">&lt;head&gt;</div><div class="line">&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=utf-8&quot;&gt;</div><div class="line">&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot;&gt;</div><div class="line">&lt;/head&gt;</div><div class="line">&lt;body&gt;</div><div class="line">网站临时维护中，请稍后访问...</div><div class="line">&lt;/body&gt;</div><div class="line">&lt;/html&gt;</div></pre></td></tr></table></figure></p>
<p>3）也可以使用$http_x_forwarded_for参数进行访问的分发限制，如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line">server &#123;</div><div class="line">        listen       80;</div><div class="line">        server_name  testwww.wangshibo.com;</div><div class="line">        root /var/www/vhosts/testwww.wangshibo.com/httpdocs/main;</div><div class="line"> </div><div class="line"> </div><div class="line">        access_log  /var/www/vhosts/testwww.wangshibo.com/logs/access.log  main;</div><div class="line">        error_log  /var/www/vhosts/testwww.wangshibo.com/logs/error.log;</div><div class="line"> </div><div class="line"> </div><div class="line">  ##白名单设置，只允许下面三个来源ip的客户端以及本地能访问该站。</div><div class="line">       if ($http_x_forwarded_for !~ ^(100.110.15.16|100.110.15.17|100.110.15.18|127.0.0.1)) &#123;</div><div class="line">           rewrite ^.*$  /maintence.php last;</div><div class="line">        &#125;</div><div class="line">         </div><div class="line">         </div><div class="line">        location / &#123;</div><div class="line">            try_files $uri $uri/ @router;</div><div class="line">            index  index.php;</div><div class="line">        &#125;</div><div class="line">     </div><div class="line"> </div><div class="line">        error_page   500 502 503 504  /50x.html;</div><div class="line"> </div><div class="line">        location @router &#123;</div><div class="line">            rewrite ^.*$ /index.php last;</div><div class="line">        &#125;</div><div class="line"> </div><div class="line"> </div><div class="line">        location ~ \.php$ &#123;</div><div class="line">            fastcgi_pass   127.0.0.1:9001;</div><div class="line">            fastcgi_read_timeout 30;</div><div class="line">            fastcgi_index  index.php;</div><div class="line">            fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;</div><div class="line">            #include        fastcgi_params;</div><div class="line">            include        fastcgi.conf;</div><div class="line">        &#125;</div><div class="line"> </div><div class="line">    &#125;</div></pre></td></tr></table></figure></p>
<p>4）还可以利用nginx的allow、deny参数进行访问限制<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line">[root@china vhosts]# cat testwww.wangshibo.com.conf</div><div class="line">server &#123;</div><div class="line">        listen       80;</div><div class="line">        server_name  testwww.wangshibo.com;</div><div class="line">        root /var/www/vhosts/testwww.wangshibo.com/httpdocs/main;</div><div class="line"> </div><div class="line"> </div><div class="line">        access_log  /var/www/vhosts/testwww.wangshibo.com/logs/access.log  main;</div><div class="line">        error_log  /var/www/vhosts/testwww.wangshibo.com/logs/error.log;</div><div class="line"> </div><div class="line">        ##白名单设置，只允许下面三个来源ip的客户端以及本地能访问该站。</div><div class="line">        allow 100.110.15.16;</div><div class="line">        allow 100.110.15.17;</div><div class="line">        allow 100.110.15.18;</div><div class="line">        allow 127.0.0.1;</div><div class="line">        deny all;</div><div class="line"> </div><div class="line">        location / &#123;</div><div class="line">            try_files $uri $uri/ @router;</div><div class="line">            index  index.php;</div><div class="line">        &#125;</div><div class="line">     </div><div class="line"> </div><div class="line">        error_page   500 502 503 504  /50x.html;</div><div class="line"> </div><div class="line">        location @router &#123;</div><div class="line">            rewrite ^.*$ /index.php last;</div><div class="line">        &#125;</div><div class="line"> </div><div class="line"> </div><div class="line">        location ~ \.php$ &#123;</div><div class="line">            fastcgi_pass   127.0.0.1:9001;</div><div class="line">            fastcgi_read_timeout 30;</div><div class="line">            fastcgi_index  index.php;</div><div class="line">            fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;</div><div class="line">            #include        fastcgi_params;</div><div class="line">            include        fastcgi.conf;</div><div class="line">        &#125;</div><div class="line"> </div><div class="line">    &#125;</div></pre></td></tr></table></figure></p>
<p><strong>nginx中remote_addr和x_forwarded_for参数使用说明</strong><br>做网站时经常会用到remote_addr和x_forwarded_for这两个头信息来获取客户端的IP，然而当有反向代理或者CDN的情况下，这两个值就不够准确了，需要调整一些配置。<br>1）什么是remote_addr<br>remote_addr代表客户端的IP，但它的值不是由客户端提供的，而是服务端根据客户端的ip指定的，当你的浏览器访问某个网站时，假设中间没有任何代理，那么网站的<br>web服务器（Nginx，Apache等）就会把remote_addr设为你的机器IP，如果你用了某个代理，那么你的浏览器会先访问这个代理，然后再由这个代理转发到网站，这样web<br>服务器就会把remote_addr设为这台代理机器的IP。</p>
<p>2）什么是x_forwarded_for<br>正如上面所述，当你使用了代理时，web服务器就不知道你的真实IP了，为了避免这个情况，代理服务器通常会增加一个叫做x_forwarded_for的头信息，把连接它的客户<br>端IP（即你的上网机器IP）加到这个头信息里，这样就能保证网站的web服务器能获取到真实IP</p>
<p><strong>使用HAProxy做反向代理</strong><br>通常网站为了支撑更大的访问量，会增加很多web服务器，并在这些服务器前面增加一个反向代理（如HAProxy），它可以把负载均匀的分布到这些机器上。你的浏览器访<br>问的首先是这台反向代理，它再把你的请求转发到后面的web服务器，这就使得web服务器会把remote_addr设为这台反向代理的IP，为了能让你的程序获取到真实的客户端<br>IP，你需要给HAProxy增加以下配置：</p>
<p>option forwardfor<br>它的作用就像上面说的，增加一个x_forwarded_for的头信息，把你上网机器的ip添加进去</p>
<p><strong>使用Nginx的realip模块</strong><br>当Nginx处在HAProxy后面时，就会把remote_addr设为HAProxy的IP，这个值其实是毫无意义的，你可以通过nginx的realip模块，让它使用x_forwarded_for里的值。使用这<br>个模块需要重新编译Nginx，增加–with-http_realip_module参数</p>
<p>set_real_ip_from   10.1.10.0/24;<br>real_ip_header     X-Forwarded-For;<br>上面的配置就是把从10.1.10这一网段过来的请求全部使用X-Forwarded-For里的头信息作为remote_addr</p>
<p><strong>将Nginx架在HAProxy前面做HTTPS代理</strong><br>网站为了安全考虑通常会使用https连接来传输敏感信息，https使用了ssl加密，HAProxy没法直接解析，所以要在HAProxy前面先架台Nginx解密，再转发到HAProxy做负载均<br>衡。这样在Web服务器前面就存在了两个代理，为了能让它获取到真实的客户端IP，需要做以下配置。</p>
<p>首先要在Nginx的代理规则里设定：<br>proxy_set_header   X-Forwarded-For  $proxy_add_x_forwarded_for;<br>这样会让Nginx的https代理增加x_forwarded_for头信息，保存客户的真实IP。</p>
<p>其次修改HAProxy的配置：<br>option     forwardfor except 10.1.10.0/24<br>这个配置和之前设定的差不多，只是多了个内网的IP段，表示如果HAProxy收到的请求是由内网传过来的话（https代理机器），就不会设定x_forwarded_for的值，保证后面的<br>web服务器拿到的就是前面https代理传过来的。</p>
<p><strong>为什么PHP里的HTTP_X_FORWARDED_FOR和Nginx的不一样</strong><br>当你的网站使用了CDN后，用户会先访问CDN，如果CDN没有缓存，则回源站（即你的反向代理）取数据。CDN在回源站时，会先添加x_forwarded_for头信息，保存用户的真实IP，<br>而你的反向代理也会设定这个值，不过它不会覆盖，而是把CDN服务器的IP（即当前remote_addr）添加到x_forwarded_for的后面，这样x_forwarded_for里就会存在两个值。<br>Nginx会使用这些值里的第一个，即客户的真实IP，而PHP则会使用第二个，即CDN的地址。为了能让PHP也使用第一个值，你需要添加以下fastcgi的配置。</p>
<p>fastcgi_param HTTP_X_FORWARDED_FOR $http_x_forwarded_for;<br>它会把nginx使用的值（即第一个IP）传给PHP，这样PHP拿到的x_forwarded_for里其实就只有一个值了，也就不会用第二个CDN的IP了。</p>
<p>忽略x_forwarded_for</p>
<p>其实，当你使用了Nginx的realip模块后，就已经保证了remote_addr里设定的就是客户端的真实IP，再看下这个配置</p>
<p>set_real_ip_from   10.1.10.0/24;<br>real_ip_header     X-Forwarded-For;<br>它就是把x_forwarded_for设为remote_addr，而nginx里的x_forwarded_for取的就是其中第一个IP。</p>
<p>使用这些设置就能保证你的remote_addr里设定的一直都是客户端的真实IP，而x_forwarded_for则可以忽略了:)</p>
<p><strong>nginx location匹配规则</strong><br><code>location</code>匹配命令<br><code>~</code>  表示执行一个正则匹配，区分大小写<br><code>~*</code> 表示执行一个正则匹配，不区分大小写<br><code>^~</code>表示普通字符匹配，如果该选项匹配，只匹配该选项，不匹配别的选项，一般用来匹配目录<br><code>=</code> 进行普通字符精确匹配<br><code>@</code> 定义一个命名的 location，使用在内部定向时，例如 <code>error_page, try_files</code></p>
<p><code>=</code>前缀的指令严格匹配这个查询。如果找到，停止搜索。<br>所有剩下的常规字符串，最长的匹配。如果这个匹配使用^〜前缀，搜索停止。<br>正则表达式，在配置文件中定义的顺序。<br>如果第3条规则产生匹配的话，结果被使用。否则，如同从第2条规则被使用。</p>
<p><code>location</code> 匹配的优先级(与location在配置文件中的顺序无关)<br><code>= 精确匹配会第一个被处理。如果发现精确匹配，nginx停止搜索其他匹配。
普通字符匹配，正则表达式规则和长的块规则将被优先和查询匹配，也就是说如果该项匹配还需去看有没有正则表达式匹配和更长的匹配。</code>^~` 则只匹配该规则，nginx停止搜索其他匹配，否则nginx会继续处理其他location指令。<br>最后匹配理带有”~”和”~*”的指令，如果找到相应的匹配，则nginx停止搜索其他匹配；当没有正则表达式或者没有正则表达式被匹配的情况下，那么匹配程度最高的逐字匹配指令会被使用。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">location = / &#123;                     # 只匹配&quot;/&quot;.</div><div class="line">[ configuration A ]</div><div class="line">&#125;</div><div class="line"></div><div class="line">location / &#123;                        # 匹配任何请求，因为所有请求都是以&quot;/&quot;开始，但是更长字符匹配或者正则表达式匹配会优先匹配</div><div class="line">[ configuration B ]</div><div class="line">&#125;</div><div class="line"> </div><div class="line">location ^~ /images/ &#123;           # 匹配任何以 /images/ 开始的请求，并停止匹配 其它location</div><div class="line">[ configuration C ]</div><div class="line">&#125;</div><div class="line"> </div><div class="line">location ~* \.(gif|jpg|jpeg)$ &#123;         # 匹配以 gif, jpg, or jpeg结尾的请求. 但是所有 /images/ 目录的请求将由 [Configuration C]处理.</div><div class="line">[ configuration D ]</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> nginx </category>
            
        </categories>
        
        
        <tags>
            
            <tag> nginx </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[区块链技术(1)--区块链概念]]></title>
      <url>http://yoursite.com/2016/10/10/%E5%8C%BA%E5%9D%97%E9%93%BE%E6%8A%80%E6%9C%AF(1)--%E5%8C%BA%E5%9D%97%E9%93%BE%E6%A6%82%E5%BF%B5/</url>
      <content type="html"><![CDATA[<p>区块链是目前一个比较热门的新概念，蕴含了技术与金融两层概念。从技术角度来看，这是一个牺牲一致性效率且保证最终一致性的的分布式的数据库，当然这是比较片面的。从经济学的角度来看，这种容错能力很强的点对点网络，恰恰满足了共享经济的一个必须要求——低成本的可信环境</p>
<a id="more"></a>
<h3 id="区块链定义"><a href="#区块链定义" class="headerlink" title="区块链定义"></a>区块链定义</h3><p><img src="http://static.zybuluo.com/BruceTang/vvkyo2dxtzb9en6cgm0ype6u/image_1bfk92cjp2231uin190k10v5ts99.png" alt="image_1bfk92cjp2231uin190k10v5ts99.png-244.3kB"><br><code>区块链技术到底是什么</code>？很少有人能够解释清楚。现在市面上有很多关于区块链的书籍，内容基本都是，区块链能做什么，区块链的未来前景等。总的来说，区块链是一套协议，一组规范，而不是具体代码、项目。</p>
<p>理解了这套协议，你可以基于现有的技术，以不同的语言去实现它。我们也无法用一句简单的话去概况什么是区块链，站的角度不同，得到的结论也不一样。</p>
<p><code>金融业</code>的人会说区块链是一个分布式的账本，是一个分布式的银行记账系统。</p>
<p><code>密码学者</code>的会说区块链是使用密码学构建的去信任网络。</p>
<p><code>码农</code>可能会说区块链就是一个确保最终一致性的分布式数据库。（ps：基于对IBM的超级账本Hyperledger项目fabric的认识。）</p>
<p><code>吃瓜群众可以从网络获取定义</code>：区块链（Blockchain）是一种分布式数据库，起源自比特币。区块链是一串使用密码学方法相关联产生的数据块，每一个数据块中包含了一次比特币网络交易的信息，用于验证其信息的有效性（防伪）和生成下一个区块。该概念在中本聪的白皮书中提出，中本聪创造第一个区块，即“创世区块”（摘自维基百科）。</p>
<p>但无论怎么定义，只要理解了其技术要点，每个人都会有自己的认识。</p>
<h3 id="区块链技术三要素"><a href="#区块链技术三要素" class="headerlink" title="区块链技术三要素"></a>区块链技术三要素</h3><p><img src="http://static.zybuluo.com/BruceTang/0f3pyodhky6erwbf3kd9j2n8/image_1bfk93q1o1rgd9u41rtl1jp46ram.png" alt="image_1bfk93q1o1rgd9u41rtl1jp46ram.png-266.4kB"><br>首先，我们回顾一下软件系统架构。</p>
<h4 id="中心化"><a href="#中心化" class="headerlink" title="中心化"></a>中心化</h4><p>在互联网技术飞速发展的前半程，client与server的角色基本上是分工明确，1个server提供服务，n个client调用服务，这即所谓的中心化，系统的可靠性依赖server的可靠性。</p>
<h4 id="分布式"><a href="#分布式" class="headerlink" title="分布式"></a>分布式</h4><p>随着业务复杂度上升、业务量激增，传统的中心化已经不能满足需要。这时候，服务分拆，横向纵向拓展变得理所应当，这就是我们现在所处的分布式系统架构，系统的可靠性依赖于分布式系统的容灾恢复能力。</p>
<h4 id="去中心化"><a href="#去中心化" class="headerlink" title="去中心化"></a>去中心化</h4><p>分布式架构给我们带来的便利性很容易让我们觉得这就是“完美无缺”的架构，但服务提供方还是只依赖某一机构。如果机构作恶，宕机，篡改数据，那么造成的后果我想大家都清楚。（如果不清楚，请脑补机构==支付宝）。</p>
<p>区块链使用的p2p网络通信技术或许给了我们另外一种选择：人皆生而平等，没有谁生来就是server，就是client。每个节点都是平等的，既是生产者也是消费者。</p>
<p>注：今天所说的去中心化是一个理想化的状态，就如同共产主义理想。现阶段来说区块链去中心化本质上是相对去中心化。</p>
<p>有人可能会问，p2p网络就能保证不作恶，不宕机，数据不被篡改么？别急，p2p网络只是为所有节点提供了信息交换的方式。做事的还是共识算法和加密算法。</p>
<h4 id="共识算法"><a href="#共识算法" class="headerlink" title="共识算法"></a>共识算法</h4><p>一提到区块链，所有懂的人都会说到共识算法，拜占庭将军问题，然后拽出一大堆高端大气上档次的英文缩写：POW,POS,DPOS,PBFT，等等。听众一脸懵逼，而如果你让他详细解释，可能绝大部分人也解释不清楚，这就如同爱因斯坦的相对论。</p>
<p>但别担心，最简单的解释，共识算法就是保证少数服从多数！大多数人认定一件事，这件事就是事实，也就意味着如果你要去改变一个既定事实，那么你必须伙同大多数人陪你一起作假。</p>
<p>在电影电视剧中，这种情况很常见，弱者屈服于强者做伪证。但在基于p2p通信的数以千计的节点中，想要伙同其他节点一起作恶，除非“大多数节点”都被统一组织（人）控制，有共同的利益，且利益大于付出，否则不可达成。</p>
<p>这里“大多数节点”加了引号，因为有些算法并不是在大多数的临界点51%时就能达成共识。如PBFT，需要66%以上的确定节点才能达成共识。比如现在比特币网络有人就提出了这样的担心，因为大概有75%的算力被中国矿池掌控。</p>
<h4 id="加密算法"><a href="#加密算法" class="headerlink" title="加密算法"></a>加密算法</h4><p>说到加密算法，大多数码农都会想到诸如对称加密，非对称加密，hash, md5，des，rsa等。加密的本质其实很简单，让信息真实、隐秘的交流及存储。真实性由数据签名保证，隐私性由数据加密实现。区块链平台现在广泛使用的算法有椭圆曲线签名算法（ECDSA）、SHA256以及ripemd160，三者的结合使用保证了区块链在密码学层面上达到高度隐私。</p>
<h4 id="结合"><a href="#结合" class="headerlink" title="结合"></a>结合</h4><p>回到刚刚的问题：p2p网络就能保证不作恶，不宕机，数据不被篡改么？我们把区块链技术三要素结合起来探讨这个问题。</p>
<p><code>作恶</code>：要在数以千计的平等节点之间寻找作恶同伙，通常作恶的收获还不如作恶的付出，这就从根本上杜绝了大量坏节点的出现。比如，比特币的POW共识算法，就算联合了比特币网络51%以上的算力去实现双花、硬分叉，得到的收益或许还不够交电费。</p>
<p><code>宕机</code>：这个很好理解，所有的节点都是平等的，一个宕机了，不影响整个网络的持续运行。</p>
<p><code>数据篡改</code>：这其实是作恶的子集，但是比较重要，拿出来说。区块链的一个重要特征就是时序性，前一时间产生的交易会影响后续所有交易（交易签名），如果想要篡改中间某一交易的数据，那么必须在此交易所在的区块开始分叉，产生一个新链，改变这之后的所有交易，而且还要比其他链的区块产生的速度更快，否则没有意义，因为区块链网络只认最长的那条链（基于比特币区块链）。</p>
<h3 id="区块链应用四展望"><a href="#区块链应用四展望" class="headerlink" title="区块链应用四展望"></a>区块链应用四展望</h3><h4 id="区块链金融"><a href="#区块链金融" class="headerlink" title="区块链金融"></a>区块链金融</h4><p>比尔盖茨曾经讲过一句话：“传统银行如果不改变思路，就是21世纪要灭绝的恐龙”。之前，我们都只是当做一句笑谈。就像马云爸爸说他这辈子最大的错误就是建立阿里巴巴。</p>
<p>在区块链技术被挖掘出来以后，这句话被反复引用，无论是否炒作，必须看到区块链在应对金融业务时拥有的得天独厚的优势，如果银行不思求变，那么被时代抛弃是必然。因此，诸如花旗银行、汇丰银行、摩根斯坦利等42家巨头银行加入由一家区块链创业公司创建的R3区块链联盟也就不难理解了。</p>
<p>未来世界是数字世界，数字资产会变成大家资产的主要凭证。金融的本质就是信用，如何在银行全面数字化过程中利用去信任的区块链技术，这必定是未来5-10年金融创业的黄金命题。</p>
<h4 id="价值互联网"><a href="#价值互联网" class="headerlink" title="价值互联网"></a>价值互联网</h4><p>过去20年，我们亲眼目睹了互联网技术如何改变我们的生活，信息化的巨大变革彻底的改变（便利）了我们的衣食住行。实现了信息传播与分享的解放，是信息的去中心化。但互联网并没有解决财富与价值在互联网上的交换与转移。</p>
<p>如果说现有的互联网已解决信息传播与分享的瓶颈，那么区块链要解决的就是资金、合约和数字化资产在互联网上交换、交易与转移的难题。未来20年，是信息互联网升级为价值互联网的创业潮。</p>
<h4 id="共享经济"><a href="#共享经济" class="headerlink" title="共享经济"></a>共享经济</h4><p>近两年来，滴滴与uber之间的互联网租车争夺战，将“共享经济”推到了风口浪尖。这种个人与个人之间直接共享闲置资产的方式将通过区块链更加流行。因为区块链网络作为一个去信任去中心网络，让人们摆脱了个人与个人之间的信任危机以及中心化的非市场化运作。比如法国一个去中心化的叫车平台Arade City，司机与乘客直接交易。</p>
<p>而我们公司现在也正在做一个共享用户闲置磁盘空间的区块链应用平台。我们相信，唯数据与空间不可辜负，基于区块链技术，可让闲置的空间存储可被信任的加密数据。数据可以是用户自己的照片视频，也可以是某组织的业务数据。</p>
<p>而对大数据分析来说，现有的大数据应用，数据都是存在一个中心化的厂商手里，谁敢保证数据拥有者不会因为自身的利益修改数据内容？而用了区块链技术保管的数据才能保证数据被所有人共同管理，不可篡改。</p>
<h4 id="智能合约"><a href="#智能合约" class="headerlink" title="智能合约"></a>智能合约</h4><p>智能合约也是现在很火热的一个概念。简单的说，智能合约类似于计算机语言的if语句，当一个预先编好的合约的某一条件被触发时，就自动在区块链网络中执行合约相应的合同条款，而不需人为干预。</p>
<p>按照这样的愿景，未来律师的职责可能会大变样，律师的职责不是裁定个人合约，而是生产智能合约模板。定制性如何，易用性如何将决定合约的价格或者律师的身价。所以才会有笑谈：不会写脚本的律师不是好的码农。</p>
<h3 id="开源项目"><a href="#开源项目" class="headerlink" title="开源项目"></a>开源项目</h3><p>以前，重复造轮子是衡量一个公司技术能力的重要指标。但是随着开源精神的普及以及github平台的广泛使用，贡献开源项目已经是互联网公司的常态。这里介绍两个比较出名的区块链平台开源项目。</p>
<h4 id="超级账本"><a href="#超级账本" class="headerlink" title="超级账本"></a>超级账本</h4><p>超级账本（hyperledger）是Linux基金会于2015年发起的推进区块链数字技术和交易验证的开源项目，加入成员包括：荷兰银行（ABN AMRO）、埃森哲（Accenture）、IBM等十几个不同利益体，目标是让成员共同合作，共建开放平台，满足来自多个不同行业各种用户案例，并简化业务流程。</p>
<p>超级账本项目很适合联盟链，私有链的构建。现在超级账本的开源代码实现Fabric由IBM主持孵化，由go语言开发，现在版本为0.6， 坑还很多，需要时间来填，我们的项目也是基于Fabric。所以，现在开始学习Fabric，应该是比较好的选择。</p>
<h4 id="以太坊"><a href="#以太坊" class="headerlink" title="以太坊"></a>以太坊</h4><p>以太坊（Ethereum）是一个运行智能合约的去中心化平台（Platform for Smart Contract），平台上的应用按程序设定运行，不存在停机、审查、欺诈、第三方人为干预的可能。以太坊平台由 Golang、C++、Python 等多种编程语言实现。</p>
<p>前段时间的The DAO事件让以太坊平台损失惨重，以太坊也分裂成ETC和ETH，平台的发展前景不明。</p>
<h3 id="国内现状"><a href="#国内现状" class="headerlink" title="国内现状"></a>国内现状</h3><p><img src="http://static.zybuluo.com/BruceTang/n0yl2zw7h92d0ac4kribo2oh/image_1bfk9ad21181f1vkf1rfgqcm18v913.png" alt="image_1bfk9ad21181f1vkf1rfgqcm18v913.png-344.4kB"></p>
<h4 id="布比"><a href="#布比" class="headerlink" title="布比"></a>布比</h4><p>布比区块链已经广泛应用于数字资产、股权债券、贸易金融、供应链溯源、商业积分、联合征信、公示公证、数据安全等领域，并正在与交易所、银行等主流金融机构开展应用试验和测试。以多中心化信任为核心，致力于打造新一代价值流通网络，让数字资产都自由流动起来。</p>
<h4 id="小蚁"><a href="#小蚁" class="headerlink" title="小蚁"></a>小蚁</h4><p>小蚁是基于区块链技术，将实体世界的资产和权益进行数字化，通过点对点网络进行登记发行、转让交易、清算交割等金融业务的去中心化网络协议。</p>
<h4 id="唯链"><a href="#唯链" class="headerlink" title="唯链"></a>唯链</h4><p>以区块链技术为核心，VeChain提供一套面向全球的真假校验和透明供应链管理的解决方案以应对全球泛滥的假货问题，同时使得消费客户更加关注所购买的产品本身，包括产地，材料质地，设计理念，品牌故事等。</p>
<h4 id="ASCH"><a href="#ASCH" class="headerlink" title="ASCH"></a>ASCH</h4><p>Asch 是一个去中心化的应用平台。它提供了一系列的 sdk 和 api 来帮助开发者构建基于 Javascript 和侧链技术的去中心化应用。Asch 通过提供定制侧链、智能合约、应用托管等一体化的行业解决方案，致力于打造一个易于使用、功能完备、即插即用的系统。</p>
<h4 id="云象"><a href="#云象" class="headerlink" title="云象"></a>云象</h4><p>云象区块链为企业级的B端客户进行服务，提供身份验证、电子证据保全、供应链管理、产品追溯等商业智能合约应用，同时我们为行业私有链应用，提供不可篡改、安全、部署成本低的区块链数据库产品。</p>
<h4 id="太一"><a href="#太一" class="headerlink" title="太一"></a>太一</h4><p>太一云科技，拥有全球最顶尖的区块链研发团队，已研发包括区块链征信，区块链资产登记流转，区块链安全，智能合约，区块链大数据，区块链物联网，区块链云计算中心等领域的数十项核心专利技术。</p>
<p>将立足中国市场，积极开展区块链技术的产业化应用，在金融，商业，个人及企业信用等社会活动中，植入区块链的基因，改变人们对传统信用机制的认知，重塑互联网的价值传输构架，为创造崭新的更合理更公平全球新经济和新金融生态环境提供普适化的基础设施和解决方案。</p>
<h3 id="如何从技术角度理解区块链"><a href="#如何从技术角度理解区块链" class="headerlink" title="如何从技术角度理解区块链"></a>如何从技术角度理解区块链</h3><ul>
<li>作者 陈浩</li>
</ul>
<p>我接触过一些工程师，初次接触区块链时，不约而同的表达了：都是成熟的技术，不就是分布式存储嘛。站在工程师的角度，第一反应将这种新概念映射到自己的知识框架中，是非常自然的。但是细究之下发现，这种片面的理解可能将对区块链的理解带入一个误区，那就是作为一个技术人员，忽略了区块链的经济学特性——一个权力分散且完全自治的系统。</p>
<p>区块链本质上是一个基于P2P的价值传输协议，我们不能只看到了P2P，而看不到价值传输。同样的，也不能只看到了价值传输，而看不到区块链的底层技术。</p>
<p>可以这么说，区块链更像是一门交叉学科，结合了P2P网络技术、非对称加密技术、宏观经济学、经济学博弈等等知识，构建的一个新领域——针对价值互联网的探索。</p>
<p><code>那什么是价值互联网</code>？价值互联网可以是当下如日中天的电子商务所衍生的支付业务。但，真的只是支付领域吗？很显然这是不够的，一级资本市场，实体资产确权与转移，证券登记交割、征信与反欺诈。我们再仔细想想，我们的各大电商平台的专业差评师，恶意刷单还少吗？</p>
<p>如今的金融领域，除了支付比较便利之外，在其他绝大部分的业务中，我们就像是被套着锁链走路一样，我们反复确认，反复审核，反复监督，我们反复构建一个又一个的大大小小的高可用集群，保证线上服务的可靠性与连续性，我们雇佣一个又一个的安全工程师，交付一个又一个的渗透测试项目。为什么？因为作弊的成本太低了，低到只要改数据库的一行记录就可以提取上百万的资金。</p>
<p>强大的互联网给了我们成本几乎为零的高速信息传输通道，却没有一个成本低廉可靠的高速价值传输通道，那么这也就是区块链即将带来的。</p>
<p><strong>区块链是一个公共的分布式总账，下面从技术角度简单介绍一下</strong>。</p>
<p>想象有一个100台的分布式数据库集群，现在的情况是这100个节点实际上的拥有者是一个机构，并且所有节点处在该机构的内网当中，所以这个机构想让这100个数据库节点干嘛就干嘛，换句话说这100个节点之间是处于一个可信任的环境，并且受控于一个实体，这个实体具有绝对仲裁分配权。</p>
<p>另外的情况是这样的，想象这100个节点分别归不同的人所有，且每个人的节点数据都是一样的，即完全冗余，并且所有的节点是处在广域网当中，换句话说就是这100个节点之间是不信任的，且不存在一个实体，它拥有绝对仲裁权。</p>
<p>现在考虑第二种情况，采用什么样的算法（共识模型）能够提供一个可信任的环境，使：</p>
<pre><code>每个节点交换数据过程不被篡改；交换历史记录不可被篡改；

每个节点的数据会同步到最新数据，且承认经过共识的最新数据；

基于少数服从多数的原则，整体节点维护的数据本身客观反映了交换历史。
</code></pre><p>区块链本质上就是要解决以上第二种情况的一种技术方案，更确切的说应该叫分布式的冗余的链式总帐本方案。有关区块链的一些要素，在我以往的文章里有总结过一些：</p>
<pre><code>包含一个分布式数据库

分布式数据库是区块链的物理载体，区块链是交易的逻辑载体，所有核心节点都应包含该条区块链数据的全副本

区块链按时间序列化区块，且区块链是整个网络交易数据的唯一主体

区块链只对添加有效，对其他操作无效

基于非对称加密的公私钥验证

记账节点要求拜占庭将军问题可解/避免

共识过程（consensus progress）是演化稳定的，即面对一定量的不同节点的矛盾数据不会崩溃。

共识过程能够解决double-spending问题
</code></pre><p>所以作为一个技术人员，不应当只看到了区块链所依赖的技术，更应该关注区块链以外的点和面，综合来看，区块链将会有趣得多。</p>
<h3 id="区块链的一般性架构介绍"><a href="#区块链的一般性架构介绍" class="headerlink" title="区块链的一般性架构介绍"></a>区块链的一般性架构介绍</h3><p>有关区块链技术的介绍，在各个区块链平台的社区是有详细资料的，但是针对这些资料的总结，以及抽象出一共通概念的介绍，还是凤毛麟角，本文尝试总结一下。</p>
<p>在介绍之前，我想稍微介绍一下公有链，联盟链的概念，这些概念是以太坊创始人Vitalik提出的，我在这些概念的基础上做了一些研究。</p>
<p>其实区分公有链、联盟链很简单，只要看这个区块链的访问权限就可以了，如果访问该区块链需要获得链上节点的许可，那么这是一个联盟链，否则是公有链。根据名称，我们也可以”望文生义“，公有表示一个完全开放的网络，联盟表示一个半开放的网络，成员之间是共享的，非成员身份是没有自由访问权限的，所以我们也称联盟链为许可链。</p>
<p>下面我们来看几个比较主流的区块链平台（<strong>公有链，皆开源</strong>）：</p>
<pre><code>比特币 Bitcoin

以太坊 Ethereum/经典以太坊 Ethereum Classic

比特股 Bitshares
</code></pre><p>我一般戏称为”三巨头“，从生态上来看，比特币是最为成熟稳定的，以太坊更像是一个冲在前面的勇士，比特股相比前两位生态要小很多，但是从创新的角度，也不亚于前两位。其他的很多项目，是从这三个区块链上衍生出来的，所以以这三个为基础，基本上可以吃透区块链了。</p>
<p>不得不提的还有Linux基金会项目——HyperLedger项目（主打联盟链，开源），也是旨在打造一个通用的区块链技术，不过我认为目前尚在开发迭代当中，还没有具体的应用案例，按下不讲。</p>
<p>另外还有一些银行寡头间的联盟链项目——R3 CEV项目（联盟链，闭源），以及中国的R3项目——ChinaLedger（联盟链，闭源），当然这些不是开源的，我无法获得有用的资料进行分析，所以就不展开了。</p>
<p>从技术上来看，针对不同的业务场景，对区块链有不同需求，比如实时结算业务，要求区块链提供秒级的交割，相对应的就是出块速度的要求，而出块速度过快往往会导致区块链分叉（fork），形成孤儿链，孤儿链是无效的，那么交易也就作废了，影响了区块链的最终一致性。如果频繁产生分叉造成相当比例的用户交易失效，那么可以认为系统是不可靠的。</p>
<p>如果我们将这种实时性要求比较高的业务安插到联盟链中，就可以控制风险，通过调整共识算法，利用快速一致共识模型（Consensus Model）来避免上述问题，虽然不如公有链那么健壮，但对某些特殊场景足够了。所以架构层面，对公有链和联盟链的技术也要差异化对待。</p>
<p>不过客户端整体的设计还是有一些通用的概念的，如下图：<br><img src="http://static.zybuluo.com/BruceTang/y41educy1ksad45ueyiq0bj0/image_1bfk9irjs139416lt163nvh21a4e1g.png" alt="image_1bfk9irjs139416lt163nvh21a4e1g.png-477.6kB"></p>
<p>一个区块链至少分为三层，最底层是一些通用的基础模块，比如基础加密算法，网络通讯库，流处理，线程封装，消息封装与解码，系统时间等；</p>
<p>中间一层是区块链的核心模块，一般包含了区块链的主要逻辑，如P2P网络协议，共识模块，交易处理模块，交易池模块，简单合约或者智能合约模块，嵌入式数据库处理模块，钱包模块等；</p>
<p>最上面一层，往往都是基于Json Standard RPC的交互模块，基于Json-RPC，我们还可以做出更好的UI界面，也可以是一个web-service。</p>
<p>如果区块链 支持智能合约，可能还要分更多的层，比如增加BaaS层，区块链上的智能合约提供自治的服务，比如下面这张以太坊的架构图（来自Google，仅作参考）：<br><img src="http://static.zybuluo.com/BruceTang/z0ec109xddsjoohezg5teffz/image_1bfk9jm551tqrku13icrbmpj1t.png" alt="image_1bfk9jm551tqrku13icrbmpj1t.png-430kB"></p>
<p>这种分层更加关注的是区块链本身的分层，即业务上的视角，而不完全是技术的。</p>
<p>我们再转向比特币的设计：</p>
<p><img src="http://static.zybuluo.com/BruceTang/w6ag2x3fl20c8y0kj9cywq3f/image_1bfk9k38u176tafp144k18p369u2a.png" alt="image_1bfk9k38u176tafp144k18p369u2a.png-302.4kB"><br>比特币几个模块之间的耦合度其实比较高，而且有不少历史包袱，比特币的发明者——中本聪在开发比特币的时候，使用VC++开发，而VC++的标准库中的sstream流处理性能非常感人，不得不放弃，自行实现了了基于vector的流处理容器。而随着c++11的推出以及标准库的更新迭代，性能不可同日而语。</p>
<p>从整张图我们可以看出，比特币的模块比较少，也比较简单。chain-paramters描述了整个区块链的参数设置，wallet是与地址/加密还有存储相关的，mem-pool是未确认的交易池。得益于比特币核心开发者的不朽贡献，相比中本聪时代的比特币代码，现在的比特币代码质量已经相当不错了。</p>
<p>以上无论哪种设计，一般都要从P2P网络协议作为切入，作为一个P2P钱包，既要提供Service也要提供Client，作为Service依赖P2P网络协议，作为Client依赖Json-RPC。</p>
<p>需要指出的是，目前”三巨头”所使用的账户模型是不同的（所谓账户模型是指账户记账方法），比特币使用UXTO模型，以太坊和比特股使用账户余额模型。</p>
<p>UXTO模型（Unspent Transaction Outputs (UTXOs) ）：此模型表达了一种转移的概念，即任何产生的新币，在以后的生命周期中，只有转移，没有消亡，转移实质上是由加密算法的签名与验证控制的：</p>
<p><img src="http://static.zybuluo.com/BruceTang/7lq9t57oo5bo2xif6zvjcytd/image_1bfk9kfg31162fo21gr21kbh6ie2n.png" alt="image_1bfk9kfg31162fo21gr21kbh6ie2n.png-98.7kB"></p>
<h3 id="共识算法与分布式"><a href="#共识算法与分布式" class="headerlink" title="共识算法与分布式"></a>共识算法与分布式</h3><p>终于来到重点了，本文每节其实都可以展开成为独立的文章，内容所限，简单讲。</p>
<p>所谓区块链共识过程，在上文有所提及，是指如何将全网交易数据客观记录并且不可篡改的过程。目前”三巨头”分别使用不同的共识算法（Consensus Algorithm）, 比特币使用工作量证明PoW（Proof of Work），以太坊即将转换为权益证明PoS（Proof of Stake），比特股使用授权权益证明DPoS（Delegated Proof of Stake）。</p>
<p>以上这些算法我称之为“经济学”的算法，所谓经济学的算法，是指让作弊成本可计算，且让作弊成本往往远大于作弊带来的收益，即作弊无利可图，通过这种思想构造一个用于节点之间博弈的算法，并使之趋向一个稳定的平衡。相对应的我们还有计算机领域的分布式一致性算法，例如Paxos、Raft，我也称之为传统分布式一致性算法。</p>
<p>它们之间的最大区别是：系统在拜占庭将军（Byzantine Generals Problem）情景下的可靠性，即拜占庭容错（PBFT算法支持拜占庭容错）。然而无论是Paxos还是Raft算法，理论上都可能会进入无法表决通过的死循环(尽管这个概率其实是非常非常低的)，但是他们都是满足safety的，只是放松了liveness的要求, PBFT也是这样。</p>
<p>下面是一些传统分布式一致性算法和区块链共识过程的异同点。先来看<strong>相同点</strong>：</p>
<pre><code>Append only

强调序列化

少数服从多数原则

分离覆盖的问题：即长链覆盖短链区块，多节点覆盖少数节点日志
</code></pre><p><strong>不同点:</strong></p>
<pre><code>传统分布式一致性算法大多不考虑拜占庭容错（Byzanetine Paxos除外），即假设所有节点只发生宕机、网络故障等非人为问题，并不考虑恶意节点篡改数据的问题；

传统分布式一致性算法是面向日志（数据库）的，即更通用的情况，而区块链共识模型面向交易的，所以严格来说，传统分布式一致性算法应该处于区块链共识模型的下面一层。

考虑上面的不同点，结合公有链和联盟链的特征，我们有：

联盟链：半封闭生态的价值网络，存在对等的不信任节点，如某某协会成员之间。

公有链：开放生态的价值网络，这层主要是为行业链和私有链提供全球交易网络。
</code></pre><p>由于联盟行业链其半封闭半开放特性，使用Delegated Proof of XXX 是可行的，可以考虑以传统一致性算法作为基础加入拜占庭容错/安全防护机制进行改进也是可以的。</p>
<p>而针对公有链，PoW/Pos/DPos等“经济学”的算法可能是最优算法。技术上，以上不同的共识算法，我们很多新开发区块链都相应的支持一个特性：共识模块可插拔，以应对不同场景下的要求。</p>
<p>下图是一张未来区块链生态示意图：<br><img src="http://static.zybuluo.com/BruceTang/owcgyx3292b3gdph9bb2qloe/image_1bfk9n6161m0pbqi1v5f1g531ovr34.png" alt="image_1bfk9n6161m0pbqi1v5f1g531ovr34.png-316.3kB"></p>
<p>公有链提供可信可靠的价值传输网络，上面可以继续组建去中心化应用（DAPP）或者部署联盟链，甚至传统数据库都行，在上层搭建C端应用。</p>
<p>数字资产与价值流通网络</p>
<p>这里有张未来区块链发展的示意图：<br><img src="http://static.zybuluo.com/BruceTang/nypl7awzbnwb1qp6z0z4p2zu/image_1bfk9nh14dpitsu1a8i1u8i81u3h.png" alt="image_1bfk9nh14dpitsu1a8i1u8i81u3h.png-216.6kB"></p>
<p>ref: Metaverse元界白皮书-CN(概要)</p>
<p>“三巨头”中，比特币在“数字货币”处，比特股在“去中心化交易所”附近，以太坊在“去中心化组织”处。而实际上，区块链和现实的接触点，还在图示位置。所以区块链仍是一个正在成长的事物，结合图5，我们希望构建一个基础设施完善的价值传输网络，上层应用丰富的区块链生态，仍然需要付出巨大的努力。</p>
<p>下一步目标，是将资产数字化（类比资产证券化），例如我们可以将珍稀物品（艺术品/古董）数字化、知识产权数字化、票据基金等收益权数字化，将极大的提升市场运作效率，配备智能合约，甚至人工智能，可编程社会不再是梦想。</p>
]]></content>
      
        <categories>
            
            <category> 区块链技术 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 区块链技术 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[zabbix 3.0 分布式监控]]></title>
      <url>http://yoursite.com/2016/10/04/zabbix%203.0%20%E5%88%86%E5%B8%83%E5%BC%8F%E7%9B%91%E6%8E%A7/</url>
      <content type="html"><![CDATA[<p>Zabbix Proxy是一个类似于代理的服务，可以代替Zabbix-server获取 zabbix-agent信息。其中数据存到本地（Proxy有自己的数据库）然后在发送给Server，这样可以保证数据不丢失 </p>
<a id="more"></a>
<p>　　Zabbix-server —–&gt;Zabbix-Proxy —–&gt;Zabbix-agent<br><img src="http://static.zybuluo.com/BruceTang/61a8i6ptqxvqq9jt8rz08u4r/image_1bf5l7am9187gaosmifsuebqs9.png" alt="image_1bf5l7am9187gaosmifsuebqs9.png-105.7kB"></p>
<p>地址：<a href="https://www.zabbix.com/documentation/3.0/manual/distributed_monitoring/proxies" target="_blank" rel="external">https://www.zabbix.com/documentation/3.0/manual/distributed_monitoring/proxies</a></p>
<h2 id="Zabbix-Proxy-使用场景"><a href="#Zabbix-Proxy-使用场景" class="headerlink" title="Zabbix Proxy 使用场景"></a>Zabbix Proxy 使用场景</h2><p>常用于多机房情况或者监控主机特别多，几千台左右。这时候使用Zabbix Proxy 可以减轻服务器server的压力，还可以减轻Zabbix的维护。<br>　　最常用的特点是适用于多机房、网络不稳定的时候，因为如果直接由Zabbix-server发送信息可能agent没有收到，但是直接使用Zabbix-Proxy就不会遇到这个问题。 </p>
<p><strong>Zabbix官方说明（分布式监控）</strong><br><img src="http://static.zybuluo.com/BruceTang/fk76r97vk45wrb63f4b7borw/image_1bf5l9b69uc81pum12eg17cm1o2tm.png" alt="image_1bf5l9b69uc81pum12eg17cm1o2tm.png-141.7kB"><br>地址： <a href="https://www.zabbix.com/documentation/3.0/manual/distributed_monitoring" target="_blank" rel="external">https://www.zabbix.com/documentation/3.0/manual/distributed_monitoring</a><br><strong>NO - 中文解释</strong><br>1.没有Web界面<br>2.本身不做任何告警通知（告警通知都是Server做）</p>
<p><strong>小结：</strong><br>　　Zabbix Proxy 可以有多个，用来代理Zabbix server来运行。Proxy会将所有数据暂存于本地,然后同一转发到Zabbix Server上<br>　　Proxy只需要一条TCP链接，可以连接到Zabbix-server上即可。所以防火墙只需要添加一条Zabbix Proxy即可 我们可以参考上面的Zabbix Proxy图<br>　　Proxy是需要使用单独的数据库，所以不能将Server和Agent放在一起<br>Proxy说明：<a href="https://www.zabbix.com/documentation/3.0/manual/distributed_monitoring/proxies" target="_blank" rel="external">https://www.zabbix.com/documentation/3.0/manual/distributed_monitoring/proxies</a><br>安装文档：<a href="https://www.zabbix.com/documentation/3.0/manual/installation/install" target="_blank" rel="external">https://www.zabbix.com/documentation/3.0/manual/installation/install</a><br>　官方文档使用的是源码安装，因为方便我们使用yum安装，因为我们只有2台，所以就用agent当做Proxy</p>
<h2 id="zabbix-proxy安装"><a href="#zabbix-proxy安装" class="headerlink" title="zabbix-proxy安装"></a>zabbix-proxy安装</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[root@node-12 ~]#  rpm -ivh http://mirrors.aliyun.com/zabbix/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm</div><div class="line"></div><div class="line">[root@node-12 ~]# yum install -y zabbix-proxy zabbix-proxy-mysql mariadb-server</div><div class="line"></div><div class="line">我们需要启动MySQL</div><div class="line">[root@node-12 ~]# systemctl start mariadb.service</div></pre></td></tr></table></figure>
<p>我们还需要创建一个库<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt;create database zabbix_proxy character set utf8;</div><div class="line">&gt;grant all on zabbix_proxy.* to zabbix_proxy@localhost identified by &apos;zabbix_proxy&apos;;</div></pre></td></tr></table></figure></p>
<p>我们需要导入数据<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[root@node-12 ~]# cd /usr/share/doc/zabbix-proxy-mysql-3.0.9/</div><div class="line">[root@node-12 zabbix-proxy-mysql-3.0.9]# zcat schema.sql.gz | mysql -uzabbix_proxy -p zabbix_proxy</div><div class="line">Enter password: </div><div class="line"></div><div class="line">#密码是：zabbix_proxy 是我们数据库授权的密码</div></pre></td></tr></table></figure></p>
<p>检查数据库<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">&gt;show databases;</div><div class="line">&gt;use zabbix_proxy;</div><div class="line">&gt;show tables;</div><div class="line"></div><div class="line">#查看是否含有数据</div></pre></td></tr></table></figure></p>
<p>我们需要修改proxy的配置文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">[root@node-12 ~]# vim /etc/zabbix/zabbix_proxy.conf</div><div class="line">Server=192.168.10.10（zabbixserver端IP）</div><div class="line">Hostname=Zabbix proxy</div><div class="line">DBName=zabbix_proxy</div><div class="line">#数据库名称</div><div class="line"></div><div class="line">DBUser=zabbix_proxy</div><div class="line">#用户名</div><div class="line"></div><div class="line">DBPassword=zabbix_proxy</div><div class="line">#用户密码</div><div class="line">配置文件中没有配置的内容如下：（有需要可以配置）</div><div class="line"></div><div class="line"># ProxyLocalBuffer=0</div><div class="line">#数据保留的时间（小时为单位）</div><div class="line"></div><div class="line"># ProxyOfflineBuffer=1</div><div class="line">#连不上Server，数据要保留多久（小时为单位，默认1小时）</div><div class="line"></div><div class="line"># DataSenderFrequency=1</div><div class="line">#数据的发送时间间隔（默认是1秒）</div><div class="line"></div><div class="line"># StartPollers=5</div><div class="line">#启动的线程数</div><div class="line"></div><div class="line"># StartIPMIPollers=0</div><div class="line">#启动IPMI的线程数</div><div class="line">从这往下都是性能的监控，就不一次说明了。 上面都有中文注释</div></pre></td></tr></table></figure></p>
<p>过滤修改过的配置如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">[root@node-12 ~]# grep &apos;^[a-Z]&apos; /etc/zabbix/zabbix_proxy.conf</div><div class="line">Server=192.168.10.10</div><div class="line">Hostname=Zabbix proxy</div><div class="line">LogFile=/var/log/zabbix/zabbix_proxy.log</div><div class="line">LogFileSize=0</div><div class="line">PidFile=/var/run/zabbix/zabbix_proxy.pid</div><div class="line">DBName=zabbix_proxy</div><div class="line">DBUser=zabbix_proxy</div><div class="line">SNMPTrapperFile=/var/log/snmptrap/snmptrap.log</div><div class="line">Timeout=4</div><div class="line">ExternalScripts=/usr/lib/zabbix/externalscripts</div><div class="line">LogSlowQueries=3000</div></pre></td></tr></table></figure></p>
<p>启动：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">[root@node-12 ~]# systemctl start zabbix-proxy (坑：需要被seLinux关闭，不然起不来)</div><div class="line">[root@node-12 ~]# netstat -lntup</div><div class="line">Active Internet connections (only servers)</div><div class="line">Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    </div><div class="line">tcp        0      0 127.0.0.1:25            0.0.0.0:*               LISTEN      2558/master         </div><div class="line">tcp        0      0 0.0.0.0:5050            0.0.0.0:*               LISTEN      1483/mesos-master   </div><div class="line">tcp        0      0 0.0.0.0:5051            0.0.0.0:*               LISTEN      2997/mesos-slave    </div><div class="line">tcp        0      0 0.0.0.0:10051           0.0.0.0:*               LISTEN      7992/zabbix_proxy   </div><div class="line">tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      1501/sshd           </div><div class="line">tcp6       0      0 ::1:25                  :::*                    LISTEN      2558/master         </div><div class="line">tcp6       0      0 :::10051                :::*                    LISTEN      7992/zabbix_proxy   </div><div class="line">tcp6       0      0 :::3306                 :::*                    LISTEN      2949/mysqld         </div><div class="line">tcp6       0      0 :::22                   :::*                    LISTEN      1501/sshd           </div><div class="line">udp        0      0 192.168.10.12:123       0.0.0.0:*                           823/ntpd            </div><div class="line">udp        0      0 172.17.0.1:123          0.0.0.0:*                           823/ntpd            </div><div class="line">udp        0      0 127.0.0.1:123           0.0.0.0:*                           823/ntpd            </div><div class="line">udp        0      0 0.0.0.0:123             0.0.0.0:*                           823/ntpd            </div><div class="line">udp        0      0 0.0.0.0:33999           0.0.0.0:*                           780/avahi-daemon: r </div><div class="line">udp        0      0 0.0.0.0:5353            0.0.0.0:*                           780/avahi-daemon: r </div><div class="line">udp6       0      0 fe80::20c:29ff:fe81:123 :::*                                823/ntpd            </div><div class="line">udp6       0      0 ::1:123                 :::*                                823/ntpd            </div><div class="line">udp6       0      0 :::123                  :::*                                823/ntpd</div></pre></td></tr></table></figure></p>
<p>Zabbix-proxy 监控10051端口，因为是代理就必须跟Server的端口相同，对于Agent Proxy就是Server</p>
<p>##Zabbix Web 添加##<br><img src="http://static.zybuluo.com/BruceTang/05cl1r3e7k20m58nfyf9kj77/image_1bf79pmp0154n9l11i0e6oi1h6613.png" alt="image_1bf79pmp0154n9l11i0e6oi1h6613.png-135.8kB"><br><img src="http://static.zybuluo.com/BruceTang/59qn9ugnygfm97vjhlmdbflo/image_1bf7cnf1h1dasr391grh1vj02bi9.png" alt="!image_1bf79rsj1q5ro691a9eo331sc21g.png-142.4kB"><br><img src="http://static.zybuluo.com/BruceTang/u5uivrm6a15q9jz0v345w5rt/image_1bf79sfc71gotd92lianj919a81t.png" alt="image_1bf79sfc71gotd92lianj919a81t.png-144.8kB"></p>
<p>修改agent主机<br><img src="http://static.zybuluo.com/BruceTang/1lsab5jzw89u55g8urvicns3/image_1bf79t1vv1s5sc2f17hckkvr232a.png" alt="image_1bf79t1vv1s5sc2f17hckkvr232a.png-191.8kB"><br><img src="http://static.zybuluo.com/BruceTang/k9og1jxtydejrf7anq8zfwt6/image_1bf79ugsd3ru8mu1ct71pao4ta2n.png" alt="image_1bf79ugsd3ru8mu1ct71pao4ta2n.png-130.5kB"></p>
<p>我们需要将这代理端的数据发送给给Proxy<br>编辑agent端（192.168.10.11）这台主机，需要将Server的IP地址修改成自己的<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@node-11 ~]# vim /etc/zabbix/zabbix_agentd.conf </div><div class="line">ServerActive=192.168.10.11</div><div class="line">#配置文件修改完需要重启</div><div class="line">[root@node-11 ~]# systemctl restart zabbix-agent</div></pre></td></tr></table></figure></p>
<p>这时候我们就可以看到那个proxy都管理了那些机器,做到方便管理的机制<br><img src="http://static.zybuluo.com/BruceTang/mylylk75c5533bzsybqno5kk/image_1bf7a6hvoek0lndvir12rhedv34.png" alt="image_1bf7a6hvoek0lndvir12rhedv34.png-201.6kB"><br><img src="http://static.zybuluo.com/BruceTang/o36z39h959h4sdm774ujmxpp/image_1bf7arfluk05lk1ug719dd2cd3h.png" alt="image_1bf7arfluk05lk1ug719dd2cd3h.png-225.7kB"></p>
]]></content>
      
        <categories>
            
            <category> 运维监控 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> zabbix3.0 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[zabbix 3.0 主动式监控]]></title>
      <url>http://yoursite.com/2016/10/04/zabbix%203.0%20%E4%B8%BB%E5%8A%A8%E5%BC%8F%E7%9B%91%E6%8E%A7/</url>
      <content type="html"><![CDATA[<p><strong>监控常遇到的问题？</strong><br>　　1.监控主机多，性能跟不上，延迟大<br>　　2.多机房，防火墙因素<br>Zabbix轻松解决以上问题，Nagios不太好解决的问题。</p>
<p><strong>Zabbix 模式介绍：</strong><br>1、被动模式<br>2、主动模式</p>
<a id="more"></a>
<p>默认是被动模式，我们可以通过以下方式查看监控项是什么模式<br><img src="http://static.zybuluo.com/BruceTang/i209oboed960ccdai7j30opw/image_1bf4mod7e6mfhfpbit1ct359om.png" alt="image_1bf4mod7e6mfhfpbit1ct359om.png-219.5kB"></p>
<p>因为我们使用的是模板，无法进行修改。我们可以修改配置文件或者新建item的时候设置。<br><img src="http://static.zybuluo.com/BruceTang/a26801341q0bo1ihn3kmm3vv/image_1bf4ms3fc1gfj1qk4m4113fi126213.png" alt="image_1bf4ms3fc1gfj1qk4m4113fi126213.png-233.1kB"></p>
<p>　　<strong>注意：</strong><br>　1、当监控主机超过300+，建议使用主动模式（此处是一个经验值，要根据服务器的硬件来进行考虑）<br>　2、还需要保证Queue对列里面没有延迟的主机</p>
<p><strong>Queue 对列介绍</strong><br>如果此处的延迟主机有点多的话，我们就需要将被动模式修改为主动模式.<br><img src="http://static.zybuluo.com/BruceTang/0o13q9g70f96zrvbuv9shl5r/image_1bf4mtvfgh8kcldre55kn78k1g.png" alt="image_1bf4mtvfgh8kcldre55kn78k1g.png-173.8kB"></p>
<h2 id="主动模式设置"><a href="#主动模式设置" class="headerlink" title="主动模式设置"></a>主动模式设置</h2><p>将原来的agent端192.168.10.11监控设置为主动模式 </p>
<p>###　修改配置文件<br>为了方便模拟，我们将node-11(192.168.10.11)从Zabbix删除从新添加<br><img src="http://static.zybuluo.com/BruceTang/jqzj9iexu6gb432wiqtouczd/image_1bf4n2lv01c3h1p9oh8763v16ft1t.png" alt="image_1bf4n2lv01c3h1p9oh8763v16ft1t.png-192.8kB"></p>
<h3 id="配置zabbix-agentd-conf文件"><a href="#配置zabbix-agentd-conf文件" class="headerlink" title="配置zabbix_agentd.conf文件"></a>配置zabbix_agentd.conf文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">[root@node-11 ~]# vim /etc/zabbix/zabbix_agentd.conf</div><div class="line">#Server=192.168.10.10</div><div class="line">#servr端IP,我们需要注释Server，因为这个是被动模式用的</div><div class="line"></div><div class="line">StartAgents=0</div><div class="line">#设置为0之后就不会TCP端口，之前监听TCP端口是因为Server要去问agent信息所以需要开启</div><div class="line"></div><div class="line">ServerActive=192.168.10.10</div><div class="line">#server端IP，此处可以是IP或者是域名，他会连接10051端口</div><div class="line"></div><div class="line">Hostname=node-11</div><div class="line">#agent端主机名，唯一识别符，我们需要修改成我们本机的主机名。如果我们不设置，它默认会通过item来获取</div><div class="line"></div><div class="line">[root@node-11 ~]# systemctl restart zabbix-agent.service </div><div class="line">保存重启</div></pre></td></tr></table></figure>
<p>保存重启之后我们可以查看我们监听的一些端口，因为我们关闭的被动模式所以不会在监听zabbix端口了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">[root@node-11 ~]# netstat -lntup</div><div class="line">Active Internet connections (only servers)</div><div class="line">Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    </div><div class="line">tcp        0      0 127.0.0.1:25            0.0.0.0:*               LISTEN      2435/master         </div><div class="line">tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      1416/sshd           </div><div class="line">tcp6       0      0 ::1:25                  :::*                    LISTEN      2435/master         </div><div class="line">tcp6       0      0 :::3306                 :::*                    LISTEN      2606/mysqld         </div><div class="line">tcp6       0      0 :::22                   :::*                    LISTEN      1416/sshd           </div><div class="line">udp        0      0 0.0.0.0:51218           0.0.0.0:*                           757/avahi-daemon: r </div><div class="line">udp        0      0 0.0.0.0:5353            0.0.0.0:*                           757/avahi-daemon: r</div></pre></td></tr></table></figure>
<h2 id="Zabbix-web设置"><a href="#Zabbix-web设置" class="headerlink" title="Zabbix-web设置"></a>Zabbix-web设置</h2><p>我们需要添加zabbix-agent active(也就是主动模式)<br>添加模板，zabbix没有提供主动模式的模板。所以我们需要克隆一下OS Linux<br><img src="http://static.zybuluo.com/BruceTang/qfuux37zmoxlo6gn31j4uw2l/image_1bf4njff3uh1s1l1v1v9clabc2a.png" alt="image_1bf4njff3uh1s1l1v1v9clabc2a.png-252.3kB"></p>
<p>找到OS Linux 模板，移动到最下面 点击复制<br><img src="http://static.zybuluo.com/BruceTang/5ekpof92atjk7g0hcqs9mpjy/image_1bf4nkreaettphkcm7lsvt5o2n.png" alt="image_1bf4nkreaettphkcm7lsvt5o2n.png-72.2kB"></p>
<p>我们从新进行设置名称<br><img src="http://static.zybuluo.com/BruceTang/mwbj07z0pffea84pwvujycii/image_1bf4nms3hgji1gin190map5r334.png" alt="image_1bf4nms3hgji1gin190map5r334.png-168.6kB"></p>
<p>修改我们刚刚添加的模板名为OS Linux Active<br><img src="http://static.zybuluo.com/BruceTang/rtpignfk79cek3kmez85ku2o/image_1bf4npoaq1qckergqj31m7319pr3h.png" alt="image_1bf4npoaq1qckergqj31m7319pr3h.png-283.4kB"></p>
<p>我们点击刚刚创建模板的item<br><img src="http://static.zybuluo.com/BruceTang/f0bce1j1xk1l6msgsw4sfbzk/image_1bf4nsdeq6nfl3v25l7186u3u.png" alt="image_1bf4nsdeq6nfl3v25l7186u3u.png-145.3kB"></p>
<p>进行批量更新<br><img src="http://static.zybuluo.com/BruceTang/ersmlo255wtx7nkrex97lf3i/image_1bf4ntjqf148vk261ig0a43set4b.png" alt="image_1bf4ntjqf148vk261ig0a43set4b.png-218.3kB"><br><img src="http://static.zybuluo.com/BruceTang/cshaw8fwtwhwt0a9r6ombarp/image_1bf4nv4q31doa1c2q15868s644k4o.png" alt="image_1bf4nv4q31doa1c2q15868s644k4o.png-166.7kB"><br>然后选择最下方Update </p>
<p>结果如下：<br><img src="http://static.zybuluo.com/BruceTang/r9er3o91cz5smz9wtmwz9w0w/image_1bf4o0hpje881qd7pf0hk816jn55.png" alt="image_1bf4o0hpje881qd7pf0hk816jn55.png-230.1kB"></p>
<p>添加主机<br><img src="http://static.zybuluo.com/BruceTang/lrs64t8ywuxnjbqws9mmhis8/image_1bf4o4oigigd192ldaj1i6v17na5i.png" alt="image_1bf4o4oigigd192ldaj1i6v17na5i.png-166kB"><br><img src="http://static.zybuluo.com/BruceTang/3z92a8f0kzuwf22xuwgkholx/image_1bf4o5aj015aa1j86b0k1880eh05v.png" alt="image_1bf4o5aj015aa1j86b0k1880eh05v.png-147.5kB"></p>
<p>最终结果<br><img src="http://static.zybuluo.com/BruceTang/8t107a1gptzj6ijvjl90ikbm/image_1bf4o9eo2vrp1s8449m1cfgo296c.png" alt="image_1bf4o9eo2vrp1s8449m1cfgo296c.png-186.6kB"><br><img src="http://static.zybuluo.com/BruceTang/72otq3n4r8nmll2892jgj7he/image_1bf4oa0sm4ih9qef4d1ouj1rdv6p.png" alt="image_1bf4oa0sm4ih9qef4d1ouj1rdv6p.png-220.5kB"></p>
]]></content>
      
        <categories>
            
            <category> 运维监控 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> zabbix3.0 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[zabbix 3.0 自定义监控--磁盘读写]]></title>
      <url>http://yoursite.com/2016/10/03/zabbix%203.0%20%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9B%91%E6%8E%A7--%E7%A3%81%E7%9B%98%E8%AF%BB%E5%86%99/</url>
      <content type="html"><![CDATA[<h2 id="zabbix-客户端"><a href="#zabbix-客户端" class="headerlink" title="zabbix 客户端"></a>zabbix 客户端</h2><p>修改zabbix_agentd.conf文件<br>在zabbix_agentd.conf最后添加以下内容<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@node-11 ~]# vim /etc/zabbix/zabbix_agentd.conf</div><div class="line">UserParameter=check_disk_status,mount | awk &apos;&#123;print $NF&#125;&apos;|cut -c 2-3|awk &apos;&#123;if($1~/ro/) &#123;print 1&#125;&#125;&apos;|wc -l|awk &apos;&#123;if($1&lt;=0) &#123;print 0 &#125; else &#123;print 1&#125;&#125;&apos;</div><div class="line"></div><div class="line">[root@node-11 ~]# systemctl restart zabbix-agent</div></pre></td></tr></table></figure></p>
<a id="more"></a>
<h2 id="zabbix-服务端"><a href="#zabbix-服务端" class="headerlink" title="zabbix 服务端"></a>zabbix 服务端</h2><h3 id="新增监控项"><a href="#新增监控项" class="headerlink" title="新增监控项"></a>新增监控项</h3><p><img src="http://static.zybuluo.com/BruceTang/gcauptcv5r5nky2cnww2x8yg/image_1bf22nn2l7t7udk1kjqd2l1t3dej.png" alt="image_1bf22nn2l7t7udk1kjqd2l1t3dej.png-187.3kB"></p>
<h3 id="新增图形"><a href="#新增图形" class="headerlink" title="新增图形"></a>新增图形</h3><p><img src="http://static.zybuluo.com/BruceTang/e8ounaz18lziyz6xeb7ggqgl/image_1bf22oou51ip4sia13te1dl2cshf0.png" alt="image_1bf22oou51ip4sia13te1dl2cshf0.png-169.3kB"><br>结果<br><img src="http://static.zybuluo.com/BruceTang/7vxhvytul7r9ry8bkjwd06u9/image_1bf22pf941si614nr3401jetb6kfd.png" alt="image_1bf22pf941si614nr3401jetb6kfd.png-203.4kB"><br>如果返回值0代表磁盘都是rw状态可以正常读写，返回值1的话，代表磁盘是ro状态</p>
]]></content>
      
        <categories>
            
            <category> 运维监控 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> zabbix3.0 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[zabbix 3.0 自定义监控--磁盘IO]]></title>
      <url>http://yoursite.com/2016/10/03/zabbix%203.0%20%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9B%91%E6%8E%A7--%E7%A3%81%E7%9B%98IO/</url>
      <content type="html"><![CDATA[<p>对于我们的服务器来说，性能瓶颈往往就是磁盘，针对这种情况，我觉得我们有必要监控磁盘的IO情况，这里我们使用iostat命令取得的结果，然后图形化的展示到zabbix中。<br>zabbix的安装配置叫简单这么不做过多的描述<br><a id="more"></a></p>
<h2 id="zabbix中自定义监控的key"><a href="#zabbix中自定义监控的key" class="headerlink" title="zabbix中自定义监控的key"></a>zabbix中自定义监控的key</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[root@node-11 ~]# yum install -y sysstat</div><div class="line">[root@node-11 ~]# vim /etc/zabbix/zabbix_agentd.conf </div><div class="line">##disk_io</div><div class="line">UserParameter=io_sda_idle,iostat -x /dev/mapper/centos-root  | sed -n &apos;4p&apos; | awk &apos;&#123;print $NF&#125;&apos;</div><div class="line">UserParameter=io_sda_iowait,iostat -x /dev/mapper/centos-root  | sed -n &apos;4p&apos; | awk &apos;&#123;print $4&#125;&apos;</div><div class="line">UserParameter=io_sda_tps,iostat -d /dev/mapper/centos-root  | sed -n &apos;4p&apos; | awk &apos;&#123;print $2&#125;&apos;</div><div class="line"></div><div class="line">[root@node-11 ~]# systemctl restart zabbix-agent</div></pre></td></tr></table></figure>
<h2 id="添加监控项"><a href="#添加监控项" class="headerlink" title="添加监控项"></a>添加监控项</h2><p>添加监控项<br><img src="http://static.zybuluo.com/BruceTang/qvlwkrpuff58wsahhgsdmxix/image_1bf1u1po91g81195d12ut1d23ctidp.png" alt="image_1bf1tb05v1dcmgcmp391r98e9tcv.png-189kB"><br>添加图形<br><img src="http://static.zybuluo.com/BruceTang/n6amyy2rhqws0iksoini81la/image_1bf1tdfc2166m10tm1j5d1anv1ciedc.png" alt="image_1bf1tdfc2166m10tm1j5d1anv1ciedc.png-193.2kB"><br>最终结果<br><img src="http://static.zybuluo.com/BruceTang/2jujgugo6tdgjeiq206tm331/image_1bf1ug87iedn1qu61ib1157ok35e6.png" alt="image_1bf1ug87iedn1qu61ib1157ok35e6.png-206.5kB"></p>
]]></content>
      
        <categories>
            
            <category> 运维监控 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> zabbix3.0 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[zabbix 3.0 自定义监控--磁盘使用率]]></title>
      <url>http://yoursite.com/2016/10/03/zabbix%203.0%20%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9B%91%E6%8E%A7--%E7%A3%81%E7%9B%98%E4%BD%BF%E7%94%A8%E7%8E%87/</url>
      <content type="html"><![CDATA[<h2 id="磁盘监控脚本"><a href="#磁盘监控脚本" class="headerlink" title="磁盘监控脚本"></a>磁盘监控脚本</h2><p>本次zabbix监控磁盘测试。只监控磁盘的/目录和mount挂载的home两个目录使用率情况。<br><a id="more"></a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">磁盘情况</div><div class="line">[root@node-11 ~]# df -h</div><div class="line">文件系统                 容量  已用  可用 已用% 挂载点</div><div class="line">/dev/mapper/centos-root   50G  2.1G   48G    5% /</div><div class="line">devtmpfs                 911M     0  911M    0% /dev</div><div class="line">tmpfs                    918M     0  918M    0% /dev/shm</div><div class="line">tmpfs                    918M  8.6M  909M    1% /run</div><div class="line">tmpfs                    918M     0  918M    0% /sys/fs/cgroup</div><div class="line">/dev/mapper/centos-home   42G   33M   42G    1% /home</div><div class="line">/dev/sda1                497M   97M  400M   20% /boot</div><div class="line">tmpfs                    184M     0  184M    0% /run/user/0</div></pre></td></tr></table></figure></p>
<p>磁盘监控脚本<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div></pre></td><td class="code"><pre><div class="line">[root@node-11 script]# pwd</div><div class="line">/etc/zabbix/script</div><div class="line">[root@node-11 script]# vim  disk_use.sh</div><div class="line">#!/bin/bash</div><div class="line">system()&#123;</div><div class="line">    df -m |awk &apos;&#123;if($1~&quot;/dev&quot;) print $2,$3,$4,$5,$NF&#125;&apos;|grep &quot;/$&quot;</div><div class="line">&#125;</div><div class="line">mount()&#123;</div><div class="line">    df -m | awk &apos;&#123;if($1~&quot;/dev&quot;) print $2,$3,$4,$5,$NF&#125;&apos;|grep &quot;/home$&quot;</div><div class="line">&#125;</div><div class="line">system_inode()&#123;</div><div class="line">    df -i | awk &apos;&#123;if($1~&quot;/dev&quot;) print $2,$3,$4,$5,$NF&#125;&apos;|grep &quot;/$&quot;</div><div class="line">&#125;</div><div class="line">mount_inode()&#123;</div><div class="line">    df -i | awk &apos;&#123;if($1~&quot;/dev&quot;) print $2,$3,$4,$5,$NF&#125;&apos;|grep &quot;/home$&quot;</div><div class="line">&#125;</div><div class="line"></div><div class="line">case &quot;$1&quot; in</div><div class="line">    system_size)</div><div class="line">        #system | awk &apos;&#123;print$1&apos;&#125; | awk &apos;&#123;sub(/.$/,&quot;&quot;)&#125;1&apos;</div><div class="line">        system | awk &apos;&#123;print$1&apos;&#125;</div><div class="line">        ;;</div><div class="line">    system_used)</div><div class="line">        system | awk &apos;&#123;print$2&apos;&#125;</div><div class="line">        ;;</div><div class="line">    system_avail)</div><div class="line">        system | awk &apos;&#123;print$3&apos;&#125;</div><div class="line">        ;;</div><div class="line">    system_use)</div><div class="line">        system | awk &apos;&#123;print$4&apos;&#125; | awk &apos;&#123;sub(/.$/,&quot;&quot;)&#125;1&apos;</div><div class="line">        ;;</div><div class="line">    mount_size)</div><div class="line">        mount | awk  &apos;&#123;print $1&#125;&apos;</div><div class="line">        ;;</div><div class="line">        mount_used)</div><div class="line">        mount | awk  &apos;&#123;print $2&#125;&apos;</div><div class="line">        ;;</div><div class="line">    mount_avail)</div><div class="line">        mount | awk  &apos;&#123;print $3&#125;&apos;</div><div class="line">        ;;</div><div class="line">    mount_use)</div><div class="line">        mount | awk  &apos;&#123;print $4&#125;&apos; | awk &apos;&#123;sub(/.$/,&quot;&quot;)&#125;1&apos;</div><div class="line">        ;;</div><div class="line">    system_inode_use)</div><div class="line">        system_inode | awk &apos;&#123;print$4&apos;&#125; | awk &apos;&#123;sub(/.$/,&quot;&quot;)&#125;1&apos;</div><div class="line">        ;;</div><div class="line">    mount_inode_use)</div><div class="line">        mount_inode | awk  &apos;&#123;print $4&#125;&apos; |awk &apos;&#123;sub(/.$/,&quot;&quot;)&#125;1&apos;</div><div class="line">        ;;</div><div class="line">esac</div><div class="line"></div><div class="line">[root@node-11 script]# chmod +x disk_use.sh</div></pre></td></tr></table></figure></p>
<h2 id="添加磁盘自定义键值"><a href="#添加磁盘自定义键值" class="headerlink" title="添加磁盘自定义键值"></a>添加磁盘自定义键值</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">[root@node-11 script]# vim /etc/zabbix/zabbix_agentd.conf </div><div class="line">##在末尾添加以下内容</div><div class="line">##disk_use</div><div class="line">UserParameter=system.size,/etc/zabbix/script/disk_use.sh system_size</div><div class="line">UserParameter=system.used,/etc/zabbix/script/disk_use.sh system_used</div><div class="line">UserParameter=system.avail,/etc/zabbix/script/disk_use.sh system_avail</div><div class="line">UserParameter=system.use,/etc/zabbix/script/disk_use.sh system_use</div><div class="line">UserParameter=mount.size,/etc/zabbix/script/disk_use.sh mount_size</div><div class="line">UserParameter=mount.used,/etc/zabbix/script/disk_use.sh mount_used</div><div class="line">UserParameter=mount.avail,/etc/zabbix/script/disk_use.sh mount_avail</div><div class="line">UserParameter=mount.use,/etc/zabbix/script/disk_use.sh mount_use</div><div class="line">UserParameter=system.inode.use,/etc/zabbix/script/disk_use.sh system_inode_use</div><div class="line">UserParameter=mount.inode.use,/etc/zabbix/script/disk_use.sh mount_inode_use</div></pre></td></tr></table></figure>
<h2 id="在zabbix-server端测试"><a href="#在zabbix-server端测试" class="headerlink" title="在zabbix-server端测试"></a>在zabbix-server端测试</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# zabbix_get -s 192.168.1.11 -k  system.avail</div><div class="line">49049</div><div class="line">[root@node-10 ~]# zabbix_get -s 192.168.1.11 -k  system.use</div><div class="line">5</div><div class="line">[root@node-10 ~]# zabbix_get -s 192.168.1.11 -k  mount.inode.use</div><div class="line">1</div><div class="line">[root@node-10 ~]# zabbix_get -s 192.168.1.11 -k  mount.size</div><div class="line">42596</div><div class="line">[root@node-10 ~]# zabbix_get -s 192.168.1.11 -k  mount.used</div><div class="line">33</div><div class="line">[root@node-10 ~]# zabbix_get -s 192.168.1.11 -k  mount.avail</div><div class="line"></div><div class="line">[root@node-10 ~]# zabbix_get -s 192.168.1.11 -k  mount.avail</div><div class="line">42564</div><div class="line">[root@node-10 ~]# zabbix_get -s 192.168.1.11 -k  mount.use</div><div class="line">1</div><div class="line">[root@node-10 ~]# zabbix_get -s 192.168.1.11 -k  system.inode.use</div><div class="line">1</div><div class="line">[root@node-10 ~]# zabbix_get -s 192.168.1.11 -k  mount.inode.use</div><div class="line">1</div></pre></td></tr></table></figure>
<h2 id="zabbix-web端配置"><a href="#zabbix-web端配置" class="headerlink" title="zabbix web端配置"></a>zabbix web端配置</h2><p>添加监控项<br><img src="http://static.zybuluo.com/BruceTang/9thfbdrtdsuurehwb62iaom8/image_1bf1i5u5gcpvsld18jfh9u1oajbb.png" alt="image_1bf1i5u5gcpvsld18jfh9u1oajbb.png-194.4kB"><br><img src="http://static.zybuluo.com/BruceTang/tf9zqh0g4hbnt4d7t64unmk6/image_1bf1i797s186l15hg6qd1sj7181ibo.png" alt="image_1bf1i797s186l15hg6qd1sj7181ibo.png-189.4kB"><br>添加图形<br><img src="http://static.zybuluo.com/BruceTang/t80lcbk2s8mwbuk76ckm4xps/image_1bf1i8ka04ri1i7m1qbqb131ia5c5.png" alt="image_1bf1i8ka04ri1i7m1qbqb131ia5c5.png-179.8kB"><br>最终结果<br><img src="http://static.zybuluo.com/BruceTang/uiozu46wxau944h673qiy2zw/image_1bf1ihld31irk102ummb1a4a11lkci.png" alt="image_1bf1ihld31irk102ummb1a4a11lkci.png-336.6kB"></p>
]]></content>
      
        <categories>
            
            <category> 运维监控 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> zabbix3.0 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[zabbix 3.0 自定义监控--内存、cpu、负载]]></title>
      <url>http://yoursite.com/2016/10/03/zabbix%203.0%20%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9B%91%E6%8E%A7--%E5%86%85%E5%AD%98%E3%80%81cpu%E3%80%81%E8%B4%9F%E8%BD%BD/</url>
      <content type="html"><![CDATA[<h2 id="客户端编写监控内存脚本"><a href="#客户端编写监控内存脚本" class="headerlink" title="客户端编写监控内存脚本"></a>客户端编写监控内存脚本</h2><a id="more"></a>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">bash-3.2# yum install -y zabbix zabbix-agent</div><div class="line">bash-3.2# cd /etc/zabbix</div><div class="line">bash-3.2 zabbix# mkdir script</div><div class="line">bash-3.2 zabbix# vim script/mem.sh</div><div class="line">#!/bin/bash</div><div class="line">MEMTotal()&#123;</div><div class="line">free -m | awk &apos;/Mem:/&#123;print $2&#125;&apos;</div><div class="line">&#125;</div><div class="line"> </div><div class="line">MEMuser()&#123;</div><div class="line">free -m | awk &apos;/buffers\/cache:/&#123;print $3&#125;&apos;</div><div class="line">&#125;</div><div class="line"> </div><div class="line">MEMfree()&#123;</div><div class="line">free -m | awk &apos;/buffers\/cache:/&#123;print $4&#125;&apos;</div><div class="line">&#125;</div><div class="line">$1</div><div class="line">bash-3.2 zabbix# vim zabbix_agentd.conf     #末尾新增如下</div><div class="line">UnsafeUserParameters=1</div><div class="line">UserParameter=memtotal,/etc/zabbix/script/mem.sh MEMTotal</div><div class="line">UserParameter=memuse,/etc/zabbix/script/mem.sh MEMuser</div><div class="line">UserParameter=memfree,/etc/zabbix/script/mem.sh MEMfree</div><div class="line">bash-3.2 zabbix# /etc/init.d/zabbix-agent start</div><div class="line">bash-3.2 ~# zabbix_get -s zabbix_agent_ip -k memfree        #zabbix服务端执行</div><div class="line">718</div></pre></td></tr></table></figure>
<p><img src="http://static.zybuluo.com/BruceTang/32i8iq8t3o9abswhjb0p2j2l/image_1bf1d4vsr6bj137v178017691hfs76.png" alt="image_1bf1d4vsr6bj137v178017691hfs76.png-39.4kB"><br><img src="http://static.zybuluo.com/BruceTang/f3uecktt07o5t4fqm4449ej9/image_1bf1d58ma11a8s2r151j1fmi1mbe7j.png" alt="image_1bf1d58ma11a8s2r151j1fmi1mbe7j.png-95kB"><br><img src="http://static.zybuluo.com/BruceTang/emkzzliwpjt51g4s7nouh7r6/image_1bf1d5o1j1rk81vr51orjstdg7880.png" alt="image_1bf1d5o1j1rk81vr51orjstdg7880.png-71.2kB"><br><img src="http://static.zybuluo.com/BruceTang/49hyikugt8oafhcajx6wclty/image_1bf1d6jjn8iu135g1os1t4f1d3m8t.png" alt="image_1bf1d6jjn8iu135g1os1t4f1d3m8t.png-118.4kB"><br><img src="http://static.zybuluo.com/BruceTang/qv5lkan78z0nitewqm5xu0cn/image_1bf1d6uq1novqcj1ru2t6k1crs9a.png" alt="image_1bf1d6uq1novqcj1ru2t6k1crs9a.png-114.4kB"><br><img src="http://static.zybuluo.com/BruceTang/umcff896jjffl0u2lxdsj3cu/image_1bf1d791h5nec6ae8q1u851d289n.png" alt="image_1bf1d791h5nec6ae8q1u851d289n.png-111.9kB"><br><img src="http://static.zybuluo.com/BruceTang/v2puisqc1adw197xox19bc4f/image_1bf1d7h4r1cs3l731f7c4pg14kpa4.png" alt="image_1bf1d7h4r1cs3l731f7c4pg14kpa4.png-112.2kB"></p>
<p><strong>这里的键值是根据客户端脚本所定义的.</strong></p>
<h2 id="监控cpu使用率"><a href="#监控cpu使用率" class="headerlink" title="监控cpu使用率"></a>监控cpu使用率</h2><p><img src="http://static.zybuluo.com/BruceTang/vm3dy667vow4blaf7hle46ig/image_1bf1d8jih1kkl148revntge17k3ah.png" alt="image_1bf1d8jih1kkl148revntge17k3ah.png-195.1kB"><br><img src="http://static.zybuluo.com/BruceTang/3lib1rpxmq7m58us2mq77jc0/image_1bf1d8sbp1t85162mm41nvlkhtau.png" alt="image_1bf1d8sbp1t85162mm41nvlkhtau.png-155.2kB"></p>
]]></content>
      
        <categories>
            
            <category> 运维监控 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> zabbix3.0 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[zabbix 3.0 自定义监控]]></title>
      <url>http://yoursite.com/2016/10/03/zabbix%203.0%20%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9B%91%E6%8E%A7/</url>
      <content type="html"><![CDATA[<h2 id="为什么要自定义KEY"><a href="#为什么要自定义KEY" class="headerlink" title="为什么要自定义KEY"></a>为什么要自定义KEY</h2><p>有时候我们想让被监控端执行一个zabbix没有预定义的检测，zabbix的用户自定义参数功能提供了这个方法。我们可以在客户端配置文件zabbix_angentd.conf里面配置UserParameter.<br><a id="more"></a><br>语法如下:</p>
<blockquote>
<p>UserParameter=key,command</p>
</blockquote>
<p>用户自定义参数包含一个key和一个命令，key必须整个系统唯一，配置好之后，重启客户端。</p>
<p>然后配置item,在key的位置填上我们自定义的key即可。</p>
<p>用户自定义参数里指定的脚本由zabbix agent来执行，最大可以返回512KB的数据.</p>
<p>实例（以监控memory free为例）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[root@node-11 ~]# vim /etc/zabbix/zabbix_agentd.conf</div><div class="line">UserParameter=memory.free,/usr/bin/free | awk &apos;/^Mem:/&#123;print $4&#125;&apos;</div></pre></td></tr></table></figure></p>
<p><code>说明</code>：UserParameter为语法，memory.free为key值， /usr/bin/free为free的全路径，awk ‘/^Men:/{print $4}’为用awk所执行的命令，同时这里也可以把脚本路径填写到这里。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@node-11 ~]# systemctl restart  zabbix-agent</div></pre></td></tr></table></figure></p>
<p>在服务器端模拟获取数据（如获取不到数据，仔细查看你的key或Ip是否对，等等）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">[root@node-11 ~]# /usr/bin/free </div><div class="line">             total       used       free     shared    buffers     cached</div><div class="line">Mem:       1878212    1779704      98508       8908         64    1205268</div><div class="line">-/+ buffers/cache:     574372    1303840</div><div class="line">Swap:      8273916          0    8273916</div><div class="line">[root@node-10 ~]#  zabbix_get -s 192.168.1.11  -k &quot;memory.free&quot;</div><div class="line">98360</div><div class="line"></div><div class="line">提示：因为内存正在使用，所以获取的值有一点相差，不影响</div></pre></td></tr></table></figure></p>
<h2 id="在服务端添加到监控项"><a href="#在服务端添加到监控项" class="headerlink" title="在服务端添加到监控项"></a>在服务端添加到监控项</h2><p>配置—–主机—–你的主机—–监控项<br><img src="http://static.zybuluo.com/BruceTang/xxdnr0n7ked9ttoyvp6rcled/image_1bf11tv32rcf1338aa21r7s3gf34.png" alt="image_1bf11tv32rcf1338aa21r7s3gf34.png-159.5kB"><br>监控项—-创建监控项—–添加<br><img src="http://static.zybuluo.com/BruceTang/20idxm2qwyz78nsh7cpqn639/image_1bf1378rr1k7s9konmfocfpfk5v.png" alt="image_1bf122m8j1jvnj93dlfrja1go43h.png-182.6kB"><br>配置–主机–图形–创建图形<br><img src="http://static.zybuluo.com/BruceTang/y4phc4t4211tfwy5s8i02rqe/image_1bf126nn6grtm59o9e1d4l1dpf3u.png" alt="image_1bf126nn6grtm59o9e1d4l1dpf3u.png-174.5kB"><br><img src="http://static.zybuluo.com/BruceTang/ptbgpu9iqzq2ncn6ceocy9mz/image_1bf127c7p1m8q1grs8o21j541k0p4b.png" alt="image_1bf127c7p1m8q1grs8o21j541k0p4b.png-192.5kB"><br><img src="http://static.zybuluo.com/BruceTang/pzqmhcv7nirpdgnfpa8md61k/image_1bf129hon18sq1r571j9h64n4qm4o.png" alt="image_1bf129hon18sq1r571j9h64n4qm4o.png-346.9kB"><br>查看图形结果<br><img src="http://static.zybuluo.com/BruceTang/91gedw8aeav65kg20t70hxrr/image_1bf1386ai1odb7801d0mrbeimf6c.png" alt="image_1bf1386ai1odb7801d0mrbeimf6c.png-322.6kB"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[root@node-11 ~]# free -m</div><div class="line">             total       used       free     shared    buffers     cached</div><div class="line">Mem:          1834       1735         98          8          0       1177</div><div class="line">-/+ buffers/cache:        558       1275</div><div class="line">Swap:         8079          0       8079</div></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> 运维监控 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> zabbix3.0 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[zabbix 3.0 服务监控--Web监控]]></title>
      <url>http://yoursite.com/2016/10/03/zabbix%203.0%20%E6%9C%8D%E5%8A%A1%E7%9B%91%E6%8E%A7--Web%E7%9B%91%E6%8E%A7/</url>
      <content type="html"><![CDATA[<h2 id="检查"><a href="#检查" class="headerlink" title="检查"></a>检查</h2><p>1.查看进程<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[root@node-11 ~]# ps -ef | grep java</div><div class="line">root     27297     1  3 18:43 pts/1    00:00:04 /usr/local/java/bin/java -Djava.util.logging.config.file=/usr/local/apache-tomcat-8.0.9/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Djava.endorsed.dirs=/usr/local/apache-tomcat-8.0.9/endorsed -classpath /usr/local/apache-tomcat-8.0.9/bin/bootstrap.jar:/usr/local/apache-tomcat-8.0.9/bin/tomcat-juli.jar -Dcatalina.base=/usr/local/apache-tomcat-8.0.9 -Dcatalina.home=/usr/local/apache-tomcat-8.0.9 -Djava.io.tmpdir=/usr/local/apache-tomcat-8.0.9/temp org.apache.catalina.startup.Bootstrap start</div><div class="line">root     27993  2730  0 18:45 pts/1    00:00:00 grep --color=auto java</div></pre></td></tr></table></figure></p>
<a id="more"></a>
<p>2.查看端口<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[root@node-11 ~]# lsof -i:8080</div><div class="line">COMMAND   PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME</div><div class="line">java    27297 root   49u  IPv6 148863      0t0  TCP *:webcache (LISTEN)</div></pre></td></tr></table></figure></p>
<p>3.测试是否可以访问8080端口<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[root@node-11 ~]#  curl  -I 192.168.1.11:8080</div><div class="line">HTTP/1.1 200 OK</div><div class="line">Server: Apache-Coyote/1.1</div><div class="line">Content-Type: text/html;charset=UTF-8</div><div class="line">Transfer-Encoding: chunked</div><div class="line">Date: Sat, 29 Apr 2017 10:46:51 GMT</div></pre></td></tr></table></figure></p>
<h2 id="Zabbix-Web界面配置"><a href="#Zabbix-Web界面配置" class="headerlink" title="Zabbix Web界面配置"></a>Zabbix Web界面配置</h2><p><img src="http://static.zybuluo.com/BruceTang/kz17dvimywbelx57br72cps5/image_1bev6qnjf1lb91rb81suj1vj7u42a.png" alt="image_1bev6qnjf1lb91rb81suj1vj7u42a.png-188.4kB"><br><strong>提示： 监控Web 不依赖于agent，是server直接发送请求的</strong><br><img src="http://static.zybuluo.com/BruceTang/lptove1xf8s4v27ybf5p5fbt/image_1bev6s8p7p2lui8lka37ghnf2n.png" alt="image_1bev6s8p7p2lui8lka37ghnf2n.png-153kB"><br>提示： 这里名字叫做Web场景，因为我们可以设置触发上面3个选项后，才进行报警<br><img src="http://static.zybuluo.com/BruceTang/5x8mg0w8a6ynealfn3504dgh/image_1bev73jns1doj9kf1nefefr1i6v34.png" alt="image_1bev73jns1doj9kf1nefefr1i6v34.png-162.2kB"><br>提示： 字符串里面可以添加一些字符串，当请求下来有这个字符串就是正常，没有就是不正常。但是最常用的还是状态<br><img src="http://static.zybuluo.com/BruceTang/g3ikswqp3ldtrs2xw4qwt0en/image_1bev75c4cito938ac4fp91arn3h.png" alt="image_1bev75c4cito938ac4fp91arn3h.png-166.1kB"></p>
<p><strong>新添加web监控，zabbix默认是没有给我们设置触发器的，需要我们自己设置</strong><br><img src="http://static.zybuluo.com/BruceTang/vimeqk9yl563j3kwzd4u4hbw/image_1bf0r8ctjsrs1c4s1amd18lb7759.png" alt="image_1bf0r8ctjsrs1c4s1amd18lb7759.png-378.3kB"></p>
<h2 id="触发器添加"><a href="#触发器添加" class="headerlink" title="触发器添加"></a>触发器添加</h2><p><img src="http://static.zybuluo.com/BruceTang/oae0fg901d0s0xx45j6ef1vn/image_1bf0ran3pa4u1o14u8ibr6op2m.png" alt="image_1bf0ran3pa4u1o14u8ibr6op2m.png-175.7kB"></p>
<p>Web监控中默认不含有触发器，所以需要手动添加<br><img src="http://static.zybuluo.com/BruceTang/des9cftvyz2o8ugoblormytq/image_1bf0rcmro1a9f1osa1ti41rhu1n6h13.png" alt="image_1bf0rcmro1a9f1osa1ti41rhu1n6h13.png-291.9kB"><br><img src="http://static.zybuluo.com/BruceTang/ny633o9e2c7wp5ucqeap5y8i/image_1bf0rf8sgo96a0s1vm113j31j8e1g.png" alt="image_1bf0rf8sgo96a0s1vm113j31j8e1g.png-183.1kB"><br><img src="http://static.zybuluo.com/BruceTang/2rn27e3311bvjxdinfyb22ds/image_1bf0rgn8u1pf6c6u1sl39v97mv1t.png" alt="image_1bf0rgn8u1pf6c6u1sl39v97mv1t.png-351.9kB"><br>最终结果：<br><img src="http://static.zybuluo.com/BruceTang/tsmijy5us0zkrstlg12b03lh/image_1bf0rjbr1rt1misgnbfod1dvu2a.png" alt="image_1bf0rjbr1rt1misgnbfod1dvu2a.png-159.6kB"></p>
]]></content>
      
        <categories>
            
            <category> 运维监控 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> zabbix3.0 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[zabbix 3.0 服务监控--MySQL]]></title>
      <url>http://yoursite.com/2016/10/02/zabbix%203.0%20%E6%9C%8D%E5%8A%A1%E7%9B%91%E6%8E%A7--MySQL/</url>
      <content type="html"><![CDATA[<p>Mysql监控<br>zabbix自带了一个监控mysql的模板，但是真正监控mysql的并不是zabbix自带的模板。而是percona公司的一个监控mysql模板<br>　<em> percona官网： www.percona.com<br><a id="more"></a><br><em>*Percona组成介绍</em></em></p>
<pre><code>1、php脚本    用来数据采集
2、shell脚本  用来调用采集信息
3、zabbix配置文件
4、zabbix模板文件
</code></pre><p>安装文档：<a href="https://www.percona.com/doc/percona-monitoring-plugins/LATEST/zabbix/index.html" target="_blank" rel="external">https://www.percona.com/doc/percona-monitoring-plugins/LATEST/zabbix/index.html</a><br>　　percona 利用的是php来获取mysql的相关信息，所以如果我们想使用percona插件监控mysql就需要在agent端安装php。在安装文档上有写哦~<br><img src="http://static.zybuluo.com/BruceTang/dy8905qhs5ziio5o3ul25au8/image_1beu2alu21fr713i5d2e1t577kj9.png" alt="image_1beu2alu21fr713i5d2e1t577kj9.png-171.9kB"><br>安装步骤： 查看上面的链接也可以进行安装<br>我们安装在zabbix-agent上，因为上面有一个MySQL<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">[root@node-11 web]# yum install http://www.percona.com/downloads/percona-release/redhat/0.1-3/percona-release-0.1-3.noarch.rpm</div><div class="line">[root@node-11 web]# yum install percona-zabbix-templates php php-mysql -y</div><div class="line">#percona插件是通过php去获取mysql的参数，所以我们要安装php和php-mysql</div><div class="line"></div><div class="line">我们可以查看它都安装了那些软件</div><div class="line">[root@node-11 web]# rpm -ql percona-zabbix-templates</div><div class="line">/var/lib/zabbix/percona</div><div class="line">/var/lib/zabbix/percona/scripts</div><div class="line">/var/lib/zabbix/percona/scripts/get_mysql_stats_wrapper.sh  #shell脚本</div><div class="line">/var/lib/zabbix/percona/scripts/ss_get_mysql_stats.php      #php获取mysql信息</div><div class="line">/var/lib/zabbix/percona/templates</div><div class="line">/var/lib/zabbix/percona/templates/userparameter_percona_mysql.conf #zabbix配置文件</div><div class="line">/var/lib/zabbix/percona/templates/zabbix_agent_template_percona_mysql_server_ht_2.0.9-sver1.1.6.xml  </div><div class="line">#zabbix模板文件在percona组成我们已经说过了，此处只是略微介绍</div></pre></td></tr></table></figure></p>
<p>我们将zabbix模板下载下来<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@node-11 web]# sz /var/lib/zabbix/percona/templates/zabbix_agent_template_percona_mysql_server_ht_2.0.9-sver1.1.6.xml</div></pre></td></tr></table></figure></p>
<p>然后我们需要将模板通过web界面导入到zabbix中<br><img src="http://static.zybuluo.com/BruceTang/u8mn9wzijy535kmttzlpnlrc/image_1beu2f5lrcf2lvqdp51q0p1pimm.png" alt="image_1beu2f5lrcf2lvqdp51q0p1pimm.png-349.1kB"><br><img src="http://static.zybuluo.com/BruceTang/h8tfadwpsgo4m806yy9ywhcu/image_1beu2fgf51av097h1t6n24a1s8l13.png" alt="image_1beu2fgf51av097h1t6n24a1s8l13.png-101.8kB"></p>
<p><strong>提示</strong>：如果出现错误，可能是zabbix 3.0版本的问题。我们这里提供了一个生产的模板<br>下载链接：<a href="http://pan.baidu.com/s/1pLjKvxh" target="_blank" rel="external">http://pan.baidu.com/s/1pLjKvxh</a> 密码：75g0<br>然后从新上传之后导入即可</p>
<p>复制配置文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[root@node-11 web]# cp /var/lib/zabbix/percona/templates/userparameter_percona_mysql.conf /etc/zabbix/zabbix_agentd.d/</div><div class="line">[root@node-11 web]# ls /etc/zabbix/zabbix_agentd.d/</div><div class="line">#安装完软件包后会在/var/lib/zabbix/percona/templates/目录下产生一个配置文件，我们将它拷贝，因为在前面的博文中，我们已经修改过zabbix的配置文件[Include=/etc/abbix/zabbix_agentd.d/</div><div class="line">] 所以将配置文件放在这个目录下，zabbix就会自己在这个目录下查找相关信息</div><div class="line">[root@node-11 web]# systemctl restart zabbix-agent.service </div><div class="line">重启一下！</div></pre></td></tr></table></figure></p>
<p>下面就应该配置与MySQL的连接<br>在<code>/var/lib/zabbix/percona/scripts/ss_get_mysql_stats.php.cnf</code>创建一个文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[root@linux-node1 ~]# cat /var/lib/zabbix/percona/scripts/ss_get_mysql_stats.php.cnf</div><div class="line">&lt;?php</div><div class="line">$mysql_user = &apos;root&apos;;</div><div class="line">$mysql_pass = &apos;&apos;;</div><div class="line">#用户名密码可以自己创建，有密码写密码，没密码为空就好了</div></pre></td></tr></table></figure></p>
<p>提示： 正常这里的用户我们应该创建一个专门用来监控的，由于我这里是测试环境。就不浪费时间了</p>
<p><strong>测试</strong><br>查看是否可以获取到值，随便找一个测试<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">[root@node-11 ~]# cat /var/lib/zabbix/percona/templates/userparameter_percona_mysql.conf</div><div class="line">选择一个肯定有值的key</div><div class="line">[root@node-11 ~]# cat /var/lib/zabbix/percona/templates/userparameter_percona_mysql.conf|grep gm</div><div class="line">UserParameter=MySQL.read-views,/var/lib/zabbix/percona/scripts/get_mysql_stats_wrapper.sh gm</div><div class="line">测试结果如下：</div><div class="line">[root@node-11 ~]# cd /var/lib/zabbix/percona/scripts/</div><div class="line">[root@node-11 scripts]# ./get_mysql_stats_wrapper.sh gm</div><div class="line">1</div><div class="line">[root@node-11 scripts]# ./get_mysql_stats_wrapper.sh gw</div><div class="line">468</div><div class="line">可以获取到值，说明没有问题</div></pre></td></tr></table></figure></p>
<p>温馨提示： shell脚本中数据库的路径是localhost，如果我们没有授权localhost会获取不到值<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@node-11 scripts]# cat get_mysql_stats_wrapper.sh </div><div class="line">HOST=localhost</div><div class="line">    RES=`HOME=~zabbix mysql -e &apos;SHOW SLAVE STATUS\G&apos; | egrep &apos;(Slave_IO_Running|Slave_SQL_Running):&apos; | awk -F: &apos;&#123;print $2&#125;&apos; | tr &apos;\n&apos; &apos;,&apos;`</div><div class="line">#mysql是通过命令来获取的，如果环境变量不一样 也可能造成影响</div></pre></td></tr></table></figure></p>
<p><strong>Zabbix_Web界面配置</strong><br>添加mysql监控模板（之前上传的模板）<br><img src="http://static.zybuluo.com/BruceTang/w1ab39zccz0tljsfzvs4i1na/image_1bev53r7edua1em5bfv1c7j1jbu9.png" alt="image_1bev53r7edua1em5bfv1c7j1jbu9.png-177.8kB"><br><img src="http://static.zybuluo.com/BruceTang/myvivvv31aix0kpu5pdnu8w0/image_1bev55cfl1a4g1o699b102i13sdm.png" alt="image_1bev55cfl1a4g1o699b102i13sdm.png-143.5kB"><br><img src="http://static.zybuluo.com/BruceTang/duenq36yvf99cpe6y6lwnmj9/image_1bev56ate29m1kcm57s9fheak13.png" alt="image_1bev56ate29m1kcm57s9fheak13.png-180.5kB"></p>
<p>结果如下图<br><img src="http://static.zybuluo.com/BruceTang/plbsp2l5642bwycd9luig2t6/image_1bev585u0i29hev4tl27v177t1g.png" alt="image_1bev585u0i29hev4tl27v177t1g.png-401.9kB"><br><img src="http://static.zybuluo.com/BruceTang/huc2e0r9zzuw7kvhcuywibgz/image_1bev59nho1k071dvrbs3rn89621t.png" alt="image_1bev59nho1k071dvrbs3rn89621t.png-335.5kB"></p>
<p><strong>思想：</strong><br>　　如果出现错误我们需要先查看shell的脚本，因为shell是去调用php。 错误的因素有很多，最简单的方法就是用shell 后面加上key 看看是否可以有值。<br>　　其中报错最多的地方就是php和mysql连接的问题，还有我们mysql授权的一些问题。</p>
]]></content>
      
        <categories>
            
            <category> 运维监控 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> zabbix3.0 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[zabbix 3.0 服务监控--nginx]]></title>
      <url>http://yoursite.com/2016/10/02/zabbix%203.0%20%E6%9C%8D%E5%8A%A1%E7%9B%91%E6%8E%A7--nginx/</url>
      <content type="html"><![CDATA[<p>在zabbix agentd客户端上，查看nginx是否加载了–with-http_stub_status_module。因为zabbix监控nginx是根据nginx的Stub Status模块，抓取Status模块所提供的数据。假如以前没开启，现在想启用StubStatus 模块，在编译nginx 的时候要加上参数 –with-http_stub_status_module，执行./configure &amp;&amp; make就可以了，不用make install。不过，一般情况下都是安装了的。<br><a id="more"></a></p>
<h2 id="nginx安装"><a href="#nginx安装" class="headerlink" title="nginx安装"></a>nginx安装</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@node-11 ~]# yum install -y nginx</div></pre></td></tr></table></figure>
<h2 id="添加nginx-status模块"><a href="#添加nginx-status模块" class="headerlink" title="添加nginx_status模块"></a>添加nginx_status模块</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">[root@node-11 ~]# cd /etc/nginx/conf.d/</div><div class="line">[root@node-11 conf.d]# vim nginx_status.conf </div><div class="line">server &#123;</div><div class="line">    listen    80;</div><div class="line">    location /nginx_status &#123;</div><div class="line">    stub_status on;</div><div class="line">        allow 127.0.0.1;   </div><div class="line">        allow 192.168.1.10;  </div><div class="line">    access_log off;</div><div class="line">&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">提示：nginx必须要有--with-http_stub_status_module模块</div></pre></td></tr></table></figure>
<h2 id="nginx状态测试"><a href="#nginx状态测试" class="headerlink" title="nginx状态测试"></a>nginx状态测试</h2><p>测试：<a href="http://192.168.1.11/nginx_status" target="_blank" rel="external">http://192.168.1.11/nginx_status</a><br><img src="http://static.zybuluo.com/BruceTang/22kbpb7sl7qtsvzwjm9surq7/image_1besj334d1sod120dhjk8q5nrm52.png" alt="image_1besj334d1sod120dhjk8q5nrm52.png-97.9kB"></p>
<p>解释说明：使用zabbix来监控nginx状态，通过status状态模块为前提<br>我们现在命令取出我们想要的值，例如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[root@node-11 conf.d]# curl -s http://192.168.1.11/nginx_status|grep Active|awk -F &quot;[ ]&quot; &apos;&#123;print $3&#125;&apos;</div><div class="line">1</div><div class="line">这里我们现在只是监控了nginx的一种最大连接数的状态，其实我们可以监控其他的状态</div></pre></td></tr></table></figure></p>
<h2 id="nginx自定义文件"><a href="#nginx自定义文件" class="headerlink" title="nginx自定义文件"></a>nginx自定义文件</h2><blockquote>
<p>自己编写一个nginx文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">[root@node-11 ~]# cd /etc/zabbix/zabbix_agentd.d/</div><div class="line">[root@node-11 zabbix_agentd.d]# ll</div><div class="line">总用量 12</div><div class="line">-rw-r--r--. 1 root root  469 4月  29 17:04 nginx_status.conf</div><div class="line">[root@node-11 zabbix_agentd.d]# cat nginx_status.conf </div><div class="line">UserParameter=nginx.active,/usr/local/src/nginx_status.sh active</div><div class="line">UserParameter=nginx.accepts,/usr/local/src/nginx_status.sh accepts</div><div class="line">UserParameter=nginx.handled,/usr/local/src/nginx_status.sh handled</div><div class="line">UserParameter=nginx.requests,/usr/local/src/nginx_status.sh requests</div><div class="line">UserParameter=nginx.reading,/usr/local/src/nginx_status.sh reading</div><div class="line">UserParameter=nginx.writing,/usr/local/src/nginx_status.sh writing</div><div class="line">UserParameter=nginx.waiting,/usr/local/src/nginx_status.sh waiting</div></pre></td></tr></table></figure></p>
<p>添加nginx监控脚本<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">[root@node-11 zabbix_agentd.d]# cd /usr/local/src/</div><div class="line">[root@node-11 src]# ll</div><div class="line">总用量 8</div><div class="line">-rwxr-xr-x. 1 root root  759 4月  29 17:05 nginx_status.sh</div><div class="line">[root@node-11 src]# cat nginx_status.sh</div><div class="line">#!/bin/bash</div><div class="line">case $1 in</div><div class="line">    active)</div><div class="line">        curl -s http://127.0.0.1/nginx_status | awk &apos;/Active/ &#123;print $3&#125;&apos; ;;</div><div class="line">    accepts)</div><div class="line">        curl -s http://127.0.0.1/nginx_status | awk &apos;NR==3 &#123;print $1&#125;&apos; ;;</div><div class="line">    handled)</div><div class="line">        curl -s http://127.0.0.1/nginx_status | awk &apos;NR==3 &#123;print $2&#125;&apos; ;;</div><div class="line">    requests)</div><div class="line">        curl -s http://127.0.0.1/nginx_status | awk &apos;NR==3 &#123;print $3&#125;&apos; ;;</div><div class="line">    reading)</div><div class="line">        curl -s http://127.0.0.1/nginx_status | awk &apos;/Reading/ &#123;print $2&#125;&apos; ;;</div><div class="line">    writing)</div><div class="line">        curl -s http://127.0.0.1/nginx_status | awk &apos;/Writing/ &#123;print $4&#125;&apos; ;;</div><div class="line">    waiting)</div><div class="line">        curl -s http://127.0.0.1/nginx_status | awk &apos;/Waiting/ &#123;print $6&#125;&apos; ;;</div><div class="line">    *)</div><div class="line">        echo &quot;Usage: $0 &#123; active | accepts | handled | requests | reading | writing | waiting &#125;&quot; ;;</div><div class="line">esa</div></pre></td></tr></table></figure></p>
</blockquote>
<p><strong>修改完配置文件都要重启zabbix-agent</strong></p>
<h2 id="在server端对nginx进行测试"><a href="#在server端对nginx进行测试" class="headerlink" title="在server端对nginx进行测试"></a>在server端对nginx进行测试</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# yum install -y zabbix-get</div><div class="line">[root@node-10 ~]#  zabbix_get -s 192.168.1.11  -p 10050 -k &quot;nginx.active&quot;</div><div class="line">1</div><div class="line">[root@node-10 ~]#  zabbix_get -s 192.168.1.11  -p 10050 -k &quot;nginx.accepts&quot;</div><div class="line">4839</div><div class="line">[root@node-10 ~]#  zabbix_get -s 192.168.1.11  -p 10050 -k &quot;nginx.requests&quot;</div><div class="line">4841</div><div class="line">[root@node-10 ~]#  zabbix_get -s 192.168.1.11  -p 10050 -k &quot;nginx.reading&quot;</div><div class="line">0</div><div class="line">[root@node-10 ~]#  zabbix_get -s 192.168.1.11  -p 10050 -k &quot;nginx.writing&quot;</div><div class="line">1</div><div class="line">[root@node-10 ~]#  zabbix_get -s 192.168.1.11  -p 10050 -k &quot;nginx.waiting&quot;</div><div class="line">0</div></pre></td></tr></table></figure>
<p>以上测试正确，我们还需要在zabbix-web页面上进行设置</p>
<h2 id="监控项添加"><a href="#监控项添加" class="headerlink" title="监控项添加"></a>监控项添加</h2><p>在主机模板上新添一个监控项：<br><img src="http://static.zybuluo.com/BruceTang/e7hxc6s39weeads3rnpnzq2p/image_1besjpivc17rmeqg121v1lb21q045f.png" alt="image_1besjpivc17rmeqg121v1lb21q045f.png-202.6kB"><br><img src="http://static.zybuluo.com/BruceTang/em6kqvgwt3ycbbgigflho70t/image_1besjsftu15mt11up99dr5m113e69.png" alt="image_1besjsftu15mt11up99dr5m113e69.png-178.7kB"><br><img src="http://static.zybuluo.com/BruceTang/ir2ngoxqvxbprxxfwqq23mq1/image_1besjtqfo2njidk1piq1savdkv73.png" alt="image_1besjtqfo2njidk1piq1savdkv73.png-139.1kB"><br>现在一个监控项已经添加好，剩余的直接克隆模板，修改就行<br>最终监控项结果<br><img src="http://static.zybuluo.com/BruceTang/wwx083y7bc6b66voaog1hka3/image_1besk0m01aus19m3a514ol1t5c7g.png" alt="image_1besk0m01aus19m3a514ol1t5c7g.png-266.7kB"></p>
<h3 id="图形添加"><a href="#图形添加" class="headerlink" title="图形添加"></a>图形添加</h3><p><img src="http://static.zybuluo.com/BruceTang/wm6mxp9j2qu4gvvuesjlsfkz/image_1besk2evb1cu71sjrilt3fc15vn8a.png" alt="image_1besk1ce41cdl1oast6p1i9t13687t.png-190.3kB"><br><img src="http://static.zybuluo.com/BruceTang/jxnf3b5cyl3xrtg5zsmrrxr3/image_1besk3o6c13dc1ugi1j931uul1sj38n.png" alt="image_1besk3o6c13dc1ugi1j931uul1sj38n.png-154.6kB"><br><img src="http://static.zybuluo.com/BruceTang/7ba752fts15h1m2elwtcbdyk/image_1besk4i0m17n01nct16co4lm1u3l94.png" alt="image_1besk4i0m17n01nct16co4lm1u3l94.png-312.6kB"><br>最终结果：<br><img src="http://static.zybuluo.com/BruceTang/n1vu0z9kg8sq298hjovfrnzh/image_1besk67081san1sh61u961uqv11ub9h.png" alt="image_1besk67081san1sh61u961uqv11ub9h.png-321.9kB"></p>
<p><strong>添加自定义监控项小结： *</strong><br>　　　1、添加用户自定义参数（在/etc/zabbix/zabbix.agent.d/定义了一个nginx_status.conf步骤如上）,<br>　　　2.添加用户自定义获取nginx状态的脚本（/usr/local/src/nginx_status.sh）<br>　　　2、重启zabbix-agent<br>　　　3、在Server端使用zabbix_get测试获取（命令如上）<br>　　　4、在web界面创建item（监控项）<br>　　　5、在web界面创建图形</p>
]]></content>
      
        <categories>
            
            <category> 运维监控 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> zabbix3.0 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[zabbix 3.0 基础介绍]]></title>
      <url>http://yoursite.com/2016/10/01/zabbix%203.0%20%E5%9F%BA%E7%A1%80%E4%BB%8B%E7%BB%8D%20%5B%E4%B8%80%5D/</url>
      <content type="html"><![CDATA[<h2 id="Zabbix介绍"><a href="#Zabbix介绍" class="headerlink" title="Zabbix介绍"></a>Zabbix介绍</h2><h3 id="zabbix-简介"><a href="#zabbix-简介" class="headerlink" title="zabbix 简介"></a>zabbix 简介</h3><p>　　Zabbix是一个高度集成的网络监控解决方案，可以提供企业级的开源分布式监控解决方案，由一个国外的团队持续维护更新，软件可以自由下载使用，运作团队靠提供收费的技术支持赢利<br>　　zabbix是一个基于Web界面的，提供分布式系统监控以及网络监视功能的企业级的开源解决方案。<br>　　zabbix能监视各种网络参数，保证服务器系统的安全运营，并提供灵活的通知机制以让系统管理员快速定位/解决存在的各种问题<br>　　zabbix主要由2部分构成zabbixserver和zabbixagent，可选组建zabbix proxyzabbix。　　<br>　　server可以通过SNMP，zabbixagent，fping端口监视等方法对远程服务器或网络状态完成监视，数据收集等功能。同时支持Linux以及Unix平台，Windows平台只能安装客户端<br><a id="more"></a></p>
<h3 id="zabbix功能"><a href="#zabbix功能" class="headerlink" title="zabbix功能"></a>zabbix功能</h3><p>　　①具备常见的商业监控软件所具备的功能（主机的性能监控、网络设备性能监控、数据库、性能监控、FTP 等通用协议监控、多种告警方式、详细的报表图表绘制）<br>　　②支持自动发现网络设备和服务器（可以通过配置自动发现服务器规则来实现）<br>　　③支持自动发现（low discovery）key 实现动态监控项的批量监控（需写脚本）<br>　　④支持分布式，能集中展示、管理分布式的监控点<br>　　⑤扩展性强，server 提供通用接口（api 功能），可以自己开发完善各类监控（根据相关接口编写程序实现）编写插件容易，可以自定义监控项，报警级别的设置。<br>　　⑥数据收集<br>　可用和性能检测<br>　支持snmp(包括trapping and polling)，IPMI，JMX，SSH，TELNET<br>　自定义的检测<br>　自定义收集数据的频率<br>　服务器/代理和客户端模式<br>　灵活的触发器<br>　可以定义非常灵活的问题阈值，称为触发器，从后端数据库的参考值<br>　高可定制的报警<br>　发送通知，可定制的报警升级，收件人，媒体类型<br>　通知可以使用宏变量有用的变量<br>　自动操作包括远程命令<br>　实时的绘图功能<br>　监控项实时的将数据绘制在图形上面<br>　WEB 监控能力<br>　ZABBIX 可以模拟鼠标点击了一个网站，并检查返回值和响应时间</p>
<h3 id="Api-功能"><a href="#Api-功能" class="headerlink" title="Api 功能"></a>Api 功能</h3><p>应用api功能，可以方便的和其他系统结合，包括手机客户端的使用。<br>更多功能请查看<br><a href="http://www.zabbix.com/documentation.php" target="_blank" rel="external">http://www.zabbix.com/documentation.php</a></p>
<h3 id="Zabbix版本"><a href="#Zabbix版本" class="headerlink" title="Zabbix版本"></a>Zabbix版本</h3><p>Zabbix 3.0 Manual<br>Zabbix 2.4 Manual<br>Zabbix 2.2 Manual<br>Zabbix 2.0 Manual<br>下载地址：<a href="http://www.zabbix.com/documentation.php" target="_blank" rel="external">http://www.zabbix.com/documentation.php</a><br>本次采用yum安装，安装zabbix3.0.使用Centos7</p>
<h3 id="Zabbix优缺点"><a href="#Zabbix优缺点" class="headerlink" title="Zabbix优缺点"></a>Zabbix优缺点</h3><p><strong>优点</strong><br>　1、开源，无软件成本投入<br>　2、Server 对设备性能要求低<br>　3、支持设备多，自带多种监控模板<br>　4、支持分布式集中管理，有自动发现功能，可以实现自动化监控<br>　5、开放式接口，扩展性强，插件编写容易<br>　6、当监控的item 比较多服务器队列比较大时可以采用被动状态，被监控客户端主动从<br>　7、server 端去下载需要监控的item 然后取数据上传到server 端。这种方式对服务器的负载比较小。<br>　8、Api 的支持，方便与其他系统结合<br><strong>缺点</strong><br>　　需在被监控主机上安装agent，所有数据都存在数据库里，产生的数据据很大,瓶颈主要在<code>数据库</code>。</p>
<h3 id="Zabbix监控原理"><a href="#Zabbix监控原理" class="headerlink" title="Zabbix监控原理"></a>Zabbix监控原理</h3><p><strong>Server</strong>：Zabbix Server需运行在LAMP（Linux+Apache+Mysql+PHP）环境下（或者LNMP），对硬件要求低。<br><strong>Agent</strong>：目前已有的agent基本支持市面常见的OS，包含Linux、HPX、Solaris、Sun、 windows<br><strong>SNMP：</strong>支持各类常见的网络设备 SNMP(Simple NetworkManagement Protocol,简单网络管理协议</p>
<h3 id="Zabbix监控过程逻辑图"><a href="#Zabbix监控过程逻辑图" class="headerlink" title="Zabbix监控过程逻辑图"></a>Zabbix监控过程逻辑图</h3><p><img src="http://static.zybuluo.com/abcdocker/3k6ikw8aqzewig8krhbbj7h5/1.png" alt="此处输入图片的描述"></p>
<h3 id="监控类型"><a href="#监控类型" class="headerlink" title="监控类型"></a>监控类型</h3><p><strong>硬件监控:</strong> 适用于物理机、远程管理卡（iDRAC），IPMI（只能平台管理接口） ipmitools:，MegaCli（查看Raid磁盘）<br><strong>系统监控:</strong> 监控cpt：lscpu、uptime、top、vmstat 1 、mpstat 1、htop<br><strong>监控内存:</strong> free -m<br><strong>监控硬盘:</strong> df -h、iotop<br><strong>监控网络：</strong> iftop、netstat、ss<br><strong>应用服务监控：</strong> tomcat、MySQL、nginx、apache、php、redis<br>更详细的监控类型可以参考:<a href="https://tangxiaoyue.github.io/2017/01/01/%E7%9B%91%E6%8E%A7%E4%BD%93%E7%B3%BB/" target="_blank" rel="external">https://tangxiaoyue.github.io/2017/01/01/%E7%9B%91%E6%8E%A7%E4%BD%93%E7%B3%BB/</a></p>
<h3 id="引入zabbix"><a href="#引入zabbix" class="headerlink" title="引入zabbix"></a>引入zabbix</h3><p>所有监控范畴，都可以整合到Zabbix中 :<br><code>硬件监控</code>：Zabbix、IPMI、lnterface<br><code>系统监控</code>：Zabbix、Agent、Interface<br><code>Java监控</code>：Zabbix、JMX、lnterface<br><code>网络设备监控</code>：Zabbix、SNMP、lnterface<br><code>应用服务监控</code>：Zabbix、Agent、UserParameter<br><code>MySQL数据库监控</code>：percona-monitoring-plulgins<br><code>URL监控</code>：Zabbix Web监控 </p>
<h2 id="Zabbix-环境配置"><a href="#Zabbix-环境配置" class="headerlink" title="Zabbix 环境配置"></a>Zabbix 环境配置</h2><h3 id="环境信息"><a href="#环境信息" class="headerlink" title="环境信息"></a>环境信息</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# cat /etc/redhat-release </div><div class="line">CentOS Linux release 7.0.1406 (Core) </div><div class="line">[root@localhost ~]# uname -r</div><div class="line">3.10.0-123.el7.x86_64</div><div class="line">[root@node-10 ~]# ifconfig|awk -F &apos; &apos; &apos;NR==2&#123;print $2&#125;&apos;</div><div class="line">192.168.1.10</div></pre></td></tr></table></figure>
<h2 id="yum安装zabbix-server"><a href="#yum安装zabbix-server" class="headerlink" title="yum安装zabbix-server"></a>yum安装zabbix-server</h2><p>阿里云yum源已经提供了zabbix3.0，因此我们需要使用官方yum源。官方yum源下载会比较慢<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# rpm -ivh    http://mirrors.aliyun.com/zabbix/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm</div></pre></td></tr></table></figure></p>
<p>问题：为什么要下载release版本的zabbix？<br>因为下载这个版本会在yum.repos.d下面生成一个zabbix.repo的文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# ll /etc/yum.repos.d/</div><div class="line">总用量 28</div><div class="line">-rw-r--r--. 1 root root 1612 7月   4 2014 CentOS-Base.repo</div><div class="line">-rw-r--r--. 1 root root  640 7月   4 2014 CentOS-Debuginfo.repo</div><div class="line">-rw-r--r--. 1 root root 1331 7月   4 2014 CentOS-Sources.repo</div><div class="line">-rw-r--r--. 1 root root  156 7月   4 2014 CentOS-Vault.repo</div><div class="line">-rw-r--r--. 1 root root  957 12月 28 01:37 epel.repo</div><div class="line">-rw-r--r--. 1 root root 1056 12月 28 01:37 epel-testing.repo</div><div class="line">-rw-r--r--. 1 root root  401 2月  15 2016 zabbix.repo</div></pre></td></tr></table></figure></p>
<h3 id="安装zabbix-server相关软件包"><a href="#安装zabbix-server相关软件包" class="headerlink" title="安装zabbix-server相关软件包"></a>安装zabbix-server相关软件包</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# yum install zabbix-server zabbix-web zabbix-server-mysql zabbix-web-mysql mariadb-server mariadb -y</div></pre></td></tr></table></figure>
<ul>
<li>提示：在Centos7中，mysql改名为mariadb<h3 id="安装zabbix-agent"><a href="#安装zabbix-agent" class="headerlink" title="安装zabbix-agent"></a>安装zabbix-agent</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# rpm -ivh http://repo.zabbix.com/zabbix/2.4/rhel/7/x86_64/zabbix-release-2.4-1.el7.noarch.rpm</div><div class="line">[root@node-10 ~]# yum install -y zabbix-agent</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="修改PHP时区设置"><a href="#修改PHP时区设置" class="headerlink" title="修改PHP时区设置"></a>修改PHP时区设置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# sed -i &apos;s@# php_value date.timezone Europe/Riga@php_value date.timezone Asia/Shanghai@g&apos; /etc/httpd/conf.d/zabbix.conf</div><div class="line">#要注意需要改的配置文件是/etc/httpd/conf.d/zabbix.conf而不是/etc/php.ini，</div></pre></td></tr></table></figure>
<h2 id="数据库设置"><a href="#数据库设置" class="headerlink" title="数据库设置"></a>数据库设置</h2><h3 id="启动数据库"><a href="#启动数据库" class="headerlink" title="启动数据库"></a>启动数据库</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# systemctl start mariadb</div></pre></td></tr></table></figure>
<h3 id="创建zabbix数据库及用户"><a href="#创建zabbix数据库及用户" class="headerlink" title="创建zabbix数据库及用户"></a>创建zabbix数据库及用户</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">mysql</div><div class="line">&gt; create database zabbix character set utf8 collate utf8_bin;</div><div class="line">&gt; grant all on zabbix.* to zabbix@&apos;localhost&apos; identified by &apos;123456&apos;;</div><div class="line">&gt; exit</div></pre></td></tr></table></figure>
<h3 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# cd /usr/share/doc/zabbix-server-mysql-3.0.9/</div><div class="line">[root@node-10 zabbix-server-mysql-3.0.9]# ll</div><div class="line">总用量 1872</div><div class="line">-rw-r--r--. 1 root root      98 4月  20 20:05 AUTHORS</div><div class="line">-rw-r--r--. 1 root root  718465 4月  20 20:05 ChangeLog</div><div class="line">-rw-r--r--. 1 root root   17990 4月  20 20:05 COPYING</div><div class="line">-rw-r--r--. 1 root root 1159237 4月  24 02:04 create.sql.gz</div><div class="line">-rw-r--r--. 1 root root      52 4月  20 20:05 NEWS</div><div class="line">-rw-r--r--. 1 root root     188 4月  20 20:05 README</div><div class="line">[root@node-10 zabbix-server-mysql-3.0.4]# zcat create.sql.gz |mysql -uzabbix -p123456 zabbix</div></pre></td></tr></table></figure>
<p>我们使用<code>zcat</code>，专门查看<code>sql.gz</code>包。和<code>cat</code>基本相似</p>
<h3 id="修改zabbix配置文件"><a href="#修改zabbix配置文件" class="headerlink" title="修改zabbix配置文件"></a>修改zabbix配置文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# vim /etc/zabbix/zabbix_server.conf </div><div class="line">DBHost=localhost    #数据库所在主机</div><div class="line">DBName=zabbix       #数据库名</div><div class="line">DBUser=zabbix       #数据库用户</div><div class="line">DBPassword=123456   #数据库密码</div></pre></td></tr></table></figure>
<h3 id="启动zabbix及apache"><a href="#启动zabbix及apache" class="headerlink" title="启动zabbix及apache"></a>启动zabbix及apache</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[root@localhost ~]# systemctl start zabbix-server</div><div class="line">[root@localhost ~]# systemctl start httpd</div><div class="line">注意：如果没有启动成功，要看一下是不是80端口被占用</div></pre></td></tr></table></figure>
<h3 id="Web界面安装master"><a href="#Web界面安装master" class="headerlink" title="Web界面安装master"></a>Web界面安装master</h3><p>访问地址：<a href="http://192.168.1.11/zabbix/setup.php" target="_blank" rel="external">http://192.168.1.11/zabbix/setup.php</a><br><img src="http://static.zybuluo.com/abcdocker/am14alnxj6pp1g6ih7gkohom/1.png" alt="此处输入图片的描述"><br>点击<code>Next step</code>进行安装<br><img src="http://static.zybuluo.com/abcdocker/g9f1uz2h9cpmg8hn13spxpyi/1.png" alt="此处输入图片的描述"><br>…<br>点击Finish<br><img src="http://static.zybuluo.com/abcdocker/227kxcx6p58dac0d0tr064xi/1.png" alt="此处输入图片的描述"></p>
<blockquote>
<p>提示：上去之后请立即修改密码</p>
</blockquote>
<h3 id="配置zabbix-agent端"><a href="#配置zabbix-agent端" class="headerlink" title="配置zabbix-agent端"></a>配置zabbix-agent端</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@localhost ~]# vim /etc/zabbix/zabbix_agentd.conf </div><div class="line">Server=127.0.0.1       修改Server端的IP地址（被动模式IP地址）</div><div class="line">ServerActive=127.0.0.1     主动模式，主动向server端报告</div><div class="line">[root@localhost ~]# systemctl start zabbix-agent</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# netstat -lntp</div><div class="line">Active Internet connections (only servers)</div><div class="line">Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    </div><div class="line">tcp        0      0 127.0.0.1:25            0.0.0.0:*               LISTEN      2434/master         </div><div class="line">tcp        0      0 0.0.0.0:10050           0.0.0.0:*               LISTEN      4103/zabbix_agentd  </div><div class="line">tcp        0      0 0.0.0.0:10051           0.0.0.0:*               LISTEN      3887/zabbix_server  </div><div class="line">tcp        0      0 0.0.0.0:3306            0.0.0.0:*               LISTEN      3800/mysqld         </div><div class="line">tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      1482/sshd           </div><div class="line">tcp6       0      0 ::1:25                  :::*                    LISTEN      2434/master         </div><div class="line">tcp6       0      0 :::10050                :::*                    LISTEN      4103/zabbix_agentd  </div><div class="line">tcp6       0      0 :::10051                :::*                    LISTEN      3887/zabbix_server  </div><div class="line">tcp6       0      0 :::80                   :::*                    LISTEN      3973/httpd          </div><div class="line">tcp6       0      0 :::22                   :::*                    LISTEN      1482/sshd</div></pre></td></tr></table></figure>
<h2 id="Web界面配置"><a href="#Web界面配置" class="headerlink" title="Web界面配置"></a>Web界面配置</h2><h3 id="修改密码语言界面风格"><a href="#修改密码语言界面风格" class="headerlink" title="修改密码语言界面风格"></a>修改密码语言界面风格</h3><p><img src="http://static.zybuluo.com/BruceTang/tn8r6ame2y2rq58kzw2q32mk/2.png" alt="2.png-177.5kB"><br><img src="http://static.zybuluo.com/BruceTang/2xr9i9a545o6ndd0vk5d7s2u/3.png" alt="3.png-106.2kB"><br><img src="http://static.zybuluo.com/BruceTang/04ebhowe4n5tbqz6zgg0kkxv/4.png" alt="4.png-131.6kB"><br><img src="http://static.zybuluo.com/BruceTang/45dy06yuqlgjnyjdx3tidjin/5.png" alt="5.png-115.3kB"></p>
<h3 id="设置中文字符集"><a href="#设置中文字符集" class="headerlink" title="设置中文字符集"></a>设置中文字符集</h3><p>语言设置成中文之后发现是图形下面的文字出现乱码，不能显示出中文<br><img src="http://static.zybuluo.com/BruceTang/uwrph70u7b8eaawsoithts2x/6.png" alt="6.png-278kB"></p>
<p>zabbix默认字体在/usr/share/zabbix/fonts目录下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@node-10 fonts]# cd /usr/share/zabbix/fonts</div><div class="line">[root@node-10 fonts]# ll</div><div class="line">总用量 0</div><div class="line">lrwxrwxrwx. 1 root root 33 4月  29 15:49 graphfont.ttf -&gt; /etc/alternatives/zabbix-web-font</div></pre></td></tr></table></figure></p>
<p>上传微软字体<br>可以在Windows这个目录里面找字体<br><img src="http://static.zybuluo.com/BruceTang/hhcsp1p5iro89vt4eqso39ar/7.png" alt="7.png-339.8kB"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[root@node-10 fonts]# yum install -y lrzsz</div><div class="line">[root@node-10 fonts]# rz -y</div><div class="line"></div><div class="line">[root@node-10 fonts]# ll</div><div class="line">总用量 35524</div><div class="line">lrwxrwxrwx. 1 root root       33 4月  29 15:49 graphfont.ttf -&gt; /etc/alternatives/zabbix-web-font</div><div class="line">-rw-r--r--. 1 root root 14602860 6月  11 2009 msyhbd.ttf</div><div class="line">-rw-r--r--. 1 root root 21767952 6月  11 2009 msyh.ttf</div></pre></td></tr></table></figure></p>
<p>修改zabbix的web页面文件/usr/share/zabbix/include/defines.inc.php<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]#  vim /usr/share/zabbix/include/defines.inc.php</div><div class="line"></div><div class="line">define(&apos;ZBX_GRAPH_FONT_NAME&apos;,           &apos;msyh&apos;); // font file name</div><div class="line">define(&apos;ZBX_FONT_NAME&apos;, &apos;msyh&apos;);</div></pre></td></tr></table></figure></p>
<p>其中msyh为字体的前缀不包含ttf后缀。刷新页面后，完美的字体重新，不再是乱码<br><img src="http://static.zybuluo.com/BruceTang/pwff8lydhc6uj3rkop9amq1e/8.png" alt="8.png-284.2kB"></p>
]]></content>
      
        <categories>
            
            <category> 运维监控 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> zabbix3.0 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[监控体系]]></title>
      <url>http://yoursite.com/2016/10/01/%E7%9B%91%E6%8E%A7%E4%BD%93%E7%B3%BB/</url>
      <content type="html"><![CDATA[<h3 id="监控对象"><a href="#监控对象" class="headerlink" title="监控对象"></a>监控对象</h3><p>1.监控对象的理解：CPU是怎么工作的,原理<br>2.监控对象的指标：CPU使用率，CPU负载，CPU个数，上下文切换<br>3.确定性能基准线：怎样才算故障？CPU负载多少才算高</p>
<a id="more"></a>
<h3 id="监控范围"><a href="#监控范围" class="headerlink" title="监控范围"></a>监控范围</h3><p>1.硬件监控服务器的硬件故障<br>2.操作系统监控CPU、内存、硬盘、IO、进程<br>3.应用服务监控nginx、mysql等服务<br>4.业务监控</p>
<h3 id="硬件监控"><a href="#硬件监控" class="headerlink" title="硬件监控"></a>硬件监控</h3><p>1.使用IPMI<br>2.机房巡检</p>
<p>远程控制卡：<br>DELL服务器：<code>IDRAC</code><br>HP服务器：<code>ILO</code>—-Linux就可以使用IPMI（依赖于BMC控制器）<br>IBM服务器：<code>IMM</code></p>
<p>Linux是管理<code>IPMI</code>工具<br><code>ipmitools</code>（监控和控制）</p>
<blockquote>
<p>1.硬件要支持<br>2.操作系统Linux IPMI</p>
</blockquote>
<p>ipmitool安装</p>
<pre><code>[root@tang ~]# yum install OpenIPMI ipmitool -y
[root@tang ~]# rpm -qa OpenIPMI ipmitool
OpenIPMI-2.0.19-15.el7.x86_64
ipmitool-1.8.15-7.el7.x86_64
</code></pre><p>使用IPMI有两种方式</p>
<pre><code>1.本地进行调用
2.远程调用（IP地址 用户名和密码）

[root@tang ~]# systemctl start ipmi    启动（以centos7为例）
</code></pre><blockquote>
<p>IPMI相关命令</p>
</blockquote>
<pre><code>[root@tang ~]# ipmitool --help
</code></pre><blockquote>
<p>IPMI配置网络，有两种方式：</p>
</blockquote>
<pre><code>1.ipmi over lan（大体意识是通过网络来进行连接）
2.独立（给服务器单独查一根网线）Dell服务器可以在小面板中设置IPMI（云主机不需要考虑IPMI）
</code></pre><h3 id="SNMP监控"><a href="#SNMP监控" class="headerlink" title="SNMP监控"></a>SNMP监控</h3><p>对于路由器和交换机:SNMP（简单网络管理协议）监控<br>配置SNMP：（可以参考监控宝来进行监控）</p>
<pre><code>[root@tang ~]# yum -y install net-snmp net-snmp-utils
[root@tang ~]# rpm -qa net-snmp net-snmp-utils
net-snmp-5.7.2-24.el7_3.2.x86_64
net-snmp-utils-5.7.2-24.el7_3.2.x86_64
</code></pre><p>如果不知道要安装什么软件包，可以使用yum list|grep snmp</p>
<p>SNMP配置文件路径：</p>
<pre><code>[root@tang ~]# ll /etc/snmp/
total 8
-rw-r--r-- 1 root root  28 Apr 18 21:45 snmpd.conf
-rw------- 1 root root 220 Apr 13 02:34 snmptrapd.conf
</code></pre><p>修改配置文件，备份修改：</p>
<pre><code>[root@tang snmp]# mv snmpd.conf snmpd.conf.org
[root@tang snmp]# cat snmpd.conf.org 
rocommunity tang 172.18.0.1   第二个为团体名，IP是要监控的服务端
</code></pre><p>我们被发采集的服务器需要开启snmp<br>被采集的服务器要允许snmp访问</p>
<p>开启服务</p>
<pre><code>[root@tang snmp]#  systemctl start snmpd
[root@tang snmp]# netstat -lntup    #snmp默认监听的是udp161端口
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    
tcp        0      0 0.0.0.0:9133            0.0.0.0:*               LISTEN      2478/bubi           
tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      771/sshd            
tcp        0      0 127.0.0.1:5432          0.0.0.0:*               LISTEN      1594/postmaster     
tcp        0      0 0.0.0.0:19333           0.0.0.0:*               LISTEN      2478/bubi           
tcp        0      0 127.0.0.1:199           0.0.0.0:*               LISTEN      19346/snmpd         
tcp6       0      0 :::3306                 :::*                    LISTEN      2383/mysqld         
udp        0      0 172.18.0.1:123          0.0.0.0:*                           760/ntpd            
udp        0      0 172.17.82.185:123       0.0.0.0:*                           760/ntpd            
udp        0      0 127.0.0.1:123           0.0.0.0:*                           760/ntpd            
udp        0      0 0.0.0.0:123             0.0.0.0:*                           760/ntpd            
udp        0      0 0.0.0.0:161             0.0.0.0:*                           19346/snmpd         
udp6       0      0 :::123                  :::*                                760/ntpd            
</code></pre><h3 id="SNMP相关知识"><a href="#SNMP相关知识" class="headerlink" title="SNMP相关知识"></a>SNMP相关知识</h3><ul>
<li>snmp原理图</li>
</ul>
<p><img src="http://static.zybuluo.com/abcdocker/2imo9lugq26ugfjcqi7aaxhg/1.png" alt="image"></p>
<blockquote>
<p>什么是MIB？</p>
</blockquote>
<p>MIB是描述被管理设备商的参数的数据结构。如前所述管理一个设备，就是利用snmp协议，通过网络对被管理的设备上的参数进行get和get操作。<br>    那么如何组织被管理设备上的参数呢？多数情况下，可以get和set的参数实在多得惊人，假如仅仅简单地线性罗列它们，操作会十分不便。<br>    想象一下把1000个参数列成一张表，需要使用的时候查询这样一张表会有多么困难啊？比如您打算在地球上找一个城市，”Ithaca”，如果没有归类和分级，则需要查找一张巨大的表格。<br>    但如果告诉您城市”Ithaca”是：南美洲国家圭亚那的北部城市”Ithaca”，那么就容易些了吧？<br>    被管理的设备相当复杂，拥有很多可以被管理的参数，需要对它们进行归类，分级。<br>    管理信息库(MIB)是一个具有分层特性的信息的集合，我们可以通过 SNMP 去存取它。<br>    MIB 的成员是一些被管理的对象(ManagedObject)，以对象标示符(ObjectIdentifiers)来区分它们。被管理的对象由一个或多个对象实例(ObjectInstances)组成，本质上，这些对象实例就是变量。<br>    在 MIB 的层次结构中，一个对象标示符唯一标识了被管理对象。MIB的层次结构可以被描述成无根名的树，树的级别被不同的组织所划分。如下图所示： </p>
<p>   <img src="http://static.zybuluo.com/abcdocker/p24aj4t6lb0iizva85uk8pct/2.png" alt="image"></p>
<p> 相应的数字表示（对象标识符OID，唯一标识一个MIB对象）<br> 很多能够被 SNMP 管理的对象都是由标准组织定义好的。比如系统磁盘的信息，用 OID ”1.3.6.1.4.1.2021.9” 表示。这串数字是国际标准化组织协商定义好的，大家都要去遵循它。<br> 当然，国际组织不可能预知未来，如果您要开发的设备有一些管理需求没有任何 RFC 定义过，那么您也可以编写自己的 MIB 文件来定义私有的 MIB 对象。<br> NET-SNMP 是一种开放源代码的 SNMP 协议实现。它支持 SNMP v1, SNMP v2c 与 SNMP v3，并可以使用 IPV4 及 IPV6 。也包含 SNMP Trap 的所有相关实现。<br> Net-snmp 包含了 snmp 实用程序集和完整的 snmp 开发库。<br>用户使用 net-snmp 提供的工具，可以完成很多关于 SNMP 的操作，具体说来，包括以下一些命令行应用程序：<br>一些应用程序可以用来从支持 SNMP 的设备获得数据。其中 snmpget, snmpgetnext 可以支持独立请求，比如：</p>
<p> <img src="http://static.zybuluo.com/abcdocker/r7hrbhcj5ixjsxqi7qxcgvko/3.png" alt="image"></p>
<blockquote>
<p>NET-SNMP 简介</p>
</blockquote>
<p> 在 Linux 系统中，我们可以选择 net-snmp 来处理绝大多数和 SNMP 相关的工作。<br>NET-SNMP 是一种开放源代码的 SNMP 协议实现。它支持 SNMP v1, SNMP v2c 与 SNMP v3，并可以使用 IPV4 及 IPV6 。也包含 SNMP Trap 的所有相关实现。Net-snmp 包含了 snmp 实用程序集和完整的 snmp 开发库。<br>用户使用 net-snmp 提供的工具，可以完成很多关于 SNMP 的操作，具体说来，包括以下一些命令行应用程序：<br>一些应用程序可以用来从支持 SNMP 的设备获得数据。其中 snmpget, snmpgetnext 可以支持独立请求，比如:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">% snmpget -v 1 -c demopublic test.net-snmp.org system.sysUpTime.0 </div><div class="line">system.sysUpTime.0 = Timeticks: (586731977) 67 days, 21:48:39.77</div></pre></td></tr></table></figure></p>
<p>该命令获得单个独立的 MIB 对象 system.sysUpTime.0 的值。</p>
<p>而 snmpwalk, snmptable, snmpdelta 则用来支持重复请求。</p>
<pre><code>% snmpwalk -v 2c -c demopublic test.net-snmp.org system 
SNMPv2-MIB::sysDescr.0 = HP-UX net-snmp B.10.20 A 9000/715 
SNMPv2-MIB::sysObjectID.0 = OID: enterprises.ucdavis.ucdSnmpAgent.hpux10 
SNMPv2-MIB::sysUpTime.0 = Timeticks: (586998396) 67 days, 22:33:03.96 
SNMPv2-MIB::sysContact.0 = Wes Hardaker wjhardaker@ucdavis.edu 
SNMPv2-MIB::sysName.0 = net-snmp
</code></pre><p>上面的命令返回所有 system 节点以下的 MIB 对象的值。<br>命令 snmpset 对支持 SNMP 的设备配置属性。如下例所示</p>
<pre><code>$ snmpget -v 1 -c demopublic test.net-snmp.org ucdDemoPublicString.0 
UCD-DEMO-MIB::ucdDemoPublicString.0 = &quot;hi there!&quot; 
$ snmpset -v 1 -c demopublic test.net-snmp.org ucdDemoPublicString.0 s &quot;Hello, world!&quot; 
UCD-DEMO-MIB::ucdDemoPublicString.0 = &quot;Hello, world!&quot; 
$ snmpget -v 1 -c demopublic test.net-snmp.org ucdDemoPublicString.0 
UCD-DEMO-MIB::ucdDemoPublicString.0 = &quot;Hello, world!&quot;
</code></pre><p>命令snmpdf, snmpnetstat, snmpstatus 可以从支持 SNMP 的设备获取特定的信息。比如下面的命令从目标系统上获得类似 netstat 的信息：</p>
<pre><code>% snmpnetstat -v 2c -c public -a testhost 
Active Internet (tcp) Connections (including servers) 
Proto Local Address Foreign Address (state) 
tcp *.echo *.* LISTEN 
tcp *.discard *.* LISTEN 
tcp *.daytime *.* LISTEN 
tcp *.chargen *.* LISTEN 
tcp *.ftp *.* LISTEN
tcp *.telnet *.* LISTEN 
tcp *.smtp *.* LISTEN 
Active Internet (udp) Connections 
Proto Local Address 
udp *.echo 
udp *.discard 
udp *.daytime 
udp *.chargen 
udp *.time
</code></pre><p>snmptranslate 命令将 MIB OIDs 的两种表现形式 ( 数字及文字 ) 相互转换。并显示 MIB 的内容与结构，如下所示：</p>
<pre><code>% snmptranslate .1.3.6.1.2.1.1.3.0 
    SNMPv2-MIB::sysUpTime.0 
% snmptranslate -On SNMPv2-MIB::sysUpTime.0 
    .1.3.6.1.2.1.1.3.0
</code></pre><p>Net-snmp还提供了一个基于 Tk/perl 的，图形化的 MIB 浏览器 tkmib。<br>首先调用函数 snmp_pdu_create 创建一个 SNMPv2 的 Trap PDU。然后调用 snmp_add_var 向该 PDU 中添加图三所示的三个部分。<br>sysUpTime 在 SNMPv2-MIB中定义，其OID为”1.3.6.1.2.1.1.3.0”。我们只需要通过 get_uptime() 函数获得该值，然后调用snmp_add_var将该变量加入刚才创建的 PDU中。</p>
<p>SNMP例子：查看系统第一分钟的负载</p>
<pre><code>[root@tang snmp]#  snmpget -v2c -c tang 172.17.82.185  1.3.6.1.4.1.2021.10.1.3.1
</code></pre><ul>
<li><p>-c是团体名，在配置文件中定义的，还有ip地址       </p>
<pre><code>UCD-SNMP-MIB::laLoad.1 = STRING: 0.00
[root@tang snmp]# cat /etc/snmp/snmpd.conf
rocommunity tang 172.17.82.185
</code></pre></li>
</ul>
<p>提示：我们cpu所有指标都有一个oid 后面我们定义的数字就是oid<br>例如cacti就是通过snmp来获取性能指标，在使用RRDTool来进行画图</p>
<blockquote>
<p>SNMP 2种常用模式</p>
</blockquote>
<p>1.GerRequest PDU<br>2.GetNextRequest PDU</p>
<pre><code>[root@localhost snmp]# snmpwalk -v2c -c tang 172.17.82.185 1.3.6.1.4.1.2021.10.1.3
UCD-SNMP-MIB::laLoad.1 = STRING: 0.00
UCD-SNMP-MIB::laLoad.2 = STRING: 0.01
UCD-SNMP-MIB::laLoad.3 = STRING: 0.05
[root@localhost snmp]# uptime 
 13:16:08 up  6:35,  2 users,  load average: 0.00, 0.01, 0.05
</code></pre><p>linux下常用Oid<br><a href="http://linux.chinaunix.net/techdoc/net/2008/08/21/1026818.shtml" target="_blank" rel="external">http://linux.chinaunix.net/techdoc/net/2008/08/21/1026818.shtml</a><br><a href="http://www.2cto.com/os/201211/170730.html" target="_blank" rel="external">http://www.2cto.com/os/201211/170730.html</a><br>提示：只需要在IP地址后面输入相对应的oid即可</p>
<h3 id="系统监控"><a href="#系统监控" class="headerlink" title="系统监控"></a>系统监控</h3><blockquote>
<p>CPU<br>内存<br>IO Input/Output(网络、磁盘)</p>
</blockquote>
<pre><code>企业面试题：如果系统负载达到200了，SSH连接不上，如何让SSH连接上
      解答：改变SSH的优先级
</code></pre><h4 id="CPU监控"><a href="#CPU监控" class="headerlink" title="CPU监控"></a>CPU监控</h4><pre><code>cpu三个重要概念：
1.上下文切换：CPU调度器实施的进程的切换过程，上下文切换
2.运行队列（负载）：运行队列，排队可以参考 我是一个进程文章（http://blog.csdn.net/nylx/article/details/51058389）
3.使用率

监控CPU需要确定服务类型：
1.IO密集型（数据库）
2.CPU密集型（web/mail）

确定性能的基准线：
1.运行队列：1-3个线程    基准：1CPU 4核 负载不超过12
2.CPU使用：65%-70%用户态利用率
           30%-35%内核态利用率
           0%-5%空闲
3.上下文切换：越少越好

所有的监控都要根据业务来考虑
</code></pre><h4 id="常见CPU监控工具"><a href="#常见CPU监控工具" class="headerlink" title="常见CPU监控工具"></a>常见CPU监控工具</h4><p><code>top sysstat mpstat</code></p>
<h5 id="top说明"><a href="#top说明" class="headerlink" title="top说明"></a>top说明</h5><p><img src="http://static.zybuluo.com/abcdocker/hecq3ii0fy0pq8cahuhxblun/4.png" alt="image"></p>
<p><strong>第一行</strong> <code>分别显示：系统当前时间 系统运行时间 当前用户登陆数 系统负载</code>。<br>　　系统负载（loadaverage），这里有三个数值，分别是系统最近<code>1分钟</code>，<code>5分钟</code>，<code>15分钟</code>的平均负载。<br>　　一般对于单个处理器来说，负载在0—1.00之间是正常的，超过1.00就要引起注意了。在多核处理器中，你的系统均值不应该高于处理器核心的总数。</p>
<p><strong>第二行</strong> 分别显示：<code>total</code>进程总数、 <code>running</code>正在运行的进程数、 <code>sleeping</code>睡眠的进程数、<code>stopped</code>停止的进程数、 <code>zombie</code>僵尸进程数。</p>
<p><strong>第三行</strong><br>    分别显示：<br>   <code>%us</code>用户空间占用CPU百分比、<br>    <code>%sy</code>内核空间占用CPU百分比、<br>    <code>%ni</code>用户进程空间内改变过优先级的进程占用CPU百分比、<br>    <code>%id</code>空闲CPU百分比、<br>    <code>%wa</code>等待输入输出（I/O）的CPU时间百分比 、<br>    <code>%hi</code>指的是cpu处理硬件中断的时间、%si指的是cpu处理软中断的时间 、<br>    <code>%st</code>用于有虚拟cpu的情况，用来指示被虚拟机偷掉的cpu时间。<br>    通常<code>id%</code>值可以反映一个系统cpu的闲忙程度。</p>
<p><strong>第四行</strong> MEM ：<code>total</code> 物理内存总量、 <code>used</code> 使用的物理内存总量、<code>free</code> 空闲内存总量、 <code>buffers</code> 用作内核缓存的内存量。</p>
<p><strong>第五行</strong> SWAP：<code>total</code> 交换区总量、 <code>used</code>使用的交换区总量、<code>free</code> 空闲交换区总量、 <code>cached</code>缓冲的交换区总量。<br><code>buffers</code>和<code>cached</code>的区别需要说明一下，<code>buffers</code>指的是块设备的读写缓冲区，cached指的是文件系统本身的页面缓存。它们都是linux操作系统底层的机制，目的就是为了加速对磁盘的访问</p>
<p><strong>第六行</strong> PID(进程号)、 <code>USER</code>（运行用户）、<code>PR</code>（优先级）、<code>NI</code>（任务nice值）、<code>VIRT</code>（虚拟内存用量）<code>VIRT=SWAP+RES</code> 、<code>RES</code>（物理内存用量）、<code>SHR</code>（共享内存用量）、<code>S（进程状态）、%CPU</code>（CPU占用比）、<code>%MEM</code>（物理内存占用比）、<code>TIME+</code>（累计CPU占 用时间)、　<code>COMMAND</code> 命令名/命令行。</p>
<p><strong>top命令的使用方法</strong>：<br>top [-] [d]</p>
<p>[q] [c] [C] [S]  [n]<br>运维必会！<br>参数说明<br>d指定每两次屏幕信息刷新之间的时间间隔。当然用户可以使用s交互命令来改变之。<br>p通过指定监控进程ID来仅仅监控某个进程的状态。<br>q该选项将使top没有任何延迟的进行刷新。如果调用程序有超级用户权限，那么top将以尽可能高的优先级运行。<br>S指定累计模式。<br>s使top命令在安全模式中运行。这将去除交互命令所带来的潜在危险。<br>i使top不显示任何闲置或者僵死进程。<br>c显示整个命令行而不只是显示命令名。</p>
<p>下面介绍在top命令执行过程中可以使用的一些交互命令<br>　　从使用角度来看，熟练的掌握这些命令比掌握选项还重要一些。<br>　　这些命令都是单字母的，如果在命令行选项中使用了s选项，则可能其中一些命令会被屏蔽掉。<br>Ctrl+L 擦除并且重写屏幕。<br>h或者? 显示帮助画面，给出一些简短的命令总结说明。<br>k 终止一个进程。系统将提示用户输入需要终止的进程PID，以及需要发送给该进程什么样的信号。一般的终止进程可以使用15信号；如果不能正常结束那就使用信号9强制结束该进程。默认值是信号15。在安全模式中此命令被屏蔽。<br>i 忽略闲置和僵死进程。这是一个开关式命令。<br>q 退出程序。<br>r 重新安排一个进程的优先级别。系统提示用户输入需要改变的进程PID以及需要设置的进程优先级值。输入一个正值将使优先级降低，反之则可以使该进程拥有更高的优先权。默认值是10。<br>s 改变两次刷新之间的延迟时间。系统将提示用户输入新的时间，单位为s。如果有小数，就换算成m s。输入0值则系统将不断刷新，默认值是5 s。需要注意的是如果设置太小的时间，很可能会引起不断刷新，从而根本来不及看清显示的情况，而且系统负载也会大大增加。<br>f或者F 从当前显示中添加或者删除项目。<br>o或者O 改变显示项目的顺序。<br>l 切换显示平均负载和启动时间信息。<br>m 切换显示内存信息。<br>t 切换显示进程和CPU状态信息。<br>c 切换显示命令名称和完整命令行。<br>M 根据驻留内存大小进行排序。<br>P 根据CPU使用百分比大小进行排序。<br>T 根据时间/累计时间进行排序。<br>W 将当前设置写入~/.toprc文件中。这是写top配置文件的推荐方法。<br>Shift+M 可按内存占用情况进行排序。</p>
<h5 id="sysstat-说明"><a href="#sysstat-说明" class="headerlink" title="sysstat 说明"></a>sysstat 说明</h5><pre><code>[root@tang ~]# yum install sysstat -y
[root@tang ~]# vmstat --help
usage: vmstat [-V] [-n] [delay [count]]
              -V prints version.
              -n causes the headers not to be reprinted regularly.
              -a print inactive/active page stats.
              -d prints disk statistics
              -D prints disk table
              -p prints disk partition statistics
              -s prints vm table
              -m prints slabinfo
              -t add timestamp to output
              -S unit size
              delay is the delay between updates in seconds. 
              unit size k:1000 K:1024 m:1000000 M:1048576 (default is K)
              count is the number of updates.
</code></pre><blockquote>
<p>例子：每隔1秒获取1次，次数不限</p>
</blockquote>
<pre><code>[root@tang snmp]# vmstat 1
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 4  0      0 926348 124344 624748    0    0     2     6  124  150  1  1 98  0  0
 0  0      0 926332 124344 624748    0    0     0     0 1252 2559  0  1 99  0  0
 0  0      0 926332 124344 624748    0    0     0     0 1260 2562  1  1 98  0  0
 0  0      0 926332 124344 624748    0    0     0     0 1256 2569  1  0 99  0  0

r表示CPU排队的情况，b代表 进程堵塞，等待io 
每隔1秒获取1次，次数10次

[root@tang snmp]# vmstat 1 10
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 4  0      0 926332 124344 624748    0    0     2     6  125  150  1  1 98  0  0
 0  0      0 926332 124344 624748    0    0     0     0 1260 2574  1  0 99  0  0
 0  0      0 926332 124344 624748    0    0     0     0 1253 2558  0  1 99  0  0
 0  0      0 926332 124344 624748    0    0     0     0 1279 2589  1  1 98  0  0
 0  0      0 926332 124344 624748    0    0     0     0 1272 2577  1  1 98  0  0
 0  0      0 926332 124344 624748    0    0     0     0 1272 2575  1  0 99  0  0
 0  0      0 926332 124344 624748    0    0     0     0 1267 2574  1  1 98  0  0
 0  0      0 926332 124344 624748    0    0     0     0 1269 2571  0  1 99  0  0
 0  0      0 926332 124344 624748    0    0     0     0 1289 2597  1  1 98  0  0
 0  0      0 926332 124344 624748    0    0     0     0 1279 2600  0  1 99  0  0
</code></pre><h5 id="mpstat说明"><a href="#mpstat说明" class="headerlink" title="mpstat说明"></a>mpstat说明</h5><p>查看所有CPU的平均值</p>
<pre><code>[root@tang snmp]# mpstat 1
Linux 3.10.0-514.10.2.el7.x86_64 (tang)     04/23/2017     _x86_64_    (1 CPU)

04:45:51 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
04:45:52 PM  all    1.01    0.00    1.01    0.00    0.00    0.00    0.00    0.00    0.00   97.98
04:45:53 PM  all    1.01    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   98.99
04:45:54 PM  all    1.01    0.00    1.01    0.00    0.00    0.00    0.00    0.00    0.00   97.98
04:45:55 PM  all    0.00    0.00    1.02    0.00    0.00    0.00    0.00    0.00    0.00   98.98

[root@tang snmp]# mpstat 1 10
Linux 3.10.0-514.10.2.el7.x86_64 (tang)     04/23/2017     _x86_64_    (1 CPU)

04:46:20 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
04:46:21 PM  all    1.02    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   98.98
04:46:22 PM  all    0.00    0.00    1.01    0.00    0.00    0.00    0.00    0.00    0.00   98.99
04:46:23 PM  all    1.01    0.00    1.01    0.00    0.00    0.00    0.00    0.00    0.00   97.98
04:46:24 PM  all    1.00    0.00    1.00    0.00    0.00    0.00    0.00    0.00    0.00   98.00
04:46:25 PM  all    2.02    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   97.98
04:46:26 PM  all    1.00    0.00    1.00    0.00    0.00    0.00    0.00    0.00    0.00   98.00
04:46:27 PM  all    1.01    0.00    1.01    0.00    0.00    0.00    0.00    0.00    0.00   97.98
04:46:28 PM  all    1.01    0.00    1.01    0.00    0.00    0.00    0.00    0.00    0.00   97.98
04:46:29 PM  all    1.00    0.00    1.00    0.00    0.00    0.00    0.00    0.00    0.00   98.00
04:46:30 PM  all    1.01    0.00    1.01    0.00    0.00    0.00    0.00    0.00    0.00   97.98
Average:     all    1.01    0.00    0.81    0.00    0.00    0.00    0.00    0.00    0.00   98.19
</code></pre><p>上述是CPU监控，CPU监控主要靠经验。因为业务不同指标不同，指标越低越好是不变的道理</p>
<h4 id="内存监控"><a href="#内存监控" class="headerlink" title="内存监控"></a>内存监控</h4><p>硬盘格式化后分成块（blog）<br>内存默认是页（大小4kb）读取按照页来进行读取<br>内存： <code>free</code> <code>vmstat</code></p>
<pre><code>[root@www ~]# free -m
             total       used       free     shared    buffers     cached
Mem:          1875       1338        537          0        173        523
-/+ buffers/cache:        640       1234
Swap:            0          0          0
</code></pre><p>提示：云主机是没有Swap分区的<br><code>total</code> 总内存<br><code>used</code> 已使用内存<br><code>free</code> 空闲内存<br><code>shared</code> 共享内存（进程间相互通信使用共享内存）<br><code>buffers</code> 缓冲<br><code>cached</code>缓存<br>Centos7 会有一个<code>available</code>，活动内存 </p>
<p>云服务器一般不分配swap分区，物理机能不使用交换分区就不使用交换分区</p>
<h5 id="vmstat命令"><a href="#vmstat命令" class="headerlink" title="vmstat命令"></a>vmstat命令</h5><pre><code>[root@www ~]# vmstat 1
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0      0 550628 177684 536324    0    0     1     6    7   46  1  0 98  0  0    
 0  0      0 550620 177684 536324    0    0     0    40  187  429  0  0 100  0  0
 0  0      0 550620 177684 536324    0    0     0     0  183  427  1  0 99  0  0    
 0  0      0 550620 177684 536324    0    0     0     0  197  436  0  1 99  0  0
</code></pre><p><code>swpd</code>交换分区的大小<br><code>free</code>可用的物理内存大小<br><code>buff</code> 缓冲区的大小<br><code>cache</code> 缓存区的大小<br><code>si</code> 数据从交换分区读取到内存的大小<br><code>so</code> 数据从内存到交换分区<br><code>bi</code> 从交换分区读到内存（block）<br><code>bo</code>内存写到硬盘的</p>
<p>内存达到多少报警呢？ <code>80%</code><br>正常是一个进程启动后会一直往上升，最后到达一个平稳期</p>
<h4 id="硬盘监控"><a href="#硬盘监控" class="headerlink" title="硬盘监控"></a>硬盘监控</h4><p>硬盘：IOPS IO’s Per Second iotop df -h iostat<br>　　顺序IO（快）<br>　　随机IO（慢） </p>
<blockquote>
<p>查看磁盘剩余空间</p>
</blockquote>
<pre><code>[root@tang ~]# df -h
Filesystem      Size  Used Avail Use% Mounted on
/dev/xvda1       40G  4.1G   34G  11% /
tmpfs           938M     0  938M   0% /dev/shm
</code></pre><p>```</p>
<blockquote>
<p>监控磁盘IO iotop</p>
</blockquote>
<pre><code>[root@www ~]# yum install iotop -y
</code></pre><p>iotop<br><img src="http://static.zybuluo.com/abcdocker/uqklmvh78n4k51q8cuukn4rb/1.png" alt="http://static.zybuluo.com/abcdocker/uqklmvh78n4k51q8cuukn4rb/1.png">  </p>
<p>可以使用dd命令生成一个文件夹进行测试<br>生成命令如下：</p>
<pre><code>[root@www ~]# dd if=/dev/zero of=/tmp/1.txt bs=1M count=1000
1000+0 records in
1000+0 records out
1048576000 bytes (1.0 GB) copied, 20.509 s, 51.1 MB/s
[root@www ~]# ls -lh /tmp/1.txt 
-rw-r--r-- 1 root root 1000M Aug 30 19:48 /tmp/1.txt
</code></pre><p>此时IO写入如下图<br><img src="http://static.zybuluo.com/abcdocker/qa2kribzw85j1w7hdt2zcs0n/2.png" alt="http://static.zybuluo.com/abcdocker/qa2kribzw85j1w7hdt2zcs0n/2.png"></p>
<p><code>iostat命令，可以看到那块磁盘，比iotop更加细致</code></p>
<pre><code>[root@tang ~]# iostat 1 2
Linux 2.6.32-431.23.3.el6.x86_64 (www)  08/30/2016  _x86_64_    (1 CPU)
avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           1.10    0.00    0.27    0.16    0.00   98.46
Device:            tps   Blk_read/s   Blk_wrtn/s   Blk_read   Blk_wrtn
xvda              1.51         2.26        17.09     986748    7467560
avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           1.02    0.00    0.00    0.00    0.00   98.98
Device:            tps   Blk_read/s   Blk_wrtn/s   Blk_read   Blk_wrtn
xvda              0.00         0.00         0.00          0   
</code></pre><p><code>tps</code> 设备每秒的传输次数（每秒多少的io请求）<br><code>Blk_read/s</code> 每秒从设备读取的数据量<br><code>Blk_wrtn/s</code> 每秒像设备写入的数据量<br><code>Blk_read</code>写入数据的总数<br><code>Blk_wrtn</code> 读取数据的总数</p>
<h4 id="网络监控"><a href="#网络监控" class="headerlink" title="网络监控"></a>网络监控</h4><h5 id="iftop说明"><a href="#iftop说明" class="headerlink" title="iftop说明"></a>iftop说明</h5><pre><code>[root@www ~]# yum install iftop -y
[root@www ~]# iftop -n    #-n不做域名解析
</code></pre><p><img src="http://static.zybuluo.com/abcdocker/rdwly3nsqifomp378oitvmfe/3.png" alt="http://static.zybuluo.com/abcdocker/rdwly3nsqifomp378oitvmfe/3.png"><br>正常监控只需要监控网卡带宽即可<br>其中网络监控是最复杂的，ping监控网络延迟网络丢包等。但是此类的网络监控只是监控自己到客户端是否丢包，并不能保证客户端到服务器这边不丢包<br>　其中就产生了如：<code>阿里测、奇云测、站长工具</code>等一系列多节点的监控工具</p>
<p>性能测试常用工具：<code>IBM nmon （nmon analyser---生成AIX性能报告的免费工具）</code><br><a href="http://nmon.sourceforge.net/pmwiki.php" target="_blank" rel="external">http://nmon.sourceforge.net/pmwiki.php</a> #下载地址（需要翻墙工具）<br>所以我们提供了百度云下载<br>链接：<a href="http://pan.baidu.com/s/1boXV6R9" target="_blank" rel="external">http://pan.baidu.com/s/1boXV6R9</a> 密码：sblf<br>只需要下载对应的版本，给执行权限。执行即可</p>
<pre><code>[root@tang tmp]# chmod +x nmon16e_x86_rhel72 
[root@tang tmp]# ./nmon16e_x86_rhel72
</code></pre><p><img src="http://static.zybuluo.com/abcdocker/zi2fr7i0glig9ad4r9qaz15i/4.png" alt="http://static.zybuluo.com/abcdocker/zi2fr7i0glig9ad4r9qaz15i/4.png"><br>我们可以直接输入一个c 一个m一个d。这个是实时的一个状态<br><img src="http://static.zybuluo.com/abcdocker/rx2i4p0yakya27f2aodjfa93/5.png" alt="http://static.zybuluo.com/abcdocker/rx2i4p0yakya27f2aodjfa93/5.png"></p>
<p>我们可以查看帮助</p>
<pre><code>[root@localhost tmp]# ./nmon16e_x86_rhel72 --help
./nmon16e_x86_rhel72: invalid option -- &apos;-&apos;
Hint for nmon16e_x86_rhel72 version 16e
    Full Help Info : nmon16e_x86_rhel72 -h
    On-screen Stats: nmon16e_x86_rhel72
    Data Collection: nmon16e_x86_rhel72 -f [-s &lt;seconds&gt;] [-c &lt;count&gt;] [-t|-T]
    Capacity Plan  : nmon16e_x86_rhel72 -x
Interactive-Mode:
    Read the Welcome screen &amp; at any time type: &quot;h&quot; for more help
    Type &quot;q&quot; to exit nmon
For Data-Collect-Mode
    -f            Must be the first option on the line (switches off interactive mode)
                  Saves data to a CSV Spreadsheet format .nmon file in then local directory
                  Note: -f sets a defaults -s300 -c288    which you can then modify
    Further Data Collection Options:
    -s &lt;seconds&gt;  time between data snapshots
    -c &lt;count&gt;    of snapshots before exiting
    -t            Includes Top Processes stats (-T also collects command arguments)
    -x            Capacity Planning=15 min snapshots for 1 day. (nmon -ft -s 900 -c 96)
---- End of Hints
</code></pre><p><code>-c</code>  采集的次数<br><code>-s</code>  采集的间隔时间<br><code>-f</code> 生成一个文件<br><code>-m</code>  指定生成文件位置<br>采集10次 间隔10秒</p>
<pre><code>[root@localhost tmp]# ./nmon16e_x86_rhel72 -c 10 -s 10 -f -m /tmp/
[root@localhost tmp]# ls
localhost_160831_0435.nmon  nmon16e_x86_rhel72
</code></pre><p>前面为主机名后面是日期（年月日时分）<br>因为测试可能需要，我们要制作成表格，所以现在将文件上传到桌面上</p>
<pre><code>[root@localhost tmp]# sz localhost_160831_0435.nmon 
</code></pre><p>我们打开下载的工具<br><img src="http://static.zybuluo.com/abcdocker/d4rown1bnx8bgk8wgu2rfu4f/6.png" alt="http://static.zybuluo.com/abcdocker/d4rown1bnx8bgk8wgu2rfu4f/6.png"></p>
<p>解压文件夹，打开nmon analyser v34a.xls<br><img src="http://static.zybuluo.com/abcdocker/g1ob74tdxdnbo5p71x95ot35/7.png" alt="http://static.zybuluo.com/abcdocker/g1ob74tdxdnbo5p71x95ot35/7.png"></p>
<p>点击Analyse nmon data找到我们刚刚复制出来的文件，就可以看到了。<br><img src="http://static.zybuluo.com/abcdocker/z1m3apomvrg8k1y3li8wpmcy/8.png" alt="http://static.zybuluo.com/abcdocker/z1m3apomvrg8k1y3li8wpmcy/8.png"></p>
<h3 id="应用服务监控"><a href="#应用服务监控" class="headerlink" title="应用服务监控"></a>应用服务监控</h3><p>举例：Nginx<br>安装nginx</p>
<pre><code>[root@localhost ~]# yum install -y gcc glibc gcc-c++ prce-devel openssl-devel
</code></pre><p>提示：nginx可以使用稳定版的最新版，因为安全性会不断的提高。如果是特别老的版本会有一些漏洞和功能<br>　　要想监控nginx需要在编译时添加如下参数</p>
<p><code>--with-http_stub_status_module</code></p>
<p>下载Nginx</p>
<pre><code>[root@localhost src]# wget http://nginx.org/download/nginx-1.10.1.tar.gz
</code></pre><p>解压，后面步骤太简单不说了<br>安装</p>
<pre><code>[root@localhost nginx-1.10.1]# useradd -s /sbin/nologin www
[root@localhost nginx-1.10.1]# ./configure --prefix=/usr/local/nginx-1.10.1 --user=www --group=www --with-http_ssl_module --with-http_stub_status_module
</code></pre><p><code>configure</code> 是一个shell脚本，执行它的作用是生成MAKEFILE（编译make需要）</p>
<pre><code>[root@localhost nginx-1.10.1]# make &amp;&amp; make install
[root@localhost nginx-1.10.1]# ll
total 676
drwxr-xr-x 6 1001 1001   4096 Aug 31 06:02 auto
-rw-r--r-- 1 1001 1001 262898 May 31 09:47 CHANGES
-rw-r--r-- 1 1001 1001 400701 May 31 09:47 CHANGES.ru
drwxr-xr-x 2 1001 1001   4096 Aug 31 06:02 conf
-rwxr-xr-x 1 1001 1001   2481 May 31 09:47 configure
drwxr-xr-x 4 1001 1001     68 Aug 31 06:02 contrib
drwxr-xr-x 2 1001 1001     38 Aug 31 06:02 html
-rw-r--r-- 1 1001 1001   1397 May 31 09:47 LICENSE
-rw-r--r-- 1 root root    404 Aug 31 07:46 Makefile
drwxr-xr-x 2 1001 1001     20 Aug 31 06:02 man
drwxr-xr-x 3 root root    119 Aug 31 07:46 objs
-rw-r--r-- 1 1001 1001     49 May 31 09:47 README
drwxr-xr-x 9 1001 1001     84 Aug 31 06:02 src
</code></pre><p><code>make是生成文件</code>，<code>make install</code>是将生成的文件拷贝到不同的地方<br>make install 完成之后可以直接将当前目录拷贝到其他服务器上，安装相同的依赖就可以进行使用。</p>
<pre><code>[root@localhost nginx-1.10.1]# ln -s /usr/local/nginx-1.10.1/ /usr/local/nginx
[root@localhost nginx-1.10.1]# netstat -lntp|grep nginx
tcp        0      0 0.0.0.0:80              0.0.0.0:*               LISTEN      7058/nginx: master  
</code></pre><p>修改nginx.conf配置文件</p>
<pre><code>location /status {
stub_status on;
access_log off;
    allow 192.168.56.0/24;
deny all;
}
</code></pre><p>设置只允许56网段访问，并开启日志和状态模块<br>这个比较基础，如果不知道怎么添加。可以参考www.nginx.org 状态模块<br>浏览器访问：<a href="http://192.168.56.11/status" target="_blank" rel="external">http://192.168.56.11/status</a></p>
<pre><code>Active connections: 1 
server accepts handled requests
 3 3 163 
Reading: 0 Writing: 1 Waiting: 0 
Active connections: 当前活跃的连接数 
</code></pre><p>3—-&gt; 一共处理了多少个链接（请求）<br>3—-&gt; 成功创建多少次握手<br>163–&gt; 总共创建了多少个请求<br>Reading:当前读取客户端heardr的数量<br>Writing:当前返回给客户端heardr的数量 　#如果这个指标飙升，说明是后面的节点挂掉了，例如数据库等。<br>Waiting:大体意思是已经处理完，等待下次请求的数量<br>提示：我们只需要关注活动链接即可</p>
<p><strong>监控最基础的功能</strong><br><strong><code>采集 存储 展示 告警</code></strong></p>
<p>　<strong>几款监控软件说明：</strong><br>    <code>Nagios+Cacti</code>Nagios报警功能比较强，但是画图比较弱（有插件） Cacti 画图比较强，报警比较弱（有插件）<br><code>Zabbix</code>可以直接监控IPMI、SNMP、JVM 这些监控项目别的软件本身干不了，插件除外 Zabbix分为Server—-&gt;Agent 有主动和被动模式<br><code>Gangla</code>　根本没听说过！</p>
]]></content>
      
        <categories>
            
            <category> 运维监控 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 运维监控 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[五分钟商学院--大纲]]></title>
      <url>http://yoursite.com/2016/09/25/%E4%BA%94%E5%88%86%E9%92%9F%E5%95%86%E5%AD%A6%E9%99%A2--%E5%A4%A7%E7%BA%B2/</url>
      <content type="html"><![CDATA[<p>商业四大体系合体。</p>
<p>1）商业，你与企业外部的关系；<br>2）管理，你与企业内部的关系；<br>3）个人，你与自己的关系；<br>4）以及提升前三者的：工具。    </p>
<a id="more"></a>
<h2 id="商业篇"><a href="#商业篇" class="headerlink" title="商业篇"></a>商业篇</h2><h3 id="消费心理学"><a href="#消费心理学" class="headerlink" title="消费心理学"></a>消费心理学</h3><p>1.心理账户<br>2.沉没成本<br>3.比例偏见<br>4.损失规避<br>5.价格锚点          </p>
<h3 id="商业世界五大基础逻辑"><a href="#商业世界五大基础逻辑" class="headerlink" title="商业世界五大基础逻辑"></a>商业世界五大基础逻辑</h3><p>6.流量之河<br>7.倍率之刀<br>8.价量之秤<br>9.风险之眼<br>10.规则之缝  </p>
<h3 id="互联网世界五大基本定律"><a href="#互联网世界五大基本定律" class="headerlink" title="互联网世界五大基本定律"></a>互联网世界五大基本定律</h3><p>11.信息对称<br>12.平台经济<br>13.边际成本<br>14.长尾理论<br>15.免费理论  </p>
<h3 id="行为经济学"><a href="#行为经济学" class="headerlink" title="行为经济学"></a>行为经济学</h3><p>16.结果偏见<br>17.适应性偏见<br>18.鸡蛋理论<br>19.概率偏见<br>20.凡勃伦效应</p>
<h3 id="微观经济学"><a href="#微观经济学" class="headerlink" title="微观经济学"></a>微观经济学</h3><p>21.供需理论<br>22.边际效用<br>23.机会成本<br>24.代理两难<br>25.科斯定理   </p>
<h3 id="宏观经济学"><a href="#宏观经济学" class="headerlink" title="宏观经济学"></a>宏观经济学</h3><p>26.节约悖论<br>27.张维迎林毅夫之争<br>28.人口抚养比<br>29.经济泡沫<br>30.福利经济  </p>
<h3 id="金融法律"><a href="#金融法律" class="headerlink" title="金融法律"></a>金融法律</h3><p>31.风险投资<br>32.公司的形态：有限责任，合伙企业，个人独资<br>33.期权（员工激励方案）<br>34.庞氏骗局<br>35.互联网金融   </p>
<h3 id="市场营销-Product"><a href="#市场营销-Product" class="headerlink" title="市场营销 Product"></a>市场营销 Product</h3><p>36.产品定位<br>37.自我认知<br>38.极致单品<br>39.三驾马车<br>40.最小可用品  </p>
<h3 id="市场营销-Price"><a href="#市场营销-Price" class="headerlink" title="市场营销 Price"></a>市场营销 Price</h3><p>41.渗透定价法<br>42.组合定价法<br>43.撇脂定价法<br>44.价格歧视<br>45.客户自定价   </p>
<h3 id="市场营销-Promotion"><a href="#市场营销-Promotion" class="headerlink" title="市场营销 Promotion"></a>市场营销 Promotion</h3><p>46.定位营销<br>47.饥饿营销<br>48.死亡之井<br>49.危机公关<br>50.独特的销售主张-USP   </p>
<h3 id="市场营销-Place"><a href="#市场营销-Place" class="headerlink" title="市场营销 Place"></a>市场营销 Place</h3><p>51.深度分销<br>52.直接销售<br>53.虚实结合<br>54.社区商务<br>55.反向定制  </p>
<h3 id="市场营销-互联网营销"><a href="#市场营销-互联网营销" class="headerlink" title="市场营销 互联网营销"></a>市场营销 互联网营销</h3><p>56.社群经济<br>57.口碑经济（POE理论）<br>58.粉丝经济<br>59.引爆点<br>60.红利理论  </p>
<h3 id="所有现象背后都有商业逻辑"><a href="#所有现象背后都有商业逻辑" class="headerlink" title="所有现象背后都有商业逻辑"></a>所有现象背后都有商业逻辑</h3><p>61.运动对赌<br>62.雇佣客户<br>63.服务行业美女越多，经济越不景气<br>64.狩猎式 vs 农耕式<br>65.稳定平衡态 vs 不稳定平衡态   </p>
<h2 id="管理篇"><a href="#管理篇" class="headerlink" title="管理篇"></a>管理篇</h2><h3 id="管理选人"><a href="#管理选人" class="headerlink" title="管理选人"></a>管理选人</h3><p>66.上下车法则<br>67.奥格尔维定律<br>68.首因效应/光环效应<br>69.特雷默定律<br>70.重视面试被拒的人   </p>
<h3 id="管理育人"><a href="#管理育人" class="headerlink" title="管理育人"></a>管理育人</h3><p>71.蘑菇定律<br>72.师傅制<br>73.情境领导II<br>74.鲶鱼效应<br>75.贝尼斯定理  </p>
<h3 id="管理用人"><a href="#管理用人" class="headerlink" title="管理用人"></a>管理用人</h3><p>76.不值得定律<br>77.懒蚂蚁效应<br>78.热炉法则<br>79.拜伦法则<br>80.波特定律  </p>
<h3 id="管理留人"><a href="#管理留人" class="headerlink" title="管理留人"></a>管理留人</h3><p>81.酒与污水定律<br>82.格雷欣法则（劣币驱逐良币）<br>83.雷尼尔效应<br>84.南风法则<br>85.离职面试  </p>
<h3 id="管理就是激励需求理论"><a href="#管理就是激励需求理论" class="headerlink" title="管理就是激励需求理论"></a>管理就是激励需求理论</h3><p>86.马斯洛人类需求五层次理论-生理<br>87.马斯洛人类需求五层次理论-安全<br>88.马斯洛人类需求五层次理论-归属<br>89.马斯洛人类需求五层次理论-尊重<br>90.马斯洛人类需求五层次理论-实现  </p>
<h3 id="管理就是激励其他理论"><a href="#管理就是激励其他理论" class="headerlink" title="管理就是激励其他理论"></a>管理就是激励其他理论</h3><p>91.卡诺满意度模型<br>92.赫兹伯格的双因素激励理论<br>93.亚佛斯德原则（期望理论）<br>94.马蝇效应<br>95.波什定律   </p>
<h3 id="从员工到经理"><a href="#从员工到经理" class="headerlink" title="从员工到经理"></a>从员工到经理</h3><p>96.古狄逊定理<br>97.吉格勒定理<br>98.刺猬法则<br>99.目标置换效应<br>100.篮球架子原理  </p>
<h3 id="管理1"><a href="#管理1" class="headerlink" title="管理1"></a>管理1</h3><p>101.崔西定律<br>102.蓝柏格定理<br>103.阿什定律<br>104.彼得斯定律<br>105.超限效应   </p>
<h3 id="管理2"><a href="#管理2" class="headerlink" title="管理2"></a>管理2</h3><p>106.奥卡姆剃刀定律<br>107.法约尔原则（责权利心法）<br>108.例外原则<br>109.洛克忠告<br>110.海恩法则   </p>
<h3 id="管理3"><a href="#管理3" class="headerlink" title="管理3"></a>管理3</h3><p>111.波特法则<br>112.卡贝定律<br>113.飞轮效应<br>114.墨菲定律<br>115.克里夫兰法则   </p>
<h3 id="团队合作"><a href="#团队合作" class="headerlink" title="团队合作"></a>团队合作</h3><p>116.球队，交响乐队，军队<br>117.木桶定律<br>118.多样性（异性效应）<br>119.苛希纳定律<br>120.蚁群效应  </p>
<h3 id="项目管理"><a href="#项目管理" class="headerlink" title="项目管理"></a>项目管理</h3><p>121.作战指挥室<br>122.关键路径<br>123.范围、时间、资源的金三角<br>124.风险管理（已知的未知风险）<br>125.权利来源：专业   </p>
<h3 id="管理常见病"><a href="#管理常见病" class="headerlink" title="管理常见病"></a>管理常见病</h3><p>126.破窗效应<br>127.旁观者效应<br>128.帕金森定律<br>129.彼得原理<br>130.手表定律  </p>
<h2 id="个人篇"><a href="#个人篇" class="headerlink" title="个人篇"></a>个人篇</h2><h3 id="高效能人士的七种习惯"><a href="#高效能人士的七种习惯" class="headerlink" title="高效能人士的七种习惯"></a>高效能人士的七种习惯</h3><p>131.范式转变<br>132.情感账户<br>133.积极主动<br>134.以终为始<br>135.要事第一  </p>
<h3 id="高效能人士的七种习惯-1"><a href="#高效能人士的七种习惯-1" class="headerlink" title="高效能人士的七种习惯"></a>高效能人士的七种习惯</h3><p>136.双赢思维<br>137.知彼解己<br>138.统合综效<br>139.不断更新<br>140.找到心声  </p>
<h3 id="时间管理"><a href="#时间管理" class="headerlink" title="时间管理"></a>时间管理</h3><p>141.时间成本<br>142.GTD<br>143.猴子理论<br>144.三八理论<br>145.番茄钟   </p>
<h3 id="职业素养"><a href="#职业素养" class="headerlink" title="职业素养"></a>职业素养</h3><p>146.如何打招呼<br>147.如何吃西餐<br>148.如何和老板一起坐车<br>149.如何搭配衣服<br>150.邮件礼仪   </p>
<h3 id="学习能力"><a href="#学习能力" class="headerlink" title="学习能力"></a>学习能力</h3><p>151.幸存者偏见<br>152.库博经验学习圈<br>153.知识、技能、态度<br>154.学习小组（私人董事会）<br>155.如何最快速的学习    </p>
<h3 id="思考能力"><a href="#思考能力" class="headerlink" title="思考能力"></a>思考能力</h3><p>156.六顶思考帽<br>157.批判性思维/辩证思维<br>158.系统思维-关联的、整体的、动态的<br>159.正向思维<br>160.逆向思维   </p>
<h3 id="逻辑思维"><a href="#逻辑思维" class="headerlink" title="逻辑思维"></a>逻辑思维</h3><p>161.偷换概念-同一律<br>162.自相矛盾-矛盾律<br>163.模棱两可-排中律<br>164.三段论<br>165.归纳法与黑天鹅事件   </p>
<h3 id="谈判能力"><a href="#谈判能力" class="headerlink" title="谈判能力"></a>谈判能力</h3><p>166.吉普赛陷阱<br>167.定位调整偏见<br>168.有限的权利 &amp; 不露面的人<br>169.战略延迟 &amp; 最终期限<br>170.吃惊 &amp; 撤退    </p>
<h3 id="情感能力"><a href="#情感能力" class="headerlink" title="情感能力"></a>情感能力</h3><p>171.元能力：同理心<br>172.元能力：自我认知（卢维斯定理）<br>173.元能力：自我控制<br>174.元能力：自我激励<br>175.元能力：人际关系处理   </p>
<h3 id="演讲能力"><a href="#演讲能力" class="headerlink" title="演讲能力"></a>演讲能力</h3><p>176.导游心法<br>177.注意力法则<br>178.空中加油<br>179.案例和幽默感<br>180.打透     </p>
<h3 id="沟通能力"><a href="#沟通能力" class="headerlink" title="沟通能力"></a>沟通能力</h3><p>181.快乐痛苦四原则<br>182.亨利法则<br>183.踢猫效应<br>184.电梯测验<br>185.如何问出好问题    </p>
<h3 id="创新能力"><a href="#创新能力" class="headerlink" title="创新能力"></a>创新能力</h3><p>186.创新者的窘境<br>187.人无我有，人有我优，人优我廉……<br>188.达维多定律<br>189.路径依赖<br>190.比伦定律   </p>
<h3 id="领导能力"><a href="#领导能力" class="headerlink" title="领导能力"></a>领导能力</h3><p>191.远（后喻文明）<br>192.小（科斯定理）<br>193.变（企业生命周期）<br>194.快（快鱼吃慢鱼）<br>195.专（网状激活系统）   </p>
<h2 id="战略篇"><a href="#战略篇" class="headerlink" title="战略篇"></a>战略篇</h2><h3 id="战略工具"><a href="#战略工具" class="headerlink" title="战略工具"></a>战略工具</h3><p>196.麦肯锡·MECE法<br>197.波特·五力模型<br>198.波士顿矩阵<br>199.金字塔原理<br>200.通用电器矩阵    </p>
<h3 id="战略工具-1"><a href="#战略工具-1" class="headerlink" title="战略工具"></a>战略工具</h3><p>201.正态分布理论<br>202.逻辑树/决策树<br>203.平衡计分表<br>204.SWOT模型<br>205.麦肯锡·七步成诗法    </p>
<h3 id="博弈工具"><a href="#博弈工具" class="headerlink" title="博弈工具"></a>博弈工具</h3><p>206.纳什均衡<br>207.囚徒困境<br>208.贝叶斯均衡<br>209.智猪博弈<br>210.公地悲剧     </p>
<h3 id="博弈工具-1"><a href="#博弈工具-1" class="headerlink" title="博弈工具"></a>博弈工具</h3><p>211.你分我拿<br>212.拍卖逻辑<br>213.零和游戏原理<br>214.拍卖美元<br>215.用餐者困境    </p>
<h3 id="决策工具"><a href="#决策工具" class="headerlink" title="决策工具"></a>决策工具</h3><p>216.儒佛尔定律<br>217.吉德林法则<br>218.布利丹效应<br>219.羊群效应<br>220.麦穗哲理     </p>
<h3 id="创新工具"><a href="#创新工具" class="headerlink" title="创新工具"></a>创新工具</h3><p>221.减法创新<br>222.除法创新<br>223.乘法创新<br>224.任务统筹策略<br>225.属性依存策略   </p>
<h3 id="管理工具"><a href="#管理工具" class="headerlink" title="管理工具"></a>管理工具</h3><p>226.OKR<br>227.MBTI人格理论（自我管理）<br>228.SMART原则（目标管理）<br>229.PDCA循环规则（项目管理）<br>230.5W2H法（目标管理）    </p>
<h3 id="思考工具"><a href="#思考工具" class="headerlink" title="思考工具"></a>思考工具</h3><p>231.头脑风暴法<br>232.思考工具：白板<br>233.思维导图<br>234.5WHY分析法<br>235.复盘     </p>
<h3 id="沟通工具"><a href="#沟通工具" class="headerlink" title="沟通工具"></a>沟通工具</h3><p>236.有效的1：1<br>237.罗伯特议事规则<br>238.白板墙、低隔板、下午茶和即时贴<br>239.拉波波特评论规则<br>240.结构沟通法     </p>
<h3 id="财务工具"><a href="#财务工具" class="headerlink" title="财务工具"></a>财务工具</h3><p>241.财务分析中的五力分析法<br>242.零基预算？<br>243.本福特定律<br>244.独立P&amp;L<br>245.计算企业价值     </p>
<h3 id="营销工具"><a href="#营销工具" class="headerlink" title="营销工具"></a>营销工具</h3><p>246.直播营销<br>247.Focus Group<br>248.STP<br>249.4C<br>250.4P   </p>
<h3 id="未来已来"><a href="#未来已来" class="headerlink" title="未来已来"></a>未来已来</h3><p>256.零边际成本社会<br>257.奇点临近<br>258.比特币<br>259.基因科技<br>260.人工智能   </p>
]]></content>
      
        <categories>
            
            <category> 读书 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 五分钟商学院 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MySQL问题系列- MySQL连接数被限制为214个]]></title>
      <url>http://yoursite.com/2016/09/04/MySQL%E9%97%AE%E9%A2%98%E7%B3%BB%E5%88%97-%20MySQL%E8%BF%9E%E6%8E%A5%E6%95%B0%E8%A2%AB%E9%99%90%E5%88%B6%E4%B8%BA214%E4%B8%AA/</url>
      <content type="html"><![CDATA[<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>项目中，由于连接数过多，提示“Too many connections”，需要增加连接数。我在 /etc/my.cnf中修改了</p>
<a id="more"></a>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">max_connections = 2000</div></pre></td></tr></table></figure>
<p>但是， 实际连接数一直被限制在 214<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">mysql&gt; show variables like &quot;max_connections&quot;;</div><div class="line">+-----------------+-------+</div><div class="line">| Variable_name   | Value |</div><div class="line">+-----------------+-------+</div><div class="line">| max_connections | 214   |</div><div class="line">+-----------------+-------+</div><div class="line">1 row in set</div></pre></td></tr></table></figure></p>
<p><code>MySQL max_connections 总是 214</code> 。不能设大了？</p>
<h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><p>CentOS 7.1<br>MySQL 5.6.25</p>
<h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><p>如果我设置连接小于214时，比如 200，那么实际连接数就是 200，也就是说，我的配置文件是没有问题的。</p>
<p>查 MySQL 官方文档，里面说了<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">The maximum number of connections MySQL can support depends on the quality of the thread library on a given platform, the amount of RAM available, how much RAM is used for each connection, the workload from each connection, and the desired response time. Linux or Solaris should be able to support at 500 to 1000 simultaneous connections routinely and as many as 10,000 connections if you have many gigabytes of RAM available and the workload from each is low or the response time target undemanding. Windows is limited to (open tables × 2 + open connections) &lt; 2048 due to the Posix compatibility layer used on that platform.</div><div class="line"></div><div class="line">Increasing open-files-limit may be necessary. Also see Section 2.5, “Installing MySQL on Linux”, for how to raise the operating system limit on how many handles can be used by MySQL.</div></pre></td></tr></table></figure></p>
<p>大概意思是 MySQL 能够支持的最大连接数量受限于操作系统,必要时可以增大 <code>open-files-limit</code>。换言之，连接数与文件打开数有关。</p>
<h3 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h3><p>执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[root@emsc ~]#  ulimit -n</div><div class="line">1024</div></pre></td></tr></table></figure></p>
<p>可知，操作系统最大文件描述符限制为 1024， 在 配置文件中添加<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[root@emsc ~]# vim /etc/security/limits.conf</div><div class="line">open_files_limit = 65535</div></pre></td></tr></table></figure></p>
<p>实际上也没有生效</p>
<p>更改 MySQL 在 Linux 的最大文件描述符限制，编辑 <code>/usr/lib/systemd/system/mysqld.service</code> 文件，在文件最后添加:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[root@emsc ~]# vim /usr/lib/systemd/system/mysqld.service</div><div class="line">LimitNOFILE=65535</div><div class="line">LimitNPROC=65535</div></pre></td></tr></table></figure></p>
<p>保存后，执行下面命令，使配置生效<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ systemctl daemon-reload</div><div class="line">$ systemctl restart  mysqld.service</div></pre></td></tr></table></figure></p>
<p>实际连接数到 2000 了，解决<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">mysql&gt; show variables like &quot;max_connections&quot;;</div><div class="line">+-----------------+-------+</div><div class="line">| Variable_name   | Value |</div><div class="line">+-----------------+-------+</div><div class="line">| max_connections | 2000  |</div><div class="line">+-----------------+-------+</div><div class="line">1 row in set</div></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> Mysql </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[企业必会技能 tomcat(2)]]></title>
      <url>http://yoursite.com/2016/07/22/%E4%BC%81%E4%B8%9A%E5%BF%85%E4%BC%9A%E6%8A%80%E8%83%BD%20tomcat(2)/</url>
      <content type="html"><![CDATA[<h2 id="什么是Tomcat？"><a href="#什么是Tomcat？" class="headerlink" title="什么是Tomcat？"></a>什么是Tomcat？</h2><p>　Tomcat是Apache 软件基金会（Apache Software Foundation）的Jakarta项目中的一个核心项目，由Apache、Sun和其他一些公司及个人共同开发而成。由于有了Sun 的参与和支持，最新的Servlet 和JSP规范总是能在Tomcat 中得到体现，Tomcat 5支持最新的Servlet 2.4 和JSP<br>2.0 规范。因为Tomcat 技术先进、性能稳定，而且免费，因而深受Java爱好者的喜爱并得到了部分软件开发商的认可，成为目前比较流行的Web 应用服务器。 　　<br>　　Tomcat 服务器是一个免费的开放源代码的Web 应用服务器，属于轻量级应用服务器，在中小型系统和并发访问用户不是很多的场合下被普遍使用，是开发和调试JSP 程序的首选。对于一个初学者来说，可以这样认为，当在一台机器上配置好Apache 服务器，可利用它响应HTML（标准通用标记语言下的一个应用）页面的访问请求。实际上Tomcat 部分是Apache 服务器的扩展，但它是独立运行的，所以当你运行tomcat 时，它实际上作为一个与Apache 独立的进程单独运行的。  　<br>　　诀窍是，当配置正确时，Apache 为HTML页面服务，而Tomcat 实际上运行JSP 页面和Servlet。另外，Tomcat和IIS等Web服务器一样，具有处理HTML页面的功能，另外它还是一个Servlet和JSP容器，独立的Servlet容器是Tomcat的默认模式。不过，Tomcat处理静态HTML的能力不如Apache服务器。目前Tomcat最新版本为9.0。</p>
<a id="more"></a>
<p>Apache软件基金会：<a href="http://apache.org/index.html#projects-list" target="_blank" rel="external">http://apache.org/index.html#projects-list</a></p>
<h2 id="Tomcat版本及其区别介绍"><a href="#Tomcat版本及其区别介绍" class="headerlink" title="Tomcat版本及其区别介绍"></a>Tomcat版本及其区别介绍</h2><p><strong>TOMCAT版本的区别主要反映在两个方面：</strong></p>
<ol>
<li>Tomcat本身的技术演进，包括性能的不断提高，功能的增加增强，甚至于重构</li>
<li>因为Tomcat本身是块Servlet容器的试验田，所以他的版本是跟Servlet和JSP的规范一起发展<br><img src="http://static.zybuluo.com/BruceTang/b1cqbsulz64u6z19rudqsr30/image_1bg5a9ggr16ul1f3ijurpfh3vk9.png" alt="image_1bg5a9ggr16ul1f3ijurpfh3vk9.png-66.5kB"></li>
</ol>
<h2 id="Tomcat-安装"><a href="#Tomcat-安装" class="headerlink" title="Tomcat 安装"></a>Tomcat 安装</h2><h3 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h3><pre><code>[root@tang ~]# /etc/init.d/iptables stop
[root@tang ~]#getenforce 0
Disabled
#提示：因为tomcat是主要跑程序的，内存是需要比较大的。如果我们本地测试可以设置低一点
</code></pre><h3 id="安装JDK"><a href="#安装JDK" class="headerlink" title="安装JDK"></a>安装JDK</h3><p>tomcat运行需要JDK支持</p>
<pre><code>下载安装http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html
配置Java环境
# tar zxf jdk-8u91-linux-x64.tar.gz -C /usr/local/
# ln –s /usr/local/jdk1.8.0_91 /usr/local/jdk
# vim /etc/profile
export JAVA_HOME=/usr/local/jdk
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
export PATH=$PATH:$JAVA_HOME/bin
# source /etc/profile
看到如下信息，java环境配置成功
# java -version
java version &quot;1.8.0_91&quot;
Java(TM) SE Runtime Environment (build 1.8.0_91-b14)
Java HotSpot(TM) 64-Bit Server VM (build 25.91-b14, mixed mode)
</code></pre><p>温馨提示： JDK版本最好对应tomcat版本(可能会出现不兼容现学)</p>
<h3 id="安装Tomcat"><a href="#安装Tomcat" class="headerlink" title="安装Tomcat"></a>安装Tomcat</h3><pre><code>[root@tang ~]# wget http://mirrors.hust.edu.cn/apache/tomcat/tomcat-8/v8.5.13/bin/apache-tomcat-8.5.13.tar.gz
[root@tang ~]# tar xf apache-tomcat-8.5.13.tar.gz -C /usr/local/
[root@tang ~]# mv /usr/local/apache-tomcat-8.5.13.tar.gz/ /usr/local/tomcat
启动
[root@tang ~]# /usr/local/tomcat/bin/startup.sh &amp;&amp; tailf /usr/local/tomcat/logs/catalina.out 
#这样启动是为了方便看日志
tomcat启动停止脚本
# 启动startup.sh
# 停止shutdown.sh
</code></pre><p>访问路径：<a href="http://ip:8080" target="_blank" rel="external">http://ip:8080</a> (默认8080端口)<br><img src="http://static.zybuluo.com/BruceTang/lh3h7tje5wo4xdn3iiekg01i/image_1bg5afule1blfrar3p91ltj1qs2m.png" alt="image_1bg5afule1blfrar3p91ltj1qs2m.png-201.9kB"></p>
<h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><p>tomcat配置文件路径<code>/tomcat/bin/server.xml</code></p>
<pre><code># shutdown指定终止Tomcat服务器运行时,发给Tomcat服务器的shutdown监听端口的字符串.该属性必须设置
&lt;Server port=&quot;8005&quot; shutdown=&quot;SHUTDOWN&quot;&gt;
  &lt;Listener className=&quot;org.apache.catalina.startup.VersionLoggerListener&quot; /&gt;
  &lt;!-- Security listener. Documentation at /docs/config/listeners.html
  &lt;Listener className=&quot;org.apache.catalina.security.SecurityListener&quot; /&gt;
  --&gt;
  &lt;!--APR library loader. Documentation at /docs/apr.html --&gt;
  &lt;Listener className=&quot;org.apache.catalina.core.AprLifecycleListener&quot; SSLEngine=&quot;on&quot; /&gt;
  &lt;!-- Prevent memory leaks due to use of particular java/javax APIs--&gt;
  &lt;Listener className=&quot;org.apache.catalina.core.JreMemoryLeakPreventionListener&quot; /&gt;
  &lt;Listener className=&quot;org.apache.catalina.mbeans.GlobalResourcesLifecycleListener&quot; /&gt;
  &lt;Listener className=&quot;org.apache.catalina.core.ThreadLocalLeakPreventionListener&quot; /&gt;
</code></pre><p>service服务配置</p>
<pre><code>&lt;Connector port=&quot;8221&quot; protocol=&quot;HTTP/1.1&quot;      #port 端口配置
           connectionTimeout=&quot;20000&quot;            #connectionTimeout指定超时的时间数(以毫秒为单位)
           maxThreads=&quot;3000&quot;               #tomcat起动的最大线程数，即同时处理的任务个数，默认值为200
           minSpareThreads=&quot;100&quot;　　　　　　　　　#初始化时创建的线程数
           acceptCount=&quot;800&quot;　#指定当所有可以使用的处理请求的线程数都被使用时，
           　　　　　　　　　　　　　　　　　　　　可以放到处理队列中的请求数，超过这个数的请求将不予处理
           　　　　　　　　　　　　　　　　　　　　
           maxKeepAliveRequests=&quot;200&quot;　　#表示该连接最大支持的请求数。超过该请求数的连接也将被关闭（此时就会返回一个Connection: close头给客户端）。
           URIEncoding=&quot;UTF-8&quot;　　　　　#指定字符集
           redirectPort=&quot;8443&quot; /&gt;   #指定服务器正在处理http请求时收到了一个SSL传输请求后重定向的端口号
</code></pre><h2 id="设置Tomcat-内存限制"><a href="#设置Tomcat-内存限制" class="headerlink" title="设置Tomcat 内存限制"></a>设置Tomcat 内存限制</h2><p>优化catalina.sh配置文件。在catalina.sh配置文件中添加以下代码：</p>
<pre><code>JAVA_OPTS=&quot;-Djava.awt.headless=true -Dfile.encoding=UTF-8 -server -Xms1024m -Xmx1024m -XX:NewSize=512m -XX:MaxNewSize=512m -XX:PermSize=512m -XX:MaxPermSize=512m&quot;
server:一定要作为第一个参数，在多个CPU时性能佳
-Xms：初始堆内存Heap大小，使用的最小内存,cpu性能高时此值应设的大一些
-Xmx：初始堆内存heap最大值，使用的最大内存
上面两个值是分配JVM的最小和最大内存，取决于硬件物理内存的大小，建议均设为物理内存的一半。
-XX:PermSize:设定内存的永久保存区域
-XX:MaxPermSize:设定最大内存的永久保存区域
-XX:MaxNewSize:
-Xss 15120 这使得JBoss每增加一个线程（thread)就会立即消耗15M内存，而最佳值应该是128K,默认值好像是512k.
+XX:AggressiveHeap 会使得 Xms没有意义。这个参数让jvm忽略Xmx参数,疯狂地吃完一个G物理内存,再吃尽一个G的swap。
-Xss：每个线程的Stack大小
-verbose:gc 现实垃圾收集信息
-Xloggc:gc.log 指定垃圾收集日志文件
-Xmn：young generation的heap大小，一般设置为Xmx的3、4分之一
-XX:+UseParNewGC ：缩短minor收集的时间
-XX:+UseConcMarkSweepGC ：缩短major收集的时间
</code></pre><p><strong>例子：我公司服务器Tomcat内存设置如下</strong><br>服务器硬件：2核8G<br>tomcat实例：3个tomcat实例</p>
<pre><code>JAVA_OPTS=&quot;-server -Xms2048m -Xmx4096m&quot;
</code></pre><h2 id="Tomcat获取用户IP地址"><a href="#Tomcat获取用户IP地址" class="headerlink" title="Tomcat获取用户IP地址"></a>Tomcat获取用户IP地址</h2><p>在tomcat配置文件<code>/conf/server.xml</code>下配置</p>
<pre><code>&lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot;
       prefix=&quot;localhost_access_log&quot; suffix=&quot;.txt&quot;
       pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt;
</code></pre><h2 id="tomcat启动停止脚本"><a href="#tomcat启动停止脚本" class="headerlink" title="tomcat启动停止脚本"></a>tomcat启动停止脚本</h2><p>考虑到Tomcat启动每次需要手动比较麻烦，我们这有写好的启动脚本</p>
<pre><code>#!/bin/bash
# chkconfig: 2345 74 44
# description: Tomcat is a Java Servlet Container
. /etc/profile
TOMCAT_HOME=/usr/local/tomcat
start () {
TOMCAT_PID=`ps -ef |grep &quot;$TOMCAT_HOME&quot; |grep -v &quot;grep&quot; |awk &apos;{print $2}&apos;`
if [ -z $TOMCAT_PID ];then
    /bin/bash $TOMCAT_HOME/bin/startup.sh
else
    echo &quot;$0 is  running&quot;
fi
}
stop () {
TOMCAT_PID=`ps -ef |grep &quot;$TOMCAT_HOME&quot; |grep -v &quot;grep&quot; |awk &apos;{print $2}&apos;`
if [ -z $TOMCAT_PID ];then
        echo &quot;$0 is not running&quot;
else
        echo &quot;shutting down $0&quot;
        kill -9 &quot;$TOMCAT_PID&quot; &amp;&amp; echo &quot;PID $TOMCAT_PID killed.&quot;
fi
}
status () {
TOMCAT_PID=`ps -ef |grep &quot;$TOMCAT_HOME&quot; |grep -v &quot;grep&quot; |awk &apos;{print $2}&apos;`
if [ -z $TOMCAT_PID ];then
        echo &quot;$0 is not running&quot;
else
        echo &quot;$0 is running PID is $TOMCAT_PID&quot;
fi
}
case $1 in
start)
start
#tail -f $TOMCAT_HOME/logs/catalina.out
;;
stop)
stop
;;
status)
status
;;
restart)
stop
start
#tail -f $TOMCAT_HOME/logs/catalina.out
;;
*)
echo &quot;Usage:$0  {start|stop|status|restart}.&quot;
;;
esac
</code></pre><p><strong>提示：</strong> 本脚本不提供log，还需要在脚本后面加上&amp;&amp; tailf logs/catalina.out</p>
]]></content>
      
        <categories>
            
            <category> Tomcat </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Tomcat </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[postgresql（3）--常用命令]]></title>
      <url>http://yoursite.com/2016/07/21/postgresql%EF%BC%883%EF%BC%89--%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
      <content type="html"><![CDATA[<a id="more"></a>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line">创建数据库</div><div class="line">CREATE DATABASE test WITH OWNER = postgres ENCODING = &apos;UTF8&apos;;</div><div class="line"></div><div class="line">进入控制台方法，在postgreSQL的安装目的bin下执行命令： psql 数据库名，</div><div class="line"> 例： /usr/local/pgsql/bin/psql mydb</div><div class="line">指定host、用户名和数据库的话，如：</div><div class="line">/usr/local/pgsql/bin/psql -h localhost -U postgres -d test</div><div class="line"></div><div class="line">查看版本： psql --version 或 SELECT version();</div><div class="line"></div><div class="line">查看所有数据库：\l</div><div class="line"></div><div class="line">查看所有数据库（包括详细参数）：select * from pg_database;</div><div class="line"></div><div class="line">选择数据库：\c databasename</div><div class="line"></div><div class="line">查看所有表：\dt</div><div class="line"></div><div class="line">查看某个表的结构：\d tablename</div><div class="line"></div><div class="line">退出psql控制台：\q</div><div class="line"></div><div class="line">查看表的索引：</div><div class="line">select * from pg_indexes where tablename=&apos;log&apos;;</div><div class="line"></div><div class="line">导出备份数据库：</div><div class="line">pg_dump -h localhost -U postgres databasename &gt; /tmp/databasename.bak.yyyymmdd.sql</div><div class="line"></div><div class="line">导入恢复数据库(sql文件是pg_dump导出的文件就行，可以是整个数据库，也可以只是单个表，也可以只是结构等)：</div><div class="line">psql -h localhost -U postgres -d databasename &lt; /tmp/databasename.bak.yyyymmdd.sql</div><div class="line"></div><div class="line">导出数据结构，主要是加上参数-s：</div><div class="line">pg_dump -U username -W dbname -f /tmp/filename.sql</div><div class="line">导出某个表：</div><div class="line">pg_dump -h localhost -U postgres -t tablename dbname &gt; test.sql</div><div class="line"></div><div class="line">导出某个表的结构，同样是加参数&quot;-s&quot;：</div><div class="line">pg_dump -h localhost -U postgres -t tablename -s dbname &gt; test_construct.sql</div><div class="line"></div><div class="line">导出某个表的数据，加参数&quot;-a&quot;：</div><div class="line">pg_dump -h localhost -U postgres -t tablename -a dbname &gt; test_data.sql</div><div class="line"></div><div class="line">查看序列：select * from information_schema.sequences where sequence_schema = &apos;public&apos;;</div><div class="line"></div><div class="line">查看数据库大小：select pg_size_pretty(pg_database_size(&apos;test&apos;));</div><div class="line"></div><div class="line">查看表的大小：select pg_size_pretty(pg_relation_size(&apos;test&apos;));</div></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> Postgresql </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Postgresql </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[postgresql（2）--安装方式]]></title>
      <url>http://yoursite.com/2016/07/21/postgresql%EF%BC%882%EF%BC%89--%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F/</url>
      <content type="html"><![CDATA[<h3 id="RPM安装方式"><a href="#RPM安装方式" class="headerlink" title="RPM安装方式"></a>RPM安装方式</h3><h4 id="rpm安装包"><a href="#rpm安装包" class="headerlink" title="rpm安装包"></a>rpm安装包</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">postgresql94-9.4.8-1PGDG.rhel6.x86_64.rpm</div><div class="line">postgresql94-contrib-9.4.8-1PGDG.rhel6.x86_64.rpm</div><div class="line">postgresql94-devel-9.4.8-1PGDG.rhel6.x86_64.rpm</div><div class="line">postgresql94-libs-9.4.8-1PGDG.rhel6.x86_64.rpm</div><div class="line">postgresql94-server-9.4.8-1PGDG.rhel6.x86_64.rpm</div><div class="line"></div><div class="line">cat psql_install.sh                                             #安装脚本</div><div class="line">rpm -ivh libxslt1-1.1.28-66.1.x86_64.rpm                        #依赖包</div><div class="line">rpm -ivh --force postgresql94-*</div><div class="line">service postgresql-9.4 initdb                                   #初始化</div><div class="line">sed -i &quot;s/peer/trust/g&quot; /var/lib/pgsql/9.4/data/pg_hba.conf     #允许远程连接</div><div class="line">sed -i &quot;s/ident/trust/g&quot; /var/lib/pgsql/9.4/data/pg_hba.conf</div><div class="line">service postgresql-9.4 start</div></pre></td></tr></table></figure>
<a id="more"></a>
<h3 id="源码安装方式"><a href="#源码安装方式" class="headerlink" title="源码安装方式"></a>源码安装方式</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">cd /usr/src/ </div><div class="line">wget http://ftp.postgresql.org/pub/source/v9.4.8/postgresql-9.4.8.tar.gz</div><div class="line">tar -zxvf postgresql-9.4.8.tar.gz</div><div class="line">cd postgresql-9.1.4 </div><div class="line"></div><div class="line">./configure </div><div class="line">make </div><div class="line">make install </div><div class="line">mkdir /usr/local/pgsql/data </div><div class="line">chown postgres /usr/local/pgsql/data </div><div class="line">su – postgres </div><div class="line">/usr/local/pgsql/bin/initdb -D /usr/local/pgsql/data</div></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> Postgresql </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Postgresql </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Tomcat相关知识整理（1）]]></title>
      <url>http://yoursite.com/2016/07/20/Tomcat%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86%EF%BC%881%EF%BC%89/</url>
      <content type="html"><![CDATA[<h3 id="初识Servlet"><a href="#初识Servlet" class="headerlink" title="初识Servlet"></a>初识Servlet</h3><p>SUN公司制定了一系列Web应用与Web服务器进行协作的标准Java接口，统称为Java Servlet API，还对Web服务器发布及运行Web应用的一些细节做了规约。SUN公司把这一系列标准Java接口和规约统称为Servlet规范。Servlet就是Web服务器与Web应用进行协作的标准接口。</p>
<p>Servlet规范把能够发布和运行JavaWeb应用的Web服务器称为Servlet容器，它的最主要的特征就是动态执行JavaWeb应用中的Servlet实现类中的程序代码。</p>
<p>Servlet是一种运行在服务器上的小插件，其最常见的用途是扩展Web服务器的功能，可作为非常安全的、可移植的、易于使用的CGI替代品。具有以下特点：</p>
<p>提供了可被服务器动态加载并执行的程序代码，为来自客户端的请求提供相应的服务；</p>
<p>Servlet完全用Java语言编写，因此要求运行Servlet的服务器必须支持Java语言；</p>
<p>Servlet完全在服务器端运行，因此它的运行不依赖于浏览器。不管浏览器是否支持Java语言，都能请求访问服务器端的Servlet。</p>
<a id="more"></a>
<h3 id="Tomcat"><a href="#Tomcat" class="headerlink" title="Tomcat"></a>Tomcat</h3><pre><code>Tomcat作为运行Servlet的容器，其基本功能是负责接收和解析来自客户端的请求，同时把客户端的请求传送给相应的Servlet，并把Servlet的响应结果返回给客户端。
</code></pre><h4 id="Tomcat组件"><a href="#Tomcat组件" class="headerlink" title="Tomcat组件"></a>Tomcat组件</h4><p><strong>Tomcat组件分为4类：</strong></p>
<pre><code>1.顶层类元素：包括&lt;Server&gt;元素和&lt;Service&gt;元素，它们位于整个配置文件的顶层；

2.连接器类元素：为&lt;Connector&gt;元素，代表介于客户端与服务器端之间的通信接口，负责将客户端的请求发送给服务器端，并将服务器的响应结果返回给客户端；

3.容器类元素：代表处理客户端请求并生成响应结果的组件，共有四类，分别为&lt;Engine&gt;、&lt;Host&gt;、&lt;Context&gt;和&lt;Cluster&gt;元素。Engine组件为特定的Service组件处理所有客户端请求，Host组件为特定的虚拟主机处理所有的客户端请求，Context组件为特定的Web应用处理所有的客户端请求。
Cluster组件负责为Tomcat集群系统进行会话复制、Context组件的属性的复制，以及集群范围内WAR文件的发布。

4.嵌套类元素：代表可以被嵌入到容器中的组件，如&lt;Valve&gt;元素和&lt;Realm&gt;元素等。

#### Tomcat元素
&lt;Server&gt;元素：代表整个Servlet容器组件，是Tomcat的顶级元素。在&lt;Server&gt;元素中可包含一个或多个&lt;Service&gt;元素；

&lt;Service&gt;元素：包含一个&lt;Engine&gt;元素，以及一个或多个&lt;Connector&gt;元素，这些&lt;Connector&gt;元素共享同一个&lt;Engine&gt;元素；

&lt;Connector&gt;元素：代表和客户端实际交互的组件，负责接收客户端请求，以及向客户端返回响应结果；

&lt;Engine&gt;元素：每个&lt;Service&gt;元素只能包含一个&lt;Engine&gt;元素。&lt;Engine&gt;元素处理在同一个&lt;Service&gt;中所有&lt;Connector&gt;元素接收到的客户端请求；

&lt;Host&gt;元素：在一个&lt;Engine&gt;元素中可以包含多个&lt;Host&gt;元素。每个&lt;Host&gt;元素定义了一个虚拟主机，它可以包含一个或多个Web应用；

&lt;Context&gt;元素：每个&lt;Context&gt;元素代表了运行在虚拟主机上的单个Web应用。在一个&lt;Host&gt;元素中可以包含多个&lt;Context&gt;元素。
</code></pre><h4 id="Tomcat的工作模式"><a href="#Tomcat的工作模式" class="headerlink" title="Tomcat的工作模式"></a>Tomcat的工作模式</h4><h5 id="独立的Servlet容器"><a href="#独立的Servlet容器" class="headerlink" title="独立的Servlet容器"></a>独立的Servlet容器</h5><p>Tomcat作为独立的web服务器来单独运行，Servlet容器组件作为web服务器中的一部分存在，这是Tomcat的默认工作模式。 在这种模式下，Tomcat是一个独立进行的Java程序。和运行其他Java程序一样，运行Tomcat需要启动一个Java虚拟机进程，由该进程来运行Tomcat。<br><img src="http://static.zybuluo.com/BruceTang/lg138tny62x2rnd5dry8upfs/image_1bfm7br8h1nbq1jad1i3h11bm6i79.png" alt="image_1bfm7br8h1nbq1jad1i3h11bm6i79.png-15.6kB"></p>
<h5 id="其他web服务器进程内的Servlet容器"><a href="#其他web服务器进程内的Servlet容器" class="headerlink" title="其他web服务器进程内的Servlet容器"></a>其他web服务器进程内的Servlet容器</h5><p>在这种模式下，Tomcat分为web服务器插件和Servlet容器插件两部分。web服务器插件在其他web服务器进程的内部地址空间启动一个JVM，Servlet在此JVM中运行。如有客户端发出调用Servlet的请求，web服务器插件获得对此请求的控制并将它转发(JNI通信机制)给Servlet容器组件。<br><img src="http://static.zybuluo.com/BruceTang/kiw621autpc9px2fyp2luu8m/image_1bfm7cdrkm8q18hc5ep1per1sk9m.png" alt="image_1bfm7cdrkm8q18hc5ep1per1sk9m.png-28.4kB"></p>
<h5 id="其他web服务器进程外的Servlet容器"><a href="#其他web服务器进程外的Servlet容器" class="headerlink" title="其他web服务器进程外的Servlet容器"></a>其他web服务器进程外的Servlet容器</h5><p>在这种模式下，Tomcat分为web服务器插件和Servlet容器组件两部分。web服务器插件在其他web服务器的外部地址空间启动一个JVM进程，Servlet容器组件再次JVM中运行。如有客户端发出调用Servlet的请求，web服务器插件获得对此请求的控制并将它转发(IPC通信机制)给Servlet容器组件。</p>
<p>当Tomcat作为独立的Servlet容器来运行时，可看做是能运行Java Servlet的独立web服务器。此外，Tomcat还可作为其他web服务器进程内或进程外的Servlet容器，从而与其他web服务器集成，集成的意义在于：对于不支持运行Java Servlet的其web服务器，可通过集成Tomcat来提供运行Servlet的功能。<br><img src="http://static.zybuluo.com/BruceTang/kqmhyt4qz1o9g612e9kc8jqa/image_1bfm7cspmd441ob91pft119680813.png" alt="image_1bfm7cspmd441ob91pft119680813.png-26.6kB"></p>
<h3 id="Tomcat的目录结构"><a href="#Tomcat的目录结构" class="headerlink" title="Tomcat的目录结构"></a>Tomcat的目录结构</h3><p><code>bin</code>：存放启动和关闭Tomcat的脚本文件及所用到的类；</p>
<p><code>conf</code>：存放Tomcat的各种配置文件，其中最重要的配置文件是server.xml；</p>
<p><code>logs</code>：存放Tomcat的日志文件；</p>
<p><code>lib</code>：存放Tomcat服务器及所有Web应用都可以访问的jar文件；</p>
<p><code>webapps</code>：Web应用的默认部署目录；</p>
<p><code>work</code>：Tomcat的工作目录，Tomcat在运行时把生成的一些工作文件放于此目录下。在默认情况下，Tomcat把编译JSP而生成的Servlet类文件放于此目录下；</p>
<p><code>tmp</code>：临时文件目录。</p>
<p><strong>NOTE:</strong></p>
<p>Tomcat的lib子目录：存放的jar文件不仅能被Tomcat访问，还能被所有在Tomcat中发布的JavaWeb应用访问；</p>
<p>JavaWeb应用的lib子目录：存放的jar文件只能被当前JavaWeb应用访问。</p>
<p><strong>NOTE：</strong></p>
<p>Tomcat在加载Web应用时，会把相应的web.xml文件中的数据读入到内存中。</p>
<p>Context元素</p>
<h4 id="主要属性"><a href="#主要属性" class="headerlink" title="主要属性"></a>主要属性</h4><p><code>path</code>：指定访问该Web应用的URL入口，什么都不写表示根路径；</p>
<p><code>docBase</code>：指定Web应用的文件路径，可以给定绝对路径，也可以给定相对于<host>的appBase属性的相对路径。如果Web应用采用开放目录结构，则指定Web应用的根路径；如果Web应用是个war文件，则是定war文件的路径；</host></p>
<p><code>className</code>：指定实现Context组件的Java类的名字，这个类必须实现org.apache.catalina.Context接口；</p>
<p><code>reloadable</code>：如果这个属性设为true，Tomcat服务器在运行状态下会监视在WEB-INF/classes和WEB-INF/lib目录下的class文件的改动，以监视Web应用的WEB-INF/web.xml文件的改动。如果检测到有class文件或web.xml文件被更新，服务器会自动重新加载Web应用。</p>
<h4 id="专有属性"><a href="#专有属性" class="headerlink" title="专有属性"></a>专有属性</h4><p><code>cachingAllowed</code>：如果为true，表示允许启用静态资源的缓存，默认值为true；</p>
<p><code>cacheMaxSize</code>：设定静态资源缓存的最大容量，默认为10m；</p>
<p><code>workDir</code>：指定Web应用的工作目录，Tomcat在运行时会把与这个web应用相关的临时文件放在这个目录下；</p>
<p><code>uppackWar</code>：如果设为true，表示将把Web应用的WAR文件展开为开放目录结构后再运行。如果设为false，则直接运行war文件。默认为true。</p>
<h4 id="Host元素"><a href="#Host元素" class="headerlink" title="Host元素"></a>Host元素</h4><h5 id="主要属性-1"><a href="#主要属性-1" class="headerlink" title="主要属性"></a>主要属性</h5><p><code>name</code>：指定虚拟主机的名字</p>
<p><code>className</code>：指定实现虚拟主机的Java类的名字，这个Java类必须实现org.apache.catalina.Host接口；</p>
<p><code>appBase</code>：指定虚拟主机的目录，可以指定绝对目录，也可以指定相对于<catalina_home>的相对路径；</catalina_home></p>
<p><code>autoDeploy</code>：如果设定为true，表示当Tomcat服务器处于运行状态时，能够检测appBase下的文件，如果有新的Web应用加进来，则会自动发布这个Web应用；</p>
<p><code>deployOnStart</code>：如果此项设置为true，则表示当Tomcat启动时会自动发布appBase目录下的所有Web应用。如果web应用没有相应的context元素，那么Tomcat会提供一个默认的context组件。默认值为true。</p>
<h5 id="专有属性-1"><a href="#专有属性-1" class="headerlink" title="专有属性"></a>专有属性</h5><p><code>unpackWARS</code>：如果设置为true，表示将把appBase属性指定的目录下的web应用的war文件先展开为开放的目录结构后再运行，如果设置为false，则直接运行war文件；</p>
<p><code>workDir</code>：指定虚拟主机的工作目录，Tomcat在运行时会把与这个虚拟主机的所有web应用相关的临时文件放在此目录下，默认值为<code>&lt;CATALINA_HOME&gt;/work</code>。如果<code>&lt;Host&gt;</code>元素下的一个<code>&lt;Context&gt;</code>元素也设置了workDIR属性，那么<code>&lt;Context&gt;</code>的workDir属性会覆盖<code>&lt;Host&gt;</code>元素的workDir属性；</p>
<p><code>deployXML</code>：如果设置为false，那么Tomcat不会解析web应用中的用于设置context元素的META-INF/context.xml文件。默认值为true。</p>
<h3 id="JavaWeb"><a href="#JavaWeb" class="headerlink" title="JavaWeb"></a>JavaWeb</h3><p>SUN的Servlet规范对JavaWeb应用的定义：JavaWeb应用由一组Servlet/JSP、HTML文件、相关Java类，以及其他可以绑定的资源构成，它可以在由各种供应商提供的符合Servlet规范的Servlet容器中运行。</p>
<p><strong>JavaWeb应用包含的内容：</strong></p>
<p><code>Srvlet组件</code>：标准Servlet接口的实现类，运行在服务器端，包含了被Servlet容器动态调用的程序代码。</p>
<p><code>JSP组件</code>：包含Java程序代码的HTML文档，运行在服务器端。当客户端请求JSP文件时，Servlet容器先把它翻译成Servlet类，然后动态调用它的程序代码。</p>
<p>相关的Java类：开发人员自定义的与Web应用相关的Java类。</p>
<p>静态文档：存放在存放在服务器端的文件系统中，如HTML文件、图片文件等。当客户端请求访问这些文件时，Servlet容器先从本地文件系统中读取这些文件的数据，再把它发送到客户端。</p>
<p><code>web.xml文件</code>：JavaWeb应用的配置文件，采用XML格式。该文件必须位于Web应用的WEB-INF目录下。</p>
<p>Servlet规范规定：JavaWeb应用必须采用固定的目录结构，即每种类型的组件在web应用中都有固定的存放目录。</p>
<p><strong>JavaWeb应用的目录结构，以helloapp为例</strong>   </p>
<p><code>/helloapp</code>：此Web应用的根目录，所有的JSP和HTML文件都存放于此目录或用户自定义的子目录下(WEB-INF子目录除外)；</p>
<p><code>/helloapp/WEB-INF</code>：存放此Web应用的配置文件web.xml；</p>
<p><code>/helloapp/WEB-INF/classes</code>：存放各种.class文件，Servlet类的.class文件也存放于此目录下；</p>
<p><code>/helloapp/WEB-INF/lib</code>：存放此Web应用所需的各种jar文件；</p>
<p><code>/helloapp/META-INF</code>：当前Webapp的私有资源目录，通常存放自用的context.xml；</p>
<p><code>/helloapp/classes</code>：此Webapp的私有类；</p>
<p><code>/helloapp/lib</code>：此Webapp的私有类，被打包为jar格式；</p>
<p><code>/helloapp/index.jsp</code>：此Webapp的主页。</p>
<p>NOTE：在WEB-INF目录的classes及lib子目录下都可以存放类文件。在运行时，Servlet容器的类加载器先加载classes目录下的类，再加载lib目录下的jar文件中的类。</p>
<h3 id="Tomcat阀-Valve"><a href="#Tomcat阀-Valve" class="headerlink" title="Tomcat阀(Valve)"></a>Tomcat阀(Valve)</h3><p>Tomcat阀能够对Catalina容器接收到的http请求进行预处理。Tomcat阀可以可以加入到3种Catalina容器中，它们是Engine、Host和Context。</p>
<p><strong>Tomcat阀主要包括以下几种：</strong></p>
<pre><code>客户访问日志阀(Access Log Valve)

远程地址过滤器(Remote Address Filter)

远程主机过滤器(Remote Host Filter)

客户请求记录器(Request Dumper)
</code></pre><h4 id="客户访问日志阀"><a href="#客户访问日志阀" class="headerlink" title="客户访问日志阀"></a>客户访问日志阀</h4><p>能够将客户端的请求信息写到日志文件中，这些日志文件可以记录网页的访问次数、访问时间、用户的会话活动和用户的安全验证信息等。客户访问日志阀可以加入到Engine、Host或Context容器。</p>
<p>属性：</p>
<p><code>className</code>：指定阀的实现类，此处为org.apache.catalina.valves.AccessLogValve；</p>
<p><code>directory</code>：设定存放日志文件的绝对或相对于<code>&lt;CATALINA_HOME</code>&gt;的目录，默认为<code>&lt;CATALINA_HOME&gt;/logs</code>；</p>
<p><code>pattern</code>：设定日志的格式和内容；</p>
<p><code>prefix</code>：设定日志文件名前缀，默认为access_log；</p>
<p><code>resolveHosts</code>：如果设为true，表示把远程IP地址解析为主机名；如果设为false，表示直接记录远程IP地址，默认为false；</p>
<p><code>suffix</code>：设定日志文件的扩展名，默认为””；</p>
<p><strong>pattern属性的可选值：</strong></p>
<pre><code>%a：远程IP地址；
%A：本地IP地址；
%b：发送的字节数，不包括HTTP头部，符号“-”表示发送字节为零；
%B：发送的字节数，不包括HTTP头部；
%h：远程主机名；
%H：客户端请求所用的协议；
%l：远程逻辑用户名(目前总是返回符号“-”)；
%m：客户端的请方式；
%p：接收到客户端请求的本地服务器端口；
%q：客户端请求中的查询字符串(Query String)，即HTTP请求的第一行的URI部分的“?”后面的内容；
%r：客户端请求的第一行内容(包括请求方式、请求URI及HTTP协议版本)；
%s：服务器响应结果中的HTTP状态代码；
%S：用户的额Session ID；
%t：时间和日期；
%u：通过安全认证的远程用户名，符号“-”表示不存在远程用户名；
%U：客户端请求的URL路径；
%v：本地服务器名；
</code></pre><h4 id="远程地址过滤器"><a href="#远程地址过滤器" class="headerlink" title="远程地址过滤器"></a>远程地址过滤器</h4><p>可以根据远程客户端的IP地址来决定是否接受客户端的请求。在远程地址过滤器中，事先保存了一份被拒绝的IP地址清单和允许访问的IP地址清单。</p>
<p>属性</p>
<p><code>className</code>：指定阀实现类，此处为<code>org.apache.catalina.valves.AccessLogValve</code>；</p>
<p><code>allow</code>：指定允许访问的客户端IP地址，如果没有设定，则表示只要客户端IP地址不在deny清单中，就允许访问，多个IP地址用逗号隔开；</p>
<p><code>deny</code>：指定不允许访问的IP地址；</p>
<h4 id="远程主机过滤器"><a href="#远程主机过滤器" class="headerlink" title="远程主机过滤器"></a>远程主机过滤器</h4><p>与远程地址多滤器基本上相同，只是一个是基于ip，一个是基于主机名。</p>
<h4 id="客户请求记录器"><a href="#客户请求记录器" class="headerlink" title="客户请求记录器"></a>客户请求记录器</h4><p>用于把客户端请求的详细信息记录到日志文件，是一个有效的跟踪工具，尤其是当HTTP请求中的Header或Cookie有错误时，它可以跟踪客户请求的详细信息。</p>
]]></content>
      
        <categories>
            
            <category> Tomcat </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Tomcat </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Mysql 启动慢查询日志]]></title>
      <url>http://yoursite.com/2016/04/05/Mysql%20%E5%90%AF%E5%8A%A8%E6%85%A2%E6%9F%A5%E8%AF%A2%E6%97%A5%E5%BF%97/</url>
      <content type="html"><![CDATA[<h3 id="查看mysql系统参数"><a href="#查看mysql系统参数" class="headerlink" title="查看mysql系统参数"></a>查看mysql系统参数</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">mysql&gt; show variables like &quot;%slow%&quot;;</div><div class="line">+---------------------------+-------------------------------+</div><div class="line">| Variable_name             | Value                         |</div><div class="line">+---------------------------+-------------------------------+</div><div class="line">| log_slow_admin_statements | OFF                           |</div><div class="line">| log_slow_slave_statements | OFF                           |</div><div class="line">| slow_launch_time          | 2                             |</div><div class="line">| slow_query_log            | OFF                           |</div><div class="line">| slow_query_log_file       | /mysql/data/nagiosdb-slow.log |</div><div class="line">+---------------------------+-------------------------------+</div><div class="line">5 rows in set (0.00 sec)</div><div class="line"></div><div class="line"></div><div class="line">slow_query_log： off关闭状态  on开启状态</div><div class="line">slow_launch_time   默认超过2s为慢查询</div><div class="line">slow_query_log_file  慢查询日志存放地点</div><div class="line"></div><div class="line"></div><div class="line">这三个参数，在不同的mysql版本中，不太一样，不过都可以通过 show variables like &quot;%slow%&quot; 查看出来</div></pre></td></tr></table></figure>
<a id="more"></a>
<h3 id="运行如下命令即可运行慢查询日志"><a href="#运行如下命令即可运行慢查询日志" class="headerlink" title="运行如下命令即可运行慢查询日志"></a>运行如下命令即可运行慢查询日志</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">mysql&gt; set global slow_query_log=ON;</div><div class="line">Query OK, 0 rows affected (0.03 sec)</div><div class="line"></div><div class="line">mysql&gt; set global slow_launch_time=5;</div><div class="line">Query OK, 0 rows affected (0.00 sec)</div><div class="line"></div><div class="line">mysql&gt; show variables like &quot;%slow%&quot;;</div><div class="line">+---------------------------+-------------------------------+</div><div class="line">| Variable_name             | Value                         |</div><div class="line">+---------------------------+-------------------------------+</div><div class="line">| log_slow_admin_statements | OFF                           |</div><div class="line">| log_slow_slave_statements | OFF                           |</div><div class="line">| slow_launch_time          | 5                             |</div><div class="line">| slow_query_log            | ON                            |</div><div class="line">| slow_query_log_file       | /mysql/data/nagiosdb-slow.log |</div><div class="line">+---------------------------+-------------------------------+</div><div class="line">5 rows in set (0.00 sec)</div><div class="line"></div><div class="line"></div><div class="line">mysql 5.1.6版本起，slow_query_log 和 slow_launch_time 支持写文件或写数据库表两种方式，并且日志的开启，输出方式的修改，都可以在global级别动态修改。</div><div class="line">只需简单通过set global slow_query_log=ON;即可开启慢查询，而不需要重启数据库！</div></pre></td></tr></table></figure>
<h3 id="可以直接写到配置文件中-my-cnf"><a href="#可以直接写到配置文件中-my-cnf" class="headerlink" title="可以直接写到配置文件中 my.cnf"></a>可以直接写到配置文件中 my.cnf</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">slow_query_log_file=/mysql/log/nagiosdb-slow.log</div><div class="line">slow_launch_time=5</div><div class="line"></div><div class="line">可以完成配置！！</div></pre></td></tr></table></figure>]]></content>
      
        <categories>
            
            <category> Mysql </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Mysql优化系列--总结梳理]]></title>
      <url>http://yoursite.com/2016/03/12/Mysql%E4%BC%98%E5%8C%96%E7%B3%BB%E5%88%97--%E6%80%BB%E7%BB%93%E6%A2%B3%E7%90%86/</url>
      <content type="html"><![CDATA[<p>对于一个网站来说，在运行很长一段时间后，数据库瓶颈问题会越来越暴露出来。作为运维人员，对数据库做必要的优化十分重要！<br>    下面总结以往查阅到的以及自己工作中的一些优化操作经验，并根据OSI七层模型从下往上进行优化mysql数据库记录。<br><a id="more"></a></p>
<h3 id="物理层面"><a href="#物理层面" class="headerlink" title="物理层面"></a>物理层面</h3><pre><code>1、cpu:2-16个 2*4双四核，L1L2越大越好
2、内存:越大越好
3、磁盘:SAS或者固态 300G*12磁盘越多IO越高
raid 0&gt;10&gt;5&gt;1
4、网卡:千兆
5、slave的配置最好大于等于master
</code></pre><h3 id="系统配置"><a href="#系统配置" class="headerlink" title="系统配置"></a>系统配置</h3><pre><code>如下，配置系统内核参数/etc/sysctl.conf（配置后，使用sysctl -p使之生效）
net.ipv4.tcp_fin_timeout = 2
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_tw_recycle = 1
net.ipv4.tcp_syncookies = 1
net.ipv4.tcp_keepalive_time =600
net.ipv4.ip_local_port_range = 4000 65000
net.ipv4.tcp_max_syn_backlog = 16384
net.ipv4.tcp_max_tw_buckets = 36000
net.ipv4.route.gc_timeout = 100
net.ipv4.tcp_syn_retries = 1
net.ipv4.tcp_synack_retries = 1
net.core.somaxconn = 16384
net.core.netdev_max_backlog = 16384
net.ipv4.tcp_max_orphans = 16384

vm.swappiness=0      //尽量不使用swap
vm.dirty_backgroud_ratio 5-10 
vm.dirty_ratio          //上面的值的两倍 将操作系统的脏数据刷到磁
</code></pre><h3 id="mysql的安装"><a href="#mysql的安装" class="headerlink" title="mysql的安装"></a>mysql的安装</h3><p>MySQL数据库的线上环境安装，建议采取编译安装的方式，这样性能会有较大的提升。服务器系统则建议CentOS6.7 X86_64，源码包的编译参数会默认以Debug模式生成二进制代码，而Debug模式给MySQL带来的性能损失是比较大的，所以当我们编译准备安装的产品代码时，一定不要忘记使用–without-debug参数禁止Debug模式。如果把–with-mysqld-ldflags和–with-client-ld-flags两个编译参数设置为–all-static的话，可以告诉编译器以静态的方式编译，编译结果将得到最高的性能。使用静态编译和使用动态编译的代码相比，性能差距可能会达到5%至10%之多。在后面我会跟大家分享我们线上MySQL数据库的编译参数，大家可以参考下，然后根据自己的线上环境自行修改内容。</p>
<blockquote>
<p>下面是对mysql服务配置文件my.cnf的详解：</p>
</blockquote>
<pre><code>[client]
port = 3306
# 客户端端口号为3306
socket = /data/3306/mysql.sock
default-character-set = utf8
# 客户端字符集,(控制character_set_client、character_set_connection、character_set_results)
[mysql]
no-auto-rehash 
# 仅仅允许使用键值的updates和deletes
[mysqld] 
# 组包括了mysqld服务启动的参数，它涉及的方面很多，其中有MySQL的目录和文件，通信、网络、信息安全，内存管理、优化、查询缓存区，还有MySQL日志设置等。
user = mysql
# mysql_safe脚本使用MySQL运行用户(编译时--user=mysql指定),推荐使用mysql用户。
port = 3306
# MySQL服务运行时的端口号。建议更改默认端口,默认容易遭受攻击。
socket = /data/3306/mysql.sock 
# socket文件是在Linux/Unix环境下特有的，用户在Linux/Unix环境下客户端连接可以不通过TCP/IP网络而直接使用unix socket连接MySQL。
basedir = /application/mysql 
# mysql程序所存放路径,常用于存放mysql启动、配置文件、日志等
datadir = /data/3306/data 
# MySQL数据存放文件(极其重要)
character-set-server = utf8 
# 数据库和数据库表的默认字符集。(推荐utf8,以免导致乱码)
log-error=/data/3306/mysql.err
# mysql错误日志存放路径及名称(启动出现错误一定要看错误日志,百分之百都能通过错误日志排插解决。)
pid-file=/data/3306/mysql.pid 
# MySQL_pid文件记录的是当前mysqld进程的pid，pid亦即ProcessID。
skip-locking
# 避免MySQL的外部锁定，减少出错几率，增强稳定性。
skip-name-resolv
# 禁止MySQL对外部连接进行DNS解析，使用这一选项可以消除MySQL进行DNS解析的时候。但是需要注意的是，如果开启该选项，则所有远程主机连接授权都要使用IP地址方式了，否则MySQL将无法正常处理连接请求！
skip-networking 
# 开启该选项可以彻底关闭MySQL的TCP/IP连接方式，如果Web服务器是以远程连接的方式访问MySQL数据库服务器的，则不要开启该选项，否则无法正常连接！
open_files_limit = 1024
# MySQLd能打开文件的最大个数,如果出现too mant open files之类的就需要调整该值了。
back_log = 384 
# back_log参数是值指出在MySQL暂时停止响应新请求之前，短时间内的多少个请求可以被存在堆栈中。如果系统在短时间内有很多连接，则需要增加该参数的值，该参数值指定到来的TCP/IP连接的监听队列的大小。不同的操作系统在这个队列的大小上有自己的限制。如果试图将back_log设置得高于操作系统的限制将是无效的，其默认值为50.对于Linux系统而言，推荐设置为小于512的整数。
max_connections = 800
# 指定MySQL允许的最大连接进程数。如果在访问博客时经常出现 Too Many Connections的错误提示，则需要增大该参数值。
max_connect_errors = 6000 
# 设置每个主机的连接请求异常中断的最大次数，当超过该次数，MySQL服务器将禁止host的连接请求，直到MySQL服务器重启或通过flush hosts命令清空此host的相关信息。
wait_timeout = 120 
# 指定一个请求的最大连接时间，对于4GB左右内存的服务器来说，可以将其设置为5~10。
table_cache = 614K 
# table_cache指示表高速缓冲区的大小。当MySQL访问一个表时，如果在MySQL缓冲区还有空间，那么这个表就被打开并放入表缓冲区，这样做的好处是可以更快速地访问表中的内容。一般来说，可以查看数据库运行峰值时间的状态值Open_tables和Open_tables，用以判断是否需要增加table_cache的值，即如果Open_tables接近table_cache的时候，并且Opened_tables这个值在逐步增加，那就要考虑增加这个值的大小了。
external-locking = FALSE 
# MySQL选项可以避免外部锁定。True为开启。
max_allowed_packet =16M 
# 服务器一次能处理最大的查询包的值，也是服务器程序能够处理的最大查询
sort_buffer_size = 1M 
# 设置查询排序时所能使用的缓冲区大小，系统默认大小为2MB。
# 注意：该参数对应的分配内存是每个连接独占的，如果有100个连接，那么实际分配的总排序缓冲区大小为100 x6=600MB。所以，对于内存在4GB左右的服务器来说，推荐将其设置为6MB~8MB
join_buffer_size = 8M
# 联合查询操作所能使用的缓冲区大小，和sort_buffer_size一样，该参数对应的分配内存也是每个连接独享。
thread_cache_size = 64
# 设置Thread Cache池中可以缓存的连接线程最大数量，可设置为0~16384，默认为0.这个值表示可以重新利用保存在缓存中线程的数量，当断开连接时如果缓存中还有空间，那么客户端的线程将被放到缓存中;如果线程重新被请求，那么请求将从缓存中读取,如果缓存中是空的或者是新的请求，那么这个线程将被重新创建，如果有很多线程，增加这个值可以改善系统性能。通过比较Connections和Threads_created状态的变量，可以看到这个变量的作用。我们可以根据物理内存设置规则如下:1GB内存我们配置为8,2GB内存我们配置为16,3GB我们配置为32,4GB或4GB以上我们给此值为64或更大的值。
thread_concurrency = 8 
# 该参数取值为服务器逻辑CPU数量x 2，在本例中，服务器有两个物理CPU，而每个物理CPU又支持H.T超线程，所以实际取值为4 x 2 = 8。这也是双四核主流服务器的配置。
query_cache_size = 64M
# 指定MySQL查询缓冲区的大小。可以通过在MySQL控制台观察，如果Qcache_lowmem_prunes的值非常大，则表明经常出现缓冲不够的情况;如果Qcache_hits的值非常大，则表明查询缓冲使用得非常频繁。另外如果改值较小反而会影响效率，那么可以考虑不用查询缓冲。对于Qcache_free_blocks，如果该值非常大，则表明缓冲区中碎片很多。
query_cache_limit = 2M 
# 只有小于此设置值的结果才会被缓存
query_cache_min_res_unit = 2k 
# 设置查询缓存分配内存的最小单位，要适当第设置此参数，可以做到为减少内存快的申请和分配次数，但是设置过大可能导致内存碎片数值上升。默认值为4K，建议设置为1K~16K。
default_table_type = InnoDB 
# 默认表的类型为InnoDB
thread_stack = 256K 
# 设置MySQL每个线程的堆栈大小，默认值足够大，可满足普通操作。可设置范围为128KB至4GB，默认为192KB
#transaction_isolation = Level
# 数据库隔离级别 (READ UNCOMMITTED(读取未提交内容) READ COMMITTED(读取提交内容) REPEATABLE
READ(可重读) SERIALIZABLE(可串行化))
tmp_table_size = 64M 
# 设置内存临时表最大值。如果超过该值，则会将临时表写入磁盘，其范围1KB到4GB。
max_heap_table_size = 64M 
# 独立的内存表所允许的最大容量。
table_cache = 614
# 给经常访问的表分配的内存，物理内存越大，设置就越大。调大这个值，一般情况下可以降低磁盘IO，但相应的会占用更多的内存,这里设置为614。
table_open_cache = 512 
# 设置表高速缓存的数目。每个连接进来，都会至少打开一个表缓存。因此， table_cache 的大小应与 max_connections 的设置有关。例如，对于 200 个并行运行的连接，应该让表的缓存至少有 200 × N ，这里 N 是应用可以执行的查询的一个联接中表的最大数量。此外，还需要为临时表和文件保留一些额外的文件描述符。
long_query_time = 1 
# 慢查询的执行用时上限,默认设置是10s,推荐(1s~2s)
log_long_format 
# 没有使用索引的查询也会被记录。(推荐,根据业务来调整)
log-slow-queries = /data/3306/slow.log 
# 慢查询日志文件路径(如果开启慢查询,建议打开此日志)
log-bin = /data/3306/mysql-bin 
# logbin数据库的操作日志,例如update、delete、create等都会存储到binlog日志,通过logbin可以实现增量恢复
relay-log = /data/3306/relay-bin
# relay-log日志记录的是从服务器I/O线程将主服务器的二进制日志读取过来记录到从服务器本地文件,然后SQL线程会读取relay-log日志的内容并应用到从服务器
relay-log-info-file = /data/3306/relay-log.info 
# 从服务器用于记录中继日志相关信息的文件,默认名为数据目录中的relay-log.info。
binlog_cache_size = 4M 
# 在一个事务中binlog为了记录sql状态所持有的cache大小，如果你经常使用大的，多声明的事务，可以增加此值来获取更大的性能，所有从事务来的状态都被缓冲在binlog缓冲中，然后再提交后一次性写入到binlog中，如果事务比此值大，会使用磁盘上的临时文件来替代，此缓冲在每个链接的事务第一次更新状态时被创建。
max_binlog_cache_size = 8M 
# 最大的二进制Cache日志缓冲尺寸。
max_binlog_size = 1G 
# 二进制日志文件的最大长度(默认设置1GB)一个二进制文件信息超过了这个最大长度之前,MySQL服务器会自动提供一个新的二进制日志文件接续上。
expire_logs_days = 7 
# 超过7天的binlog,mysql程序自动删除(如果数据重要,建议不要开启该选项)
key_buffer_size = 256M 
# 指定用于索引的缓冲区大小，增加它可得到更好的索引处理性能。对于内存在4GB左右的服务器来说，该参数可设置为256MB或384MB。
# 注意：如果该参数值设置得过大反而会使服务器的整体效率降低！
read_buffer_size = 4M 
# 读查询操作所能使用的缓冲区大小。和sort_buffer_size一样，该参数对应的分配内存也是每个连接独享。
read_rnd_buffer_size = 16M
# 设置进行随机读的时候所使用的缓冲区。此参数和read_buffer_size所设置的Buffer相反，一个是顺序读的时候使用，一个是随机读的时候使用。但是两者都是针对与线程的设置，每个线程都可以产生两种Buffer中的任何一个。默认值256KB，最大值4GB。
bulk_insert_buffer_size = 8M 
# 如果经常性的需要使用批量插入的特殊语句来插入数据,可以适当调整参数至16MB~32MB,建议8MB。
myisam_sort_buffer_size = 8M
# 设置在REPAIR Table或用Create index创建索引或 Alter table的过程中排序索引所分配的缓冲区大小，可设置范围4Bytes至4GB，默认为8MB
lower_case_table_names = 1 
# 实现MySQL不区分大小。(发开需求-建议开启)
slave-skip-errors = 1032,1062 
# 从库可以跳过的错误数字值(mysql错误以数字代码反馈,全的mysql错误代码大全,以后会发布至博客)。
replicate-ignore-db=mysql 
# 在做主从的情况下,设置不需要同步的库。
server-id = 1 
# 表示本机的序列号为1,如果做主从，或者多实例,serverid一定不能相同。
myisam_sort_buffer_size = 128M
# 当需要对于执行REPAIR, OPTIMIZE, ALTER 语句重建索引时，MySQL会分配这个缓存，以及LOAD DATA INFILE会加载到一个新表，它会根据最大的配置认真的分配的每个线程。
myisam_max_sort_file_size = 10G
# 当重新建索引（REPAIR，ALTER，TABLE，或者LOAD，DATA，TNFILE）时，MySQL被允许使用临时文件的最大值。
myisam_repair_threads = 1
# 如果一个表拥有超过一个索引, MyISAM 可以通过并行排序使用超过一个线程去修复他们.
myisam_recover
# 自动检查和修复没有适当关闭的 MyISAM 表.
innodb_additional_mem_pool_size = 4M 
# 用来设置InnoDB存储的数据目录信息和其他内部数据结构的内存池大小。应用程序里的表越多，你需要在这里面分配越多的内存。对于一个相对稳定的应用，这个参数的大小也是相对稳定的，也没有必要预留非常大的值。如果InnoDB用广了这个池内的内存，InnoDB开始从操作系统分配内存，并且往MySQL错误日志写警告信息。默认为1MB，当发现错误日志中已经有相关的警告信息时，就应该适当的增加该参数的大小。
innodb_buffer_pool_size = 64M 
# InnoDB使用一个缓冲池来保存索引和原始数据，设置越大，在存取表里面数据时所需要的磁盘I/O越少。强烈建议不要武断地将InnoDB的Buffer Pool值配置为物理内存的50%~80%，应根据具体环境而定。
innodb_data_file_path = ibdata1:128M:autoextend 
# 设置配置一个可扩展大小的尺寸为128MB的单独文件，名为ibdata1.没有给出文件的位置，所以默认的是在MySQL的数据目录内。
innodb_file_io_threads = 4 
# InnoDB中的文件I/O线程。通常设置为4，如果是windows可以设置更大的值以提高磁盘I/O
innodb_thread_concurrency = 8 
# 你的服务器有几个CPU就设置为几，建议用默认设置，一般设为8。
innodb_flush_log_at_trx_commit = 1 
# 设置为0就等于innodb_log_buffer_size队列满后在统一存储，默认为1，也是最安全的设置。
innodb_log_buffer_size = 2M 
# 默认为1MB，通常设置为8~16MB就足够了。
innodb_log_file_size = 32M 
# 确定日志文件的大小，更大的设置可以提高性能，但也会增加恢复数据库的时间。
innodb_log_files_in_group = 3 
# 为提高性能,MySQL可以以循环方式将日志文件写到多个文件。推荐设置为3。
innodb_max_dirty_pages_pct = 90 
# InnoDB主线程刷新缓存池中的数据。
innodb_lock_wait_timeout = 120 
# InnoDB事务被回滚之前可以等待一个锁定的超时秒数。InnoDB在它自己的锁定表中自动检测事务死锁并且回滚事务。InnoDB用locak tables 语句注意到锁定设置。默认值是50秒。
innodb_file_per_table = 0 
# InnoDB为独立表空间模式，每个数据库的每个表都会生成一个数据空间。0关闭，1开启。
# 独立表空间优点：
# 1、每个表都有自己独立的表空间。
# 2 、每个表的数据和索引都会存在自己的表空间中。
# 3、可以实现单表在不同的数据库中移动。
# 4、空间可以回收（除drop table操作处，表空不能自己回收。）
[mysqldump]

quick

max_allowed_packet = 2M

# 设定在网络传输中一次消息传输量的最大值。系统默认值为1MB，最大值是1GB，必须设置为1024的倍数。单位为字节。
</code></pre><blockquote>
<p>一些建议：</p>
</blockquote>
<pre><code>强烈建议不要武断地将InnoDB的Buffer Pool值配置为物理内存的50%~80%，应根据具体环境而定。
如果key_reads太大，则应该把my.cnf中的key_buffer_size变大，保持key_reads/key_read_re-quests至少在1/100以上，越小越好。
如果qcache_lowmem_prunes很大，就要增加query_cache_size的值。
不过很多时候需要具体情况具体分析，其他参数的变更我们可以等MySQL上线稳定一段时间后在根据status值进行调整。
</code></pre><blockquote>
<p>配置范例:</p>
</blockquote>
<p>一份电子商务网站MySQL数据库调整后所运行的配置文件/etc/my.cnf(服务器为DELL R710、16GB内存、RAID10)，大家可以根据实际的MySQL数据库硬件情况进行调整配置文件如下：</p>
<pre><code>[client]
port = 3306
socket = /data/3306/mysql.sock
default-character-set = utf8
[mysqld]
user = mysql
port = 3306
character-set-server = utf8
socket = /data/3306/mysql.sock
basedir = /application/mysql
datadir = /data/3306/data
log-error=/data/3306/mysql_err.log
pid-file=/data/3306/mysql.pid
log_slave_updates = 1
log-bin = /data/3306/mysql-bin
binlog_format = mixed
binlog_cache_size = 4M
max_binlog_cache_size = 8M
max_binlog_size = 1G
expire_logs_days = 90
binlog-ignore - db = mysql
binlog-ignore - db = information_schema
key_buffer_size = 384M
sort_buffer_size = 2M
read_buffer_size = 2M
read_rnd_buffer_size = 16M
join_buffer_size = 2M
thread_cache_size = 8
query_cache_size = 32M
query_cache_limit = 2M
query_cache_min_res_unit = 2k
thread_concurrency = 32
table_cache = 614
table_open_cache = 512
open_files_limit = 10240
back_log = 600
max_connections = 5000
max_connect_errors = 6000
external-locking = FALSE
max_allowed_packet =16M
thread_stack = 192K
transaction_isolation = READ-COMMITTED
tmp_table_size = 256M
max_heap_table_size = 512M
bulk_insert_buffer_size = 64M
myisam_sort_buffer_size = 64M
myisam_max_sort_file_size = 10G
myisam_repair_threads = 1
myisam_recover
long_query_time = 2
slow_query_log
slow_query_log_file = /data/3306/slow.log
skip-name-resolv
skip-locking
skip-networking
server-id = 1
innodb_additional_mem_pool_size = 16M
innodb_buffer_pool_size = 512M
innodb_data_file_path = ibdata1:256M:autoextend
innodb_file_io_threads = 4
innodb_thread_concurrency = 8
innodb_flush_log_at_trx_commit = 2
innodb_log_buffer_size = 16M
innodb_log_file_size = 128M
innodb_log_files_in_group = 3
innodb_max_dirty_pages_pct = 90
innodb_lock_wait_timeout = 120
innodb_file_per_table = 0
[mysqldump]
quick
max_allowed_packet = 64M
[mysql]
no – auto - rehash
</code></pre><h3 id="存储引擎的选择"><a href="#存储引擎的选择" class="headerlink" title="存储引擎的选择"></a>存储引擎的选择</h3><p>关于存储引擎的选择请看博客：MySQL存储引擎之Myisam和Innodb总结性梳理</p>
<h3 id="线上优化调整"><a href="#线上优化调整" class="headerlink" title="线上优化调整"></a>线上优化调整</h3><blockquote>
<p>MySQL数据库上线后，可以等其稳定运行一段时间后再根据服务器的status状态进行适当优化，我们可以用如下命令列出MySQL服务器运行的各种状态值。通过命令：show global status; 也可以通过 show status like ‘查询%’;</p>
<h4 id="慢查询"><a href="#慢查询" class="headerlink" title="慢查询"></a>慢查询</h4><pre><code>有时我们为了定位系统中效率比较低下的Query语法，需要打开慢查询日志，也就是Slow Query log。打开慢查询日志的相关命令如下：
</code></pre></blockquote>
<pre><code>mysql&gt;show variables like &apos;%slow%&apos;;
+---------------------+-----------------------------------------+
|
Variable_name | Value |
+---------------------+-----------------------------------------+
|
log_slow_queries | ON |
|
slow_launch_time | 2 |
+---------------------+-----------------------------------------+
mysql&gt;show global status like &apos;%slow%&apos;;
+---------------------+-------+
|
Variable_name | Value |
+---------------------+-------+
|
Slow_launch_threads | 0 |
|
Slow_queries | 2128 |
+---------------------+-------+
</code></pre><p>打开慢查询日志可能会对系统性能有一点点影响，如果你的MySQL是主从结构，可以考虑打开其中一台从服务器的慢查询日志，这样既可以监控慢查询，对系统性能影响也会很小。另外，可以用MySQL自带的命令mysqldumpslow进行查询。比如：下面的命令可以查出访问次数最多的20个SQL语句：<br><code>mysqldumpslow -s c -t 20 host-slow.log</code></p>
<h4 id="连接数"><a href="#连接数" class="headerlink" title="连接数"></a>连接数</h4><p>我们如果经常遇见MySQL：ERROR1040：Too many connections的情况，一种情况是访问量确实很高，MySQL服务器扛不住了，这个时候就要考虑增加从服务器分散读压力，从架构层面。另外一种情况是MySQL配置文件中max_connections的值过小。来看一个例子。</p>
<pre><code>mysql&gt; show variables like &apos;max_connections&apos;;
+-----------------+-------+
|
Variable_name | Value |
+-----------------+-------+
|
max_connections | 800 |
+-----------------+-------+
</code></pre><blockquote>
<p>这台服务器最大连接数是256，然后查询一下该服务器响应的最大连接数；</p>
</blockquote>
<pre><code>mysql&gt; show global status like &apos;Max_used_connections&apos;;
+----------------------+-------+
|
Variable_name | Value |
+----------------------+-------+
|
Max_used_connections | 245 |
+----------------------+-------+
</code></pre><blockquote>
<p>MySQL服务器过去的最大连接数是245，没有达到服务器连接数的上线800，不会出现1040错误。</p>
</blockquote>
<p><code>Max_used_connections /max_connections * 100% = 85%</code><br>最大连接数占上限连接数的85%左右,如果发现比例在10%以下，则说明MySQL服务器连接数的上限设置得过高了。</p>
<h4 id="key-buffer-size"><a href="#key-buffer-size" class="headerlink" title="key_buffer_size"></a>key_buffer_size</h4><pre><code>key_buffer_size是设置MyISAM表索引缓存空间的大小，此参数对MyISAM表性能影响最大。下面是一台MyISAM为主要存储引擎服务器的配置：
mysql&gt; show variables like &apos;key_buffer_size&apos;;
+-----------------+-----------+
|
Variable_name | Value |
+-----------------+-----------+
|
key_buffer_size | 536870912 |
+-----------------+-----------+
</code></pre><blockquote>
<p>从上面可以看出，分配了512MB内存给key_buffer_size。再来看key_buffer_size的使用情况：</p>
</blockquote>
<pre><code>mysql&gt; show global status like &apos;key_read%&apos;;
+-------------------+--------------+
|
Variable_name | Value |
+-------------------+-------+
|
Key_read_requests | 27813678766 |
|
Key_reads | 6798830|
+-------------------+--------------+

一共有27813678766个索引读取请求，有6798830个请求在内存中没有找到，直接从硬盘读取索引。
key_cache_miss_rate = key_reads / key_read_requests * 100%
比如上面的数据，key_cache_miss_rate为0.0244%，4000%个索引读取请求才有一个直接读硬盘，效果已经很好了，key_cache_miss_rate在0.1%以下都很好，如果key_cache_miss_rate在0.01%以下的话，则说明key_buffer_size分配得过多，可以适当减少。
</code></pre><h4 id="临时表"><a href="#临时表" class="headerlink" title="临时表"></a>临时表</h4><pre><code>当执行语句时，关于已经被创建了隐含临时表的数量，我们可以用如下命令查询其具体情况：
mysql&gt; show global status like &apos;created_tmp%&apos;;
+-------------------------+----------+
|
Variable_name | Value |
+-------------------------+----------+
|
Created_tmp_disk_tables | 21119 |
|
Created_tmp_files | 6 |
|
Created_tmp_tables | 17715532 |
+-------------------------+----------+
</code></pre><blockquote>
<p>MySQL服务器对临时表的配置：</p>
</blockquote>
<pre><code>mysql&gt; show variables where Variable_name in (&apos;tmp_table_size&apos;,&apos;max_heap_table_size&apos;);
+---------------------+---------+
|
Variable_name | Value |
+---------------------+---------+
|
max_heap_table_size | 2097152 |
|
tmp_table_size | 2097152 |
+---------------------+---------+

每次创建临时表时，Created_tmp_table都会增加，如果磁盘上创建临时表，Created_tmp_disk_tables也会增加。Created_tmp_files表示MySQL服务创建的临时文件数，比较理想的配置是：
Created_tmp_disk_tables / Created_tmp_files *100% &lt;= 25%
比如上面的服务器：
Created_tmp_disk_tables / Created_tmp_files *100% =1.20%，这个值就很棒了。
</code></pre><h4 id="打开表的情况"><a href="#打开表的情况" class="headerlink" title="打开表的情况"></a>打开表的情况</h4><pre><code>Open_tables表示打开表的数量，Opened_tables表示打开过的表数量，我们可以用如下命令查看其具体情况：
mysql&gt; show global status like &apos;open%tables%&apos;;
+---------------+-------+
|
Variable_name | Value |
+---------------+-------+
|
Open_tables | 351 |
|
Opened_tables | 1455 |
</code></pre><blockquote>
<p>查询下服务器table_open_cache;</p>
</blockquote>
<pre><code>mysql&gt; show variables like &apos;table_open_cache&apos;;
+------------------+-------+
|
Variable_name | Value |
+------------------+-------+
|
table_open_cache | 2048 |
+------------------+-------+
如果Opened_tables数量过大，说明配置中table_open_cache的值可能太小。
比较合适的值为：
open_tables / opened_tables* 100% &gt; = 85%
open_tables / table_open_cache* 100% &lt; = 95%
</code></pre><h4 id="进程使用情况"><a href="#进程使用情况" class="headerlink" title="进程使用情况"></a>进程使用情况</h4><pre><code>如果我们在MySQL服务器的配置文件中设置了thread_cache_size，当客户端断开时，服务器处理此客户请求的线程将会缓存起来以响应一下客户而不是销毁(前提是缓存数未达上线)Thread_created表示创建过的线程数，我们可以用如下命令查看：
mysql&gt; show global status like &apos;thread%&apos;;
+-------------------+-------+
|
Variable_name | Value |
+-------------------+-------+
|
Threads_cached | 40|
|
Threads_connected | 1 |
|
Threads_created | 330 |
|
Threads_running | 1 |
+-------------------+-------+
</code></pre><blockquote>
<p>查询服务器thread_cache_size配置如下：</p>
</blockquote>
<pre><code>mysql&gt; show variables like &apos;thread_cache_size&apos;;
+-------------------+-------+
|
Variable_name | Value |
+-------------------+-------+
|
thread_cache_size | 100 |
+-------------------+-------+
如果发现Threads_created的值过大的话，表明MySQL服务器一直在创建线程，这也是比较耗费资源的，可以适当增大配置文件中thread_cache_size的值。
</code></pre><h4 id="查询缓存-query-cache"><a href="#查询缓存-query-cache" class="headerlink" title="查询缓存(query cache)"></a>查询缓存(query cache)</h4><blockquote>
<p>它主要涉及两个参数，<code>query_cache_size</code>是设置<code>MySQL的Query Cache</code>大小，query_cache_type是设置使用查询缓存的类型，我们可以用如下命令查看其具体情况：</p>
</blockquote>
<pre><code>mysql&gt; show global status like &apos;qcache%&apos;;
+-------------------------+-----------+
|
Variable_name | Value |
+-------------------------+-----------+
|
Qcache_free_blocks | 22756 |
|
Qcache_free_memory | 76764704 |
|
Qcache_hits | 213028692 |
|
Qcache_inserts | 208894227 |
|
Qcache_lowmem_prunes | 4010916 |
|
Qcache_not_cached | 13385031 |
|
Qcache_queries_in_cache | 43560 |
|
Qcache_total_blocks | 111212 |
+-------------------------+-----------+
</code></pre><blockquote>
<p>MySQL查询缓存变量的相关解释如下：</p>
</blockquote>
<p><code>Qcache_free_blocks：</code> 缓存中相领内存快的个数。数目大说明可能有碎片。<br><code>flush query</code> cache会对缓存中的碎片进行整理，从而得到一个空间块。<br><code>Qcache_free_memory</code>：缓存中的空闲空间。<br><code>Qcache_hits</code>：多少次命中。通过这个参数可以查看到Query Cache的基本效果。<br><code>Qcache_inserts</code>：插入次数，没插入一次查询时就增加1。命中次数除以插入次数就是命中比率。<br><code>Qcache_lowmem_prunes</code>：多少条Query因为内存不足而被清楚出Query Cache。通过Qcache_lowmem_prunes和Query_free_memory相互结合，能 够更清楚地了解到系统中Query Cache的内存大小是否真的足够，是否非常频繁地出现因为内存不足而有Query被换出的情况。<br><code>Qcache_not_cached</code>：不适合进行缓存的查询数量，通常是由于这些查询不是select语句或用了now()之类的函数。<br><code>Qcache_queries_in_cach</code>：当前缓存的查询和响应数量。<br><code>Qcache_total_blocks</code>：缓存中块的数量。</p>
<blockquote>
<p>query_cache的配置命令：</p>
</blockquote>
<pre><code>mysql&gt; show variables like &apos;query_cache%&apos;;
+------------------------------+---------+
|
Variable_name | Value |
+------------------------------+---------+
|
query_cache_limit | 1048576 |
|
query_cache_min_res_unit | 2048 |
|
query_cache_size | 2097152 |
|
query_cache_type | ON |
|
query_cache_wlock_invalidate | OFF |
+------------------------------+---------+
</code></pre><blockquote>
<p>字段解释如下：</p>
</blockquote>
<p><code>query_cache_limit</code>：超过此大小的查询将不缓存。<br><code>query_cache_min_res_unit</code>：缓存块的最小值。<br><code>query_cache_size</code>：查询缓存大小。<br><code>query_cache_type</code>：缓存类型，决定缓存什么样的查询，示例中表示不缓存select sql_no_cache查询。<br><code>query_cache_wlock_invalidat</code>：表示当有其他客户端正在对MyISAM表进行写操作，读请求是要等WRITE LOCK释放资源后再查询还是允许直接从Query Cache中读取结果，默认为OFF（可以直接从Query Cache中取得结果。）<br><code>query_cache_min_res_unit</code>的配置是一柄双刃剑，默认是4KB，设置值大对大数据查询有好处，但如果你的查询都是小数据查询，就容易造成内存碎片和浪费。</p>
<p>查询缓存碎片率 = <code>Qcache_free_blocks /Qcache_total_blocks * 100%</code><br>如果查询碎片率超过20%，可以用 <code>flush query cache</code> 整理缓存碎片，或者试试减少query_cache_min_res_unit，如果你查询都是小数据库的话。<br>查询缓存利用率 = <code>(Qcache_free_size – Qcache_free_memory)/query_cache_size * 100%</code><br>查询缓存利用率在25%一下的话说明<code>query_cache_size</code>设置得过大，可适当减少;查询缓存利用率在80%以上而且<code>Qcache_lowmem_prunes &gt; 50</code>的话则说明<code>query_cache_size</code>可能有点小，不然就是碎片太多。</p>
<p>查询命中率 = <code>(Qcache_hits - Qcache_insert)/Qcache)hits * 100%</code><br>示例服务器中的查询缓存碎片率等于20%左右，查询缓存利用率在50%，查询命中率在2%，说明命中率很差，可能写操作比较频繁，而且可能有些碎片。</p>
<h4 id="排序使用情况"><a href="#排序使用情况" class="headerlink" title="排序使用情况"></a>排序使用情况</h4><p>它表示系统中对数据进行排序时所用的Buffer，我们可以用如下命令查看：</p>
<pre><code>mysql&gt; show global status like &apos;sort%&apos;;
+-------------------+----------+
|
Variable_name | Value |
+-------------------+----------+
|
Sort_merge_passes | 10 |
|
Sort_range | 37431240 |
|
Sort_rows | 6738691532 |
|
Sort_scan | 1823485 |
+-------------------+----------+
</code></pre><blockquote>
<p>Sort_merge_passes包括如下步骤：MySQL首先会尝试在内存中做排序，使用的内存大小由系统变量sort_buffer_size来决定，如果它不够大则把所有的记录都读在内存中，而MySQL则会把每次在内存中排序的结果存到临时文件中，等MySQL找到所有记录之后，再把临时文件中的记录做一次排序。这次再排序就会增加sort_merge_passes。实际上，MySQL会用另外一个临时文件来存储再次排序的结果，所以我们通常会看sort_merge_passes增加的数值是建临时文件数的两倍。因为用到了临时文件，所以速度可能会比较慢，增大sort_buffer_size会减少sort_merge_passes和创建临时文件的次数，但盲目地增大sort_buffer_size并不一定能提高速度。</p>
</blockquote>
<h4 id="文件打开数-open-files"><a href="#文件打开数-open-files" class="headerlink" title="文件打开数(open_files)"></a>文件打开数(open_files)</h4><p>我们现在处理MySQL故障时，发现当Open_files大于open_files_limit值时，MySQL数据库就会发生卡住的现象，导致Nginx服务器打不开相应页面。这个问题大家在工作中应注意，我们可以用如下命令查看其具体情况：<br>    show global status like ‘open_files’;<br>    +—————+——-+<br>    |<br>    Variable_name | Value |<br>    +—————+——-+<br>    |<br>    Open_files | 1481 |<br>    +—————+——-+<br>    mysql&gt; show global status like ‘open_files_limit’;<br>    +——————+——-+<br>    |<br>    Variable_name | Value |<br>    +——————+——–+<br>    |<br>    Open_files_limit | 4509 |<br>    +——————+——–+</p>
<p>比较合适的设置是：<code>Open_files / Open_files_limit * 100% &lt; = 75%</code></p>
<h4 id="InnoDB-buffer-pool-cache合理设置"><a href="#InnoDB-buffer-pool-cache合理设置" class="headerlink" title="InnoDB_buffer_pool_cache合理设置"></a>InnoDB_buffer_pool_cache合理设置</h4><p>InnoDB存储引擎的缓存机制和MyISAM的最大区别就在于，InnoDB不仅仅缓存索引，同时还会缓存实际的数据。此参数用来设置InnoDB最主要的Buffer的大小，也就是缓存用户表及索引数据的最主要缓存空间，对InnoDB整体性能影响也最大。<br>无论是MySQL官方手册还是网络上许多人分享的InnoDB优化建议，都是简单地建议将此值设置为整个系统物理内存的50%~80%。这种做法其实不妥，我们应根据实际的运行场景来正确设置此项参数。</p>
<p>很多时候我们会发现，通过参数设置进行性能优化所带来的性能提升，并不如许多人想象的那样会产生质的飞跃，除非是之前的设置存在严重不合理的情况。我们不能将性能调优完全依托与通过DBA在数据库上线后进行参数调整，而应该在系统设计和开发阶段就尽可能减少性能问题。(重点在于前期架构合理的设计及开发的程序合理)</p>
<h3 id="MySQL数据库的可扩展架构方案（即高可用方案）"><a href="#MySQL数据库的可扩展架构方案（即高可用方案）" class="headerlink" title="MySQL数据库的可扩展架构方案（即高可用方案）"></a>MySQL数据库的可扩展架构方案（即高可用方案）</h3><blockquote>
<p>可参考：mysql高可用方案总结性说明<br>如果凭借MySQL的优化任无法顶住压力，这个时候我们就必须考虑MySQL的可扩展性架构了(有人称为MySQL集群)它有以下明显的优势：</p>
</blockquote>
<p>1）成本低，很容易通过价格低廉Pc server搭建出一个处理能力非常强大的计算机集群。<br>2）不太容易遇到瓶颈，因为很容易通过添加主机来增加处理能力。<br>3）单节点故障对系统的整体影响较小。</p>
<h4 id="主从复制解决方案"><a href="#主从复制解决方案" class="headerlink" title="主从复制解决方案"></a>主从复制解决方案</h4><p>这是MySQL自身提供的一种高可用解决方案，数据同步方法采用的是MySQL replication技术。MySQL replication就是从服务器到主服务器拉取二进制日志文件，然后再将日志文件解析成相应的SQL在从服务器上重新执行一遍主服务器的操作，通过这种方式保证数据的一致性。<br>为了达到更高的可用性，在实际的应用环境中，一般都是采用MySQL replication技术配合高可用集群软件keepalived来实现自动failover，这种方式可以实现95.000%的SLA。<br><img src="http://images2015.cnblogs.com/blog/827552/201607/827552-20160705175153514-1750548117.png" alt="image"></p>
<blockquote>
<p>在实际应用场景中，MySQL Replication是使用最为广泛的一种提高系统扩展性的设计手段。众多的MySQL使用者通过Replication功能提升系统的扩展性后，通过 简单的增加价格低廉的硬件设备成倍 甚至成数量级地提高了原有系统的性能，是广大MySQL中低端使用者非常喜欢的功能之一，也是许多MySQL使用者选择MySQL最为重要的原因。<br>比较常规的MySQL Replication架构也有好几种，这里分别简单说明下：</p>
</blockquote>
<p><code>MySQL Replication架构一</code>：常规复制架构–Master-slaves<br>是由一个Master复制到一个或多个Salve的架构模式，主要用于读压力大的应用数据库端廉价扩展解决方案，读写分离，Master主要负责写方面的压力。<br>MySQL Replication架构二：级联复制架构<br>即Master-Slaves-Slaves,这个也是为了防止Slaves的读压力过大，而配置一层二级 Slaves，很容易解决Master端因为附属slave太多而成为瓶劲的风险。<br><code>MySQL Replication架构三</code>：Dual Master与级联复制结合架构<br>即Master-Master-Slaves，最大的好处是既可以避免主Master的写操作受到Slave集群的复制带来的影响，而且保证了主Master的单点故障。<br>MySQL Replication的不足：<br>如果Master主机硬件故障无法恢复，则可能造成部分未传送到slave端的数据丢失。所以大家应该根据自己目前的网络 规划，选择自己合理的Mysql架构方案，跟自己的MySQL DBA和程序员多沟涌，多备份(备份我至少会做到本地和异地双备份)，多测试，数据的事是最大的事，出不得半点差错，切记切记</p>
<h4 id="MMM-MHA高可用解决方案"><a href="#MMM-MHA高可用解决方案" class="headerlink" title="MMM/MHA高可用解决方案"></a>MMM/MHA高可用解决方案</h4><p>MMM提供了MySQL主主复制配置的监控、故障转移和管理的一套可伸缩的脚本套件。在MMM高可用方案中，典型的应用是双主多从架构，通过MySQL replication技术可以实现两个服务器互为主从，且在任何时候只有一个节点可以被写入，避免了多点写入的数据冲突。同时，当可写的主节点故障时，MMM套件可以立刻监控到，然后将服务自动切换到另一个主节点，继续提供服务，从而实现MySQL的高可用。<br><img src="http://images2015.cnblogs.com/blog/827552/201607/827552-20160705175154874-6474073.png" alt="image"></p>
<h4 id="Heartbeat-SAN高可用解决方案"><a href="#Heartbeat-SAN高可用解决方案" class="headerlink" title="Heartbeat/SAN高可用解决方案"></a>Heartbeat/SAN高可用解决方案</h4><p>在这个方案中，处理failover的方式是高可用集群软件Heartbeat，它监控和管理各个节点间连接的网络，并监控集群服务，<br>当节点出现故障或者服务不可用时，自动在其他节点启动集群服务。在数据共享方面，通过SAN（Storage Area Network）存储来共享数据，这种方案可以实现99.990%的SLA。<br><img src="http://images2015.cnblogs.com/blog/827552/201607/827552-20160705175157358-1766002481.png" alt="image"></p>
<h4 id="Heartbeat-DRBD高可用解决方案"><a href="#Heartbeat-DRBD高可用解决方案" class="headerlink" title="Heartbeat/DRBD高可用解决方案"></a>Heartbeat/DRBD高可用解决方案</h4><p>此方案处理failover的方式上依旧采用Heartbeat，不同的是，在数据共享方面，采用了基于块级别的数据同步软件DRBD来实现。<br>DRBD是一个用软件实现的、无共享的、服务器之间镜像块设备内容的存储复制解决方案。和SAN网络不同，它并不共享存储，而是通过服务器之间的网络复制数据。<br><img src="http://images2015.cnblogs.com/blog/827552/201607/827552-20160705175158249-1222151770.png" alt="image"></p>
<h4 id="percona-xtradb-cluster"><a href="#percona-xtradb-cluster" class="headerlink" title="percona xtradb cluster"></a>percona xtradb cluster</h4><p>Percona XtraDB Cluster（简称PXC集群）提供了MySQL高可用的一种实现方法。<br>1）集群是有节点组成的，推荐配置至少3个节点，但是也可以运行在2个节点上。<br>2）每个节点都是普通的mysql/percona服务器，可以将现有的数据库服务器组成集群，反之，也可以将集群拆分成单独的服务器。<br>3）每个节点都包含完整的数据副本。<br>PXC集群主要由两部分组成：Percona Server with XtraDB和Write Set Replication patches（使用了Galera library，一个通用的用于事务型应用的同步、多主复制插件）。<br><img src="http://images2015.cnblogs.com/blog/827552/201607/827552-20160705175158905-477494981.png" alt="image"></p>
<blockquote>
<p>MYSQL经典应用架构</p>
</blockquote>
<p><img src="http://images2015.cnblogs.com/blog/827552/201607/827552-20160705175200296-241603992.png" alt="image"></p>
<p>其中：Dbm157是mysql主，dbm158是mysql主的备机，dbs159/160/161是mysql从。<br>MySQL写操作一般采用基于heartbeat+DRBD+MySQL搭建高可用集群的方案。通过heartbeat实现对mysql主进行状态监测，而DRBD实现dbm157数据同步到dbm158。<br>读操作普遍采用基于LVS+Keepalived搭建高可用高扩展集群的方案。前端AS应用通过提高的读VIP连接LVS，LVS有keepliaved做成高可用模式，实现互备。<br>最后，mysql主的从节点dbs159/160/161通过mysql主从复制功能同步mysql主的数据，通过lvs功能提供给前端AS应用进行读操作，并实现负载均衡。</p>
]]></content>
      
        <categories>
            
            <category> Mysql </category>
            
        </categories>
        
        
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MySQ binlog三种模式及设置方法]]></title>
      <url>http://yoursite.com/2016/03/12/MySQ%20binlog%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F%E5%8F%8A%E8%AE%BE%E7%BD%AE%E6%96%B9%E6%B3%95/</url>
      <content type="html"><![CDATA[<h1 id="MySQ-binlog三种模式及设置方法"><a href="#MySQ-binlog三种模式及设置方法" class="headerlink" title="MySQ binlog三种模式及设置方法"></a>MySQ binlog三种模式及设置方法</h1><h2 id="Row-Level-行模式"><a href="#Row-Level-行模式" class="headerlink" title="Row Level 行模式"></a>Row Level 行模式</h2><pre><code>日志中会记录每一行数 据被修改的形式，然后在slave端再对相同的数据进行修改 
</code></pre><a id="more"></a>
<pre><code>优点：在row level模式下，bin-log中可以不记录执行的sql语句的上下文相关的信息，仅仅只需要记录那一条被修改。所以rowlevel的日志内容会非常清楚的记录下每一行数据修改的细节。
不会出现某些特定的情况下的存储过程或function，以及trigger的调用和触发无法被正确复制的问题

缺点：row level，所有的执行的语句当记录到日志中的时候，都将以每行记录的修改来记录，会产生大量的日志内容。
</code></pre><h2 id="Statement-Level（默认"><a href="#Statement-Level（默认" class="headerlink" title="Statement Level（默认"></a>Statement Level（默认</h2><pre><code>每一条会修改数据的sql都会记录到master的bin-log中。slave在复制的时候sql进程会解析成和原来master端执行过的相同的sql来再次执行 

优点：statement level下的优点首先就是解决了row level下的缺点，不需要记录每一行数据的变化，减少bin-log日志量，节约IO，提高性能，因为它只需要在Master上锁执行的语句的细节，以及执行语句的上下文的信息。

缺点：由于只记录语句，所以，在statement level下 已经发现了有不少情况会造成MySQL的复制出现问题，主要是修改数据的时候使用了某些定的函数或者功能的时候会出现。
</code></pre><h2 id="Mixed-自动模式"><a href="#Mixed-自动模式" class="headerlink" title="Mixed 自动模式"></a>Mixed 自动模式</h2><pre><code>在Mixed模式下，MySQL会根据执行的每一条具体的sql语句来区分对待记录的日志格式，也就是在Statement和Row之间选择一种。
如果sql语句确实就是update或者delete等修改数据的语句，那么还是会记录所有行的变更。
</code></pre><h2 id="企业场景如何选择binlog模式"><a href="#企业场景如何选择binlog模式" class="headerlink" title="企业场景如何选择binlog模式"></a>企业场景如何选择binlog模式</h2><pre><code>1、互联网公司，使用MySQL的功能相对少（存储过程、触发器、函数） 

选择默认的语句模式，Statement Level（默认） 
2、公司如果用到使用MySQL的特殊功能（存储过程、触发器、函数） 
则选择Mixed模式

3、公司如果用到使用MySQL的特殊功能（存储过程、触发器、函数）又希望数据最大化一直，此时最好选择Row level模式
</code></pre><h2 id="行模式和语句模式的区别"><a href="#行模式和语句模式的区别" class="headerlink" title="行模式和语句模式的区别"></a>行模式和语句模式的区别</h2><pre><code>1.语句模式： 
100万条记录 
只需1条delete * from test；就可以删除100万条记录

2.row模式 
100万条记录 
记录100万条删除命令
</code></pre>]]></content>
      
        <categories>
            
            <category> Mysql </category>
            
        </categories>
        
        
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Nginx配置SSL证书部署HTTPS网站]]></title>
      <url>http://yoursite.com/2016/03/11/Nginx%E9%85%8D%E7%BD%AESSL%E8%AF%81%E4%B9%A6%E9%83%A8%E7%BD%B2HTTPS%E7%BD%91%E7%AB%99/</url>
      <content type="html"><![CDATA[<h3 id="购买ssl证书"><a href="#购买ssl证书" class="headerlink" title="购买ssl证书"></a>购买ssl证书</h3><p>购买网站：沃通</p>
<h3 id="上传证书到nginx服务器，然后进行解压。"><a href="#上传证书到nginx服务器，然后进行解压。" class="headerlink" title="上传证书到nginx服务器，然后进行解压。"></a>上传证书到nginx服务器，然后进行解压。</h3><p>解压后的的效果：</p>
<p>[root@bubidev-ng3 nginx]# pwd<br>/etc/nginx</p>
<a id="more"></a>
<p>[root@bubidev-ng3 nginx]# ll<br><img src="http://static.zybuluo.com/BruceTang/7twkrgynzp9eb0nujtiifi2m/image_1bfaqkr27183sd46odrbmdh7p9.png" alt="image_1bfaqkr27183sd46odrbmdh7p9.png-13.3kB"></p>
<p>CRT 即 certificate的缩写，即证书。<br>KEY 通常指私钥。</p>
<h3 id="在nginx的配置文件里面配置"><a href="#在nginx的配置文件里面配置" class="headerlink" title="在nginx的配置文件里面配置"></a>在nginx的配置文件里面配置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">server &#123;</div><div class="line">    listen       443;</div><div class="line">    server_name  www.tang.cn tang.cn;</div><div class="line">    ssl on;</div><div class="line">    ssl_certificate bumeng_cn_ssl_pro.crt;</div><div class="line">    ssl_certificate_key bumeng_cn_ssl_pro.key;</div><div class="line">    ssl_session_timeout 5m;</div><div class="line">    ssl_protocols SSLv3 TLSv1;</div><div class="line">    ssl_ciphers HIGH:!ADH:!EXPORT56:RC4+RSA:+MEDIUM;</div><div class="line">    ssl_prefer_server_ciphers on;</div><div class="line">    if ( $http_user_agent =  &quot;Mozilla/5.0&quot;)&#123;</div><div class="line">        return 403;</div><div class="line">        &#125;</div><div class="line">    location / &#123;</div><div class="line">        proxy_pass http://10.0.0.10:8080/tang;</div><div class="line">        proxy_cookie_path /tang/ /;</div><div class="line">        proxy_set_header Host &quot;www.tang.cn&quot;;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> nginx </category>
            
        </categories>
        
        
        <tags>
            
            <tag> nginx </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Nginx采用https加密访问后出现的问题]]></title>
      <url>http://yoursite.com/2016/03/11/Nginx%E9%87%87%E7%94%A8https%E5%8A%A0%E5%AF%86%E8%AE%BF%E9%97%AE%E5%90%8E%E5%87%BA%E7%8E%B0%E7%9A%84%E9%97%AE%E9%A2%98/</url>
      <content type="html"><![CDATA[<p>线上的一个网站运行了一段时间，应领导要求，将其访问方式更改为https加密方式。<br>更改为https后，网站访问正常，但网站注册功能不能正常使用了！</p>
<p>经过排查，是nginx配置里结合php部分漏洞了一个参数（fastcgi_param  HTTPS ）导致，添加上这个参数后，问题迎刃而解！<br>nginx支持https的配置时，需要在php区域配置中添加FastCGI服务，否则https不支持php文件。</p>
<a id="more"></a>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">location ~ \.php$ &#123;</div><div class="line">root /var/www/vhosts/fff/main;</div><div class="line">fastcgi_pass 127.0.0.1:9000;</div><div class="line">fastcgi_read_timeout 30;</div><div class="line">fastcgi_index fff.php;</div><div class="line">fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name;</div><div class="line">#include fastcgi_params;</div><div class="line">include fastcgi.conf;</div><div class="line">fastcgi_param HTTPS on;                        【或者fastcgi_param HTTPS     $https if_not_empty; 】</div><div class="line">&#125; </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>如何开启 Nginx 的 SSL 或者 HTTPS呢？</p>
<p>大家有没有试过使用HTTPS登陆 phpmyadmin 的时候会自动返回“The plain HTTP request was sent to HTTPS port”？<br>这是个 fastcgi 的配置问题！</p>
<p><strong>解决方法：</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">location ~ .*\.(php|php5)?$</div><div class="line">&#123;</div><div class="line">try_files $uri =404;</div><div class="line">fastcgi_pass unix:/tmp/php-cgi.sock;</div><div class="line">fastcgi_param HTTPS     $https if_not_empty;</div><div class="line">fastcgi_index index.php;</div><div class="line">include fcgi.conf;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>解释：</strong></p>
<p>很多人认为使用 fastcgi_param HTTPS on;，这样是没错啦，不过强迫使用这个参数，可能不太有效！</p>
<p>最好的答案是上面的配置（参考下面 nginx 官方的链接）<br><code>fastcgi_param HTTPS $https if_not_empty;</code><br>有 https 协议时才自动使用 https on，否则忽略这个参数。<br>内嵌的变量：<br><code>$https</code> – 如果链接是 SSL 就返回 “ON”，否则返回空字符串。<br><code>if_not_empty</code>; – 当参数有值时才传递到服务器</p>
<p>注意：这个 if_not_empty 额外参数只适合 Nginx 1.1.11 之后的版本</p>
]]></content>
      
        <categories>
            
            <category> nginx </category>
            
        </categories>
        
        
        <tags>
            
            <tag> nginx </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Nginx服务器http重定向到https]]></title>
      <url>http://yoursite.com/2016/03/11/Nginx%E6%9C%8D%E5%8A%A1%E5%99%A8http%E9%87%8D%E5%AE%9A%E5%90%91%E5%88%B0https/</url>
      <content type="html"><![CDATA[<p>http重定向到https使用了nginx的重定向命令。那么应该如何写重定向？之前老版本的nginx可能使用了以下类似的格式。</p>
<a id="more"></a>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">rewrite ^/(.*)$ http://domain.com/$1 permanent;</div></pre></td></tr></table></figure>
<p>或者<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">rewrite ^ http://domain.com$request_uri? permanent;</div></pre></td></tr></table></figure></p>
<p>现在nginx新版本已经换了种写法，上面这些已经不再推荐。</p>
<p>下面是nginx http页面重定向到https页面最新支持的写法：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">server &#123;</div><div class="line">    listen      80;</div><div class="line">    server_name    my.domain.com;</div><div class="line">    return      301 https://$server_name$request_uri;</div><div class="line">&#125;</div><div class="line"></div><div class="line">server &#123;</div><div class="line">    listen      443 ssl;</div><div class="line">    server_name    my.domain.com;</div><div class="line"></div><div class="line">    [....]</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> nginx </category>
            
        </categories>
        
        
        <tags>
            
            <tag> nginx </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Mysqladmin命令总结]]></title>
      <url>http://yoursite.com/2016/03/11/Mysqladmin%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93/</url>
      <content type="html"><![CDATA[<pre><code>mysqladmin 工具的使用格式：
mysqladmin [option] command [command option] command ......
</code></pre><a id="more"></a>
<pre><code>参数选项：
-c number 自动运行次数统计，必须和 -i 一起使用
-i number 间隔多长时间重复执行

0）每个两秒查看一次服务器的状态，总共重复5次。
[root@test-huanqiu ~]# mysqladmin -uroot -p -i 2 -c 5 status


1）查看服务器的状况：status
[root@test-huanqiu ~]# mysqladmin -uroot -p status

2）修改root 密码：
[root@test-huanqiu ~]# mysqladmin -u root -p原密码 password &apos;newpassword&apos;

3）检查mysqlserver是否可用：
[root@test-huanqiu ~]# mysqladmin -uroot -p ping

4）查询服务器的版本
[root@test-huanqiu ~]# mysqladmin -uroot -p version

5）查看服务器状态的当前值：
[root@test-huanqiu ~]# mysqladmin -uroot -p extended-status

6）查询服务器系统变量值：
[root@test-huanqiu ~]# mysqladmin -uroot -p variables

7）显示服务器所有运行的进程：
[root@test-huanqiu ~]# mysqladmin -uroot -p processlist
[root@test-huanqiu ~]# mysqladmin -uroot -p-i 1 processlist   

8）创建数据库
[root@test-huanqiu ~]# mysqladmin -uroot -p create daba-test//每秒刷新一次

9）显示服务器上的所有数据库
[root@test-huanqiu ~]# mysqlshow -uroot -p

10）显示数据库daba-test下有些什么表：
[root@test-huanqiu ~]# mysqlshow -uroot -p daba-test

11）统计daba-test 下数据库表列的汇总
[root@test-huanqiu ~]# mysqlshow -uroot -p daba-test -v

12）统计daba-test 下数据库表的列数和行数
[root@test-huanqiu ~]# mysqlshow -uroot -p daba-test -v -v

13）删除数据库 daba-test
[root@test-huanqiu ~]# mysqladmin -uroot -p drop daba-test

14）重载权限信息
[root@test-huanqiu ~]# mysqladmin -uroot -p reload

15）刷新所有表缓存，并关闭和打开log
[root@test-huanqiu ~]# mysqladmin -uroot -p refresh

16）使用安全模式关闭数据库
[root@test-huanqiu ~]# mysqladmin -uroot -p shutdown

17）刷新命令mysqladmin flush commands
[root@test-huanqiu ~]# mysqladmin -u root -ptmppassword flush-hosts
[root@test-huanqiu ~]# mysqladmin -u root -ptmppassword flush-logs
[root@test-huanqiu ~]# mysqladmin -u root -ptmppassword flush-privileges
[root@test-huanqiu ~]# mysqladmin -u root -ptmppassword flush-status
[root@test-huanqiu ~]# mysqladmin -u root -ptmppassword flush-tables
[root@test-huanqiu ~]# mysqladmin -u root -ptmppassword flush-threads

18）mysqladmin 执行kill 进程：
[root@test-huanqiu ~]# mysqladmin -uroot -p processlist
[root@test-huanqiu ~]# mysqladmin -uroot -p kill idnum

19）停止和启动MySQL replication on a slave server
[root@test-huanqiu ~]# mysqladmin -u root -p stop-slave
[root@test-huanqiu ~]# mysqladmin -u root -p start-slave

20）同时执行多个命令
[root@test-huanqiu ~]# mysqladmin -u root -p process status version
</code></pre>]]></content>
      
        <categories>
            
            <category> Mysql </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Nginx配置文件nginx.conf中文详解]]></title>
      <url>http://yoursite.com/2016/03/11/Nginx%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6nginx.conf%E4%B8%AD%E6%96%87%E8%AF%A6%E8%A7%A3/</url>
      <content type="html"><![CDATA[<p>Nginx是一款面向性能设计的HTTP服务器，相较于Apache、lighttpd具有占有内存少，稳定性高等优势。<br>Nginx安装完毕后，会有响应的安装目录，安装目录里nginx.conf为nginx的主配置文件，ginx主配置文件分为4部分，main（全局配置）、server（主机设置）、upstream（负载均衡服务器设）和location（URL匹配特定位置的设置），这四者关系为：server继承main，location继承server，upstream既不会继承其他设置也不会被继承。</p>
<a id="more"></a>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div></pre></td><td class="code"><pre><div class="line">#定义Nginx运行的用户和用户组</div><div class="line">user www www;</div><div class="line"></div><div class="line">#nginx进程数，建议设置为等于CPU总核心数。</div><div class="line">worker_processes 8;</div><div class="line"></div><div class="line">#全局错误日志定义类型，[ debug | info | notice | warn | error | crit ]</div><div class="line">error_log /var/log/nginx/error.log info;</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">#进程文件</div><div class="line">pid /var/run/nginx.pid;</div><div class="line"></div><div class="line">#一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（系统的值ulimit -n）与nginx进程数相除，但是nginx分配请求并不均匀，所以建议与ulimit -n的值保持一致。</div><div class="line">worker_rlimit_nofile 65535;</div><div class="line"></div><div class="line">#工作模式与连接数上限</div><div class="line">events</div><div class="line">&#123;</div><div class="line">#参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型是Linux 2.6以上版本内核中的高性能网络I/O模型，如果跑在FreeBSD上面，就用kqueue模型。</div><div class="line">use epoll;</div><div class="line">#单个进程最大连接数（最大连接数=连接数*进程数）</div><div class="line">worker_connections 65535;</div><div class="line">&#125;</div><div class="line"></div><div class="line">#设定http服务器</div><div class="line">http</div><div class="line">&#123;</div><div class="line">include mime.types; #文件扩展名与文件类型映射表</div><div class="line">default_type application/octet-stream; #默认文件类型</div><div class="line">#charset utf-8; #默认编码</div><div class="line">server_names_hash_bucket_size 128; #服务器名字的hash表大小</div><div class="line">client_header_buffer_size 32k; #上传文件大小限制</div><div class="line">large_client_header_buffers 4 64k; #设定请求缓</div><div class="line">client_max_body_size 8m; #设定请求缓</div><div class="line">sendfile on; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。</div><div class="line">autoindex on; #开启目录列表访问，合适下载服务器，默认关闭。</div><div class="line">tcp_nopush on; #防止网络阻塞</div><div class="line">tcp_nodelay on; #防止网络阻塞</div><div class="line">keepalive_timeout 120; #长连接超时时间，单位是秒</div><div class="line"></div><div class="line">#FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。</div><div class="line">fastcgi_connect_timeout 300;</div><div class="line">fastcgi_send_timeout 300;</div><div class="line">fastcgi_read_timeout 300;</div><div class="line">fastcgi_buffer_size 64k;</div><div class="line">fastcgi_buffers 4 64k;</div><div class="line">fastcgi_busy_buffers_size 128k;</div><div class="line">fastcgi_temp_file_write_size 128k;</div><div class="line"></div><div class="line">#gzip模块设置</div><div class="line">gzip on; #开启gzip压缩输出</div><div class="line">gzip_min_length 1k; #最小压缩文件大小</div><div class="line">gzip_buffers 4 16k; #压缩缓冲区</div><div class="line">gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0）</div><div class="line">gzip_comp_level 2; #压缩等级</div><div class="line">gzip_types text/plain application/x-javascript text/css application/xml;</div><div class="line">#压缩类型，默认就已经包含text/html，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。</div><div class="line">gzip_vary on;</div><div class="line">#limit_zone crawler $binary_remote_addr 10m; #开启限制IP连接数的时候需要使用</div><div class="line"></div><div class="line">upstream blog.ha97.com &#123;</div><div class="line">#upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。</div><div class="line">server 192.168.80.121:80 weight=3;</div><div class="line">server 192.168.80.122:80 weight=2;</div><div class="line">server 192.168.80.123:80 weight=3;</div><div class="line">&#125;</div><div class="line"></div><div class="line">#虚拟主机的配置</div><div class="line">server</div><div class="line">&#123;</div><div class="line">#监听端口</div><div class="line">listen 80;</div><div class="line">#域名可以有多个，用空格隔开</div><div class="line">server_name www.ha97.com ha97.com;</div><div class="line">index index.html index.htm index.php;</div><div class="line">root /data/www/ha97;</div><div class="line">location ~ .*\.(php|php5)?$</div><div class="line">&#123;</div><div class="line">fastcgi_pass 127.0.0.1:9000;</div><div class="line">fastcgi_index index.php;</div><div class="line">include fastcgi.conf;</div><div class="line">&#125;</div><div class="line">#图片缓存时间设置</div><div class="line">location ~ .*\.(gif|jpg|jpeg|png|bmp|swf)$</div><div class="line">&#123;</div><div class="line">expires 10d;</div><div class="line">&#125;</div><div class="line">#JS和CSS缓存时间设置</div><div class="line">location ~ .*\.(js|css)?$</div><div class="line">&#123;</div><div class="line">expires 1h;</div><div class="line">&#125;</div><div class="line">#日志格式设定</div><div class="line">log_format access &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos;</div><div class="line">&apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos;</div><div class="line">&apos;&quot;$http_user_agent&quot; $http_x_forwarded_for&apos;;</div><div class="line">#定义本虚拟主机的访问日志</div><div class="line">access_log /var/log/nginx/ha97access.log access;</div><div class="line"></div><div class="line">#对 &quot;/&quot; 启用反向代理</div><div class="line">location / &#123;</div><div class="line">proxy_pass http://127.0.0.1:88;</div><div class="line">proxy_redirect off;</div><div class="line">proxy_set_header X-Real-IP $remote_addr;</div><div class="line">#后端的Web服务器可以通过X-Forwarded-For获取用户真实IP</div><div class="line">proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</div><div class="line">#以下是一些反向代理的配置，可选。</div><div class="line">proxy_set_header Host $host;</div><div class="line">client_max_body_size 10m; #允许客户端请求的最大单文件字节数</div><div class="line">client_body_buffer_size 128k; #缓冲区代理缓冲用户端请求的最大字节数，</div><div class="line">proxy_connect_timeout 90; #nginx跟后端服务器连接超时时间(代理连接超时)</div><div class="line">proxy_send_timeout 90; #后端服务器数据回传时间(代理发送超时)</div><div class="line">proxy_read_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时)</div><div class="line">proxy_buffer_size 4k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小</div><div class="line">proxy_buffers 4 32k; #proxy_buffers缓冲区，网页平均在32k以下的设置</div><div class="line">proxy_busy_buffers_size 64k; #高负荷下缓冲大小（proxy_buffers*2）</div><div class="line">proxy_temp_file_write_size 64k;</div><div class="line">#设定缓存文件夹大小，大于这个值，将从upstream服务器传</div><div class="line">&#125;</div><div class="line"></div><div class="line">#设定查看Nginx状态的地址</div><div class="line">location /NginxStatus &#123;</div><div class="line">stub_status on;</div><div class="line">access_log on;</div><div class="line">auth_basic &quot;NginxStatus&quot;;</div><div class="line">auth_basic_user_file conf/htpasswd;</div><div class="line">#htpasswd文件的内容可以用apache提供的htpasswd工具来产生。</div><div class="line">&#125;</div><div class="line"></div><div class="line">#本地动静分离反向代理配置</div><div class="line">#所有jsp的页面均交由tomcat或resin处理</div><div class="line">location ~ .(jsp|jspx|do)?$ &#123;</div><div class="line">proxy_set_header Host $host;</div><div class="line">proxy_set_header X-Real-IP $remote_addr;</div><div class="line">proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</div><div class="line">proxy_pass http://127.0.0.1:8080;</div><div class="line">&#125;</div><div class="line">#所有静态文件由nginx直接读取不经过tomcat或resin</div><div class="line">location ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt|pdf|xls|mp3|wma)$</div><div class="line">&#123; expires 15d; &#125;</div><div class="line">location ~ .*.(js|css)?$</div><div class="line">&#123; expires 1h; &#125;</div><div class="line">&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>]]></content>
      
        <categories>
            
            <category> nginx </category>
            
        </categories>
        
        
        <tags>
            
            <tag> nginx </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Iptables防火墙规则使用梳理]]></title>
      <url>http://yoursite.com/2016/02/25/Iptables%E9%98%B2%E7%81%AB%E5%A2%99%E8%A7%84%E5%88%99%E4%BD%BF%E7%94%A8%E6%A2%B3%E7%90%86/</url>
      <content type="html"><![CDATA[<p>iptables是组成Linux平台下的包过滤防火墙，与大多数的Linux软件一样，这个包过滤防火墙是免费的，它可以代替昂贵的商业防火墙解决方案，完成封包过滤、封包重定向和网络地址转换(NAT)等功能。在日常Linux运维工作中，经常会设置iptables防火墙规则，用来加固服务安全。以下对iptables的规则使用做了总结性梳理：</p>
<h2 id="iptables相关概念"><a href="#iptables相关概念" class="headerlink" title="iptables相关概念"></a>iptables相关概念</h2><p>###　规则概念<br><code>规则（rules）</code>其实就是网络管理员的预定义的条件，规则一般定义为’如果数据包’符合这样的条件，就这样处理这个数据包”。规则存储在内核空间的信息包过滤表中，这些规则分别指定了源地址、目的地址、传输协议（如TCP、UDP、ICMP）和服务类型（如HTTP、FTP和SMTP）等.<br>当数据包与规则匹配时，iptables就根据规则所定义的方法来处理这些数据包，如放行(accept),拒绝(reject)和丢弃(drop)等。配置防火墙的主要工作是添加,修改和删除等规则。</p>
<a id="more"></a>
<p>其中：<br><code>匹配（match）</code>：符合指定的条件，比如指定的 IP 地址和端口。<br><code>丢弃（drop）</code>：当一个包到达时，简单地丢弃，不做其它任何处理。<br><code>接受（accept</code>）：和丢弃相反，接受这个包，让这个包通过。<br><code>拒绝（reject）</code>：和丢弃相似，但它还会向发送这个包的源主机发送错误消息。这个错误消息可以指定，也可以自动产生。<br><code>目标（target）</code>：指定的动作，说明如何处理一个包，比如：丢弃，接受，或拒绝。<br><code>跳转（jump）</code>：和目标类似，不过它指定的不是一个具体的动作，而是另一个链，表示要跳转到那个链上。<br><code>规则（rule）</code>：一个或多个匹配及其对应的目标。</p>
<h3 id="iptables和netfilter的关系"><a href="#iptables和netfilter的关系" class="headerlink" title="iptables和netfilter的关系"></a>iptables和netfilter的关系</h3><p>Iptables和netfilter的关系是一个很容易让人搞不清的问题。很多的知道iptables却不知道netfilter。其实iptables只是Linux防火墙的管理工具而已，位于/sbin/iptables。真正实现防火墙功能的是 netfilter，它是Linux内核中实现包过滤的内部结构。</p>
<h3 id="iptables的规则表和链"><a href="#iptables的规则表和链" class="headerlink" title="iptables的规则表和链"></a>iptables的规则表和链</h3><p><code>表（tables）</code>：提供特定的功能，iptables内置了4个表，即<code>filter</code>表、<code>nat</code>表、<code>mangle</code>表和<code>raw</code>表，分别用于实现<code>包过滤</code>，<code>网络地址转换</code>、<code>包重构(修改)</code>和<code>数据跟踪处理</code>。</p>
<p><code>链（chains）</code>：是数据包传播的路径，每一条链其实就是众多规则的一个检查清单，每一条链中可以有一条或数条规则。当一个数据包到达一个链时，iptables就会从链中第一条规则开始检查，看该数据包是否满足规则所定义的条件。<br>如果满足，系统就会根据该条规则所定义的方法处理该数据包；否则iptables将继续检查下一条规则，如果该数据包不符合链中任一条规则，iptables就会根据该链预先定 义的默认策略来处理数据包。</p>
<p>Iptables采用“表”和“链”的分层结构，在Linux中现在是四张表五个链。下面罗列一下这四张表和五个链（注意一定要明白这些表和链的关系及作用）。<br><img src="http://static.zybuluo.com/BruceTang/iuux4tvhqmrqq9xcymn2lcz2/image_1bfhd930f1koa1kh012htjg52hep.png" alt="image_1bfhd930f1koa1kh012htjg52hep.png-77kB"></p>
<h4 id="规则表："><a href="#规则表：" class="headerlink" title="规则表："></a>规则表：</h4><p>1.filter表——三个链：INPUT、FORWARD、OUTPUT<br>作用：过滤数据包 内核模块：iptables_filter.<br>2.Nat表——三个链：PREROUTING、POSTROUTING、OUTPUT<br>作用：用于网络地址转换（IP、端口） 内核模块：iptable_nat<br>3.Mangle表——五个链：PREROUTING、POSTROUTING、INPUT、OUTPUT、FORWARD<br>作用：修改数据包的服务类型、TTL、并且可以配置路由实现QOS内核模块：iptable_mangle(别看这个表这么麻烦，咱们设置策略时几乎都不会用到它)<br>4.Raw表——两个链：OUTPUT、PREROUTING<br>作用：决定数据包是否被状态跟踪机制处理 内核模块：iptable_raw</p>
<h4 id="规则链："><a href="#规则链：" class="headerlink" title="规则链："></a>规则链：</h4><p>1.INPUT——进来的数据包应用此规则链中的策略<br>2.OUTPUT——外出的数据包应用此规则链中的策略<br>3.FORWARD——转发数据包时应用此规则链中的策略<br>4.PREROUTING——对数据包作路由选择前应用此链中的规则<br>（记住！所有的数据包进来的时侯都先由这个链处理）<br>5.POSTROUTING——对数据包作路由选择后应用此链中的规则<br>（所有的数据包出来的时侯都先由这个链处理）</p>
<p>管理和设置iptables规则：<br><img src="http://static.zybuluo.com/BruceTang/4eqk1tjwwikkrfncl6h0l4r2/image_1bfhdca29b13148g1g84bt0qup16.png" alt="image_1bfhdca29b13148g1g84bt0qup16.png-229.9kB"><br><img src="http://static.zybuluo.com/BruceTang/5nz6rz5rjzlhc68jk34nwuzi/image_1bfhdci5673tvtj7pe775lr81j.png" alt="image_1bfhdci5673tvtj7pe775lr81j.png-351.9kB"></p>
<h2 id="iptables传输数据包的过程"><a href="#iptables传输数据包的过程" class="headerlink" title="iptables传输数据包的过程"></a>iptables传输数据包的过程</h2><p><img src="http://static.zybuluo.com/BruceTang/dzlg27mgv0hvquh54x1308f8/image_1bfhdephf1fh01b961vl11p9t1elh20.png" alt="image_1bfhdephf1fh01b961vl11p9t1elh20.png-231.6kB"></p>
<p>   1）当一个数据包进入网卡时，它首先进入PREROUTING链，内核根据数据包目的IP判断是否需要转送出去。 </p>
<p>   2）如果数据包就是进入本机的，它就会沿着图向下移动，到达INPUT链。数据包到了INPUT链后，任何进程都会收到它。本机上运行的程序可以发送数据包，这些数据包会经过OUTPUT链，然后到达POSTROUTING链输出。 </p>
<p>   3）如果数据包是要转发出去的，且内核允许转发，数据包就会如图所示向右移动，经过FORWARD链，然后到达POSTROUTING链输出。</p>
<p>如果还是不清楚数据包经过iptables的基本流程，再看下面更具体的流程图：<br><img src="http://static.zybuluo.com/BruceTang/vh3t1s0moko7tjlmdvs516a9/image_1bfhdfjdd1tb1guko4p1c6kl0p2d.png" alt="image_1bfhdfjdd1tb1guko4p1c6kl0p2d.png-114.2kB"><br>从图中可将iptables数据包报文的处理过程分为三种类型：</p>
<h3 id="目的为本机的报文"><a href="#目的为本机的报文" class="headerlink" title="目的为本机的报文"></a>目的为本机的报文</h3><p>报文以本机为目的地址时，其经过iptables的过程为：<br>1.数据包从network到网卡<br>2.网卡接收到数据包后，进入raw表的PREROUTING链。这个链的作用是在连接跟踪之前处理报文，能够设置一条连接不被连接跟踪处理。(注：不要在raw表上添加其他规则)<br>3.如果设置了连接跟踪，则在这条连接上处理。<br>4.经过raw处理后，进入mangle表的PREROUTING链。这个链主要是用来修改报文的TOS、TTL以及给报文设置特殊的MARK。(注：通常mangle表以给报文设置MARK为主，在这个表里面，千万不要做过滤/NAT/伪装这类的事情)<br>5.进入nat表的PREROUTING链。这个链主要用来处理 DNAT，应该避免在这条链里面做过滤，否则可能造成有些报文会漏掉。(注：它只用来完成源/目的地址的转换)<br>6.进入路由决定数据包的处理。例如决定报文是上本机还是转发或者其他地方。(注：此处假设报文交给本机处理)<br>7.进入mangle表的 INPUT 链。在把报文实际送给本机前，路由之后，我们可以再次修改报文。<br>8.进入filter表的 INPUT 链。在这儿我们对所有送往本机的报文进行过滤，要注意所有收到的并且目的地址为本机的报文都会经过这个链，而不管哪个接口进来的或者它往哪儿去。</p>
<ol>
<li>进过规则过滤，报文交由本地进程或者应用程序处理，例如服务器或者客户端程序。<h3 id="本地主机发出报文"><a href="#本地主机发出报文" class="headerlink" title="本地主机发出报文"></a>本地主机发出报文</h3>数据包由本机发出时，其经过iptables的过程为：<br>1.本地进程或者应用程序（例如服务器或者客户端程序）发出数据包。<br>2.路由选择，用哪个源地址以及从哪个接口上出去，当然还有其他一些必要的信息。<br>3.进入raw表的OUTPUT链。这里是能够在连接跟踪生效前处理报文的点，在这可以标记某个连接不被连接跟踪处理。<br>4.连接跟踪对本地的数据包进行处理。<br>5.进入 mangle 表的 OUTPUT 链，在这里我们可以修改数据包，但不要做过滤(以避免副作用)。<br>6.进入 nat 表的 OUTPUT 链，可以对防火墙自己发出的数据做目的NAT(DNAT) 。<br>7.进入 filter 表的 OUTPUT 链，可以对本地出去的数据包进行过滤。<br>8.再次进行路由决定，因为前面的 mangle 和 nat 表可能修改了报文的路由信息。<br>9.进入 mangle 表的 POSTROUTING 链。这条链可能被两种报文遍历，一种是转发的报文，另外就是本机产生的报文。<br>10.进入 nat 表的 POSTROUTING 链。在这我们做源 NAT（SNAT），建议你不要在这做报文过滤，因为有副作用。即使你设置了默认策略，一些报文也有可能溜过去。<br>11.进入出去的网络接口。<h3 id="转发报文"><a href="#转发报文" class="headerlink" title="转发报文"></a>转发报文</h3>报文经过iptables进入转发的过程为：<br>1.数据包从network到网卡<br>2.网卡接收到数据包后，进入raw表的PREROUTING链。这个链的作用是在连接跟踪之前处理报文，能够设置一条连接不被连接跟踪处理。(注：不要在raw表上添加其他规则)<br>3.如果设置了连接跟踪，则在这条连接上处理。<br>4.经过raw处理后，进入mangle表的PREROUTING链。这个链主要是用来修改报文的TOS、TTL以及给报文设置特殊的MARK。(注：通常mangle表以给报文设置MARK为主，在这个表里面，千万不要做过滤/NAT/伪装这类的事情)<br>5.进入nat表的PREROUTING链。这个链主要用来处理 DNAT，应该避免在这条链里面做过滤，否则可能造成有些报文会漏掉。(注：它只用来完成源/目的地址的转换)<br>6.进入路由决定数据包的处理。例如决定报文是上本机还是转发或者其他地方。(注：此处假设报文进行转发)<br>7.进入 mangle 表的 FORWARD 链，这里也比较特殊，这是在第一次路由决定之后，在进行最后的路由决定之前，我们仍然可以对数据包进行某些修改。<br>8.进入 filter 表的 FORWARD 链，在这里我们可以对所有转发的数据包进行过滤。需要注意的是：经过这里的数据包是转发的，方向是双向的。<br>9.进入 mangle 表的 POSTROUTING 链，到这里已经做完了所有的路由决定，但数据包仍然在本地主机，我们还可以进行某些修改。<br>10.进入 nat 表的 POSTROUTING 链，在这里一般都是用来做 SNAT ，不要在这里进行过滤。<br>11.进入出去的网络接口。</li>
</ol>
<h2 id="iptables规则设置用法"><a href="#iptables规则设置用法" class="headerlink" title="iptables规则设置用法"></a>iptables规则设置用法</h2><h3 id="iptables的基本语法格式"><a href="#iptables的基本语法格式" class="headerlink" title="iptables的基本语法格式"></a>iptables的基本语法格式</h3><p>iptables [-t 表名] 命令选项 ［链名］ ［条件匹配］ ［-j 目标动作或跳转］<br>说明：<br>表名、链名：用于指定iptables命令所操作的表和链；<br>命令选项：用于指定管理iptables规则的方式（比如：插入、增加、删除、查看等；<br>条件匹配：用于指定对符合什么样 条件的数据包进行处理；<br>目标动作或跳转：用于指定数据包的处理方式（比如允许通过、拒绝、丢弃、跳转（Jump）给其它链处理。</p>
<h3 id="iptables命令的管理控制选项"><a href="#iptables命令的管理控制选项" class="headerlink" title="iptables命令的管理控制选项"></a>iptables命令的管理控制选项</h3><p>-A 在指定链的末尾添加（append）一条新的规则<br>-D 删除（delete）指定链中的某一条规则，可以按规则序号和内容删除<br>-I 在指定链中插入（insert）一条新的规则，默认在第一行添加<br>-R 修改、替换（replace）指定链中的某一条规则，可以按规则序号和内容替换<br>-L 列出（list）指定链中所有的规则进行查看（默认是filter表，如果列出nat表的规则需要添加-t，即iptables -t nat -L）<br>-E 重命名用户定义的链，不改变链本身<br>-F 清空（flush）<br>-N 新建（new-chain）一条用户自己定义的规则链<br>-X 删除指定表中用户自定义的规则链（delete-chain）<br>-P 设置指定链的默认策略（policy）<br>-Z 将所有表的所有链的字节和数据包计数器清零<br>-n 使用数字形式（numeric）显示输出结果<br>-v 查看规则表详细信息（verbose）的信息<br>-V 查看版本(version)<br>-h 获取帮助（help）</p>
<h3 id="防火墙处理数据包的四种方式ACCEPT-允许数据包通过"><a href="#防火墙处理数据包的四种方式ACCEPT-允许数据包通过" class="headerlink" title="防火墙处理数据包的四种方式ACCEPT 允许数据包通过"></a>防火墙处理数据包的四种方式ACCEPT 允许数据包通过</h3><p>DROP 直接丢弃数据包，不给任何回应信息<br>REJECT 拒绝数据包通过，必要时会给数据发送端一个响应的信息。<br>LOG在/var/log/messages文件中记录日志信息，然后将数据包传递给下一条规则</p>
<h3 id="iptables防火墙规则的保存与恢复"><a href="#iptables防火墙规则的保存与恢复" class="headerlink" title="iptables防火墙规则的保存与恢复"></a>iptables防火墙规则的保存与恢复</h3><p>iptables-save把规则保存到文件中，再由目录rc.d下的脚本（/etc/rc.d/init.d/iptables）自动装载<br>使用命令iptables-save来保存规则。<br>一般用：<br>iptables-save &gt; /etc/sysconfig/iptables<br>生成保存规则的文件/etc/sysconfig/iptables，<br>也可以用：<br>service iptables save<br>它能把规则自动保存在/etc/sysconfig/iptables中。<br>当计算机启动时，rc.d下的脚本将用命令iptables-restore调用这个文件，从而就自动恢复了规则。</p>
<h3 id="iptables防火墙常用的策略梳理"><a href="#iptables防火墙常用的策略梳理" class="headerlink" title="iptables防火墙常用的策略梳理"></a>iptables防火墙常用的策略梳理</h3><p>设置默认链策略<br>ptables的filter表中有三种链：INPUT, FORWARD和OUTPUT。<br>默认的链策略是ACCEPT，可以将它们设置成DROP，如下命令就将所有包都拒绝了：<br>iptables -P INPUT DROP<br>iptables -P FORWARD DROP<br>iptables -P OUTPUT DROP</p>
<hr>
<p>其实，在运维工作中最常用的两个规则就是白名单规则和NAT转发规则：</p>
<h4 id="白名单规则"><a href="#白名单规则" class="headerlink" title="白名单规则"></a>白名单规则</h4><p>在linux终端命令行里操作时，如果不是默认的filter表时，需要指定表；<br>如果在/etc/sysconfig/iptables文件里设置，就在对应表的配置区域内设置；<br>上面两种方式设置效果是一样的！<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">比如开通本机的22端口，允许192.168.1.0网段的服务器访问（-t filter表配置可以省略，默认就是这种表的配置）</div><div class="line"></div><div class="line">[root@linux-node1 ~]# iptables -A INPUT -s 192.168.1.0/24 -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT</div><div class="line">或者</div><div class="line">[root@linux-node1 ~]# iptables -t filter -A INPUT -s 192.168.1.0/24 -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">开通本机的80端口，只允许192.168.1.150机器访问（32位掩码表示单机，单机指定时可以不加掩码）</div><div class="line">[root@linux-node1 ~]# iptables -t filter -A INPUT -s 192.168.1.150/32 -p tcp -m state --state NEW -m tcp --dport 80 -j ACCEPT</div></pre></td></tr></table></figure>
<p>然后保存规则，重启iptables<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[root@linux-node1 ~]# service iptables save</div><div class="line">[root@linux-node1 ~]# service iptables restart</div></pre></td></tr></table></figure></p>
<p>或者在/etc/sysconfig/iptables文件里设置如下（其实上面在终端命令行里设置并save和restart防火墙后，就会自动保存规则到/etc/sysconfig/iptables这个文件中的）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">[root@bastion-IDC ~]# cat /etc/sysconfig/iptables</div><div class="line">......</div><div class="line">*filter</div><div class="line">:INPUT ACCEPT [442620:173026884]</div><div class="line">:FORWARD ACCEPT [118911:23993940]</div><div class="line">:OUTPUT ACCEPT [8215384:539509656]</div><div class="line">-A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT </div><div class="line">-A INPUT -p icmp -j ACCEPT </div><div class="line">-A INPUT -i lo -j ACCEPT </div><div class="line">-A INPUT -s 192.168.1.0/24 -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT</div><div class="line">-A INPUT -s 192.168.1.150/32 -p tcp -m state --state NEW -m tcp --dport 80 -j ACCEPT</div><div class="line"></div><div class="line">[root@bastion-IDC ~]# service iptables restart</div></pre></td></tr></table></figure></p>
<h4 id="NAT转发设置"><a href="#NAT转发设置" class="headerlink" title="NAT转发设置"></a>NAT转发设置</h4><p>比如访问本机（192.168.1.7）的8088端口转发到192.168.1.160的80端口；访问本机的33066端口转发到192.168.1.161的3306端口<br>准备工作：<br>本机打开ip_forword路由转发功能；192.168.1.160/161的内网网关要和本机网关一致！如果没有内网网关，就将网关设置成本机内网ip，并且关闭防火墙（防火墙要是打开了，就设置对应端口允许本机访问）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line">[root@kvm-server conf]# iptables -t nat -A PREROUTING -p tcp -m tcp --dport 8088 -j DNAT --to-destination 192.168.1.160:80</div><div class="line">[root@kvm-server conf]# iptables -t nat -A POSTROUTING -d 192.168.1.160/32 -p tcp -m tcp --sport 80 -j SNAT --to-source 192.168.1.7</div><div class="line">[root@kvm-server conf]# iptables -t filter -A INPUT -p tcp -m state --state NEW -m tcp --dport 8088 -j ACCEPT</div><div class="line"></div><div class="line">[root@kvm-server conf]# iptables -t nat -A PREROUTING -p tcp -m tcp --dport 33066 -j DNAT --to-destination 192.168.1.161:3306</div><div class="line">[root@kvm-server conf]# iptables -t nat -A POSTROUTING -d 192.168.1.161/32 -p tcp -m tcp --sport 3306 -j SNAT --to-source 192.168.1.7</div><div class="line">[root@kvm-server conf]# iptables -t filter -A INPUT -p tcp -m state --state NEW -m tcp --dport 33066 -j ACCEPT</div><div class="line"></div><div class="line">[root@kvm-server conf]# service iptables save</div><div class="line">[root@kvm-server conf]# service iptables restart</div><div class="line"></div><div class="line">或者在/etc/sysconfig/iptables文件里设置如下</div><div class="line">[root@bastion-IDC ~]# cat /etc/sysconfig/iptables</div><div class="line">......</div><div class="line">*nat</div><div class="line">:PREROUTING ACCEPT [60:4250]</div><div class="line">:INPUT ACCEPT [31:1973]</div><div class="line">:OUTPUT ACCEPT [3:220]</div><div class="line">:POSTROUTING ACCEPT [3:220]</div><div class="line">-A PREROUTING -p tcp -m tcp --dport 8088 -j DNAT --to-destination 192.168.1.160:80                              //PREROUTING规则都放在上面</div><div class="line">-A PREROUTING -p tcp -m tcp --dport 33066 -j DNAT --to-destination 192.168.1.161:3306</div><div class="line">-A POSTROUTING -d 192.168.1.160/32 -p tcp -m tcp --sport 80 -j SNAT --to-source 192.168.1.7             //POSTROUTING规则都放在下面</div><div class="line">-A POSTROUTING -d 192.168.1.161/32 -p tcp -m tcp --sport 3306 -j SNAT --to-source 192.168.1.7</div><div class="line">.....</div><div class="line">*filter</div><div class="line">:INPUT ACCEPT [16:7159]</div><div class="line">:FORWARD ACCEPT [0:0]</div><div class="line">:OUTPUT ACCEPT [715:147195]</div><div class="line">-A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT</div><div class="line">-A INPUT -p icmp -j ACCEPT</div><div class="line">-A INPUT -i lo -j ACCEPT</div><div class="line">-A INPUT -p tcp -m state --state NEW -m tcp --dport 8088 -j ACCEPT</div><div class="line">-A INPUT -p tcp -m state --state NEW -m tcp --dport 33066 -j ACCEPT</div><div class="line">.....</div><div class="line">[root@bastion-IDC ~]# service iptables restart</div><div class="line"></div><div class="line">[root@bastion-IDC ~]# iptables -L                      //列出设置的规则，默认列出的是filter表下的规则</div><div class="line">[root@bastion-IDC ~]# iptables -L -t nat            //如果列出nat表下规则，就加-t参数</div></pre></td></tr></table></figure></p>
<p>删除INPUT链的第一条规则<br><code>iptables -D INPUT 1</code></p>
<p>拒绝进入防火墙的所有ICMP协议数据包<br><code>iptables -I INPUT -p icmp -j REJECT</code></p>
<p>允许防火墙转发除ICMP协议以外的所有数据包<br><code>iptables -A FORWARD -p ! icmp -j ACCEPT</code><br>说明：使用“！”可以将条件取反</p>
<p>拒绝转发来自192.168.1.10主机的数据，允许转发来自192.168.0.0/24网段的数据<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">iptables -A FORWARD -s 192.168.1.11 -j REJECT </div><div class="line">iptables -A FORWARD -s 192.168.0.0/24 -j ACCEPT</div><div class="line"></div><div class="line">说明：注意一定要把拒绝的放在前面不然就不起作用了！</div></pre></td></tr></table></figure></p>
<p>丢弃从外网接口（eth1）进入防火墙本机的源地址为私网地址的数据包<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">iptables -A INPUT -i eth1 -s 192.168.0.0/16 -j DROP </div><div class="line">iptables -A INPUT -i eth1 -s 172.16.0.0/12 -j DROP </div><div class="line">iptables -A INPUT -i eth1 -s 10.0.0.0/8 -j DROP</div></pre></td></tr></table></figure></p>
<p>封堵网段（192.168.1.0/24），两小时后解封<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"># iptables -I INPUT -s 10.20.30.0/24 -j DROP </div><div class="line"># iptables -I FORWARD -s 10.20.30.0/24 -j DROP </div><div class="line"># at now 2 hours at&gt; iptables -D INPUT 1 at&gt; iptables -D FORWARD 1</div><div class="line">说明：这个策略可以借助crond计划任务来完成，就再好不过了</div></pre></td></tr></table></figure></p>
<p>只允许管理员从202.13.0.0/16网段使用SSH远程登录防火墙主机<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">iptables -A INPUT -s 202.13.0.0/16 -p tcp -m tcp -m state --state NEW --dport 22  -j ACCEPT </div><div class="line"></div><div class="line">说明：这个用法比较适合对设备进行远程管理时使用，比如位于分公司中的SQL服务器需要被总公司的管理员管理时</div></pre></td></tr></table></figure></p>
<p>通常在服务器上会对某一服务端口的访问做白名单限制，比如（其他端口设置和下面一致）：<br>运行本机的3306端口（mysql服务）被访问<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">iptables -A INPUT -p tcp -m tcp -m state --state NEW --dport 3306 -j ACCEPT </div><div class="line">或者只运行本机的3306端口被192.168.1.0/24网段机器访问</div><div class="line">iptables -A INPUT -s 192.168.1.0/24 -p tcp -m tcp -m state --state NEW --dport 3306 -j ACCEPT</div></pre></td></tr></table></figure></p>
<p>允许本机开放从TCP端口20-1024提供的应用服务<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">iptables -A INPUT -p tcp -m tcp -m state --state NEW --dport 20:1024 -j ACCEPT</div></pre></td></tr></table></figure></p>
<p>允许转发来自192.168.0.0/24局域网段的DNS解析请求数据包<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">iptables -A FORWARD -s 192.168.0.0/24 -p udp --dport 53 -j ACCEPT </div><div class="line">iptables -A FORWARD -d 192.168.0.0/24 -p udp --sport 53 -j ACCEPT</div></pre></td></tr></table></figure></p>
<h4 id="屏蔽指定的IP地址"><a href="#屏蔽指定的IP地址" class="headerlink" title="屏蔽指定的IP地址"></a>屏蔽指定的IP地址</h4><p>以下规则将屏蔽BLOCK_THIS_IP所指定的IP地址访问本地主机：<br>BLOCK_THIS_IP=”x.x.x.x”<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">iptables -A INPUT -i eth0 -s &quot;$BLOCK_THIS_IP&quot; -j DROP</div><div class="line">(或者仅屏蔽来自该IP的TCP数据包）</div><div class="line">iptables -A INPUT -i eth0 -p tcp -s &quot;$BLOCK_THIS_IP&quot; -j DROP</div></pre></td></tr></table></figure></p>
<p>屏蔽环回(loopback)访问<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">iptables -A INPUT -i lo -j DROP</div><div class="line">iptables -A OUTPUT -o lo -j DROP</div></pre></td></tr></table></figure></p>
<p>屏蔽来自外部的ping，即禁止外部机器ping本机<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">iptables -A INPUT -p icmp --icmp-type echo-request -j DROP</div><div class="line">iptables -A OUTPUT -p icmp --icmp-type echo-reply -j DROP</div></pre></td></tr></table></figure></p>
<p>屏蔽从本机ping外部主机，禁止本机ping外部机器<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">iptables -A OUTPUT -p icmp --icmp-type echo-request -j DROP</div><div class="line">iptables -A INPUT -p icmp --icmp-type echo-reply -j DROP</div></pre></td></tr></table></figure></p>
<p>禁止其他主机ping本机，但是允许本机ping其他主机（禁止别人ping本机，也可以使用echo 1 &gt; /proc/sys/net/ipv4/icmp_echo_ignore_all）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">iptables -I INPUT -p icmp --icmp-type echo-request -j DROP </div><div class="line">iptables -I INPUT -p icmp --icmp-type echo-reply -j ACCEPT </div><div class="line">iptables -I INPUT -p icmp --icmp-type destination-Unreachable -j ACCEPT</div></pre></td></tr></table></figure></p>
<p>禁止转发来自MAC地址为00：0C：29：27：55：3F的和主机的数据包<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">iptables -A FORWARD -m mac --mac-source 00:0c:29:27:55:3F -j DROP</div><div class="line"></div><div class="line">说明：iptables中使用“-m 模块关键字”的形式调用显示匹配。咱们这里用“-m mac –mac-source”来表示数据包的源MAC地址</div></pre></td></tr></table></figure></p>
<p>允许防火墙本机对外开放TCP端口20、21、25、110以及被动模式FTP端口1250-1280<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">iptables -A INPUT -p tcp -m multiport --dport 20,21,25,110,1250:1280 -j ACCEPT</div><div class="line"></div><div class="line">注意：这里用“-m multiport --dport”来指定多个目的端口</div><div class="line">iptables -A INPUT -p tcp -m tcp -m multiport --dports 22,80,443,1250-1280 -m state --state NEW -j ACCEPT</div><div class="line">也可以将这几个端口分开设置多行：</div><div class="line">iptables -A INPUT -p tcp -m tcp -m state --state NEW --dport 22 -j ACCEPT</div><div class="line">iptables -A INPUT -p tcp -m tcp -m state --state NEW --dport 80 -j ACCEPT</div><div class="line">iptables -A INPUT -p tcp -m tcp -m state --state NEW --dport 443 -j ACCEPT</div><div class="line">iptables -A INPUT -p tcp -m tcp -m state --state NEW --dport 1250:1280 -j ACCEPT</div></pre></td></tr></table></figure></p>
<p>禁止转发源IP地址为192.168.1.20-192.168.1.99的TCP数据包<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">iptables -A FORWARD -p tcp -m iprange --src-range 192.168.1.20-192.168.1.99 -j DROP</div><div class="line">说明：</div><div class="line">此处用“-m iprange --src-range”指定IP范围</div><div class="line">1）过滤源地址范围：</div><div class="line">iptables -A INPUT -m iprange --src-range 192.168.1.2-192.168.1.7 -j DROP</div><div class="line">2）过滤目标地址范围：</div><div class="line">iptables -A INPUT -m iprange --dst-range 192.168.1.2-192.168.1.7 -j DROP</div><div class="line">3）针对端口访问的过滤。下面表示除了192.168.1.5-192.168.1.10之间的ip能访问192.168.1.67机器的80端口以外，其他ip都不可以访问！</div><div class="line">iptables -A INPUT -d 192.168.1.67 -p tcp --dport 80 -m iprange --src-range 192.168.1.5-192.168.1.10 -j ACCEPT</div></pre></td></tr></table></figure></p>
<p>禁止转发与正常TCP连接无关的非–syn请求数据包<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">iptables -A FORWARD -m state --state NEW -p tcp ! --syn -j DROP</div><div class="line">说明：“-m state”表示数据包的连接状态，“NEW”表示与任何连接无关的</div></pre></td></tr></table></figure></p>
<p>拒绝访问防火墙的新数据包，但允许响应连接或与已有连接相关的数据包<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">iptables -A INPUT -p tcp -m state --state NEW -j DROP </div><div class="line">iptables -A INPUT -p tcp -m state --state ESTABLISHED,RELATED -j ACCEPT</div><div class="line">说明：“ESTABLISHED”表示已经响应请求或者已经建立连接的数据包，“RELATED”表示与已建立的连接有相关性的，比如FTP数据连接等</div></pre></td></tr></table></figure></p>
<h4 id="防止DoS攻击"><a href="#防止DoS攻击" class="headerlink" title="防止DoS攻击"></a>防止DoS攻击</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">iptables -A INPUT -p tcp --dport 80 -m limit --limit 25/minute --limit-burst 100 -j ACCEPT</div><div class="line">-m limit: 启用limit扩展，限制速度。</div><div class="line">--limit 25/minute: 允许最多每分钟25个连接</div><div class="line">--limit-burst 100: 当达到100个连接后，才启用上述25/minute限制</div><div class="line"></div><div class="line">--icmp-type 8 表示 Echo request——回显请求（Ping请求）。下面表示本机ping主机192.168.1.109时候的限速设置：</div><div class="line">iptables -I INPUT -d 192.168.1.109 -p icmp --icmp-type 8 -m limit --limit 3/minute --limit-burst 5 -j ACCEPT</div></pre></td></tr></table></figure>
<h4 id="允许路由"><a href="#允许路由" class="headerlink" title="允许路由"></a>允许路由</h4><p>如果本地主机有两块网卡，一块连接内网(eth0)，一块连接外网(eth1)，那么可以使用下面的规则将eth0的数据路由到eht1：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">iptables -A FORWARD -i eth0 -o eth1 -j ACCEPT</div></pre></td></tr></table></figure></p>
<p>IPtables中可以灵活的做各种网络地址转换（NAT）<br>网络地址转换主要有两种：SNAT和DNAT<br>1）SNAT是source network address translation的缩写，即源地址目标转换。<br>比如，多个PC机使用ADSL路由器共享上网，每个PC机都配置了内网IP。PC机访问外部网络的时候，路由器将数据包的报头中的源地址替换成路由器的ip，当外部网络的服务器比如网站web服务器接到访问请求的时候，它的日志记录下来的是路由器的ip地址，而不是pc机的内网ip，这是因为，这个服务器收到的数据包的报头里边的“源地址”，已经被替换了。所以叫做SNAT，基于源地址的地址转换</p>
<p>2）DNAT是destination network address translation的缩写，即目标网络地址转换。<br>典型的应用是，有个web服务器放在内网中，配置了内网ip，前端有个防火墙配置公网ip，互联网上的访问者使用公网ip来访问这个网站。<br>当访问的时候，客户端发出一个数据包，这个数据包的报头里边，目标地址写的是防火墙的公网ip，防火墙会把这个数据包的报头改写一次，将目标地址改写成web服务器的内网ip，然后再把这个数据包发送到内网的web服务器上。<br>这样，数据包就穿透了防火墙，并从公网ip变成了一个对内网地址的访问了。即DNAT，基于目标的网络地址转换</p>
<p>以下规则将会把本机192.168.1.17来自422端口的流量转发到22端口，这意味着来自422端口的SSH连接请求与来自22端口的请求等效。<br>1）启用DNAT转发<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">iptables -t nat -A PREROUTING -p tcp -d 192.168.1.17 --dport 422 -j DNAT --to-destination 192.168.1.17:22</div></pre></td></tr></table></figure></p>
<p>2）允许连接到422端口的请求<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">iptables -t filter -A INPUT -p tcp -m tcp -m state --state NEW --dport 422 -j ACCEPT</div></pre></td></tr></table></figure></p>
<p>3）保存规则<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># service iptables save</div><div class="line"># service iptables restart</div></pre></td></tr></table></figure></p>
<p>假设现在本机外网网关是58.68.250.1，那么把HTTP请求转发到内部的一台服务器192.168.1.20的8888端口上，规则如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">iptables -t nat -A PREROUTING -p tcp -i eth0 -d 58.68.250.1 --dport 8888 -j DNAT --to 192.168.1.20:80</div><div class="line">iptables -A FORWARD -p tcp -i eth0 -d 192.168.0.2 --dport 80 -j ACCEPT</div><div class="line">iptables -t filter -A INPUT -p tcp -m state --state NEW -m tcp --dport 80 -j ACCEPT</div><div class="line">service iptables save</div><div class="line">service iptables restart</div></pre></td></tr></table></figure></p>
<p>或者或本机内网ip是192.168.1.10，那么把HTTP请求转发到内部的一台服务器192.168.1.20的8888端口上，规则如下：<br>准备工作：本机打开ip_forword路由转发功能；192.168.1.20的内网网关要和本机网关保持一致！如果没有内网网关，就将网关地址设置成本机内网ip，并且关闭防火墙（防火墙要是打开了，就设置对应端口允许本机访问）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">iptables -t nat -A PREROUTING -p tcp -m tcp --dport 20022 -j DNAT --to-destination 192.168.1.150:22</div><div class="line">iptables -t nat -A POSTROUTING -d 192.168.1.150/32 -p tcp -m tcp --sport 22 -j SNAT --to-source 192.168.1.8</div><div class="line">iptables -t filter -A INPUT -p tcp -m state --state NEW -m tcp --dport 20022 -j ACCEPT</div><div class="line">service iptables save</div><div class="line">service iptables restart</div></pre></td></tr></table></figure></p>
<p>MASQUERADE，地址伪装，在iptables中有着和SNAT相近的效果，但也有一些区别：<br>1）使用SNAT的时候，出口ip的地址范围可以是一个，也可以是多个，例如：<br>1）如下命令表示把所有10.8.0.0网段的数据包SNAT成192.168.5.3的ip然后发出去<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">iptables -t nat -A POSTROUTING -s 10.8.0.0/255.255.255.0 -o eth0 -j SNAT --to-source 192.168.5.3</div></pre></td></tr></table></figure></p>
<p>2）如下命令表示把所有10.8.0.0网段的数据包SNAT成192.168.5.3/192.168.5.4/192.168.5.5等几个ip然后发出去<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">iptables -t nat -A POSTROUTING -s 10.8.0.0/255.255.255.0 -o eth0 -j SNAT --to-source 192.168.5.3-192.168.5.5</div></pre></td></tr></table></figure></p>
<p>这就是SNAT的使用方法，即可以NAT成一个地址，也可以NAT成多个地址。但是，对于SNAT，不管是几个地址，必须明确的指定要SNAT的ip<br>假如当前系统用的是ADSL动态拨号方式，那么每次拨号，出口ip192.168.5.3都会改变，而且改变的幅度很大，不一定是192.168.5.3到192.168.5.5范围内的地址。<br>这个时候如果按照现在的方式来配置iptables就会出现问题了，因为每次拨号后，服务器地址都会变化，而iptables规则内的ip是不会随着自动变化的，每次地址变化后都必须手工修改一次iptables，把规则里边的固定ip改成新的ip，这样是非常不好用的！</p>
<p>2）MASQUERADE就是针对上述场景而设计的，它的作用是，从服务器的网卡上，自动获取当前ip地址来做NAT。<br>比如下边的命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">iptables -t nat -A POSTROUTING -s 10.8.0.0/255.255.255.0 -o eth0 -j MASQUERADE</div></pre></td></tr></table></figure></p>
<p>如此配置的话，不用指定SNAT的目标ip了。<br>不管现在eth0的出口获得了怎样的动态ip，MASQUERADE会自动读取eth0现在的ip地址然后做SNAT出去<br>这样就实现了很好的动态SNAT地址转换</p>
<h2 id="运维实例设置："><a href="#运维实例设置：" class="headerlink" title="运维实例设置："></a>运维实例设置：</h2><p>1）限制本机的web服务器在周一不允许访问；<br>     新请求的速率不能超过100个每秒；<br>     web服务器包含了admin字符串的页面不允许访问：<br>     web 服务器仅允许响应报文离开本机；<br>设置如下：<br>周一不允许访问<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">iptables -A INPUT -p tcp --dport 80 -m time ! --weekdays Mon -j ACCEPT</div><div class="line">iptables -A OUTPUT -p tcp --dport 80 -m state --state ESTABLISHED -j ACCEPT</div></pre></td></tr></table></figure></p>
<p>新请求速率不能超过100个每秒<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">iptables -A INPUT -p tcp --dport 80 -m limit --limit 100/s -j ACCEPT</div></pre></td></tr></table></figure></p>
<p>web包含admin字符串的页面不允许访问，源端口：dport<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">iptables -A INPUT -p tcp --dport 80 -m string --algo bm --string &apos;admin&apos; -j REJECT</div></pre></td></tr></table></figure></p>
<p>web服务器仅允许响应报文离开主机,放行端口（目标端口）：sport<br>iptables -A OUTPUT -p tcp –dport 80 -m state –state ESTABLISHED -j ACCEPT</p>
<p>2)在工作时间，即周一到周五的8:30-18:00，开放本机的ftp服务给 192.168.1.0网络中的主机访问；<br>    数据下载请求的次数每分钟不得超过 5 个；<br>设置如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">iptables -A INPUT -p tcp --dport 21 -s 192.168.1.0/24 -m time ! --weekdays 6,7 -m time --timestart 8:30 --timestop 18:00 -m connlimit --connlimit-above 5 -j ACCET</div></pre></td></tr></table></figure></p>
<p>3）开放本机的ssh服务给192.168.1.1-192.168.1.100 中的主机；<br>     新请求建立的速率一分钟不得超过2个；<br>    仅允许响应报文通过其服务端口离开本机；<br>设置如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">iptables -A INPUT -p tcp --dport 22 -m iprange --src-rang 192.168.1.1-192.168.1.100 -m limit --limit 2/m -j ACCEPT</div><div class="line">iptables -A OUTPUT -p tcp --sport 22 -m iprange --dst-rang 192.168.1.1-192.168.1.100 -m state --state ESTABLISHED -j ACCEPT</div></pre></td></tr></table></figure></p>
<p>4）拒绝 TCP 标志位全部为 1 及全部为 0 的报文访问本机；<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">iptables -A INPUT -p tcp --tcp-flags ALL ALL -j DROP</div></pre></td></tr></table></figure></p>
<p>5）允许本机 ping 别的主机；但不开放别的主机 ping 本机；<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">iptables -I INPUT -p icmp --icmp-type echo-request -j DROP </div><div class="line">iptables -I INPUT -p icmp --icmp-type echo-reply -j ACCEPT </div><div class="line">iptables -I INPUT -p icmp --icmp-type destination-Unreachable -j ACCEPT</div><div class="line">或者下面禁ping操作：</div><div class="line">echo 1 &gt; /proc/sys/net/ipv4/icmp_echo_ignore_all</div></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> 网络知识 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 网络知识 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[SaltStack（6）--正则匹配]]></title>
      <url>http://yoursite.com/2016/01/06/SaltStack%EF%BC%886%EF%BC%89--%E6%AD%A3%E5%88%99%E5%8C%B9%E9%85%8D/</url>
      <content type="html"><![CDATA[<p>Saltstack有多种方式匹配目标主机，支持and、or，可以混合匹配</p>
<a id="more"></a>
<h3 id="Grains匹配"><a href="#Grains匹配" class="headerlink" title="Grains匹配"></a>Grains匹配</h3><p>测试全部匹配为CentOS系统的网络联通性</p>
<p><strong>-G</strong><br>    [root@node-10 ~]# salt -G os:CentOS test.ping<br>    node-10:<br>        True<br>    node-11:<br>        True</p>
<h3 id="列表匹配"><a href="#列表匹配" class="headerlink" title="列表匹配"></a>列表匹配</h3><p><strong>-L</strong></p>
<pre><code> [root@node-10 ~]# salt -L &apos;node-10,node-11&apos; test.ping  
node-10:
    True
node-11:
    True
</code></pre><h3 id="网段-IP匹配"><a href="#网段-IP匹配" class="headerlink" title="网段/IP匹配"></a>网段/IP匹配</h3><p><strong>-S</strong></p>
<pre><code>[root@node-10 ~]# salt -S 192.168.10.0/24 test.ping  
node-10:
    True
node-11:
    True
</code></pre><p>其他还包括<code>-E(PCRE Minion id匹配)</code>、<code>-P(Grains PCRE匹配)</code>、<code>-I(Pillar glob匹配)</code>、<code>-R(Range cluster匹配)</code>、<code>-D(Minion Data匹配)</code></p>
<h3 id="minion端分组"><a href="#minion端分组" class="headerlink" title="minion端分组"></a>minion端分组</h3><p><strong>-N</strong><br>将相同minion端进行分组，利于对minion进行批量操作</p>
<p>编辑/etc/salt/master配置分组</p>
<pre><code>[root@node-10 ~]# vim /etc/salt/master
nodegroups:
  web: &apos;S@192.168.10.10&apos;
  db: &apos;S@192.168.10.0/24&apos;
</code></pre><p>进行分组操作</p>
<pre><code>[root@node-10 ~]# salt -N web test.ping
node-10:
    True
[root@node-10 ~]# salt -N db test.ping
node-11:
    True
node-10:
    True
</code></pre>]]></content>
      
        <categories>
            
            <category> Saltstack </category>
            
        </categories>
        
        
        <tags>
            
            <tag> saltstack </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[SaltStack（5）--Grains]]></title>
      <url>http://yoursite.com/2016/01/05/SaltStack%EF%BC%885%EF%BC%89--Grains/</url>
      <content type="html"><![CDATA[<p>SaltStack里的Grains功能,讲的是minion端静态变量,在master端通过Granins可以获得minion对应的变量值.</p>
<p>查看minion的全部静态变量，可以通过如下实现：</p>
<a id="more"></a>
<h3 id="查看minion的全部静态变量"><a href="#查看minion的全部静态变量" class="headerlink" title="查看minion的全部静态变量."></a>查看minion的全部静态变量.</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">root@node-10 ~]# salt &apos;node-11&apos; grains.ls</div><div class="line">node-11:</div><div class="line">    - SSDs</div><div class="line">    - biosreleasedate</div><div class="line">    - biosversion</div><div class="line">    - cpu_flags</div><div class="line">    - cpu_model</div><div class="line">    - cpuarch</div><div class="line">    - disks</div><div class="line">    - dns</div><div class="line">    - domain</div><div class="line">    - fqdn</div><div class="line">    - fqdn_ip4</div><div class="line">    - fqdn_ip6</div><div class="line">    - gid</div><div class="line">    ...</div></pre></td></tr></table></figure>
<h3 id="列出key及vlaue"><a href="#列出key及vlaue" class="headerlink" title="列出key及vlaue"></a>列出key及vlaue</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# salt &apos;node-11&apos; grains.items</div><div class="line">node-11:</div><div class="line">    ----------</div><div class="line">    SSDs:</div><div class="line">    biosreleasedate:</div><div class="line">        07/31/2013</div><div class="line">    biosversion:</div><div class="line">        6.00</div><div class="line">    cpu_flags:</div><div class="line">        - fpu</div><div class="line">        - vme</div><div class="line">        - de</div><div class="line">        - pse</div><div class="line">        - tsc</div><div class="line">        ...</div></pre></td></tr></table></figure>
<p>静态变量是成组出现的，如上只是列出了组的key（用python的思维理解）</p>
<h3 id="查看指定的key值"><a href="#查看指定的key值" class="headerlink" title="查看指定的key值"></a>查看指定的key值</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# salt &apos;node-11&apos; grains.item kernelrelease </div><div class="line">node-11:</div><div class="line">    ----------</div><div class="line">    kernelrelease:</div><div class="line">        3.10.0-123.el7.x86_64</div></pre></td></tr></table></figure>
<h3 id="自定义grains-item"><a href="#自定义grains-item" class="headerlink" title="自定义grains.item"></a>自定义grains.item</h3><h4 id="第一种方法"><a href="#第一种方法" class="headerlink" title="第一种方法"></a>第一种方法</h4><p>在minion端：<br>修改配置文件<code>/etc/salt/minion</code>  中 打开 <code>default_include: minion.d/*.conf</code><br>在<code>minion</code>端的<code>/etc/salt/minion.d/</code> 目录下新建并编辑conf文件，如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[root@node-11 ~]# cd /etc/salt/minion.d/</div><div class="line">[root@node-11 minion.d]# vim idc.conf</div><div class="line">grains:         #必须声明</div><div class="line">  idc: tang</div><div class="line">  user: tang1</div><div class="line">  </div><div class="line">[root@node-11 minion.d]# systemctl restart salt-minion</div></pre></td></tr></table></figure></p>
<p>重启salt-minion服务，在master验证：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# salt &apos;node-11&apos; grains.item idc  </div><div class="line">node-11:</div><div class="line">    ----------</div><div class="line">    idc:</div><div class="line">        tang</div></pre></td></tr></table></figure></p>
<h3 id="第二种方法"><a href="#第二种方法" class="headerlink" title="第二种方法"></a>第二种方法</h3><p>在master端添加<br>在/srv/salt/ 创建_grains目录，编写grains文件，需要返回一个字典<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">cd /srv/salt/_grains/</div><div class="line">[root@node-10 /srv/salt/_grains]# vim wlink.py</div><div class="line">def wlink():  </div><div class="line">    wlink=&#123;&#125;  </div><div class="line">    wlink[&apos;wlink&apos;]=&apos;yes&apos;  </div><div class="line">    return wlink</div></pre></td></tr></table></figure></p>
<p>执行如下命令推送到minion端：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[root@node-10 /srv/salt/_grains]# salt &apos;node-11&apos; saltutil.sync_grains  </div><div class="line">node-11:</div><div class="line">    - grains.wlink     #必须要出现这个模块，不然表示推送不成功</div></pre></td></tr></table></figure></p>
<p>master端验证：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[root@node-10 /srv/salt/_grains]# salt &apos;node-11&apos; grains.item wlink </div><div class="line">node-11:</div><div class="line">    ----------</div><div class="line">    wlink:</div><div class="line">        yes      #返回了值，表示验证成功</div></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> SaltStack </category>
            
        </categories>
        
        
        <tags>
            
            <tag> saltstack </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[SaltStack（4）--ZeroMQ]]></title>
      <url>http://yoursite.com/2016/01/04/SaltStack%EF%BC%884%EF%BC%89--ZeroMQ/</url>
      <content type="html"><![CDATA[<p> 我们进行自动化运维大多数情况下，是我们的服务器数量已经远远超过人工SSH维护的范围，SaltStack可以支数以千计，甚至更多的服务器。这些性能的提供主要来自于ZeroMQ，因为SaltStack底层是基于ZeroMQ进行高效的网络通信。ZMQ用于node与node间的通信，node可以是主机也可以是进程</p>
<a id="more"></a>
<h3 id="ZeroMQ简介"><a href="#ZeroMQ简介" class="headerlink" title="ZeroMQ简介"></a>ZeroMQ简介</h3><p>  ZeroMQ（我们通常还会用ØMQ , 0MQ, zmq等来表示）是一个简单好用的传输层，像框架一样的一个套接字库，他使得Socket编程更加简单、简洁和性能更高。它还是一个消息处理队列库，可在多个线程、内核和主机盒之间弹性伸缩。</p>
<h3 id="发布与订阅"><a href="#发布与订阅" class="headerlink" title="发布与订阅"></a>发布与订阅</h3><p>ZeroMQ支持Publish/Subscribe，即发布与订阅模式，我们经常简称Pub/Sub。<br><img src="http://static.zybuluo.com/BruceTang/ae1k8th4ke29ih6a7ygl35mk/image_1bfgv1v0qh1g1a7m1s3l1h9e1lio9.png" alt="image_1bfgv1v0qh1g1a7m1s3l1h9e1lio9.png-11.6kB"></p>
<p>Salt Master运行两个网络服务，其中一个是ZeroMQ PUB系统，默认监听4505端口。可以通过修改/etc/salt/master配置文件的publish_port参数设置。它是salt的消息发布系统，如果查看4505端口，会发现所有的Minion连接到Master的4505端口，TCP状态持续保持为ESTABLISHED。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# lsof -i:4505</div><div class="line">COMMAND    PID USER   FD   TYPE  DEVICE SIZE/OFF NODE NAME</div><div class="line">salt-mast 1109 root   14u  IPv4 2130345      0t0  TCP *:4505 (LISTEN)</div><div class="line">salt-mast 1109 root   16u  IPv4 2131887      0t0  TCP node-10:4505-&gt;node-10:37255 (ESTABLISHED)</div><div class="line">salt-mast 1109 root   17u  IPv4 2133378      0t0  TCP node-10:4505-&gt;node-11:56725 (ESTABLISHED)</div><div class="line">salt-mini 4712 root   20u  IPv4 2134221      0t0  TCP node-10:37255-&gt;node-10:4505 (ESTABLISHED)</div></pre></td></tr></table></figure></p>
<pre><code>这样Salt Master发布一个消息，所有连接到4505这个Pub端口上的Minion都会接收到这个消息。然后每个Minion会再判断自己是否需要执行这个消息。
</code></pre><h3 id="请求与响应"><a href="#请求与响应" class="headerlink" title="请求与响应"></a>请求与响应</h3><p>  Salt Master运行的第二个网络服务就是ZeroMQ REP系统，默认监听4506端口，可以通过修改/etc/salt/master配置文件的ret_port参数设置。它是salt客户端与服务端通信的端口。比如说Minion执行某个命令后的返回值就是发送给Master的4506这个REP端口<br>由于我们在最初安装了python-setproctitle软件包，所以我们可以直接看到Salt Master启动的进程的名称<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# lsof -i:4506</div><div class="line">COMMAND    PID USER   FD   TYPE  DEVICE SIZE/OFF NODE NAME</div><div class="line">salt-mast 1115 root   22u  IPv4 2129518      0t0  TCP *:4506 (LISTEN)</div></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> SaltStack </category>
            
        </categories>
        
        
        <tags>
            
            <tag> saltstack </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[SaltStack（3）--配置管理]]></title>
      <url>http://yoursite.com/2016/01/03/SaltStack%EF%BC%883%EF%BC%89--%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/</url>
      <content type="html"><![CDATA[<h3 id="YAML编写技巧"><a href="#YAML编写技巧" class="headerlink" title="YAML编写技巧"></a>YAML编写技巧</h3><p>刚接触Sal tStack的状态管理，最苦恼的可能就是SLS的编写了，尽管YAML语法可能第一眼看上去很简洁，但是真正写起来也是令人畏惧，初学者很容易被各种报错搞晕，降低对Sal tStack的学习乐趣，甚至放弃SaltStack，但是只要记住三个非常简单的规则就可以快乐地使用YAML语法编写SLS文件了。</p>
<a id="more"></a>
<h4 id="规则一：缩进"><a href="#规则一：缩进" class="headerlink" title="规则一：缩进"></a>规则一：缩进</h4><p>YAML使用一个固定的缩进风格表示数据层级结构关系。SaltStack需要每个缩进级别由两个空格组成。注意：不要使用tabs，缩进是初学者总容易出错的地方之一。</p>
<p><strong>提示：</strong> 2个空格，不能使用tab键</p>
<h4 id="规则二：冒号"><a href="#规则二：冒号" class="headerlink" title="规则二：冒号"></a>规则二：冒号</h4><p>Python的字典是简单的键值对，其他语言的用户也应该知道这个数据类型叫哈希表或者关联数组。字典的key在YAML中的表现形式是一个以冒号结尾的字符串：</p>
<p><strong>提示：</strong> 冒号后面有空格<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">my_key: my_value</div></pre></td></tr></table></figure></p>
<h4 id="规则三：短横杠"><a href="#规则三：短横杠" class="headerlink" title="规则三：短横杠"></a>规则三：短横杠</h4><p>想要表示列表项，使用一个短横杠加一个空格。多个项使用同样的缩进级别作为同一列表的一<br>部分。</p>
<p><strong>提示：</strong> 短横线后面有空格</p>
<h3 id="state状态模块"><a href="#state状态模块" class="headerlink" title="state状态模块"></a>state状态模块</h3><h4 id="state功能"><a href="#state功能" class="headerlink" title="state功能"></a>state功能</h4><p>state是Saltstack最核心的功能，通过预先定制好的sls（salt state file）文件对被控制主机进行状态管理，支持包括程序包（pkg）、文件（file）、网络配置（network）、系统服务（service）、系统用户（user）等</p>
<h4 id="设置file-roots"><a href="#设置file-roots" class="headerlink" title="设置file_roots"></a>设置file_roots</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# vim /etc/salt/master</div><div class="line">file_roots:           #file_root: 需定格</div><div class="line">  base:               #base前面两个空格</div><div class="line">    - /srv/salt       #-前面四个空格，后面一个空格</div><div class="line">                      #这三行去掉前面的#即可，使用默认的配置路径</div><div class="line">                      </div><div class="line">[root@node-10 ~]# systemctl restart salt-master</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">在这里有个特别需要我们注意的问题，一定要确保file_roots前面没有空格，而base前两个空格-前面四个空格，在salt的配置里面空格十分重要，我们必须高度注意，否则及其容易造成实验不成功，之所以对空格敏感主要salt基于Python开发，并采用了yaml的语法.（注意注意注意，不要使用tab键）</div><div class="line">有必要解释下相关配置内容:</div><div class="line">base:代表环境（默认必须有），可就是说salt可以同时管理多个环境，比如测试、开发、生产等环境。其实从我们修改的行上方不难我们不难看出，salt拥有针对多环境的特点。至于底下的小- 则代表状态文件存放路径，可能有些同学对这个状态文件有些疑惑，我们拿软件安装来讲，我们想要批量安装，环境标准化。我们总得告诉系统，我们要安装什么，怎么安装。这时候我们就需要一个文件为系统指明，这个文件就是上面的状态文件。要注意-和后面的路径有中间有一个空格哦</div></pre></td></tr></table></figure>
<h4 id="创建相应的目录"><a href="#创建相应的目录" class="headerlink" title="创建相应的目录"></a>创建相应的目录</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# mkdir /srv/salt -p</div><div class="line">[root@node-10 ~]# cd /srv/salt/</div></pre></td></tr></table></figure>
<h4 id="设置top-sls"><a href="#设置top-sls" class="headerlink" title="设置top.sls"></a>设置top.sls</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">在top.sls入口文件设置环境（如生产、开发、测试对应不同的minion和模块）。</div><div class="line">[root@node-10 ~]# vim /srv/salt/top.sls</div><div class="line">base:</div><div class="line">  &apos;*&apos;:</div><div class="line">   - nginx</div><div class="line"></div><div class="line">解释：所有的Minion均执行base目录下的init模块下的pkg-init.sls。我们可以把很多的sls放在一个目录中，方便管理。在top.sls只需要指定目录结构即可。</div></pre></td></tr></table></figure>
<h4 id="编写状态文件"><a href="#编写状态文件" class="headerlink" title="编写状态文件"></a>编写状态文件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">[root@node-10 web]# vim nginx.sls </div><div class="line">nginx-install:     #state名称：nginx-install</div><div class="line">  pkg.installed:   #管理对象类型：pkg，需要执行的方法installed</div><div class="line">    - names:       #管理对象名称</div><div class="line">      - nginx      #名称：nginx</div><div class="line"></div><div class="line">nginx-service:  #管理对象类型：nginx-service，管理系统守护进程</div><div class="line">  service.running:  #service要执行的方法：running，</div><div class="line">    - name: nginx     #管理对象名称：nginx</div><div class="line">    - enable: True    #管理对象的状态，</div><div class="line">    </div><div class="line">提示：注意格式</div></pre></td></tr></table></figure>
<h3 id="执行状态"><a href="#执行状态" class="headerlink" title="执行状态"></a>执行状态</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div></pre></td><td class="code"><pre><div class="line">[root@node-10 web]# salt &apos;*&apos; state.sls web.nginx</div><div class="line">node-11:</div><div class="line">----------</div><div class="line">          ID: nginx-install</div><div class="line">    Function: pkg.installed</div><div class="line">        Name: nginx</div><div class="line">      Result: True</div><div class="line">     Comment: Package nginx is already installed</div><div class="line">     Started: 23:32:40.788400</div><div class="line">    Duration: 533.65 ms</div><div class="line">     Changes:   </div><div class="line">----------</div><div class="line">          ID: nginx-service</div><div class="line">    Function: service.running</div><div class="line">        Name: nginx</div><div class="line">      Result: True</div><div class="line">     Comment: The service nginx is already running</div><div class="line">     Started: 23:32:41.322820</div><div class="line">    Duration: 47.314 ms</div><div class="line">     Changes: </div><div class="line">Summary for node-11</div><div class="line">------------</div><div class="line">Succeeded: 2</div><div class="line">Failed:    0</div><div class="line">------------</div><div class="line">Total states run:     2</div><div class="line">Total run time: 580.964 ms</div><div class="line">node-10:</div><div class="line">----------</div><div class="line">          ID: nginx-install</div><div class="line">    Function: pkg.installed</div><div class="line">        Name: nginx</div><div class="line">      Result: True</div><div class="line">     Comment: Package nginx is already installed</div><div class="line">     Started: 21:53:53.713711</div><div class="line">    Duration: 530.331 ms</div><div class="line">     Changes:   </div><div class="line">----------</div><div class="line">          ID: nginx-service</div><div class="line">    Function: service.running</div><div class="line">        Name: nginx</div><div class="line">      Result: True</div><div class="line">     Comment: The service nginx is already running</div><div class="line">     Started: 21:53:54.244788</div><div class="line">    Duration: 49.855 ms</div><div class="line">     Changes:   </div><div class="line"></div><div class="line">Summary for node-10</div><div class="line">------------</div><div class="line">Succeeded: 2</div><div class="line">Failed:    0</div><div class="line">------------</div><div class="line">Total states run:     2</div><div class="line">Total run time: 580.186 ms</div></pre></td></tr></table></figure>
<p>实际master执行这个nginx.sls模块是将nginx.sls模块发送给minion之后，在minion上执行的<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">[root@node-11 ~]# cat /var/cache/salt/minion/files/base/web/nginx.sls </div><div class="line">nginx-install:</div><div class="line">  pkg.installed:</div><div class="line">    - names:</div><div class="line">      - nginx</div><div class="line"></div><div class="line">nginx-service:</div><div class="line">  service.running:</div><div class="line">    - name: nginx</div><div class="line">    - enable: True</div></pre></td></tr></table></figure></p>
<h4 id="top-sls高级执行状态"><a href="#top-sls高级执行状态" class="headerlink" title="top.sls高级执行状态"></a>top.sls高级执行状态</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# cd /srv/salt/</div><div class="line">[root@node-10 salt]# vim top.sls </div><div class="line">base:</div><div class="line">  &apos;node-10&apos;:</div><div class="line">    - web.nginx</div><div class="line">  &apos;node-11&apos;:</div><div class="line">    - web.nginx</div><div class="line">    </div><div class="line"></div><div class="line">[root@node-10 salt]# salt &apos;*&apos; state.highstate </div><div class="line">node-10:</div><div class="line">----------</div><div class="line">          ID: nginx-install</div><div class="line">    Function: pkg.installed</div><div class="line">        Name: nginx</div><div class="line">      Result: True</div><div class="line">     Comment: Package nginx is already installed</div><div class="line">     Started: 22:16:45.084148</div><div class="line">    Duration: 471.103 ms</div><div class="line">     Changes:   </div><div class="line">----------</div><div class="line">          ID: nginx-service</div><div class="line">    Function: service.running</div><div class="line">        Name: nginx</div><div class="line">      Result: True</div><div class="line">      ...</div><div class="line">      </div><div class="line">      </div><div class="line">在执行状态模块之前可以先测试执行，以免执行出错</div><div class="line">[root@node-10 salt]# salt &apos;*&apos; state.highstate test=True</div></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> SaltStack </category>
            
        </categories>
        
        
        <tags>
            
            <tag> saltstack </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[SaltStack（2）--远程执行]]></title>
      <url>http://yoursite.com/2016/01/02/SaltStack%EF%BC%882%EF%BC%89--%E8%BF%9C%E7%A8%8B%E6%89%A7%E8%A1%8C/</url>
      <content type="html"><![CDATA[<h3 id="软件依赖要求"><a href="#软件依赖要求" class="headerlink" title="软件依赖要求"></a>软件依赖要求</h3><ol>
<li>Python版本要求Python版本大于2.6小于3.0</li>
<li>msgpack-python: Saltstack消息交换库</li>
<li>YAML: Saltstack配置解析定义语法</li>
<li>jinja2: Saltstack states配置模板</li>
<li>MarkupSafe: Python unicode转换库</li>
<li>apache-libcloud: Saltstack对云架构编排库</li>
<li>Requests HTTP Python库</li>
<li>Zero MQ: Saltstack消息系统</li>
<li>pyzmq: ZeroMQ Python库</li>
<li>PyCrypto: Python 密码库</li>
<li>M2Crypto: Openssl Python包装库</li>
</ol>
<a id="more"></a>
<h3 id="安装系统环境"><a href="#安装系统环境" class="headerlink" title="安装系统环境"></a>安装系统环境</h3><p>操作系统：centos7 x86_64<br>主机1：IP：192.168.10.10<br>主机名：node-10</p>
<p>主机2：IP: 192.168.10.11<br>主机名：node-11</p>
<h3 id="安装说明"><a href="#安装说明" class="headerlink" title="安装说明"></a>安装说明</h3><p>1.在主机192.168.10.10上安装salt-master 和salt-minion<br>2.主机192.168.10.11上安装salt-minion</p>
<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><h4 id="具体过程"><a href="#具体过程" class="headerlink" title="具体过程"></a>具体过程</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# yum install https://repo.saltstack.com/yum/redhat/salt-repo-latest-1.el7.noarch.rpm -y</div><div class="line">[root@node-10 ~]# yum install -y salt-master salt-minion</div><div class="line">[root@node-11 ~]# yum install -y salt-minion</div><div class="line">[root@node-10 ~]# systemctl start salt-master</div></pre></td></tr></table></figure>
<h3 id="SaltStack配置"><a href="#SaltStack配置" class="headerlink" title="SaltStack配置"></a>SaltStack配置</h3><h4 id="修改master配置文件"><a href="#修改master配置文件" class="headerlink" title="修改master配置文件"></a>修改master配置文件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]#  vim /etc/salt/master</div><div class="line">interface: 129.168.10.10    #服务端ip.</div><div class="line"></div><div class="line">[root@node-10 ~]# systemctl start salt-master</div></pre></td></tr></table></figure>
<h4 id="修改被minion端"><a href="#修改被minion端" class="headerlink" title="修改被minion端"></a>修改被minion端</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# vim /etc/salt/minion</div><div class="line">master: 192.168.10.10   #master的主机名或ip. IP地址后面有一个空格</div><div class="line">id:node-10     #本机标识符,默认为主机名</div><div class="line"></div><div class="line">[root@node-10 ~]# systemctl start salt-minion</div></pre></td></tr></table></figure>
<h4 id="日志文件默认路径"><a href="#日志文件默认路径" class="headerlink" title="日志文件默认路径"></a>日志文件默认路径</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# tailf /var/log/salt/master</div><div class="line">[root@node-10 ~]# tailf /var/log/salt/minion</div></pre></td></tr></table></figure>
<h4 id="接受minion的托管请求"><a href="#接受minion的托管请求" class="headerlink" title="接受minion的托管请求"></a>接受minion的托管请求</h4><p>minion向master投诚后, 还需要master接受才行. 这个过程叫做”授信”<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# salt-key -L</div><div class="line">Accepted Keys:</div><div class="line">Denied Keys:</div><div class="line">Unaccepted Keys:</div><div class="line">node-10</div><div class="line">Rejected Keys:</div></pre></td></tr></table></figure></p>
<p>命令说明：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">salt-key -L #查看当前所有证书情况</div><div class="line">salt-key -A -y  # -A 是接受所有等待认证的key </div><div class="line">  -l ARG, --list=ARG #显示指定状态的key(支持正则表达式)</div><div class="line">  -L， --list-all  #显示所有public keys</div><div class="line">  -a ACCEPT, --accept=ACCEPT #接受指定等待认证的key(支持正则表达式)</div><div class="line">  -A, --accept-all  #接受所欲等待认证得key</div><div class="line">  -r REJECT, --reject=REJECT  #拒绝指定的等待认证的key（支持正则）</div><div class="line">  -R， --reject-all  #拒绝所有等待认证的key</div><div class="line">  -d DELETE, --delete=DELETE #删除指定key</div><div class="line">  -D, --delete-all  #删除所欲key</div><div class="line">  -f FINGER, --finger=FINGER #删除指定key</div><div class="line">  -F, --finger-all  #删除所有key</div></pre></td></tr></table></figure></p>
<p>其中Unaccepted Keys是未许可的minion. 可使用下面的命令通过认证<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# salt-key -a node-10</div><div class="line">The following keys are going to be accepted:</div><div class="line">Unaccepted Keys:</div><div class="line">node-10</div><div class="line">Proceed? [n/Y] y</div><div class="line">Key for minion node-10 accepted.</div><div class="line"></div><div class="line">[root@node-10 ~]# salt-key -L</div><div class="line">Accepted Keys:    #已许可的minion</div><div class="line">node-10</div><div class="line">Denied Keys:</div><div class="line">Unaccepted Keys:</div><div class="line">Rejected Keys:</div></pre></td></tr></table></figure></p>
<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><h4 id="基本操作命令通用格式"><a href="#基本操作命令通用格式" class="headerlink" title="基本操作命令通用格式"></a>基本操作命令通用格式</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">格式: 命令  对象   执行模块         参数</div><div class="line">salt    ‘*’      cmd.run      “ping -c 4 www.baidu.com&quot;</div></pre></td></tr></table></figure>
<h4 id="测试连通性"><a href="#测试连通性" class="headerlink" title="测试连通性"></a>测试连通性</h4><p>安装配置好之后, 首先要测试一下连通性, salt会列出每个认证过的minion连通状态(true或false).<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[root@node-10 ~]# salt &apos;*&apos; test.ping</div><div class="line">[root@node-10 minions_pre]# salt &apos;*&apos; test.ping</div><div class="line">node-10:</div><div class="line">    True</div><div class="line">node-11:</div><div class="line">    True</div></pre></td></tr></table></figure></p>
<h4 id="远程执行"><a href="#远程执行" class="headerlink" title="远程执行"></a>远程执行</h4><p>模块：  `cmd.run<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[root@node-10 minions_pre]# salt &apos;*&apos; cmd.run &apos;/etc/init.d/network restart &apos;</div><div class="line">node-11:</div><div class="line">    Restarting network (via systemctl):  [  OK  ]</div><div class="line">node-10:</div><div class="line">    Restarting network (via systemctl):  [  OK  ]</div></pre></td></tr></table></figure></p>
<h4 id="批量查看系统时间"><a href="#批量查看系统时间" class="headerlink" title="批量查看系统时间"></a>批量查看系统时间</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[root@node-10 minions_pre]# salt &apos;*&apos; cmd.run &quot;uptime&quot;</div><div class="line">node-11:</div><div class="line">     19:42:12 up  3:28,  1 user,  load average: 0.00, 0.01, 0.05</div><div class="line">node-10:</div><div class="line">     18:03:25 up 1 day, 13:03,  2 users,  load average: 0.02, 0.06, 0.10</div></pre></td></tr></table></figure>
<p><strong>注意:</strong><br>默认情况下<code>master</code>和<code>minion</code>之间使用以下端口进行通信:<br><code>4505(publish_port)</code>：salt的消息发布系统<br><code>4506(ret_port)</code>：salt客户端与服务端通信的端口<br><code>cmd.run</code> 为模块,又称之为<code>超级命令</code>. 可以执行Linux中的任何命令.</p>
]]></content>
      
        <categories>
            
            <category> SaltStack </category>
            
        </categories>
        
        
        <tags>
            
            <tag> saltstack </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[SaltStack（1）--简介]]></title>
      <url>http://yoursite.com/2016/01/01/SaltStack%EF%BC%881%EF%BC%89--%E7%AE%80%E4%BB%8B/</url>
      <content type="html"><![CDATA[<h3 id="SaltStack简单说明"><a href="#SaltStack简单说明" class="headerlink" title="SaltStack简单说明"></a>SaltStack简单说明</h3><p>一个配置管理系统，能够维护预定义状态的远程节点(比如，确保指定的报被安装，指定的服务在运行)<br>一个分布式远程执行系统，用来在远程节点（可以是单个节点，也可以是任意规则挑选出来的节点）上执行命令和查询数据<br>开发其的目的是为远程执行提供最好的解决方案，并使远程执行变得更好，更快，更简单</p>
<a id="more"></a>
<h3 id="Salt的核心功能"><a href="#Salt的核心功能" class="headerlink" title="Salt的核心功能"></a>Salt的核心功能</h3><p>1.使命令发送到远程系统是并行的而不是串行的<br>2.使用安全加密的协议<br>3.使用最小最快的网络载荷<br>4.提供简单的编程接口<br>5.Salt同样引入了更加细致化的领域控制系统来远程执行，使得系统成为目标不止可以通过主机名，还可以通过系统属性。</p>
<h3 id="Builds-on-proven-technology"><a href="#Builds-on-proven-technology" class="headerlink" title="Builds on proven technology"></a>Builds on proven technology</h3><p>   为了允许简单的扩展，Salt执行程序可以写为纯Python模块。数据从Salt执行过程中收集到可以发送回master服务端，或者发送到任何<br>任意程序。Salt可以从一个简单的Python<br>API调用，或者从命令行被调用，所以Salt可以用来执行一次性命令，也可以作为一个更大的应用程序的一个组成部分。</p>
<h3 id="Python客户端接口"><a href="#Python客户端接口" class="headerlink" title="Python客户端接口"></a>Python客户端接口</h3><p>为了允许简单的扩展，Salt执行程序可以写为纯Python模块。数据从Salt执行过程中收集到可以发送回master服务端，或者发送到任何<br>任意程序。Salt可以从一个简单的Python<br>API调用，或者从命令行被调用，所以Salt可以用来执行一次性命令，也可以作为一个更大的应用程序的一个组成部分。</p>
<h3 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h3><p><strong>快速，灵活，易扩展</strong><br>结果是能够在1台或多台目标机器上快速执行命令的系统。Salt运行快速，安装简单，高度可定制；Salt用相同的远程执行架构满足管理不同数量服务器的需求。<br>Salt基础设施可以集成最好的远程执行工具，增强了Salt的能力及用途，得到功能丰富实用可以适用于任何网络的系统</p>
<h3 id="Salt-三大功能"><a href="#Salt-三大功能" class="headerlink" title="Salt 三大功能"></a>Salt 三大功能</h3><p>A、远程执行<br>B、配置管理（状态，不可以回滚，需要谨慎操作）<br>C、云管理</p>
<h3 id="Salt竞争对手"><a href="#Salt竞争对手" class="headerlink" title="Salt竞争对手"></a>Salt竞争对手</h3><p>Pupper （需要ruby，不支持远程执行）+func使用ansible （Python）</p>
<h3 id="四种运行方式"><a href="#四种运行方式" class="headerlink" title="四种运行方式"></a>四种运行方式</h3><p>1.Local 本地模式<br>2.Minion/Master  C/S架构（客户端/服务器 ）<br>3.Syndic -Zabbix proxy  代理模式<br>4.Salt   SSHSSH模式</p>
<p>注意：最好使用Minion/Master模式来运行，一般大公司都是使用这种模式</p>
]]></content>
      
        <categories>
            
            <category> SaltStack </category>
            
        </categories>
        
        
        <tags>
            
            <tag> saltstack </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[LVM常规操作记录梳理]]></title>
      <url>http://yoursite.com/2015/05/11/LVM%E5%B8%B8%E8%A7%84%E6%93%8D%E4%BD%9C%E8%AE%B0%E5%BD%95%E6%A2%B3%E7%90%86/</url>
      <content type="html"><![CDATA[<h3 id="基本介绍"><a href="#基本介绍" class="headerlink" title="基本介绍"></a>基本介绍</h3><p>Linux用户安装Linux 操作系统时遇到的一个最常见的难以决定的问题就是如何正确地给评估各分区大小，以分配合适的硬盘空间。随着 Linux的逻辑盘卷管理功能的出现，这些问题都迎刃而解，<br>lvm是逻辑盘卷管理（Logical Volume Manager）的简称，它是 Linux环境下对磁盘分区进行管理的一种机制， LVM是建立在硬盘和分区之上的一个逻辑层，来提高磁盘分区管理的灵活性。</p>
<a id="more"></a>
<h3 id="LVM基本术语"><a href="#LVM基本术语" class="headerlink" title="LVM基本术语"></a>LVM基本术语</h3><p>1）物理存储介质：这里指系统的存储设备：硬盘，如： /dev/hda、/dev/sda等等，是存储系统最低层的存储单元。<br>2）物理卷physical volume （PV ）<br>物理卷就是指硬盘分区或从逻辑上与磁盘分区具有同样功能的设备(如 RAID)，是 LVM的基本存储逻辑块<br>3）卷组Volume Group （VG ）<br>LVM卷组由一个或多个物理卷组成，但是更确切的说，它包含由这些物理卷提供的许多PE。<br>4）逻辑卷logical volume （LV ）<br>这里是我们存储信息的地方，在逻辑卷之上可以建立文件系统 (比如/home或者 /usr等)。<br>5）PE（physical extent ）<br>每一个物理卷被划分为称为 PE的基本单元，具有唯一编号的 PE是可以被 LVM寻址的最小单元。 PE的大小是可配置的，默认为 4MB。</p>
<h3 id="具体操作"><a href="#具体操作" class="headerlink" title="具体操作"></a>具体操作</h3><h4 id="创建一个分区"><a href="#创建一个分区" class="headerlink" title="创建一个分区"></a>创建一个分区</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">[root@test-server ~]# fdisk -l             // 查看磁盘情况 </div><div class="line">[root@test-server ~]# fdisk /dev/sda            // 进入磁盘（可以依次按键p-&gt;n-&gt;e-&gt;回车-&gt;回车-&gt;w，即用此磁盘所有空闲空间创建分区）</div><div class="line">Command (m for help): n                        //n 为添加一个分区， p查看分区 </div><div class="line">First cylinder (2898-10443, default 2898):         // 按Enter 键决定</div><div class="line">Using default value 2898                               // 起始柱面选择默认值 </div><div class="line">Last cylinder or +size or +sizeM or +sizeK (289810443, default 10443): +2G             // 给2G的大小 </div><div class="line">Command (m for help): t       // 更改分区类型</div><div class="line">Partition number (1-5): 5        // 选着分区</div><div class="line">Hex code (type L to list codes): l       // 分区类型列表</div><div class="line"></div><div class="line">Hex code (type L to list codes):8e        //将新添加的分区标注成 lvm </div><div class="line">Command (m for help): p              // 查看分区表</div><div class="line">/dev/sda5 2756 2999 1959898+ 8e Linux LVM </div><div class="line">Command (m for help): w        // 保存</div><div class="line">[root@test-server ~]# partprobe /dev/sda            // 系统识别分区（代替重启） </div><div class="line">[root@test-server ~]# mkfs.ext4 /dev/sda5           // 格式化新添加的分区</div></pre></td></tr></table></figure>
<h4 id="PV的创建"><a href="#PV的创建" class="headerlink" title="PV的创建"></a>PV的创建</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[root@test-server ~]# pvcreate /dev/sda5 // 创建pv </div><div class="line">Writing physical volume data to disk &quot;/dev/sda5&quot; </div><div class="line">Physical volume &quot;/dev/sda5&quot; successfully created </div><div class="line">[root@test-server ~]# pvs                    //或pvdisplay,查看当前pv的信息 </div><div class="line">PV VG Fmt Attr PSize PFree </div><div class="line">/dev/sda5 lvm2 a-- 1.87G 1.87G</div></pre></td></tr></table></figure>
<h4 id="VG的创建"><a href="#VG的创建" class="headerlink" title="VG的创建"></a>VG的创建</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[root@test-server ~]# vgcreate vg0 /dev/sda5           //vg0 为当前vg的名 </div><div class="line">Volume group &quot;vg0&quot; successfully created </div><div class="line">[root@test-server ~]# vgs              //或vgdispaly,查看vg 的信息</div><div class="line">VG #PV #LV #SN Attr VSize VFree </div><div class="line">vg0 1 0 0 wz--n- 1.87G 1.87G</div></pre></td></tr></table></figure>
<h4 id="lvm的创建"><a href="#lvm的创建" class="headerlink" title="lvm的创建"></a>lvm的创建</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">#lvcreate -L 大小 -n 名字 隶属哪一个巻组</div><div class="line">#lvcreate -l PE个数 -n 名字 隶属哪一个巻组 </div><div class="line">[root@test-server ~]# lvcreate -L +500M -n lv01 vg0 </div><div class="line">Logical volume &quot;lv01&quot; created </div><div class="line">[root@test-server ~]# lvs                              //或lvdispaly,查看lv 的信息</div><div class="line">LV VG Attr LSize Origin Snap% Move Log Copy% Convert </div><div class="line">lv01 vg0 -wi-a- 500.00M </div><div class="line">You have mail in /var/spool/mail/root</div><div class="line">[root@test-server ~]# mkfs.ext4 /dev/vg0/lv01 //格式化</div></pre></td></tr></table></figure>
<h4 id="lvm的使用"><a href="#lvm的使用" class="headerlink" title="lvm的使用"></a>lvm的使用</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[root@test-server ~]# mkdir /mnt/lv01      //建立挂在目录 </div><div class="line">[root@test-server ~]# mount /dev/vg0/lv01 /mnt/lv01          //将制作的lvm挂载起来 </div><div class="line">[root@test-server ~]# df -h</div><div class="line">[root@test-server ~]# touch /mnt/lv01/lv.file </div><div class="line">[root@test-server ~]#ls /mnt/lv01</div></pre></td></tr></table></figure>
<h3 id="lvm的增大"><a href="#lvm的增大" class="headerlink" title="lvm的增大"></a>lvm的增大</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[root@test-server ~]# lvextend -L +300M /dev/vg0/lv01      //原来lv大小500M ，拉伸分区到 800M。前提是vg0里面还有剩余空间（vgdispaly查看Free PE）。如没有剩余，需要vgextend扩建。</div><div class="line">Logical volume lv01 successfully resized </div><div class="line">[root@test-server ~]# resize2fs /dev/vg0/lv01           //拉伸文件系统</div><div class="line">[root@test-server ~]# lvs</div><div class="line">LV VG Attr LSize Origin Snap% Move Log Copy% Convert </div><div class="line">lv01 vg0 -wi-ao 800.00M                   //大小变成了 800M</div></pre></td></tr></table></figure>
<h3 id="lvm的减小"><a href="#lvm的减小" class="headerlink" title="lvm的减小"></a>lvm的减小</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">[root@test-server ~]# umount /dev/vg0/lv01               //卸载逻辑卷 /dev/vg0/lv01，或者卸载/mnt/lv01目录也可以</div><div class="line">[root@test-server ~]# df -h              //查看 </div><div class="line">[root@test-server ~]# e2fsck -f /dev/vg0/lv01                // 磁盘校验 </div><div class="line">[root@test-server ~]# resize2fs /dev/vg0/lv01 500M              //回缩文件系统到 500M </div><div class="line">[root@test-server ~]# lvreduce -L 500M /dev/vg0/lv01           //回缩分区到 500M </div><div class="line">WARNING: Reducing active logical volume to 500.00 MB </div><div class="line">THIS MAY DESTROY YOUR DATA (filesystem etc.) </div><div class="line">Do you really want to reduce lv01? [y/n]: y </div><div class="line">[root@test-server ~]# lvs </div><div class="line">LV VG Attr LSize Origin Snap% Move Log Copy% Convert </div><div class="line">lv01 vg0 -wi-a- 500.00M           //此时已变成500M大小</div><div class="line">[root@test-server ~]# mount /dev/vg0/lv01 /mnt/lv01        //重新挂载分区 </div><div class="line">[root@test-server ~]# df -h           //查看 </div><div class="line">[root@test-server ~]# ls /mnt/lv01         //查看文件</div><div class="line"></div><div class="line"></div><div class="line">特别注意的是：</div><div class="line">resize2fs命令         针对的是ext2、ext3、ext4文件系统。</div><div class="line">xfs_growfs命令      针对的是xfs文件系统</div></pre></td></tr></table></figure>
<h3 id="lvm的系统快照"><a href="#lvm的系统快照" class="headerlink" title="lvm的系统快照"></a>lvm的系统快照</h3><p>原理：系统快照（snapshot）是 lvm的另外一种重要的功能，快照就是将当时的数据记录下来，就好像照相记录一样，以后数据有任何改动，原数据会被移动到快照区，没有被改变的区域则由快照区与文件系统共享。<br>由于快照区和原本的 LV共享很多 PE，所以快照区与被快照的区域必须在同一个 VG上<br>操作：<br>以上面创建的 lv01为例 </p>
<h4 id="挂载lvm"><a href="#挂载lvm" class="headerlink" title="挂载lvm"></a>挂载lvm</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[root@test-server ~]# mount /dev/vg0/lv01 /mnt/lv01 </div><div class="line">[root@test-server ~]# cd /mnt/lv01</div><div class="line">[root@test-server lv01]# touch &#123;a,b,c&#125;&#123;a,b,c&#125;</div><div class="line">[root@test-server lv01]# ls</div><div class="line">aa ab ac ba bb bc ca cb cc lost+found lv.file restoresymtable</div></pre></td></tr></table></figure>
<h4 id="为lvm创建快照"><a href="#为lvm创建快照" class="headerlink" title="为lvm创建快照"></a>为lvm创建快照</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[root@test-server lv01]# lvcreate -L 64M -s -n lv-backup /dev/vg0/lv01 </div><div class="line">Logical volume &quot;lv-backup&quot; create</div></pre></td></tr></table></figure>
<h4 id="挂载快照"><a href="#挂载快照" class="headerlink" title="挂载快照"></a>挂载快照</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[root@test-server lv01]# mkdir /mnt/lv-backup</div><div class="line">[root@test-server mnt]# mount -o ro /dev/vg0/lv-backup /mnt/lv-backup/</div></pre></td></tr></table></figure>
<h4 id="备份快照"><a href="#备份快照" class="headerlink" title="备份快照"></a>备份快照</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[root@test-server tmp]# dump -0u -f /tmp/lv-backup.dump /mnt/lv-backup/                  //备份</div><div class="line">DUMP: Date of this level 0 dump: Sun Nov 11 14:53:31 2012 </div><div class="line">DUMP: Dumping /dev/mapper/vg0-lv--backup (/mnt/lv-backup) to /tmp/lv-backup.dump</div></pre></td></tr></table></figure>
<h4 id="删除快照"><a href="#删除快照" class="headerlink" title="删除快照"></a>删除快照</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@test-server tmp]# umount /mnt/lv-backup/ </div><div class="line">[root@test-server tmp]# lvremove /dev/vg0/lv-backup </div><div class="line">Do you really want to remove active logical volume lv-backup? [y/n]: y </div><div class="line">Logical volume &quot;lv-backup&quot; successfully removed</div></pre></td></tr></table></figure>
<h4 id="清空-dev-vg0-lv01下内容"><a href="#清空-dev-vg0-lv01下内容" class="headerlink" title="清空/dev/vg0/lv01下内容"></a>清空/dev/vg0/lv01下内容</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[root@test-server tmp]# umount /mnt/lv01</div><div class="line">[root@test-server tmp]# mkfs.ext3 /dev/vg0/lv01 </div><div class="line">mke2fs 1.39 (29-May-2006)</div><div class="line">Filesystem label=</div><div class="line">OS type: Linux</div></pre></td></tr></table></figure>
<h4 id="恢复数据"><a href="#恢复数据" class="headerlink" title="恢复数据"></a>恢复数据</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[root@test-server tmp]# mount /dev/vg0/lv01 /mnt/lv01 </div><div class="line">[root@test-server tmp]# cd /mnt/lv01</div><div class="line">[root@test-server lv01]# ls</div><div class="line">lost+found</div><div class="line">[root@test-server lv01]# restore -rf /tmp/lv-backup.dump           //恢复</div><div class="line">restore: ./lost+found: File exists</div><div class="line">[root@test-server lv01]# ls               //由于之前都删除了，所以这些都是改变的部分 </div><div class="line">aa ab ac ba bb bc ca cb cc lost+found lv.file restoresymtable</div></pre></td></tr></table></figure>
<h3 id="lvm的关闭"><a href="#lvm的关闭" class="headerlink" title="lvm的关闭"></a>lvm的关闭</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">[root@test-server ~]# umount /mnt/lv01</div><div class="line">[root@test-server ~]# lvremove /dev/vg0/lv01        //删除lv </div><div class="line">Do you really want to remove active logical volume lv01? [y/n]: y </div><div class="line">Logical volume &quot;lv01&quot; successfully removed </div><div class="line">[root@test-server ~]# vgchange -a n vg0             //使vg0不具有 active标志 </div><div class="line">0 logical volume(s) in volume group &quot;vg0&quot; now active </div><div class="line">[root@test-server ~]# vgremove vg0            //删除vg </div><div class="line">Volume group &quot;vg0&quot; successfully removed </div><div class="line">[root@test-server ~]# pvremove /dev/sda5           //删除pv </div><div class="line">Labels on physical volume &quot;/dev/sda5&quot; successfully wiped</div></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> Linux基础 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux基础 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Nginx 伪静态设置]]></title>
      <url>http://yoursite.com/2015/04/11/Nginx%20%E4%BC%AA%E9%9D%99%E6%80%81%E8%AE%BE%E7%BD%AE/</url>
      <content type="html"><![CDATA[<p>  伪静态是一种可以把文件后缀改成任何可能的一种方法，如果我想把php文件伪静态成html文件，这种相当简单的，下面来介绍nginx 伪静态配置方法有需要了解的朋友可参考</p>
<p>nginx只需要打开nginx.conf配置文件，在server里面写需要的规则即可。</p>
<a id="more"></a>
<p>示例配置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">cat nginx.conf</div><div class="line"></div><div class="line">server &#123;</div><div class="line">listen 80;</div><div class="line">server_name localhost;</div><div class="line"></div><div class="line">location / &#123;</div><div class="line">root /usr/local/nginx-1.10/html/bbs;</div><div class="line">index index.html index.htm;</div><div class="line">ssi on;</div><div class="line">ssi_silent_errors on;</div><div class="line">ssi_types text/shtml;</div><div class="line">if (!-e $request_filename)&#123;</div><div class="line">rewrite ^(.*)$ /$1.html last;</div><div class="line">break;</div><div class="line">&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> nginx </category>
            
        </categories>
        
        
        <tags>
            
            <tag> nginx </tag>
            
        </tags>
        
    </entry>
    
  
  
</search>
